{"paperId": "7b6a8c6d44e0f77bf930484e438d77b7465a69fb", "year": 2023, "title": "Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning", "authors": "David Baidoo-Anu, Leticia Owusu Ansah", "venue": "Social Science Research Network", "citationCount": 1998, "abstract": "Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool \u23bcChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students\u2019 learning.", "isOpenAccess": false, "url": ""}
{"paperId": "f22d71c7ce9720ba1f717a4f1181488200e78198", "year": 2023, "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day", "authors": "Chunyuan Li, Cliff Wong, Sheng Zhang, N. Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, Jianfeng Gao", "venue": "Neural Information Processing Systems", "citationCount": 1290, "abstract": "Conversational generative AI has demonstrated remarkable promise for empowering biomedical practitioners, but current investigations focus on unimodal text. Multimodal conversational AI has seen rapid progress by leveraging billions of image-text pairs from the public web, but such general-domain vision-language models still lack sophistication in understanding and conversing about biomedical images. In this paper, we propose a cost-efficient approach for training a vision-language conversational assistant that can answer open-ended research questions of biomedical images. The key idea is to leverage a large-scale, broad-coverage biomedical figure-caption dataset extracted from PubMed Central, use GPT-4 to self-instruct open-ended instruction-following data from the captions, and then fine-tune a large general-domain vision-language model using a novel curriculum learning method. Specifically, the model first learns to align biomedical vocabulary using the figure-caption pairs as is, then learns to master open-ended conversational semantics using GPT-4 generated instruction-following data, broadly mimicking how a layperson gradually acquires biomedical knowledge. This enables us to train a Large Language and Vision Assistant for BioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med exhibits excellent multimodal conversational capability and can follow open-ended instruction to assist with inquiries about a biomedical image. On three standard biomedical visual question answering datasets, LLaVA-Med outperforms previous supervised state-of-the-art on certain metrics. To facilitate biomedical multimodal research, we will release our instruction-following data and the LLaVA-Med model.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.00890"}
{"paperId": "f08060425aa8a212d74185ee23a08329b89abcd2", "year": 2023, "title": "Scientific discovery in the age of artificial intelligence", "authors": "Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, P. Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Anima Anandkumar, K. Bergen, Carla P. Gomes, Shirley Ho, Pushmeet Kohli, Joan Lasenby, J. Leskovec, Tie-Yan Liu, A. Manrai, D. Marks, Bharath Ramsundar, Le Song, Jimeng Sun, Jian Tang, Petar Velickovic, Max Welling, Linfeng Zhang, Connor W. Coley, Y. Bengio, M. Zitnik", "venue": "Nature", "citationCount": 1283, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "49b66b980c91f989637b089c2e8284af443aaa25", "year": 2023, "title": "Students\u2019 voices on generative AI: perceptions, benefits, and challenges in higher education", "authors": "C. Chan, Wenjie Hu", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 1239, "abstract": "This study explores university students\u2019 perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs\u2019 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students\u2019 perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students\u2019 perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education. This study focuses on the integration of generative AI (GenAI) technologies, like ChatGPT, into higher education settings. University students\u2019 perceptions of generative AI technologies in higher education were explored, including familiarity, potential benefits, and challenges. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Insights from this study can inform policy development around the integration of GenAI technologies into higher education, helping to create well-informed guidelines and strategies for responsible and effective implementation. This study focuses on the integration of generative AI (GenAI) technologies, like ChatGPT, into higher education settings. University students\u2019 perceptions of generative AI technologies in higher education were explored, including familiarity, potential benefits, and challenges. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Insights from this study can inform policy development around the integration of GenAI technologies into higher education, helping to create well-informed guidelines and strategies for responsible and effective implementation.", "isOpenAccess": true, "url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00411-8"}
{"paperId": "eddfb9be78cfe94193766e3722eb0e56c3d24cef", "year": 2023, "title": "ChatGPT is fun, but not an author", "authors": "H. Thorp", "venue": "Science", "citationCount": 1094, "abstract": "In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the tool\u2019s developer, OpenAI. The program\u2014which automatically creates text based on written prompts\u2014is so popular that it\u2019s likely to be \u201cat capacity right now\u201d if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsa\u2014who has come home from a tough day of selling\u2014is told by her son Happy, \u201cCome on, Mom. You\u2019re Elsa from Frozen. You have ice powers and you\u2019re a queen. You\u2019re unstoppable.\u201d Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.", "isOpenAccess": true, "url": "https://www.science.org/doi/pdf/10.1126/science.adg7879?download=true"}
{"paperId": "ac675900f7c6c14c8488e09a2a6e8525bcf9d45a", "year": 2023, "title": "Generative AI", "authors": "Stefan Feuerriegel, Jochen Hartmann, Christian Janiesch, Patrick Zschech", "venue": "Business & Information Systems Engineering", "citationCount": 1030, "abstract": "Recent advancements in generative artificial intelligence (AI) have made it possible for machines to independently produce a variety of creative content. In the context of producing creative content, this essay examines the developments, difficulties, and ethical issues relating to generative AI. It looks into how generative models, such Generative Adversarial Networks (GANs) and Variational Auto encoders (VAEs), can produce realistic artwork like music, literature, and visuals. However, it is frequently discovered that GAN training is extremely unstable and frequently experiences non-convergence, mode collapse, and hyperparameter sensitivity [1]. The technical details of developing and optimizing generative models to produce desired results are covered in detail in this work. It also looks at the difficulties in guaranteeing the variety, creativity, and coherence of generated content. Additionally, the use of generative AI in the creation of original material raises ethical questions. Included in this are concerns about intellectual property, plagiarism, and possible effects on the creative industries. In specifically, the article explores the consequences of employing generative AI for content production in terms of authorship, human creativity, and the possible disruption of traditional creative practices. It also covers issues with fairness, bias, and appropriate application of generative models.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s12599-023-00834-7"}
{"paperId": "9472e198f790cb396c088c8e98bd4c5f5134cf62", "year": 2024, "title": "Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation", "authors": "Anjanava Biswas, Wrick Talukdar", "venue": "International Journal of Innovative Science and Research Technology", "citationCount": 969, "abstract": "Comprehensive clinical documentation is crucial for effective healthcare delivery, yet it poses a significant burden on healthcare professionals, leading to burnout, increased medical errors, and compromised patient safety. This paper explores the potential of generative AI (Artificial Intelligence) to streamline the clinical documentation process, specifically focusing on generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior, Intervention, Response, Plan) notes. We present a case study demonstrating the application of natural language processing (NLP) and automatic speech recognition (ASR) technologies to transcribe patient-clinician interactions, coupled with advanced prompting techniques to generate draft clinical notes using large language models (LLMs). The study highlights the benefits of this approach, including time savings, improved documentation quality, and enhanced patient-centered care. Additionally, we discuss ethical considerations, such as maintaining patient confidentiality and addressing model biases, underscoring the need for responsible deployment of generative AI in healthcare settings. The findings suggest that generative AI has the potential to revolutionize clinical documentation practices, alleviating administrative burdens and enabling healthcare professionals to focus more on direct patient care.", "isOpenAccess": true, "url": "https://doi.org/10.38124/ijisrt/ijisrt24may1483"}
{"paperId": "a01c3bb9962826a387e6ee3cc5901d9ab5884a74", "year": 2023, "title": "Generative AI and the future of education: Ragnar\u00f6k or reformation? A paradoxical perspective from management educators", "authors": "Weng Marc Lim, A. Gunasekara, J. Pallant, J. Pallant, E. Pechenkina", "venue": "The International Journal of Management Education", "citationCount": 905, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.ijme.2023.100790"}
{"paperId": "6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab", "year": 2023, "title": "Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence", "authors": "G. Cooper", "venue": "Journal of Science Education and Technology", "citationCount": 846, "abstract": "The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT\u2019s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10956-023-10039-y.pdf"}
{"paperId": "94a45955b0a1e86771e8d3cd867cd6553d418776", "year": 2023, "title": "Generative AI and ChatGPT: Applications, challenges, and AI-human collaboration", "authors": "Fiona Fui-Hoon Nah, Ruilin Zheng, Jingyuan Cai, K. Siau, Langtao Chen", "venue": "Journal of IT Cases and Applications", "citationCount": 836, "abstract": null, "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/15228053.2023.2233814?needAccess=true"}
{"paperId": "781cfd3b72b3bc690b15433cbbc012487d5553dd", "year": 2023, "title": "A comprehensive AI policy education framework for university teaching and learning", "authors": "C. Chan", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 822, "abstract": "This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly. Proposed AI Ecological Education Policy Framework for university teaching and learning. Three dimensions: Pedagogical, Governance, and Operational AI Policy Framework. Qualitative and quantitative data collected from students, teachers, and staff. Ten key areas identified for planning an AI policy in universities. Students should play an active role in drafting and implementing the policy. Proposed AI Ecological Education Policy Framework for university teaching and learning. Three dimensions: Pedagogical, Governance, and Operational AI Policy Framework. Qualitative and quantitative data collected from students, teachers, and staff. Ten key areas identified for planning an AI policy in universities. Students should play an active role in drafting and implementing the policy.", "isOpenAccess": true, "url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00408-3"}
{"paperId": "e41482f4ee984f17382f6cdd900df094d928be06", "year": 2023, "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents", "authors": "Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig", "venue": "International Conference on Learning Representations", "citationCount": 816, "abstract": "With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.13854"}
{"paperId": "5a23a489bb9e742edacc8b8e778b06e1594365d3", "year": 2023, "title": "Generative AI at Work", "authors": "Erik Brynjolfsson, Danielle Li, Lindsey Raymond", "venue": "Social Science Research Network", "citationCount": 761, "abstract": "\n We study the staggered introduction of a generative AI\u2013based conversational assistant using data from 5,172 customer-support agents. Access to AI assistance increases worker productivity, as measured by issues resolved per hour, by 15% on average, with substantial heterogeneity across workers. The effects vary significantly across different agents. Less experienced and lower-skilled workers improve both the speed and quality of their output, while the most experienced and highest-skilled workers see small gains in speed and small declines in quality. We also find evidence that AI assistance facilitates worker learning and improves English fluency, particularly among international agents. While AI systems improve with more training data, we find that the gains from AI adoption are largest for moderately rare problems, where human agents have less baseline experience but the system still has adequate training data. Finally, we provide evidence that AI assistance improves the experience of work along several dimensions: customers are more polite and less likely to ask to speak to a manager.", "isOpenAccess": true, "url": "https://doi.org/10.3386/w31161"}
{"paperId": "c68a13e60aca40e2cee71818c6791ec04ea5a580", "year": 2023, "title": "ChatGPT for Language Teaching and Learning", "authors": "Lucas Kohnke, Benjamin Luke Moorhouse, D. Zou", "venue": "RELC Journal : A Journal of Language Teaching and Research in Southeast Asia", "citationCount": 733, "abstract": "In this technology review, we explore the affordances of the generative AI chatbot ChatGPT for language teaching and learning. In addition to this, we also present debates and drawbacks of ChatGPT. Finally, we present the digital competencies teachers and learners require to use this chatbot ethically and effectively to support language learning.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/00336882231162868"}
{"paperId": "9dafa6c5c609348b46734fc8997b93b3587fec6e", "year": 2023, "title": "Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education", "authors": "J. Pavlik", "venue": "Journalism &amp; Mass Communication Educator", "citationCount": 733, "abstract": "Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.", "isOpenAccess": false, "url": ""}
{"paperId": "a7b3a868a80dbe97689135c99b1a6b6e10dcdfe5", "year": 2023, "title": "A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT", "authors": "Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, Lichao Sun", "venue": "arXiv.org", "citationCount": 719, "abstract": "Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society. As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models. The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information. In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results. With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation. This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.04226"}
{"paperId": "13dc81fce2c73de67dbe3829a32ec23d663cec89", "year": 2024, "title": "scGPT: toward building a foundation model for single-cell multi-omics using generative AI", "authors": "Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, Bo Wang", "venue": "Nature Methods", "citationCount": 715, "abstract": "Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference. Pretrained using over 33 million single-cell RNA-sequencing profiles, scGPT is a foundation model facilitating a broad spectrum of downstream single-cell analysis tasks by transfer learning.", "isOpenAccess": true, "url": "https://www.biorxiv.org/content/biorxiv/early/2023/07/02/2023.04.30.538439.full.pdf"}
{"paperId": "0893549771094fac547432cb4f84e9605c911a86", "year": 2023, "title": "The imperative for regulatory oversight of large language models (or generative AI) in healthcare", "authors": "B. Mesk\u00f3, E. Topol", "venue": "npj Digit. Medicine", "citationCount": 691, "abstract": "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-023-00873-0.pdf"}
{"paperId": "d553d008f643622e87e3ac061226865cad3b2928", "year": 2023, "title": "Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education", "authors": "Junaid Qadir", "venue": "IEEE Global Engineering Education Conference", "citationCount": 633, "abstract": "Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.", "isOpenAccess": false, "url": ""}
{"paperId": "5f996fd3592478b6923590ed5347d6206357e95a", "year": 2023, "title": "What ChatGPT and generative AI mean for science", "authors": "Chris Stokel-Walker, Richard van Noorden", "venue": "Nature", "citationCount": 587, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1038/d41586-023-00340-6"}
{"paperId": "8a9f05cdfd0ea7411e83f95b39647167ee82c087", "year": 2023, "title": "ChatGPT in higher education: Considerations for academic integrity and student learning", "authors": "Articles Info, Miriam Sullivan, Andrew Kelly, Paul Mclaughlan", "venue": "1", "citationCount": 585, "abstract": "The release of ChatGPT has sparked significant academic integrity concerns in higher education. However, some commentators have pointed out that generative artificial intelligence (AI) tools such as ChatGPT can enhance student learning, and consequently, academics should adapt their teaching and assessment practices to embrace the new reality of living, working, and studying in a world where AI is freely available. Despite this important debate, there has been very little academic literature published on ChatGPT and other generative AI tools. This article uses content analysis to examine news articles (N=100) about how ChatGPT is disrupting higher education, concentrating specifically on Australia, New Zealand, the United States", "isOpenAccess": true, "url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/731/559"}
{"paperId": "eb9c4a07a336e8deefe7b399c550d3af0241238e", "year": 2024, "title": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models", "authors": "Wenqi Fan, Yujuan Ding, Liang-bo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, Qing Li", "venue": "Knowledge Discovery and Data Mining", "citationCount": 584, "abstract": "As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/", "isOpenAccess": false, "url": ""}
{"paperId": "317ad53bea6fb603c20f692bb2f1a01e2dc86161", "year": 2023, "title": "From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy", "authors": "Maanak Gupta, Charankumar Akiri, Kshitiz Aryal, Elisabeth Parker, Lopamudra Praharaj", "venue": "IEEE Access", "citationCount": 536, "abstract": "Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it\u2019s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10198233.pdf"}
{"paperId": "7bd7431f0fa8ad5738cb2e481e8d415857b66107", "year": 2023, "title": "Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT", "authors": "Rosario Michel-Villarreal, E. Vilalta-Perdomo, D. Salinas-Navarro, Ricardo Thierry-Aguilera, F. S. Gerardou", "venue": "Education sciences", "citationCount": 516, "abstract": "ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT\u2019s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/13/9/856/pdf?version=1692771591"}
{"paperId": "53b04ccd2a001467d7ce168e9ce20b16a9466a69", "year": 2023, "title": "Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies", "authors": "Emilio Ferrara", "venue": "Social Science Research Network", "citationCount": 497, "abstract": "The significant advancements in applying artificial intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey study offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases\u2014highlighting the emergent issue of generative AI bias, where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on perpetuating inequalities and reinforcing harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discuss the ethical considerations of their implementation, and emphasize the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these. Addressing bias in AI requires a holistic approach involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the emerging field of generative AI.", "isOpenAccess": true, "url": "https://www.mdpi.com/2413-4155/6/1/3/pdf?version=1703577406"}
{"paperId": "d9b840da085a0d23abcca2142b5c796bc0f7f4b0", "year": 2023, "title": "Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT", "authors": "Jae-Bong Jeon, Seongyong Lee", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 492, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "eecb4dbf218d08d43a727c7e79f86a296502f117", "year": 2023, "title": "Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial", "authors": "B. Mesk\u00f3", "venue": "Journal of Medical Internet Research", "citationCount": 487, "abstract": "Prompt engineering is a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks. With the emergence of LLMs, the most popular one being ChatGPT that has attracted the attention of over a 100 million users in only 2 months, artificial intelligence (AI), especially generative AI, has become accessible for the masses. This is an unprecedented paradigm shift not only because of the use of AI becoming more widespread but also due to the possible implications of LLMs in health care. As more patients and medical professionals use AI-based tools, LLMs being the most popular representatives of that group, it seems inevitable to address the challenge to improve this skill. This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs.", "isOpenAccess": true, "url": "https://www.jmir.org/2023/1/e50638/PDF"}
{"paperId": "a6f7485dfdf45320e82d84bcfdc51bcd52dff18b", "year": 2024, "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models", "authors": "Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao, Ruoxi Chen, Zhengqing Yuan, Yue Huang, Hanchi Sun, Jianfeng Gao, Lifang He, Lichao Sun", "venue": "arXiv.org", "citationCount": 485, "abstract": "Sora is a text-to-video generative AI model, released by OpenAI in February 2024. The model is trained to generate videos of realistic or imaginative scenes from text instructions and show potential in simulating the physical world. Based on public technical reports and reverse engineering, this paper presents a comprehensive review of the model's background, related technologies, applications, remaining challenges, and future directions of text-to-video AI models. We first trace Sora's development and investigate the underlying technologies used to build this\"world simulator\". Then, we describe in detail the applications and potential impact of Sora in multiple industries ranging from film-making and education to marketing. We discuss the main challenges and limitations that need to be addressed to widely deploy Sora, such as ensuring safe and unbiased video generation. Lastly, we discuss the future development of Sora and video generation models in general, and how advancements in the field could enable new ways of human-AI interaction, boosting productivity and creativity of video generation.", "isOpenAccess": false, "url": ""}
{"paperId": "ea5865334a2ab386e76f22e0b4775aa904fe6920", "year": 2023, "title": "The impact of Generative AI (GenAI) on practices, policies and research direction in education: a case of ChatGPT and Midjourney", "authors": "Thomas K. F. Chiu", "venue": "Interactive Learning Environments", "citationCount": 484, "abstract": "Abstract Generative artificial intelligence (GenAI) tools have become increasingly accessible and have impacted school education in numerous ways. However, most of the discussions occur in higher education. In schools, teachers\u2019 perspectives are crucial for making sense of innovative technologies. Accordingly, this qualitative study aims to investigate how GenAI changes our school education from the perspectives of teachers and leaders. It used four domains \u2013 learning, teaching, assessment, and administration \u2013 as the initial framework suggested in a systematic literature review study on AI in education. The participants were 88 school teachers and leaders of different backgrounds. They completed a survey and joined a focus group to share how ChatGPT and Midjounery had a GenAI effect on school education. Thematic analysis identified four main themes and 12 subthemes. The findings provide three suggestions for practices: know-it-all attitude, new prerequisite knowledge, interdisciplinary teaching, and three implications for policy: new assessment, AI education, and professional standards. They also further suggest six future research directions for GenAI in education.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/10494820.2023.2253861?needAccess=true&role=button"}
{"paperId": "223cdf1198a045c049f2359ad9d1db77e8028e80", "year": 2023, "title": "Art and the science of generative AI", "authors": "Ziv Epstein, Aaron Hertzmann, L. Herman, Robert Mahari, M. Frank, Matthew Groh, Hope Schroeder, Amy Smith, Memo Akten, Jessica Fjeld, Hany Farid, Neil Leach, A. Pentland, Olga Russakovsky", "venue": "Science", "citationCount": 483, "abstract": "Understanding shifts in creative work will help guide AI\u2019s impact on the media ecosystem The capabilities of a new class of tools, colloquially known as generative artificial intelligence (AI), is a topic of much debate. One prominent application thus far is the production of high-quality artistic media for visual arts, concept art, music, and literature, as well as video and animation. For example, diffusion models can synthesize high-quality images (1), and large language models (LLMs) can produce sensible-sounding and impressive prose and verse in a wide range of contexts (2). The generative capabilities of these tools are likely to fundamentally alter the creative processes by which creators formulate ideas and put them into production. As creativity is reimagined, so too may be many sectors of society. Understanding the impact of generative AI\u2014and making policy decisions around it\u2014requires new interdisciplinary scientific inquiry into culture, economics, law, algorithms, and the interaction of technology and creativity.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2306.04141"}
{"paperId": "6c2e438068e101d31af55add9f6ac6cac7159bc8", "year": 2023, "title": "Practical and ethical challenges of large language models in education: A systematic scoping review", "authors": "Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Mart\u00ednez Maldonado, Guanliang Chen, Xinyu Li, Yueqiao Jin, D. Ga\u0161evi\u0107", "venue": "British Journal of Educational Technology", "citationCount": 482, "abstract": "Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs\u2010based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer\u2010reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state\u2010of\u2010the\u2010art models (eg, GPT\u20103/4), embracing the initiative of open\u2010sourcing models/systems, and adopting a human\u2010centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.\nWhat is currently known about this topic\n\nGenerating and analysing text\u2010based content are time\u2010consuming and laborious tasks.\nLarge language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.\nLarge language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.\nWhat this paper adds\n\nA comprehensive list of different educational tasks that could potentially benefit from LLMs\u2010based innovations through automation.\nA structured assessment of the practicality and ethicality of existing LLMs\u2010based innovations from seven important aspects using established frameworks.\nThree recommendations that could potentially support future studies to develop LLMs\u2010based innovations that are practical and ethical to implement in authentic educational contexts.\nImplications for practice and/or policy\n\nUpdating existing innovations with state\u2010of\u2010the\u2010art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.\nThe reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.\nAdopting a human\u2010centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.\n\n", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13370"}
{"paperId": "6a703c99b5403556c124f6a0d878110cf14b4439", "year": 2023, "title": "The Potential of Generative Artificial Intelligence Across Disciplines: Perspectives and Future Directions", "authors": "K. Ooi, G. Tan, M. Al-Emran, Mohammed A. Al-Sharafi, A. C\u0103p\u0103\u021b\u00een\u0103, Amrita Chakraborty, Yogesh K. Dwivedi, Tzu-Ling Huang, A. Kar, Voon\u2010Hsien Lee, Xiu-Ming Loh, Adrian Micu, Patrick Mikalef, Emmanuel Mogaji, Neeraj Pandey, R. Raman, Nripendra P. Rana, Prianka Sarker, Anshuman Sharma, Ching-I Teng, S. Wamba, Lai-Wan Wong", "venue": "Journal of Computational Information Systems", "citationCount": 437, "abstract": "ABSTRACT In a short span of time since its introduction, generative artificial intelligence (AI) has garnered much interest at both personal and organizational levels. This is because of its potential to cause drastic and widespread shifts in many aspects of life that are comparable to those of the Internet and smartphones. More specifically, generative AI utilizes machine learning, neural networks, and other techniques to generate new content (e.g. text, images, music) by analyzing patterns and information from the training data. This has enabled generative AI to have a wide range of applications, from creating personalized content to improving business operations. Despite its many benefits, there are also significant concerns about the negative implications of generative AI. In view of this, the current article brings together experts in a variety of fields to expound and provide multi-disciplinary insights on the opportunities, challenges, and research agendas of generative AI in specific industries (i.e. marketing, healthcare, human resource, education, banking, retailing, the workplace, manufacturing, and sustainable IT management).", "isOpenAccess": false, "url": ""}
{"paperId": "15abedb29536d50afeeec739a25358255cbda3e8", "year": 2023, "title": "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot", "authors": "Sida Peng, Eirini Kalliamvakou, Peter Cihon, Mert Demirer", "venue": "arXiv.org", "citationCount": 435, "abstract": "Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.", "isOpenAccess": false, "url": ""}
{"paperId": "f75f924f53082736b5ecd85b7198f7d79e42e4ae", "year": 2023, "title": "Unlocking the Power of ChatGPT: A Framework for Applying Generative AI in Education", "authors": "Jiahong Su (\u82cf\u5609\u7ea2), Weipeng Yang (\u6768\u4f1f\u9e4f)", "venue": "ECNU Review of Education", "citationCount": 418, "abstract": "Purpose Artificial intelligence (AI) chatbots, such as ChatGPT and GPT-4, developed by OpenAI, have the potential to revolutionize education. This study explores the potential benefits and challenges of using ChatGPT in education (or \u201ceducative AI\u201d). Design/Approach/Methods This paper proposes a theoretical framework called \u201cIDEE\u201d for educative AI such as using ChatGPT and other generative AI in education, which includes identifying the desired outcomes, determining the appropriate level of automation, ensuring ethical considerations, and evaluating effectiveness. Findings The benefits of using ChatGPT in education or more generally, educative AI, include a more personalized and efficient learning experience for students as well as easier and faster feedback for teachers. However, challenges such as the untested effectiveness of the technology, limitations in the quality of data, and ethical and safety concerns must also be considered. Originality/Value This study explored the opportunities and challenges of using ChatGPT in education within the proposed theoretical framework.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/20965311231168423"}
{"paperId": "bd166912fa16cec04e3ee044a0d0fb6e3ac6fe33", "year": 2023, "title": "Regulating ChatGPT and other Large Generative AI Models", "authors": "P. Hacker, A. Engel, M. Mauer", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 417, "abstract": "Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3593013.3594067"}
{"paperId": "b867ec2add2a3ef26ab2c3080d5f7d4d400d8270", "year": 2023, "title": "The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and millennial generation teachers?", "authors": "C. Chan, Katherine K. W. Lee", "venue": "Smart Learning Environments", "citationCount": 417, "abstract": "This study aimed to explore the experiences, perceptions, knowledge, concerns, and intentions of Generation Z (Gen Z) students with Generation X (Gen X) and Generation Y (Gen Y) teachers regarding the use of generative AI (GenAI) in higher education. A sample of students and teachers were recruited to investigate the above using a survey consisting of both open and closed questions. The findings showed that Gen Z participants were generally optimistic about the potential benefits of GenAI, including enhanced productivity, efficiency, and personalized learning, and expressed intentions to use GenAI for various educational purposes. Gen X and Gen Y teachers acknowledged the potential benefits of GenAI but expressed heightened concerns about overreliance, ethical and pedagogical implications, emphasizing the need for proper guidelines and policies to ensure responsible use of the technology. The study highlighted the importance of combining technology with traditional teaching methods to provide a more effective learning experience. Implications of the findings include the need to develop evidence-based guidelines and policies for GenAI integration, foster critical thinking and digital literacy skills among students, and promote responsible use of GenAI technologies in higher education.", "isOpenAccess": true, "url": "https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00269-3"}
{"paperId": "98478ac589e5b40a20630ff54bb4eec4ab4c5f6b", "year": 2023, "title": "GAIA-1: A Generative World Model for Autonomous Driving", "authors": "Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex Kendall, Jamie Shotton, Gianluca Corrado", "venue": "arXiv.org", "citationCount": 415, "abstract": "Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves. To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representation that captures expectations of future events, combined with its ability to generate realistic samples, provides new possibilities for innovation in the field of autonomy, enabling enhanced and accelerated training of autonomous driving technology.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.17080"}
{"paperId": "cdae0d5333b00e006a5e9f209a394ae46a3a0cc3", "year": 2023, "title": "The Power of Generative AI: A Review of Requirements, Models, Input-Output Formats, Evaluation Metrics, and Challenges", "authors": "A. Bandi, Pydi Venkata Satya Ramesh Adapa, Yudu Eswar Vinay Pratap Kumar Kuchi", "venue": "Future Internet", "citationCount": 394, "abstract": "Generative artificial intelligence (AI) has emerged as a powerful technology with numerous applications in various domains. There is a need to identify the requirements and evaluation metrics for generative AI models designed for specific tasks. The purpose of the research aims to investigate the fundamental aspects of generative AI systems, including their requirements, models, input\u2013output formats, and evaluation metrics. The study addresses key research questions and presents comprehensive insights to guide researchers, developers, and practitioners in the field. Firstly, the requirements necessary for implementing generative AI systems are examined and categorized into three distinct categories: hardware, software, and user experience. Furthermore, the study explores the different types of generative AI models described in the literature by presenting a taxonomy based on architectural characteristics, such as variational autoencoders (VAEs), generative adversarial networks (GANs), diffusion models, transformers, language models, normalizing flow models, and hybrid models. A comprehensive classification of input and output formats used in generative AI systems is also provided. Moreover, the research proposes a classification system based on output types and discusses commonly used evaluation metrics in generative AI. The findings contribute to advancements in the field, enabling researchers, developers, and practitioners to effectively implement and evaluate generative AI models for various applications. The significance of the research lies in understanding that generative AI system requirements are crucial for effective planning, design, and optimal performance. A taxonomy of models aids in selecting suitable options and driving advancements. Classifying input\u2013output formats enables leveraging diverse formats for customized systems, while evaluation metrics establish standardized methods to assess model quality and performance.", "isOpenAccess": true, "url": "https://www.mdpi.com/1999-5903/15/8/260/pdf?version=1690812126"}
{"paperId": "35ccd924de9e8483bdcf144cbf2edf09be157b7e", "year": 2023, "title": "Text-to-image Diffusion Models in Generative AI: A Survey", "authors": "Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In-So Kweon", "venue": "arXiv.org", "citationCount": 375, "abstract": "This survey reviews the progress of diffusion models in generating images from text, ~\\textit{i.e.} text-to-image diffusion models. As a self-contained work, this survey starts with a brief introduction of how diffusion models work for image synthesis, followed by the background for text-conditioned image synthesis. Based on that, we present an organized review of pioneering methods and their improvements on text-to-image generation. We further summarize applications beyond image generation, such as text-guided generation for various modalities like videos, and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.07909"}
{"paperId": "4761f173965195798cd3046ef4af608a83504e4d", "year": 2023, "title": "TokenFlow: Consistent Diffusion Features for Consistent Video Editing", "authors": "Michal Geyer, Omer Bar-Tal, Shai Bagon, Tali Dekel", "venue": "International Conference on Learning Representations", "citationCount": 374, "abstract": "The generative AI revolution has recently expanded to videos. Nevertheless, current state-of-the-art video models are still lagging behind image models in terms of visual quality and user control over the generated content. In this work, we present a framework that harnesses the power of a text-to-image diffusion model for the task of text-driven video editing. Specifically, given a source video and a target text-prompt, our method generates a high-quality video that adheres to the target text, while preserving the spatial layout and motion of the input video. Our method is based on a key observation that consistency in the edited video can be obtained by enforcing consistency in the diffusion feature space. We achieve this by explicitly propagating diffusion features based on inter-frame correspondences, readily available in the model. Thus, our framework does not require any training or fine-tuning, and can work in conjunction with any off-the-shelf text-to-image editing method. We demonstrate state-of-the-art editing results on a variety of real-world videos. Webpage: https://diffusion-tokenflow.github.io/", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.10373"}
{"paperId": "34276d30da30285f4ad348848ec746457730899a", "year": 2024, "title": "InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models", "authors": "Jiale Xu, Weihao Cheng, Yiming Gao, Xintao Wang, Shenghua Gao, Ying Shan", "venue": "arXiv.org", "citationCount": 344, "abstract": "We present InstantMesh, a feed-forward framework for instant 3D mesh generation from a single image, featuring state-of-the-art generation quality and significant training scalability. By synergizing the strengths of an off-the-shelf multiview diffusion model and a sparse-view reconstruction model based on the LRM architecture, InstantMesh is able to create diverse 3D assets within 10 seconds. To enhance the training efficiency and exploit more geometric supervisions, e.g, depths and normals, we integrate a differentiable iso-surface extraction module into our framework and directly optimize on the mesh representation. Experimental results on public datasets demonstrate that InstantMesh significantly outperforms other latest image-to-3D baselines, both qualitatively and quantitatively. We release all the code, weights, and demo of InstantMesh, with the intention that it can make substantial contributions to the community of 3D generative AI and empower both researchers and content creators.", "isOpenAccess": false, "url": ""}
{"paperId": "62ad7ea9467bbcdbfe325b9ee561cab3908e4583", "year": 2023, "title": "MEGA: Multilingual Evaluation of Generative AI", "authors": "Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee, Krithika Ramesh, Samuel C. Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, Sunayana Sitaram", "venue": "Conference on Empirical Methods in Natural Language Processing", "citationCount": 343, "abstract": "Generative AI models have shown impressive performance on many Natural Language Processing tasks such as language understanding, reasoning, and language generation. An important question being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs have been restricted to English and it is unclear how capable these models are at understanding and generating text in other languages. We present the first comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 16 NLP datasets across 70 typologically diverse languages. We compare the performance of generative LLMs including Chat-GPT and GPT-4 to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the field.", "isOpenAccess": true, "url": "https://aclanthology.org/2023.emnlp-main.258.pdf"}
{"paperId": "ec45c3f0f88c8ce1deb5baa71c2c0e14ad64d249", "year": 2024, "title": "Evaluating Text-to-Visual Generation with Image-to-Text Generation", "authors": "Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, Deva Ramanan", "venue": "European Conference on Computer Vision", "citationCount": 341, "abstract": "Despite significant progress in generative AI, comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance, the widely-used CLIPScore measures the alignment between a (generated) image and text prompt, but it fails to produce reliable scores for complex prompts involving compositions of objects, attributes, and relations. One reason is that text encoders of CLIP can notoriously act as a\"bag of words\", conflating prompts such as\"the horse is eating the grass\"with\"the grass is eating the horse\". To address this, we introduce the VQAScore, which uses a visual-question-answering (VQA) model to produce an alignment score by computing the probability of a\"Yes\"answer to a simple\"Does this figure show '{text}'?\"question. Though simpler than prior art, VQAScore computed with off-the-shelf models produces state-of-the-art results across many (8) image-text alignment benchmarks. We also compute VQAScore with an in-house model that follows best practices in the literature. For example, we use a bidirectional image-question encoder that allows image embeddings to depend on the question being asked (and vice versa). Our in-house model, CLIP-FlanT5, outperforms even the strongest baselines that make use of the proprietary GPT-4V. Interestingly, although we train with only images, VQAScore can also align text with video and 3D models. VQAScore allows researchers to benchmark text-to-visual generation using complex texts that capture the compositional structure of real-world prompts. We introduce GenAI-Bench, a more challenging benchmark with 1,600 compositional text prompts that require parsing scenes, objects, attributes, relationships, and high-order reasoning like comparison and logic. GenAI-Bench also offers over 15,000 human ratings for leading image and video generation models such as Stable Diffusion, DALL-E 3, and Gen2.", "isOpenAccess": false, "url": ""}
{"paperId": "fffdda51d038fcf7141e9c62739f8a292ce7ccfb", "year": 2023, "title": "ChatGPT and the Rise of Generative AI: Threat to Academic Integrity?", "authors": "Damian Okaibedi", "venue": "Journal of Responsible Technology", "citationCount": 338, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.jrt.2023.100060"}
{"paperId": "3b09a37c82d96afe0634c604664263bd50c141e0", "year": 2024, "title": "GUIDANCE FOR GENERATIVE AI IN EDUCATION AND RESEARCH\" FOR TEACHERS", "authors": "S. Boonlue", "venue": "Journal of industrial education", "citationCount": 332, "abstract": "From the book title is \"Guidance for Generative AI in Education and Research\" for teachers, or this book serves as part of the guidelines for using Generative AI (GenAI) in the fields of education and research. This book was written by W. Holmes and F. Miao in 2023. This book addresses the rapid emergence of publicly available Generative AI tools, with the release of new versions outpacing the establishment of national regulatory frameworks. The lack of national regulations on GenAI in most countries raises concerns about user data privacy and leaves educational institutions unprotected and largely unprepared to scrutinize these tools. UNESCO has issued the first global guidelines on GenAI in education, aiming to support countries in taking immediate action, formulating long-term policies, and developing human capacity to ensure that people can effectively use AI and enhance their work with Generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "1f22de83d912176cb8857efa1c6d65b14d6a2f5c", "year": 2023, "title": "ChatGPT is not all you need. A State of the Art Review of large Generative AI models", "authors": "Roberto Gozalo-Brizuela, E.C. Garrido-Merch\u00e1n", "venue": "arXiv.org", "citationCount": 323, "abstract": "During the last two years there has been a plethora of large generative models such as ChatGPT or Stable Diffusion that have been published. Concretely, these models are able to perform tasks such as being a general question and answering system or automatically creating artistic images that are revolutionizing several sectors. Consequently, the implications that these generative models have in the industry and society are enormous, as several job positions may be transformed. For example, Generative AI is capable of transforming effectively and creatively texts to images, like the DALLE-2 model; text to 3D images, like the Dreamfusion model; images to text, like the Flamingo model; texts to video, like the Phenaki model; texts to audio, like the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the Codex model; texts to scientific texts, like the Galactica model or even create algorithms like AlphaTensor. This work consists on an attempt to describe in a concise way the main models are sectors that are affected by generative AI and to provide a taxonomy of the main generative models published recently.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2301.04655"}
{"paperId": "ddf46191262aeff970d8c0106fb935f5e5690ce8", "year": 2023, "title": "Generative AI enhances individual creativity but reduces the collective diversity of novel content", "authors": "Anil R. Doshi, Oliver P. Hauser", "venue": "Science Advances", "citationCount": 318, "abstract": "Creativity is core to being human. Generative artificial intelligence (AI)\u2014including powerful large language models (LLMs)\u2014holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on generative AI ideas. We study the causal impact of generative AI ideas on the production of short stories in an online experiment where some writers obtained story ideas from an LLM. We find that access to generative AI ideas causes stories to be evaluated as more creative, better written, and more enjoyable, especially among less creative writers. However, generative AI\u2013enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity at the risk of losing collective novelty. This dynamic resembles a social dilemma: With generative AI, writers are individually better off, but collectively a narrower scope of novel content is produced. Our results have implications for researchers, policy-makers, and practitioners interested in bolstering creativity.", "isOpenAccess": true, "url": "https://www.science.org/doi/pdf/10.1126/sciadv.adn5290?download=true"}
{"paperId": "a00b966f5e335cb35f3e7537fad56f6b6f507478", "year": 2024, "title": "Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students", "authors": "Muhammad Abbas, Farooq Ahmed Jam, Tariq Iqbal Khan", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 317, "abstract": "While the discussion on generative artificial intelligence, such as ChatGPT, is making waves in academia and the popular press, there is a need for more insight into the use of ChatGPT among students and the potential harmful or beneficial consequences associated with its usage. Using samples from two studies, the current research examined the causes and consequences of ChatGPT usage among university students. Study 1 developed and validated an eight-item scale to measure ChatGPT usage by conducting a survey among university students (N\u2009=\u2009165). Study 2 used a three-wave time-lagged design to collect data from university students (N\u2009=\u2009494) to further validate the scale and test the study\u2019s hypotheses. Study 2 also examined the effects of academic workload, academic time pressure, sensitivity to rewards, and sensitivity to quality on ChatGPT usage. Study 2 further examined the effects of ChatGPT usage on students\u2019 levels of procrastination, memory loss, and academic performance. Study 1 provided evidence for the validity and reliability of the ChatGPT usage scale. Furthermore, study 2 revealed that when students faced higher academic workload and time pressure, they were more likely to use ChatGPT. In contrast, students who were sensitive to rewards were less likely to use ChatGPT. Not surprisingly, use of ChatGPT was likely to develop tendencies for procrastination and memory loss and dampen the students\u2019 academic performance. Finally, academic workload, time pressure, and sensitivity to rewards had indirect effects on students\u2019 outcomes through ChatGPT usage.", "isOpenAccess": true, "url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-024-00444-7"}
{"paperId": "15074299f9b3cfd1230f29fca3a26236dc8681b8", "year": 2024, "title": "A multimodal generative AI copilot for human pathology", "authors": "Ming Y. Lu, Bowen Chen, Drew F. K. Williamson, Richard J. Chen, Melissa Zhao, Aaron K Chow, Kenji Ikemura, Ahrong Kim, Dimitra Pouli, Ankush U Patel, Amr Soliman, Chengkuan Chen, Tong Ding, Judy J. Wang, Georg K. Gerber, Ivy Liang, L. Le, Anil V. Parwani, Luca L. Weishaupt, Faisal Mahmood", "venue": "Nature", "citationCount": 316, "abstract": "Computational pathology1,2 has witnessed considerable progress in the development of both task-specific predictive models and task-agnostic self-supervised vision encoders3,4. However, despite the explosive growth of generative artificial intelligence (AI), there have been few studies on building general-purpose multimodal AI assistants and copilots5 tailored to pathology. Here we present PathChat, a vision-language generalist AI assistant for human pathology. We built PathChat by adapting a foundational vision encoder for pathology, combining it with a pretrained large language model and fine-tuning the whole system on over 456,000 diverse visual-language instructions consisting of 999,202 question and answer turns. We compare PathChat with several multimodal vision-language AI assistants and GPT-4V, which powers the commercially available multimodal general-purpose AI assistant ChatGPT-4 (ref. 6). PathChat achieved state-of-the-art performance on multiple-choice diagnostic questions from cases with diverse tissue origins and disease models. Furthermore, using open-ended questions and human expert evaluation, we found that overall PathChat produced more accurate and pathologist-preferable responses to diverse queries related to pathology. As an interactive vision-language AI copilot that can flexibly handle both visual and natural language inputs, PathChat may potentially find impactful applications in pathology education, research and human-in-the-loop clinical decision-making. PathChat, a multimodal generative AI copilot for human pathology, has been trained on a large dataset of visual-language instructions to interactively assist users with diverse pathology tasks.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41586-024-07618-3_reference.pdf"}
{"paperId": "5fedb29a5068a3c0e576bfb5a0cf52afab20db60", "year": 2023, "title": "A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice", "authors": "Sarah Bankins, A. C. Ocampo, Mauricio Marrone, S. Restubog, S. E. Woo", "venue": "Journal of Organizational Behavior", "citationCount": 306, "abstract": "The rising use of artificially intelligent (AI) technologies, including generative AI tools, in organizations is undeniable. As these systems become increasingly integrated into organizational practices and processes, understanding their impact on workers' experiences and job designs is critical. However, the ongoing discourse surrounding AI use in the workplace remains divided. Proponents of the technology extol its benefits for enhancing efficiency and productivity, while others voice concerns about the potential harm to human workers. To provide greater clarity on this pressing issue, this article presents a systematic review of empirical research that sheds light on the implications of AI use at work. Organized under five inductively generated themes within a multilevel framework, we uncover individual, group, and organizational factors that shape the interplay between humans and AI. Specifically, the themes are: (1) human\u2013AI collaboration; (2) perceptions of algorithmic and human capabilities; (3) worker attitudes towards AI; (4) AI as a control mechanism in algorithmic management of platform\u2010based work; and (5) labor market implications of AI use. Our review offers insights into these themes and identifies five pathways for future research. Finally, we provide practical recommendations for organizational leaders seeking to implement AI technologies while prioritizing their employees' well\u2010being.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/job.2735"}
{"paperId": "f8e77bd3d573d0daee0744443c65c40e3b5dc10f", "year": 2023, "title": "Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services", "authors": "Minrui Xu, Hongyang Du, Dusist Niyato, Jiawen Kang, Zehui Xiong, Shiwen Mao, Zhu Han, A. Jamalipour, Dong In Kim, X. Shen, Victor C. M. Leung, H. Poor", "venue": "IEEE Communications Surveys and Tutorials", "citationCount": 301, "abstract": "Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, fine-tuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGC-driven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2303.16129"}
{"paperId": "77179e5ff669452b9bea479a4236a6e2009ee422", "year": 2024, "title": "The Power of Noise: Redefining Retrieval for RAG Systems", "authors": "Florin Cuconasu, Giovanni Trappolini, F. Siciliano, Simone Filice, Cesare Campagnano, Y. Maarek, Nicola Tonellotto, Fabrizio Silvestri", "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "citationCount": 300, "abstract": "Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.", "isOpenAccess": false, "url": ""}
{"paperId": "186f75e6b43d173f443902be4f8c05db6ba789c4", "year": 2023, "title": "Generative AI in Education and Research: Opportunities, Concerns, and Solutions", "authors": "Eman A. Alasadi, Carlos R. Baiz", "venue": "Journal of Chemical Education", "citationCount": 300, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "af47d88093c3f32b299cfc93be4695a954406636", "year": 2023, "title": "AI-generated feedback on writing: insights into efficacy and ENL student preference", "authors": "Juan Escalante, Austin Pack, A. Barrett", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 295, "abstract": "The question of how generative AI tools, such as large language models and chatbots, can be leveraged ethically and effectively in education is ongoing. Given the critical role that writing plays in learning and assessment within educational institutions, it is of growing importance for educators to make thoughtful and informed decisions as to how and in what capacity generative AI tools should be leveraged to assist in the development of students\u2019 writing skills. This paper reports on two longitudinal studies. Study 1 examined learning outcomes of 48 university English as a new language (ENL) learners in a six-week long repeated measures quasi experimental design where the experimental group received writing feedback generated from ChatGPT (GPT-4) and the control group received feedback from their human tutor. Study 2 analyzed the perceptions of a different group of 43 ENLs who received feedback from both ChatGPT and their tutor. Results of study 1 showed no difference in learning outcomes between the two groups. Study 2 results revealed a near even split in preference for AI-generated or human-generated feedback, with clear advantages to both forms of feedback apparent from the data. The main implication of these studies is that the use of AI-generated feedback can likely be incorporated into ENL essay evaluation without affecting learning outcomes, although we recommend a blended approach that utilizes the strengths of both forms of feedback. The main contribution of this paper is in addressing generative AI as an automatic essay evaluator while incorporating learner perspectives.", "isOpenAccess": true, "url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00425-2"}
{"paperId": "2d42566eebc5704743ed4d69c2e752d7cb73a005", "year": 2023, "title": "The Robots Are Here: Navigating the Generative AI Revolution in Computing Education", "authors": "J. Prather, Paul Denny, Juho Leinonen, Brett A. Becker, Ibrahim Albluwi, Michelle Craig, Hieke Keuning, Natalie Kiesler, Tobias Kohn, Andrew Luxton-Reilly, Stephen Macneil, Andrew Petersen, Raymond Pettit, Brent N. Reeves, Jaromir Savelka", "venue": "ITiCSE-WGR", "citationCount": 292, "abstract": "Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving. There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3623762.3633499"}
{"paperId": "df558a3daf22955fe42f4bbeb1415f6607b67567", "year": 2023, "title": "The GenAI is out of the bottle: generative artificial intelligence from a business model innovation perspective", "authors": "Dominik K. Kanbach, Louisa Heiduk, Georg Blueher, Maximilian Schreiter, Alexander Lahmann", "venue": "Reviews of Management Sciences", "citationCount": 291, "abstract": "The introduction of ChatGPT in November 2022 by OpenAI has stimulated substantial discourse on the implementation of artificial intelligence (AI) in various domains such as academia, business, and society at large. Although AI has been utilized in numerous areas for several years, the emergence of generative AI (GAI) applications such as ChatGPT, Jasper, or DALL-E are considered a breakthrough for the acceleration of AI technology due to their ease of use, intuitive interface, and performance. With GAI, it is possible to create a variety of content such as texts, images, audio, code, and even videos. This creates a variety of implications for businesses requiring a deeper examination, including an influence on business model innovation (BMI). Therefore, this study provides a BMI perspective on GAI with two primary contributions: (1) The development of six comprehensive propositions outlining the impact of GAI on businesses, and (2) the discussion of three industry examples, specifically software engineering, healthcare, and financial services. This study employs a qualitative content analysis using a scoping review methodology, drawing from a wide-ranging sample of 513 data points. These include academic publications, company reports, and public information such as press releases, news articles, interviews, and podcasts. The study thus contributes to the growing academic discourse in management research concerning AI's potential impact and offers practical insights into how to utilize this technology to develop new or improve existing business models.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11846-023-00696-z.pdf"}
{"paperId": "25361e9582996220625a1823d931b4ed5f5558d3", "year": 2024, "title": "Generative AI in healthcare: an implementation science informed translational path on application, integration and governance", "authors": "S. Reddy", "venue": "Implementation Science", "citationCount": 280, "abstract": "Artificial intelligence (AI), particularly generative AI, has emerged as a transformative tool in healthcare, with the potential to revolutionize clinical decision-making and improve health outcomes. Generative AI, capable of generating new data such as text and images, holds promise in enhancing patient care, revolutionizing disease diagnosis and expanding treatment options. However, the utility and impact of generative AI in healthcare remain poorly understood, with concerns around ethical and medico-legal implications, integration into healthcare service delivery and workforce utilisation. Also, there is not a clear pathway to implement and integrate generative AI in healthcare delivery. This article aims to provide a comprehensive overview of the use of generative AI in healthcare, focusing on the utility of the technology in healthcare and its translational application highlighting the need for careful planning, execution and management of expectations in adopting generative AI in clinical medicine. Key considerations include factors such as data privacy, security and the irreplaceable role of clinicians\u2019 expertise. Frameworks like the technology acceptance model (TAM) and the Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model are considered to promote responsible integration. These frameworks allow anticipating and proactively addressing barriers to adoption, facilitating stakeholder participation and responsibly transitioning care systems to harness generative AI\u2019s potential. Generative AI has the potential to transform healthcare through automated systems, enhanced clinical decision-making and democratization of expertise with diagnostic support tools providing timely, personalized suggestions. Generative AI applications across billing, diagnosis, treatment and research can also make healthcare delivery more efficient, equitable and effective. However, integration of generative AI necessitates meticulous change management and risk mitigation strategies. Technological capabilities alone cannot shift complex care ecosystems overnight; rather, structured adoption programs grounded in implementation science are imperative. It is strongly argued in this article that generative AI can usher in tremendous healthcare progress, if introduced responsibly. Strategic adoption based on implementation science, incremental deployment and balanced messaging around opportunities versus limitations helps promote safe, ethical generative AI integration. Extensive real-world piloting and iteration aligned to clinical priorities should drive development. With conscientious governance centred on human wellbeing over technological novelty, generative AI can enhance accessibility, affordability and quality of care. As these models continue advancing rapidly, ongoing reassessment and transparent communication around their strengths and weaknesses remain vital to restoring trust, realizing positive potential and, most importantly, improving patient outcomes.", "isOpenAccess": true, "url": "https://implementationscience.biomedcentral.com/counter/pdf/10.1186/s13012-024-01357-9"}
{"paperId": "9e0e253a7f71f6702f40b083080232989c482464", "year": 2024, "title": "Can Generative AI improve social science?", "authors": "Christopher A Bail", "venue": "Proceedings of the National Academy of Sciences of the United States of America", "citationCount": 275, "abstract": "Generative AI that can produce realistic text, images, and other human-like outputs is currently transforming many different industries. Yet it is not yet known how such tools might influence social science research. I argue Generative AI has the potential to improve survey research, online experiments, automated content analyses, agent-based models, and other techniques commonly used to study human behavior. In the second section of this article, I discuss the many limitations of Generative AI. I examine how bias in the data used to train these tools can negatively impact social science research\u2014as well as a range of other challenges related to ethics, replication, environmental impact, and the proliferation of low-quality research. I conclude by arguing that social scientists can address many of these limitations by creating open-source infrastructure for research on human behavior. Such infrastructure is not only necessary to ensure broad access to high-quality research tools, I argue, but also because the progress of AI will require deeper understanding of the social forces that guide human behavior.", "isOpenAccess": true, "url": "https://doi.org/10.1073/pnas.2314021121"}
{"paperId": "e3bbf0950ba0bc31ba991fdbfbd75b25ca3241ed", "year": 2023, "title": "Exploring the Potential Impact of Artificial Intelligence (AI) on International Students in Higher Education: Generative AI, Chatbots, Analytics, and International Student Success", "authors": "Ting Wang, Brady D. Lund, A. Marengo, A. Pagano, Nishith Reddy Mannuru, Z. A. Teel, J. Pange", "venue": "Applied Sciences", "citationCount": 273, "abstract": "International students face unique challenges in pursuing higher education in a foreign country. To address these challenges and enhance their academic experience, higher education institutions are increasingly exploring the use of artificial intelligence (AI) applications. This research essay aims to investigate the impact of AI on the education of international students. Instead of a traditional literature review, it employs a research approach to examine the potential applications of AI and discuss associated concerns. The research paper explores various AI applications, such as personalized learning experiences, adaptive testing, predictive analytics, and chatbots for learning and research. By analyzing the role of AI in education for international students, this research paper sheds light on how AI can improve learning efficiency and provide customized educational support. Additionally, it identifies significant risks and limitations, including privacy concerns, cultural differences, language proficiency, and ethical implications, which must be effectively addressed. The findings contribute to a better understanding of the potential impact of AI on international students\u2019 educational experiences and offer insights into the integration of AI into educational administration and learning processes.", "isOpenAccess": true, "url": "https://www.mdpi.com/2076-3417/13/11/6716/pdf?version=1685584918"}
{"paperId": "140ba5bc544b67adef630565a36ee045d6069ef4", "year": 2024, "title": "Future research recommendations for transforming higher education with generative AI", "authors": "T. Chiu", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 273, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2023.100197"}
{"paperId": "7a5b44ea10a51708e18786595c8d70b18950da11", "year": 2023, "title": "FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios", "authors": "Ethan Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu", "venue": "arXiv.org", "citationCount": 269, "abstract": "The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.13528"}
{"paperId": "c7492913370b5726eaa6ced163a60de6c9d4bb7f", "year": 2023, "title": "A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics", "authors": "Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria", "venue": "Information Fusion", "citationCount": 262, "abstract": "The utilization of large language models (LLMs) in the Healthcare domain has generated both excitement and concern due to their ability to effectively respond to freetext queries with certain professional knowledge. This survey outlines the capabilities of the currently developed LLMs for Healthcare and explicates their development process, with the aim of providing an overview of the development roadmap from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, as well as comparing various LLMs with each other. Then we summarize related Healthcare training data, training methods, optimization strategies, and usage. Finally, the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics. Our survey provide a comprehensive investigation from perspectives of both computer science and Healthcare specialty. Besides the discussion about Healthcare concerns, we supports the computer science community by compiling a collection of open source resources, such as accessible datasets, the latest methodologies, code implementations, and evaluation benchmarks in the Github. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well as a shift from model-centered methodologies to data-centered methodologies. Also, we determine that the biggest obstacle of using LLMs in Healthcare are fairness, accountability, transparency and ethics.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.05694"}
{"paperId": "7a36247b89384236e795c5bbddba1bdb68c5bf28", "year": 2023, "title": "A large-scale comparison of human-written versus ChatGPT-generated essays", "authors": "Steffen Herbold, Annette Hautli-Janisz, Ute Heuer, Zlata Kikteva, Alexander Trautsch", "venue": "Scientific Reports", "citationCount": 262, "abstract": "ChatGPT and similar generative AI models have attracted hundreds of millions of users and have become part of the public discourse. Many believe that such models will disrupt society and lead to significant changes in the education system and information generation. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models\u2014both lack scientific rigor. We systematically assess the quality of AI-generated content through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays. We use essays that were rated by a large number of human experts (teachers). We augment the analysis by considering a set of linguistic characteristics of the generated essays. Our results demonstrate that ChatGPT generates essays that are rated higher regarding quality than human-written essays. The writing style of the AI models exhibits linguistic characteristics that are different from those of the human-written essays. Since the technology is readily available, we believe that educators must act immediately. We must re-invent homework and develop teaching concepts that utilize these AI models in the same way as math utilizes the calculator: teach the general concepts first and then use AI tools to free up time for other learning objectives.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-023-45644-9.pdf"}
{"paperId": "16cabd6f8d93f77e175f217865d7b515d3612cc1", "year": 2023, "title": "TPACK in the age of ChatGPT and Generative AI", "authors": "Punya Mishra, Melissa Warr, Rezwana Islam", "venue": "Journal of Digital Learning in Teacher Education", "citationCount": 256, "abstract": "Abstract The educational impact of Generative AI (GenAI) technologies, such as ChatGPT, has received significant attention. We use the TPACK framework to discuss the types of knowledge teachers require to effectively use GenAI tools. We highlight the qualities of GenAI that make it like other digital technologies (they are protean, opaque, and unstable) as well as qualities that make it revolutionary (namely, they are generative and social). We describe how these traits affect specific knowledge domains (TK, TPK, TCK, XK, and TPACK) and explore implications for educators. Finally, we argue for a more expansive description of Contextual Knowledge (XK), going beyond the immediate context to include considerations of how GenAI will change individuals, society and, through that, the broader educational context.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/21532974.2023.2247480?needAccess=true"}
{"paperId": "e5148e92d74dc1f2c0aa59282aa8d83f4a1b9221", "year": 2024, "title": "Generative AI and the future of higher education: a threat to academic integrity or reformation? Evidence from multicultural perspectives", "authors": "Abdullahi Yusuf, Nasrin Pervin, Marcos Rom\u00e1n-Gonz\u00e1lez", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 255, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "7dbd3d51c453caf77cc1f9681f9b888095b97443", "year": 2023, "title": "AI Art and its Impact on Artists", "authors": "Harry H. Jiang, Lauren Brown, Jessica Cheng, Mehtab Khan, Abhishek Gupta, Deja Workman, A. Hanna, J. Flowers, Timnit Gebru", "venue": "AAAI/ACM Conference on AI, Ethics, and Society", "citationCount": 252, "abstract": "The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial \u201cgenerative AI Art\u201d products have entered the market, making generative AI an estimated $48B industry [125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604681"}
{"paperId": "bdd325fa62eef7e8ba04e3694dc13554e9e06344", "year": 2023, "title": "ChatGPT and Generative AI: Possibilities for Its Contribution to Lesson Planning, Critical Thinking and Openness in Teacher Education", "authors": "G. van den Berg, Elize du Plessis", "venue": "Education sciences", "citationCount": 251, "abstract": "Although artificial intelligence (AI) has been part of our lives for some time, the launch of the Generative Pretrained Transformer (ChatGPT) has given it renewed attention. While most of these debates are about higher education in general, this article focuses on schoolteacher education and teacher training. This research aimed to determine the contribution of generative AI tools such as ChatGPT in lesson planning, critical thinking and openness in education. The research used a qualitative approach and document analysis following an interpretative paradigm. The findings reveal that generative language models such as ChatGPT can provide specific materials and support mechanisms, such as lesson plans, to schoolteachers and student teachers. It also showed that ChatGPT has levelled the playing field by opening access to lesson plans to all teachers. However, to unleash their full potential for education, it is crucial to approach these models with caution and critically evaluate their limitations and potential biases, understanding that they are tools to support teaching and learning and do not replace teachers. The study\u2019s contribution lies in ChatGPT-generated lesson plans\u2019 implications and the enhancement of critical thinking for teacher education, and it also underscores the need for further research to explore best practices for integrating ChatGPT in lesson planning.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/13/10/998/pdf?version=1695975610"}
{"paperId": "7f4ed88e626ae733bc95406c60087d903b6b41a4", "year": 2023, "title": "Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review", "authors": "C. Preiksaitis, Christian Rose", "venue": "JMIR Medical Education", "citationCount": 243, "abstract": "Background Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications. Objective This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration. Methods We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data. Results Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners\u2019 skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions. Conclusions The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.", "isOpenAccess": true, "url": "https://jmir.org/api/download?alt_name=mededu_v9i1e48785_app3.pdf&filename=901c3f3577ab069158ca4f422af6b957.pdf"}
{"paperId": "c4d96dfef7b67ea371354b416d1e458aa65f8177", "year": 2023, "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?", "authors": "\u00d6mer Ayd\u0131n, Enis Karaarslan", "venue": "Social Science Research Network", "citationCount": 241, "abstract": "Generative AI has the potential to change the way we do things. The chatbot is one of the most popular implementation areas. Even though companies like Google and Meta had chatbots, ChatGPT became popular as it was made publicly available. Although ChatGPT is still in the early stages of its development, it attracted the attention of people and capital groups. It has taken the public interest; people from different fields, ages, and education levels started using ChatGPT. There have been many trials with ChatGPT. It is possible to see a lot of news and shares on the Internet. The study aims to shed light on what is happening in the literature and get an insight into the user expectations of ChatGPT and Generative AI. We also give information about the competitors of ChatGPT, such as Google\u2019s Bard AI, Claude, Meta\u2019s Wit.ai and Tencent\u2019s HunyuanAide. We describe technical and structural fundamentals and try to shed light on who will win the race. We also shared information about the GPT4 version of OpenAI's ChatGPT. We share the early stage due diligence and current situation analysis for all these points. We examine preprint papers and published articles. We also included striking posts on the LinkedIn platform and a compilation of various blogs and news. We also made use of ChatGPT in editing the content of these resources of this study. We can get an insight into the people's interests through their questions submitted to ChatGPT. We can also understand the capabilities of GPT3, GPT4 and also predict further enhancements.", "isOpenAccess": true, "url": "https://dergipark.org.tr/tr/download/article-file/3127764"}
{"paperId": "9f411fda2ad5b141a3115f707bcf5ee865b3fb94", "year": 2023, "title": "Any-to-Any Generation via Composable Diffusion", "authors": "Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, Mohit Bansal", "venue": "Neural Information Processing Systems", "citationCount": 241, "abstract": "We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities. Unlike existing generative AI systems, CoDi can generate multiple modalities in parallel and its input is not limited to a subset of modalities like text or image. Despite the absence of training datasets for many combinations of modalities, we propose to align modalities in both the input and output space. This allows CoDi to freely condition on any input combination and generate any group of modalities, even if they are not present in the training data. CoDi employs a novel composable generation strategy which involves building a shared multimodal space by bridging alignment in the diffusion process, enabling the synchronized generation of intertwined modalities, such as temporally aligned video and audio. Highly customizable and flexible, CoDi achieves strong joint-modality generation quality, and outperforms or is on par with the unimodal state-of-the-art for single-modality synthesis. The project page with demonstrations and code is at https://codi-gen.github.io", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.11846"}
{"paperId": "bb60d51630a649535ed3d1bcb445524fbae6cf0b", "year": 2023, "title": "Generative AI in Medicine and Healthcare: Promises, Opportunities and Challenges", "authors": "Peng Zhang, M. Boulos", "venue": "Future Internet", "citationCount": 240, "abstract": "Generative AI (artificial intelligence) refers to algorithms and models, such as OpenAI\u2019s ChatGPT, that can be prompted to generate various types of content. In this narrative review, we present a selection of representative examples of generative AI applications in medicine and healthcare. We then briefly discuss some associated issues, such as trust, veracity, clinical safety and reliability, privacy, copyrights, ownership, and opportunities, e.g., AI-driven conversational user interfaces for friendlier human-computer interaction. We conclude that generative AI will play an increasingly important role in medicine and healthcare as it further evolves and gets better tailored to the unique settings and requirements of the medical domain and as the laws, policies and regulatory frameworks surrounding its use start taking shape.", "isOpenAccess": true, "url": "https://www.mdpi.com/1999-5903/15/9/286/pdf?version=1692864615"}
{"paperId": "dfc66a53c836846d524765f44e111c94ebd2ad37", "year": 2023, "title": "Impact of Artificial Intelligence on Dental Education: A Review and Guide for Curriculum Update", "authors": "Andrej Thurzo, Martin Strunga, R. Urban, Jana Surovkov\u00e1, K. Afrashtehfar", "venue": "Education sciences", "citationCount": 237, "abstract": "In this intellectual work, the clinical and educational aspects of dentistry were confronted with practical applications of artificial intelligence (AI). The aim was to provide an up-to-date overview of the upcoming changes and a brief analysis of the influential advancements in the use of AI in dental education since 2020. In addition, this review provides a guide for a dental curriculum update for undergraduate and postgraduate education in the context of advances in AI applications and their impact on dentistry. Unsurprisingly, most dental educators have limited knowledge and skills to assess AI applications, as they were not trained to do so. Also, AI technology has evolved exponentially in recent years. Factual reliability and opportunities with OpenAI Inc.\u2019s ChatGPT are considered critical inflection points in the era of generative AI. Updating curricula at dental institutions is inevitable as advanced deep-learning approaches take over the clinical areas of dentistry and reshape diagnostics, treatment planning, management, and telemedicine screening. With recent advances in AI language models, communication with patients will change, and the foundations of dental education, including essay, thesis, or scientific paper writing, will need to adapt. However, there is a growing concern about its ethical and legal implications, and further consensus is needed for the safe and responsible implementation of AI in dental education.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/13/2/150/pdf?version=1675840149"}
{"paperId": "fc819b599d6897fe1dc09961e201489e136558eb", "year": 2023, "title": "ChatGPT and Generative Artificial Intelligence for Medical Education: Potential Impact and Opportunity", "authors": "C. Boscardin, Brian C. Gin, Polo Black Golde, K. Hauer", "venue": "Academic medicine : journal of the Association of American Medical Colleges", "citationCount": 232, "abstract": "Abstract ChatGPT has ushered in a new era of artificial intelligence (AI) that already has significant consequences for many industries, including health care and education. Generative AI tools, such as ChatGPT, refer to AI that is designed to create or generate new content, such as text, images, or music, from their trained parameters. With free access online and an easy-to-use conversational interface, ChatGPT quickly accumulated more than 100 million users within the first few months of its launch. Recent headlines in the popular press have ignited concerns relevant to medical education over the possible implications of cheating and plagiarism in assessments as well as excitement over new opportunities for learning, assessment, and research. In this Scholarly Perspective, the authors offer insights and recommendations about generative AI for medical educators based on literature review, including the AI literacy framework. The authors provide a definition of generative AI, introduce an AI literacy framework and competencies, and offer considerations for potential impacts and opportunities to optimize integration of generative AI for admissions, learning, assessment, and medical education research to help medical educators navigate and start planning for this new environment. As generative AI tools continue to expand, educators need to increase their AI literacy through education and vigilance around new advances in the technology and serve as stewards of AI literacy to foster social responsibility and ethical awareness around the use of AI.", "isOpenAccess": true, "url": "https://www.ets.berkeley.edu/sites/default/files/general/uc_learning_data_principles_final03.05.2018.pdf"}
{"paperId": "be2d38e0233ee2ef94eb05ecfe6f8bb5cf328a36", "year": 2023, "title": "Computing Education in the Era of Generative AI", "authors": "Paul Denny, J. Prather, Brett A. Becker, James Finnie-Ansley, Arto Hellas, Juho Leinonen, Andrew Luxton-Reilly, B. Reeves, E. Santos, Sami Sarsa", "venue": "Communications of the ACM", "citationCount": 232, "abstract": "Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3624720"}
{"paperId": "69a4cb1a3d84e924ab79848910507ee34e80150a", "year": 2023, "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being", "authors": "Han Li, Renwen Zhang, Yi-Chieh Lee, Robert E. Kraut, David C. Mohr", "venue": "npj Digit. Medicine", "citationCount": 230, "abstract": "Conversational artificial intelligence (AI), particularly AI-based conversational agents (CAs), is gaining traction in mental health care. Despite their growing usage, there is a scarcity of comprehensive evaluations of their impact on mental health and well-being. This systematic review and meta-analysis aims to fill this gap by synthesizing evidence on the effectiveness of AI-based CAs in improving mental health and factors influencing their effectiveness and user experience. Twelve databases were searched for experimental studies of AI-based CAs\u2019 effects on mental illnesses and psychological well-being published before May 26, 2023. Out of 7834 records, 35 eligible studies were identified for systematic review, out of which 15 randomized controlled trials were included for meta-analysis. The meta-analysis revealed that AI-based CAs significantly reduce symptoms of depression (Hedge\u2019s g 0.64 [95% CI 0.17\u20131.12]) and distress (Hedge\u2019s g 0.7 [95% CI 0.18\u20131.22]). These effects were more pronounced in CAs that are multimodal, generative AI-based, integrated with mobile/instant messaging apps, and targeting clinical/subclinical and elderly populations. However, CA-based interventions showed no significant improvement in overall psychological well-being (Hedge\u2019s g 0.32 [95% CI \u20130.13 to 0.78]). User experience with AI-based CAs was largely shaped by the quality of human-AI therapeutic relationships, content engagement, and effective communication. These findings underscore the potential of AI-based CAs in addressing mental health issues. Future research should investigate the underlying mechanisms of their effectiveness, assess long-term effects across various mental health outcomes, and evaluate the safe integration of large language models (LLMs) in mental health care.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-023-00979-5.pdf"}
{"paperId": "b50465f4c93714ce5df1b6e56dd1952080d019a8", "year": 2024, "title": "Durably reducing conspiracy beliefs through dialogues with AI", "authors": "Thomas H. Costello, Gordon Pennycook, David G. Rand", "venue": "Science", "citationCount": 226, "abstract": "Conspiracy theory beliefs are notoriously persistent. Influential hypotheses propose that they fulfill important psychological needs, thus resisting counterevidence. Yet previous failures in correcting conspiracy beliefs may be due to counterevidence being insufficiently compelling and tailored. To evaluate this possibility, we leveraged developments in generative artificial intelligence and engaged 2190 conspiracy believers in personalized evidence-based dialogues with GPT-4 Turbo. The intervention reduced conspiracy belief by ~20%. The effect remained 2 months later, generalized across a wide range of conspiracy theories, and occurred even among participants with deeply entrenched beliefs. Although the dialogues focused on a single conspiracy, they nonetheless diminished belief in unrelated conspiracies and shifted conspiracy-related behavioral intentions. These findings suggest that many conspiracy theory believers can revise their views if presented with sufficiently compelling evidence. Editor\u2019s summary Beliefs in conspiracies that a US election was stolen incited an attempted insurrection on 6 January 2021. Another conspiracy alleging that Germany\u2019s COVID-19 restrictions were motivated by nefarious intentions sparked violent protests at Berlin\u2019s Reichstag parliament building in August 2020. Amid growing threats to democracy, Costello et al. investigated whether dialogs with a generative artificial intelligence (AI) interface could convince people to abandon their conspiratorial beliefs (see the Perspective by Bago and Bonnefon). Human participants described a conspiracy theory that they subscribed to, and the AI then engaged in persuasive arguments with them that refuted their beliefs with evidence. The AI chatbot\u2019s ability to sustain tailored counterarguments and personalized in-depth conversations reduced their beliefs in conspiracies for months, challenging research suggesting that such beliefs are impervious to change. This intervention illustrates how deploying AI may mitigate conflicts and serve society. \u2014Ekeoma Uzogara INTRODUCTION Widespread belief in unsubstantiated conspiracy theories is a major source of public concern and a focus of scholarly research. Despite often being quite implausible, many such conspiracies are widely believed. Prominent psychological theories propose that many people want to adopt conspiracy theories (to satisfy underlying psychic \u201cneeds\u201d or motivations), and thus, believers cannot be convinced to abandon these unfounded and implausible beliefs using facts and counterevidence. Here, we question this conventional wisdom and ask whether it may be possible to talk people out of the conspiratorial \u201crabbit hole\u201d with sufficiently compelling evidence. RATIONALE We hypothesized that interventions based on factual, corrective information may seem ineffective simply because they lack sufficient depth and personalization. To test this hypothesis, we leveraged advancements in large language models (LLMs), a form of artificial intelligence (AI) that has access to vast amounts of information and the ability to generate bespoke arguments. LLMs can thereby directly refute particular evidence each individual cites as supporting their conspiratorial beliefs. To do so, we developed a pipeline for conducting behavioral science research using real-time, personalized interactions between research subjects and AI. Across two experiments, 2190 Americans articulated\u2014in their own words\u2014a conspiracy theory in which they believe, along with the evidence they think supports this theory. They then engaged in a three-round conversation with the LLM GPT-4 Turbo, which we prompted to respond to this specific evidence while trying to reduce participants\u2019 belief in the conspiracy theory (or, as a control condition, to converse with the AI about an unrelated topic). RESULTS The treatment reduced participants\u2019 belief in their chosen conspiracy theory by 20% on average. This effect persisted undiminished for at least 2 months; was consistently observed across a wide range of conspiracy theories, from classic conspiracies involving the assassination of John F. Kennedy, aliens, and the illuminati, to those pertaining to topical events such as COVID-19 and the 2020 US presidential election; and occurred even for participants whose conspiracy beliefs were deeply entrenched and important to their identities. Notably, the AI did not reduce belief in true conspiracies. Furthermore, when a professional fact-checker evaluated a sample of 128 claims made by the AI, 99.2% were true, 0.8% were misleading, and none were false. The debunking also spilled over to reduce beliefs in unrelated conspiracies, indicating a general decrease in conspiratorial worldview, and increased intentions to rebut other conspiracy believers. CONCLUSION Many people who strongly believe in seemingly fact-resistant conspiratorial beliefs can change their minds when presented with compelling evidence. From a theoretical perspective, this paints a surprisingly optimistic picture of human reasoning: Conspiratorial rabbit holes may indeed have an exit. Psychological needs and motivations do not inherently blind conspiracists to evidence\u2014it simply takes the right evidence to reach them. Practically, by demonstrating the persuasive power of LLMs, our findings emphasize both the potential positive impacts of generative AI when deployed responsibly and the pressing importance of minimizing opportunities for this technology to be used irresponsibly. Dialogues with AI durably reduce conspiracy beliefs even among strong believers. (Left) Average belief in participant\u2019s chosen conspiracy theory by condition (treatment, in which the AI attempted to refute the conspiracy theory, in red; control, in which the AI discussed an irrelevant topic, in blue) and time point for study 1. (Right) Change in belief in chosen conspiracy from before to after AI conversation, by condition and participant\u2019s pretreatment belief in the conspiracy.", "isOpenAccess": true, "url": "https://osf.io/xcwdn/download"}
{"paperId": "ad022cd5da75637ac3e0a8f8cc4f0d394ba5ff7a", "year": 2023, "title": "Self-Consuming Generative Models Go MAD", "authors": "Sina Alemohammad, Josue Casco-Rodriguez, L. Luzi, Ahmed Imtiaz Humayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, Richard Baraniuk", "venue": "International Conference on Learning Representations", "citationCount": 226, "abstract": "Seismic advances in generative AI algorithms have led to the temptation to use AI-synthesized data to train next-generation models. Repeating this process creates autophagous (\u201cself-consuming\u201d) loops whose properties are poorly understood. We conduct a thorough analysis using state-of-the-art generative image models of three autophagous loop families that differ in how they incorporate fixed or fresh real training data and whether previous generations' samples have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD) and show that appreciable MADness arises in just a few generations.", "isOpenAccess": true, "url": "https://doi.org/10.52591/lxai202312101"}
{"paperId": "276f6117b8b8549a47461653b95e657278260ee3", "year": 2023, "title": "HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models", "authors": "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Wei Wei, Tingbo Hou, Y. Pritch, N. Wadhwa, Michael Rubinstein, Kfir Aberman", "venue": "Computer Vision and Pattern Recognition", "citationCount": 226, "abstract": "Personalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities. However, the process of personalization presents inherent challenges in terms of time and memory requirements. Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity. To overcome these challenges, we propose HyperDreamBooth\u2014a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person. By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications. Our method achieves personalization on faces in roughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual Inversion, using as few as one reference image, with the same quality and style diversity as DreamBooth. Also our method yields a model that is 10,000x smaller than a normal DreamBooth model.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.06949"}
{"paperId": "4a597a081721e436e20b4e85197072e22aaecfad", "year": 2024, "title": "From $r$ to $Q^*$: Your Language Model is Secretly a Q-Function", "authors": "Rafael Rafailov, Joey Hejna, Ryan Park, Chelsea Finn", "venue": "", "citationCount": 220, "abstract": "Reinforcement Learning From Human Feedback (RLHF) has been critical to the success of the latest generation of generative AI models. In response to the complex nature of the classical RLHF pipeline, direct alignment algorithms such as Direct Preference Optimization (DPO) have emerged as an alternative approach. Although DPO solves the same objective as the standard RLHF setup, there is a mismatch between the two approaches. Standard RLHF deploys reinforcement learning in a specific token-level MDP, while DPO is derived as a bandit problem in which the whole response of the model is treated as a single arm. In this work we rectify this difference. We theoretically show that we can derive DPO in the token-level MDP as a general inverse Q-learning algorithm, which satisfies the Bellman equation. Using our theoretical results, we provide three concrete empirical insights. First, we show that because of its token level interpretation, DPO is able to perform some type of credit assignment. Next, we prove that under the token level formulation, classical search-based algorithms, such as MCTS, which have recently been applied to the language generation space, are equivalent to likelihood-based search on a DPO policy. Empirically we show that a simple beam search yields meaningful improvement over the base DPO policy. Finally, we show how the choice of reference policy causes implicit rewards to decline during training. We conclude by discussing applications of our work, including information elicitation in multi-turn dialogue, reasoning, agentic applications and end-to-end training of multi-model systems.", "isOpenAccess": false, "url": ""}
{"paperId": "441922f7ed3a91c5ef9fdac7025bc67012a88815", "year": 2024, "title": "Generative artificial intelligence, human creativity, and art", "authors": "Eric Zhou, Dokyun Lee", "venue": "PNAS Nexus", "citationCount": 220, "abstract": "Abstract Recent artificial intelligence (AI) tools have demonstrated the ability to produce outputs traditionally considered creative. One such system is text-to-image generative AI (e.g. Midjourney, Stable Diffusion, DALL-E), which automates humans\u2019 artistic execution to generate digital artworks. Utilizing a dataset of over 4 million artworks from more than 50,000 unique users, our research shows that over time, text-to-image AI significantly enhances human creative productivity by 25% and increases the value as measured by the likelihood of receiving a favorite per view by 50%. While peak artwork Content Novelty, defined as focal subject matter and relations, increases over time, average Content Novelty declines, suggesting an expanding but inefficient idea space. Additionally, there is a consistent reduction in both peak and average Visual Novelty, captured by pixel-level stylistic elements. Importantly, AI-assisted artists who can successfully explore more novel ideas, regardless of their prior originality, may produce artworks that their peers evaluate more favorably. Lastly, AI adoption decreased value capture (favorites earned) concentration among adopters. The results suggest that ideation and filtering are likely necessary skills in the text-to-image process, thus giving rise to \u201cgenerative synesthesia\u201d\u2014the harmonious blending of human exploration and AI exploitation to discover new creative workflows.", "isOpenAccess": true, "url": "https://academic.oup.com/pnasnexus/article-pdf/3/3/pgae052/56825840/pgae052.pdf"}
{"paperId": "dc49bcf9701e262ee55be92ff67a686002e61845", "year": 2023, "title": "Generative AI tools and assessment: Guidelines of the world's top-ranking universities", "authors": "Benjamin Luke Moorhouse, Marie Alina Yeo, Yuwei Wan", "venue": "Computers and Education Open", "citationCount": 219, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeo.2023.100151"}
{"paperId": "1c2fc6f6e9f22e109144e1dd01097b20fc86d530", "year": 2024, "title": "The potential of generative AI for personalized persuasion at scale", "authors": "S. C. Matz, J. D. Teeny, S. Vaid, H. Peters, G. M. Harari, M. Cerf", "venue": "Scientific Reports", "citationCount": 217, "abstract": "Matching the language or content of a message to the psychological profile of its recipient (known as \u201cpersonalized persuasion\u201d) is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N\u2009=\u20091788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-024-53755-0.pdf"}
{"paperId": "93a07d548608d2368ae2e3287275e3caf42a562c", "year": 2025, "title": "The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers", "authors": "Hao-Ping Lee, Advait Sarkar, Lev Tankelevitch, Ian Drosos, Sean Rintel, Richard Banks, Nicholas Wilson", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 216, "abstract": "The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user\u2019s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.", "isOpenAccess": false, "url": ""}
{"paperId": "4299b79ef41601cf6e3e0603f7216d72b6d1315f", "year": 2024, "title": "TripoSR: Fast 3D Object Reconstruction from a Single Image", "authors": "Dmitry Tochilkin, David Pankratz, Zexiang Liu, Zixuan Huang, Adam Letts, Yangguang Li, Ding Liang, Christian Laforte, Varun Jampani, Yan-Pei Cao", "venue": "arXiv.org", "citationCount": 213, "abstract": "This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0.5 seconds. Building upon the LRM network architecture, TripoSR integrates substantial improvements in data processing, model design, and training techniques. Evaluations on public datasets show that TripoSR exhibits superior performance, both quantitatively and qualitatively, compared to other open-source alternatives. Released under the MIT license, TripoSR is intended to empower researchers, developers, and creatives with the latest advancements in 3D generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "c889cdd52db3ec7a8f8270ce80e010d2725aede2", "year": 2023, "title": "Educational Design Principles of Using AI Chatbot That Supports Self-Regulated Learning in Education: Goal Setting, Feedback, and Personalization", "authors": "Daniel H. Chang, M. P. Lin, Shiva Hajian, Quincy Q. Wang", "venue": "Sustainability", "citationCount": 212, "abstract": "The invention of ChatGPT and generative AI technologies presents educators with significant challenges, as concerns arise regarding students potentially exploiting these tools unethically, misrepresenting their work, or gaining academic merits without active participation in the learning process. To effectively navigate this shift, it is crucial to embrace AI as a contemporary educational trend and establish pedagogical principles for properly utilizing emerging technologies like ChatGPT to promote self-regulation. Rather than suppressing AI-driven tools, educators should foster collaborations among stakeholders, including educators, instructional designers, AI researchers, and developers. This paper proposes three key pedagogical principles for integrating AI chatbots in classrooms, informed by Zimmerman\u2019s Self-Regulated Learning (SRL) framework and Judgment of Learning (JOL). We argue that the current conceptualization of AI chatbots in education is inadequate, so we advocate for the incorporation of goal setting (prompting), self-assessment and feedback, and personalization as three essential educational principles. First, we propose that teaching prompting is important for developing students\u2019 SRL. Second, configuring reverse prompting in the AI chatbot\u2019s capability will help to guide students\u2019 SRL and monitoring for understanding. Third, developing a data-driven mechanism that enables an AI chatbot to provide learning analytics helps learners to reflect on learning and develop SRL strategies. By bringing in Zimmerman\u2019s SRL framework with JOL, we aim to provide educators with guidelines for implementing AI in teaching and learning contexts, with a focus on promoting students\u2019 self-regulation in higher education through AI-assisted pedagogy and instructional design.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/15/17/12921/pdf?version=1693121769"}
{"paperId": "7b8adaf54e073280b65b805c5cdd51b54712f21f", "year": 2024, "title": "Drivers of generative AI adoption in higher education through the lens of the theory of planned behaviour", "authors": "Stanislav Ivanov, Mohammad Soliman, Aarni Tuomi, N. Alkathiri, Alamir N. Al-Alawi", "venue": "Technology and Society", "citationCount": 211, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.techsoc.2024.102521"}
{"paperId": "58a2e303794622205ef3982e0b4fa34bcd8bd487", "year": 2023, "title": "Reconceptualizing ChatGPT and generative AI as a student-driven innovation in higher education", "authors": "Yun Dai, Ang Liu, Cher Ping Lim", "venue": "Procedia CIRP", "citationCount": 210, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.procir.2023.05.002"}
{"paperId": "67b85fb551db8d708156d66e5250a2b0ccc01036", "year": 2023, "title": "Generative Ai: Here to Stay, But for Good?", "authors": "H. S\u00e6tra", "venue": "Social Science Research Network", "citationCount": 209, "abstract": null, "isOpenAccess": true, "url": "https://hiof.brage.unit.no/hiof-xmlui/bitstream/11250/3096766/1/SaetraGenerative2023.pdf"}
{"paperId": "5b8b994117d9d3273d91e9c671da495e9e20e889", "year": 2024, "title": "Generative artificial intelligence: a systematic review and applications", "authors": "S. S. Sengar, Affan Bin Hasan, Sanjay Kumar, Fiona Carroll", "venue": "Multimedia tools and applications", "citationCount": 207, "abstract": "In recent years, the study of artificial intelligence (AI) has undergone a paradigm shift. This has been propelled by the groundbreaking capabilities of generative models both in supervised and unsupervised learning scenarios. Generative AI has shown state-of-the-art performance in solving perplexing real-world conundrums in fields such as image translation, medical diagnostics, textual imagery fusion, natural language processing, and beyond. This paper documents the systematic review and analysis of recent advancements and techniques in Generative AI with a detailed discussion of their applications including application-specific models. Indeed, the major impact that generative AI has made to date, has been in language generation with the development of large language models, in the field of image translation and several other interdisciplinary applications of generative AI. Moreover, the primary contribution of this paper lies in its coherent synthesis of the latest advancements in these areas, seamlessly weaving together contemporary breakthroughs in the field. Particularly, how it shares an exploration of the future trajectory for generative AI. In conclusion, the paper ends with a discussion of Responsible AI principles, and the necessary ethical considerations for the sustainability and growth of these generative models.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s11042-024-20016-1"}
{"paperId": "fb0a138e8b39bb55745e81122b313e7ceae573c8", "year": 2023, "title": "Autonomous travel decision-making: An early glimpse into ChatGPT and generative AI", "authors": "I. Wong, Qi Lilith Lian, Danni Sun", "venue": "Journal of Hospitality and Tourism Management", "citationCount": 205, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "5f8bf881c80125452e4a73ad51fdb2c72c65c551", "year": 2023, "title": "Cultural bias and cultural alignment of large language models", "authors": "Yan Tao, Olga Viberg, Ryan S. Baker, Ren\u00e9 F. Kizilcec", "venue": "PNAS Nexus", "citationCount": 202, "abstract": "Abstract Culture fundamentally shapes people\u2019s reasoning, behavior, and communication. As people increasingly use generative artificial intelligence (AI) to expedite and automate personal and professional tasks, cultural values embedded in AI models may bias people\u2019s authentic expression and contribute to the dominance of certain cultures. We conduct a disaggregated evaluation of cultural bias for five widely used large language models (OpenAI\u2019s GPT-4o/4-turbo/4/3.5-turbo/3) by comparing the models\u2019 responses to nationally representative survey data. All models exhibit cultural values resembling English-speaking and Protestant European countries. We test cultural prompting as a control strategy to increase cultural alignment for each country/territory. For later models (GPT-4, 4-turbo, 4o), this improves the cultural alignment of the models\u2019 output for 71\u201381% of countries and territories. We suggest using cultural prompting and ongoing evaluation to reduce cultural bias in the output of generative AI.", "isOpenAccess": true, "url": "https://doi.org/10.1093/pnasnexus/pgae346"}
{"paperId": "515db5fefd215c05649aaa5adc4d64075d2518ab", "year": 2024, "title": "Design Principles for Generative AI Applications", "authors": "Justin D. Weisz, Jessica He, Michael Muller, Gabriela Hoefer, Rachel Miles, Werner Geyer", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 202, "abstract": "Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642466"}
{"paperId": "402303ecf9fe73d152543a4e78d4014f1c7e2df2", "year": 2024, "title": "Artificial Intelligence for Predictive Maintenance Applications: Key Components, Trustworthiness, and Future Trends", "authors": "Aysegul Ucar, Mehmet Karakose, Necim K\u0131r\u0131m\u00e7a", "venue": "Applied Sciences", "citationCount": 202, "abstract": "Predictive maintenance (PdM) is a policy applying data and analytics to predict when one of the components in a real system has been destroyed, and some anomalies appear so that maintenance can be performed before a breakdown takes place. Using cutting-edge technologies like data analytics and artificial intelligence (AI) enhances the performance and accuracy of predictive maintenance systems and increases their autonomy and adaptability in complex and dynamic working environments. This paper reviews the recent developments in AI-based PdM, focusing on key components, trustworthiness, and future trends. The state-of-the-art (SOTA) techniques, challenges, and opportunities associated with AI-based PdM are first analyzed. The integration of AI technologies into PdM in real-world applications, the human\u2013robot interaction, the ethical issues emerging from using AI, and the testing and validation abilities of the developed policies are later discussed. This study exhibits the potential working areas for future research, such as digital twin, metaverse, generative AI, collaborative robots (cobots), blockchain technology, trustworthy AI, and Industrial Internet of Things (IIoT), utilizing a comprehensive survey of the current SOTA techniques, opportunities, and challenges allied with AI-based PdM.", "isOpenAccess": true, "url": "https://www.mdpi.com/2076-3417/14/2/898/pdf?version=1705890862"}
{"paperId": "5a5e03c3c8bf5052a99f4631e874b1e608e59319", "year": 2023, "title": "Artificial intelligence in developing countries: The impact of generative artificial intelligence (AI) technologies for development", "authors": "Nishith Reddy Mannuru, Sakib Shahriar, Z. A. Teel, Ting Wang, Brady D. Lund, Solomon Tijani, Chalermchai Oak Pohboon, Daniel A. Agbaji, Joy Alhassan, JaKLyn Galley, Raana Kousari, Lydia Ogbadu-Oladapo, Shubham Kumar Saurav, Aishwarya Srivastava, Sai Priya Tummuru, Sravya Uppala, Praveenkumar Vaidya", "venue": "Information Development", "citationCount": 201, "abstract": "This paper explores the potential impact of Generative Artificial Intelligence (Generative AI) on developing countries, considering both positive and negative effects across various domains of information, culture, and industry. Generative Artificial Intelligence refers to artificial intelligence (AI) systems that generate content, such as text, audio, or video, aiming to produce novel and creative outputs based on training data. Compared to conversational artificial intelligence, generative artificial intelligence systems have the unique capability of not only providing replies but also generating the content of those responses. Recent advancements in Artificial Intelligence during the Fourth Industrial Revolution, exemplified by tools like ChatGPT, have gained popularity and reshaped content production and creation. However, the benefits of generative artificial intelligence are not equally accessible to all, especially in developing countries, where limited access to cutting-edge technologies and inadequate infrastructure pose challenges. This paper seeks to understand the potential impact of generative AI technologies on developing countries, considering economic growth, access to technology, and the potential paradigm shift in education, healthcare, and the environment. The findings emphasize the importance of providing the necessary support and infrastructure to ensure that generative AI contributes to inclusive development rather than deepening existing inequalities. The study highlights the significance of integrating Generative AI into the context of the Fourth Industrial Revolution in developing countries, where technological change is a crucial determinant of progress and equitable growth.", "isOpenAccess": false, "url": ""}
{"paperId": "d0c48d3b80efb9c170e7100cb9d78d1e7f7710bf", "year": 2023, "title": "Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration", "authors": "Ping Yu, Hua Xu, Xia Hu, C. Deng", "venue": "Healthcare", "citationCount": 200, "abstract": "Generative artificial intelligence (AI) and large language models (LLMs), exemplified by ChatGPT, are promising for revolutionizing data and information management in healthcare and medicine. However, there is scant literature guiding their integration for non-AI professionals. This study conducts a scoping literature review to address the critical need for guidance on integrating generative AI and LLMs into healthcare and medical practices. It elucidates the distinct mechanisms underpinning these technologies, such as Reinforcement Learning from Human Feedback (RLFH), including few-shot learning and chain-of-thought reasoning, which differentiates them from traditional, rule-based AI systems. It requires an inclusive, collaborative co-design process that engages all pertinent stakeholders, including clinicians and consumers, to achieve these benefits. Although global research is examining both opportunities and challenges, including ethical and legal dimensions, LLMs offer promising advancements in healthcare by enhancing data management, information retrieval, and decision-making processes. Continued innovation in data acquisition, model fine-tuning, prompt strategy development, evaluation, and system implementation is imperative for realizing the full potential of these technologies. Organizations should proactively engage with these technologies to improve healthcare quality, safety, and efficiency, adhering to ethical and legal guidelines for responsible application.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-9032/11/20/2776/pdf?version=1697783532"}
{"paperId": "1b492746ee3a304a13950cad1a59861b9ee44645", "year": 2023, "title": "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?", "authors": "Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li, Mengchun Zhang, Sumit Kumar Dam, Chu Myaet Thwal, Ye Lin Tun, Le Luang Huy, Donguk kim, S. Bae, Lik-Hang Lee, Yang Yang, Heng Tao Shen, In-So Kweon, Choong-Seon Hong", "venue": "arXiv.org", "citationCount": 198, "abstract": "As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.11717"}
{"paperId": "97a5fb3512be8dfd9c8a32f4c556ad9db6030288", "year": 2024, "title": "Beware of Metacognitive Laziness: Effects of Generative Artificial Intelligence on Learning Motivation, Processes, and Performance", "authors": "Yizhou Fan, Luzhen Tang, Huixiao Le, Kejie Shen, Shufang Tan, Yueying Zhao, Yuan Shen, Xinyu Li, D. Ga\u0161evi\u0107", "venue": "British Journal of Educational Technology", "citationCount": 197, "abstract": "With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human\u2010AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human\u2010AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self\u2010regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi\u2010channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post\u2010task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self\u2010regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self\u2010regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger \u201cmetacognitive laziness\u201d. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.\nWhat is already known about this topic\n\nHybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.\nGenerative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.\nThe effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.\nWhat this paper adds\n\nWe conducted a randomised experimental study in the lab setting and compared learners' motivations, self\u2010regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).\nWe found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive \"laziness\", which can potentially hinder their ability to self\u2010regulate and engage deeply in learning.\nWe also found that ChatGPT can significantly improve short\u2010term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.\nImplications for practice and/or policy\n\nWhen using AI in learning, learners should focus on deepening their understanding of knowledge and actively engage in metacognitive processes such as evaluation, monitoring, and orientation, rather than blindly following ChatGPT's feedback solely to complete tasks efficiently.\nWhen using AI in teaching, teachers should think about which tasks are suitable for learners to complete with the assistance of AI, pay attention to stimulating learners' intrinsic motivations, and develop scaffolding to assist learners in active learning.\nResearcher should design multi\u2010task and cross\u2010context studies in the future to deepen our understanding of how learners could ethically and effectively learn, regulate, collaborate and evolve with AI.\n\n", "isOpenAccess": false, "url": ""}
{"paperId": "a1ba4bbc0ec996278d8dc9acbcf64e444e2ada39", "year": 2023, "title": "The Metacognitive Demands and Opportunities of Generative AI", "authors": "Lev Tankelevitch, Viktor Kewenig, Auste Simkute, A. E. Scott, Advait Sarkar, Abigail Sellen, Sean Rintel", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 196, "abstract": "Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition\u2014the psychological ability to monitor and control one\u2019s thoughts and behavior\u2014offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642902"}
{"paperId": "37e6fa1ff0bab38ccf0335aeb4fcc9dd65a1666c", "year": 2024, "title": "Exploring students\u2019 perspectives on Generative AI-assisted academic writing", "authors": "Jinhee Kim, Seongryeong Yu, Rita Detrick, Na Li", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 196, "abstract": "The rapid development of generative artificial intelligence (GenAI), including large language models (LLM), has merged to support students in their academic writing process. Keeping pace with the technical and educational landscape requires careful consideration of the opportunities and challenges that GenAI-assisted systems create within education. This serves as a useful and necessary starting point for fully leveraging its potential for learning and teaching. Hence, it is crucial to gather insights from diverse perspectives and use cases from actual users, particularly the unique voices and needs of student-users. Therefore, this study explored and examined students' perceptions and experiences about GenAI-assisted academic writing by conducting in-depth interviews with 20 Chinese students in higher education after completing academic writing tasks using a ChatGPT4-embedded writing system developed by the research team. The study found that students expected AI to serve multiple roles, including multi-tasking writing assistant, virtual tutor, and digital peer to support multifaceted writing processes and performance. Students perceived that GenAI-assisted writing could benefit them in three areas including the writing process, performance, and their affective domain. Meanwhile, they also identified AI-related, student-related, and task-related challenges that were experienced during the GenAI-assisted writing activity. These findings contribute to a more nuanced understanding of GenAI's impact on academic writing that is inclusive of student perspectives, offering implications for educational AI design and instructional design.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10639-024-12878-7.pdf"}
{"paperId": "134c7410e1b58aa839de1c10c23a1c4934aad897", "year": 2023, "title": "Generative artificial intelligence as a new context for management theories: analysis of ChatGPT", "authors": "P. Korzy\u0144ski, G. Mazurek, Andreas Altmann, J. Ejdys, R\u016bta Kazlauskait\u0117, J. Paliszkiewicz, K. Wach, E. Ziemba", "venue": "Central European Management Journal", "citationCount": 196, "abstract": "PurposeThe primary purpose of this paper is to examine how generative Artificial Intelligence (AI) such as ChatGPT may serve as a new context for management theories and concepts.Design/methodology/approachThe paper presents the analyses of selected management theories on decision-making, knowledge management, customer service, human resource management and administrative tasks and explains what may change after generative AI adoption.FindingsThe paper indicates that some management theories and concepts need to be studied in the generative AI environment that may influence managerial work at the strategic, functional and administrative levels.Research limitations/implicationsThis paper is an opinion piece article and does not refer to empirical data. It formulates some conclusions to further empirical research studies.Originality/valueThe paper analyzes selected management theories in a new technological setting. The paper also provides information about the functions of generative AI that are useful in understanding and overcoming how new technology may change organizations and management.", "isOpenAccess": true, "url": "https://www.emerald.com/insight/content/doi/10.1108/CEMJ-02-2023-0091/full/pdf?title=generative-artificial-intelligence-as-a-new-context-for-management-theories-analysis-of-chatgpt"}
{"paperId": "f0b57ff93ab51bec3d85f444c89d1af3d1771928", "year": 2023, "title": "On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML", "authors": "J. C\u00e1mara, J. Troya, Lola Burgue\u00f1o, Antonio Vallecillo", "venue": "Journal of Software and Systems Modeling", "citationCount": 195, "abstract": "Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10270-023-01105-5.pdf"}
{"paperId": "f773ceb43ffc7f9cd685250c4919924ec0bc85c7", "year": 2024, "title": "RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots", "authors": "Soroush Nasiriany, Abhiram Maddukuri, Lance Zhang, Adeet Parikh, Aaron Lo, Abhishek Joshi, Ajay Mandlekar, Yuke Zhu", "venue": "arXiv.org", "citationCount": 194, "abstract": "Recent advancements in Artificial Intelligence (AI) have largely been propelled by scaling. In Robotics, scaling is hindered by the lack of access to massive robot datasets. We advocate using realistic physical simulation as a means to scale environments, tasks, and datasets for robot learning methods. We present RoboCasa, a large-scale simulation framework for training generalist robots in everyday environments. RoboCasa features realistic and diverse scenes focusing on kitchen environments. We provide thousands of 3D assets across over 150 object categories and dozens of interactable furniture and appliances. We enrich the realism and diversity of our simulation with generative AI tools, such as object assets from text-to-3D models and environment textures from text-to-image models. We design a set of 100 tasks for systematic evaluation, including composite tasks generated by the guidance of large language models. To facilitate learning, we provide high-quality human demonstrations and integrate automated trajectory generation methods to substantially enlarge our datasets with minimal human burden. Our experiments show a clear scaling trend in using synthetically generated robot data for large-scale imitation learning and show great promise in harnessing simulation data in real-world tasks. Videos and open-source code are available at https://robocasa.ai/", "isOpenAccess": false, "url": ""}
{"paperId": "90a3410bc1632ba3340de7259186c66ba03f1668", "year": 2024, "title": "Promises and challenges of generative artificial intelligence for human learning", "authors": "Lixiang Yan, Samuel Greiff, Ziwen Teuber, D. Ga\u0161evi\u0107", "venue": "Nature Human Behaviour", "citationCount": 193, "abstract": "Generative artificial intelligence (GenAI) holds the potential to transform the delivery, cultivation and evaluation of human learning. Here the authors examine the integration of GenAI as a tool for human learning, addressing its promises and challenges from a holistic viewpoint that integrates insights from learning sciences, educational technology and human\u2013computer interaction. GenAI promises to enhance learning experiences by scaling personalized support, diversifying learning materials, enabling timely feedback and innovating assessment methods. However, it also presents critical issues such as model imperfections, ethical dilemmas and the disruption of traditional assessments. Thus, cultivating AI literacy and adaptive skills is imperative for facilitating informed engagement with GenAI technologies. Rigorous research across learning contexts is essential to evaluate GenAI\u2019s effect on human cognition, metacognition and creativity. Humanity must learn with and about GenAI, ensuring that it becomes a powerful ally in the pursuit of knowledge and innovation, rather than a crutch that undermines our intellectual abilities. This Perspective describes the roles of generative AI in providing personalized support, diversity and innovative assessment in learning. However, it also raises ethical concerns and highlights issues such as model imperfection, underscoring the need for AI literacy and adaptability.", "isOpenAccess": false, "url": ""}
{"paperId": "55b7e681e14e775600b341d8cc9bf53f3e9a4567", "year": 2024, "title": "Human-AI collaboration patterns in AI-assisted academic writing", "authors": "Andy Nguyen, Yvonne Hong, Belle Dang, Xiaoshan Huang", "venue": "Studies in Higher Education", "citationCount": 193, "abstract": "ABSTRACT Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/03075079.2024.2323593?needAccess=true"}
{"paperId": "ec1c43ca684732d06716a36271a4cb3066797153", "year": 2023, "title": "Generative artificial intelligence", "authors": "Leonardo Banh, G. Strobel", "venue": "Electronic Markets", "citationCount": 192, "abstract": "Recent developments in the field of artificial intelligence (AI) have enabled new paradigms of machine processing, shifting from data-driven, discriminative AI tasks toward sophisticated, creative tasks through generative AI. Leveraging deep generative models, generative AI is capable of producing novel and realistic content across a broad spectrum (e.g., texts, images, or programming code) for various domains based on basic user prompts. In this article, we offer a comprehensive overview of the fundamentals of generative AI with its underpinning concepts and prospects. We provide a conceptual introduction to relevant terms and techniques, outline the inherent properties that constitute generative AI, and elaborate on the potentials and challenges. We underline the necessity for researchers and practitioners to comprehend the distinctive characteristics of generative artificial intelligence in order to harness its potential while mitigating its risks and to contribute to a principal understanding.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s12525-023-00680-1.pdf"}
{"paperId": "b2503e37c3bb9be19ba53268b992e29c81080aad", "year": 2023, "title": "Using artificial intelligence in craft education: crafting with text-to-image generative models", "authors": "Henriikka Vartiainen, M. Tedre", "venue": "Digital Creativity", "citationCount": 192, "abstract": "ABSTRACT Artificial intelligence (AI) and the automation of creative work have received little attention in craft education. This study aimed to address this gap by exploring Finnish pre-service craft teachers\u2019 and teacher educators\u2019 (N\u2009=\u200915) insights into the potential benefits and challenges of AI, particularly text-to-image generative AI. This study implemented a hands-on workshop on creative making with text-to-image generative AI in order to stimulate discourses and capture imaginaries concerning generative AI. The results revealed that making with AI inspired teachers to consider the unique nature of crafts as well as the tensions and tradeoffs of adopting generative AI in craft practices. The teachers identified concerns in data-driven design, including algorithmic bias, copyright violations and black-boxing creativity, as well as in power relationships, hybrid influencing and behaviour engineering. The article concludes with a discussion of the complicated relationships the results uncovered between creative making and generative AI.", "isOpenAccess": true, "url": "https://doi.org/10.1080/14626268.2023.2174557"}
{"paperId": "1517ab19bd54ff13f1431562c12955cc0e27ab83", "year": 2024, "title": "The impact of generative AI on higher education learning and teaching: A study of educators' perspectives", "authors": "Daniel Lee, Matthew Arnold, Amit Srivastava, Katrina Plastow, Peter Strelan, Florian Ploeckl, Dimitra Lekkas, Edward Palmer", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 188, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100221"}
{"paperId": "6e720226396cd3a9f0dc4836d6d391509b9df285", "year": 2023, "title": "Sociotechnical Safety Evaluation of Generative AI Systems", "authors": "Laura Weidinger, Maribeth Rauh, Nahema Marchal, Arianna Manzini, L. Hendricks, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Griffin, Ben Bariach, Iason Gabriel, Verena Rieser, William S. Isaac", "venue": "arXiv.org", "citationCount": 185, "abstract": "Generative AI systems produce a range of risks. To ensure the safety of generative AI systems, these risks must be evaluated. In this paper, we make two main contributions toward establishing such evaluations. First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks. This framework encompasses capability evaluations, which are the main current approach to safety evaluation. It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm. To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation. Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations. Three salient evaluation gaps emerge from this analysis. We propose ways forward to closing these gaps, outlining practical steps as well as roles and responsibilities for different actors. Sociotechnical safety evaluation is a tractable approach to the robust and comprehensive safety evaluation of generative AI systems.", "isOpenAccess": false, "url": ""}
{"paperId": "39444c55f07839ac6a0d1839472a982f8fb447bb", "year": 2023, "title": "Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?", "authors": "I. Alberts, L. Mercolli, T. Pyka, G. Prenosil, Kuangyu Shi, A. Rominger, A. Afshar-Oromieh", "venue": "European Journal of Nuclear Medicine and Molecular Imaging", "citationCount": 185, "abstract": "There has been substantial press recently regarding the impressive performance of large language models (LLM), particularly the OpenAI tool \u201cChat Generative Pre-Trained Transformer,\u201d commonly known as \u201cChatGPT\u201d [1]. LLM represent artificial intelligence (AI) tools based on multilayer recurrent neural networks that are trained on vast amounts of data to generate human-like text (https:// ai. googl eblog. com/ 2017/ 08/ trans formernovelneuralnetwo rk. html). Whereas traditional language models are programmed to use statistical techniques to predict the next word in a sentence, ChatGPT uses transformer-based models that allow for the processing of vast amounts of data in parallel. The result is a revolution in the ability of these models to understand and generate text. Their performance is remarkable, e.g., ChatGPT is capable of writing lines of code, producing plays, stories, poetry as well as simulated scientific content such as abstracts. While there has been much fanfare in the media regarding this undoubtedly impressive performance, there is much less information available about how this might affect the nuclear medicine community, or its reliability in producing nuclear medicine and molecular imaging-related content. It is currently unclear to what extent ChatGPT might help as a collaborative tool, for example correcting or helping to improve upon a researcher\u2019s writing or as a tool for summarising nuclear medicine literature. Within seconds, ChatGPT is capable of producing convincing and grammatically fluent prose that is indistinguishable from content produced by human researchers. The threat that this poses to academic publishing models is already apparent [2]. Controversially, ChatGPT has (at the time of writing) already been listed as a co-author on four academic publications [3]. Anecdotally, students are already using the tool as a writing assistant, raising issues of academic integrity and plagiarism [4]. There are already 25 PubMed entries for \u201cChatGPT\u201d, this will likely grow rapidly in the coming weeks and months. In response, a number of journals are already implementing editorial policies about the acceptability of AI-assisted writing or clarifying issues around authorship [3, 5]. Some internet fora have already banned ChatGPT-generated answers owing to their unreliability (https:// meta. stack overfl ow. com/ quest ions/ 421831/ tempo rarypolicychatg ptisbanned). Recent experience has shown that AI tools can be harnessed to mass-produce questionable content on social media networks or social media bots that can deliberately amplify misinformation [6]. This experience might portend the future of ChatGPT-generated academic content. A report from the Copenhagen-based Institute for Future Studies estimates that 99% of the internet could be produced by generative AI by 2025 (https:// cifs. dk/ news/ whatif99ofthemetav erseismadebyai). At present, ChatGPT is not capable of producing an entire research paper sua sponte, although it is predicted and indeed conceivable that this might soon be the case [7]. Nevertheless, it can already, even in the currently available beta version, produce a very convincing abstract [8]. We wonder whether conferences might soon be flooded with AI-generated abstracts or whether predatory publishers [9] might be catalysed by the ability of ChatGPT to churn out convincing but ultimately unreliable content. Even the review process could be influenced: there are already proposals to harness the ability of LLM to summarise text as a tool for the sifting out of low-quality studies submitted to a journal. Once can imagine a not-too distant future where AI might generate and review research [10], This article is part of the Topical Collection on Advanced Image Analyses (Radiomics and Artificial Intelligence)", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s00259-023-06172-w.pdf"}
{"paperId": "628f241e6ccf6ce5ceb4a1d866935abf31d586da", "year": 2024, "title": "Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges", "authors": "Yan Chen, Pouyan Esmaeilzadeh", "venue": "Journal of Medical Internet Research", "citationCount": 183, "abstract": "As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.", "isOpenAccess": true, "url": "https://www.jmir.org/2024/1/e53008/PDF"}
{"paperId": "f81e6a3e77bcee3e7dab40132b12a3d83ad0b88c", "year": 2023, "title": "Are both generative AI and ChatGPT game changers for 21st-Century operations and supply chain excellence?", "authors": "Samuel Fosso Wamba, M. Queiroz, Charbel Jos\u00e9 Chiappetta Jabbour, C. Shi", "venue": "International Journal of Production Economics", "citationCount": 181, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "e815233db9fb476d7bece1d5e5c62a3bfdad3d12", "year": 2024, "title": "Ethical Challenges and Solutions of Generative AI: An Interdisciplinary Perspective", "authors": "Mousa Al-kfairy, Dheya Ghazi Mustafa, N. Kshetri, Mazen Insiew, Omar Alfandi", "venue": "Informatics", "citationCount": 181, "abstract": "This paper conducts a systematic review and interdisciplinary analysis of the ethical challenges of generative AI technologies (N = 37), highlighting significant concerns such as privacy, data protection, copyright infringement, misinformation, biases, and societal inequalities. The ability of generative AI to produce convincing deepfakes and synthetic media, which threaten the foundations of truth, trust, and democratic values, exacerbates these problems. The paper combines perspectives from various disciplines, including education, media, and healthcare, underscoring the need for AI systems that promote equity and do not perpetuate social inequalities. It advocates for a proactive approach to the ethical development of AI, emphasizing the necessity of establishing policies, guidelines, and frameworks that prioritize human rights, fairness, and transparency. The paper calls for a multidisciplinary dialogue among policymakers, technologists, and researchers to ensure responsible AI development that conforms to societal values and ethical standards. It stresses the urgency of addressing these ethical concerns and advocates for the development of generative AI in a socially beneficial and ethically sound manner, contributing significantly to the discourse on managing AI\u2019s ethical implications in the modern digital era. The study highlights the theoretical and practical implications of these challenges and suggests a number of future research directions.", "isOpenAccess": false, "url": ""}
{"paperId": "5fc12e18163db6857b46cdc2787534c8c9d3803f", "year": 2024, "title": "Reinvent 4: Modern AI\u2013driven generative molecule design", "authors": "Hannes H. Loeffler, Jiazhen He, Alessandro Tibo, J. Janet, Alexey Voronov, Lewis H. Mervin, Ola Engkvist", "venue": "Journal of Cheminformatics", "citationCount": 179, "abstract": "REINVENT 4 is a modern open-source generative AI framework for the design of small molecules. The software utilizes recurrent neural networks and transformer architectures to drive molecule generation. These generators are seamlessly embedded within the general machine learning optimization algorithms, transfer learning, reinforcement learning and curriculum learning. REINVENT 4 enables and facilitates de novo design, R-group replacement, library design, linker design, scaffold hopping and molecule optimization. This contribution gives an overview of the software and describes its design. Algorithms and their applications are discussed in detail. REINVENT 4 is a command line tool which reads a user configuration in either TOML or JSON format. The aim of this release is to provide reference implementations for some of the most common algorithms in AI based molecule generation. An additional goal with the release is to create a framework for education and future innovation in AI based molecular design. The software is available from https://github.com/MolecularAI/REINVENT4 and released under the permissive Apache 2.0 license. Scientific contribution. The software provides an open\u2013source reference implementation for generative molecular design where the software is also being used in production to support in\u2013house drug discovery projects. The publication of the most common machine learning algorithms in one code and full documentation thereof will increase transparency of AI and foster innovation, collaboration and education.", "isOpenAccess": true, "url": "https://doi.org/10.1186/s13321-024-00812-5"}
{"paperId": "856e055369b0216c928c66d964aeda8817fe822e", "year": 2024, "title": "A small-molecule TNIK inhibitor targets fibrosis in preclinical and clinical models", "authors": "Fengzhi Ren, Alex Aliper, Jian Chen, Heng Zhao, Sujata Rao, C. Kuppe, I. Ozerov, Man Zhang, Klaus Witte, Chris Kruse, Vladimir Aladinskiy, Yan Ivanenkov, Daniil Polykovskiy, Yanyun Fu, Eugene Babin, Junwen Qiao, Xing Liang, Zhenzhen Mou, Hui Wang, Frank W. Pun, P. Torres-Ayuso, Alexander Veviorskiy, Dandan Song, Sang Liu, Bei Zhang, Vladimir Naumov, Xiaoqiang Ding, Andrey Kukharenko, E. Izumchenko, Alex Zhavoronkov", "venue": "Nature Biotechnology", "citationCount": 178, "abstract": "Idiopathic pulmonary fibrosis (IPF) is an aggressive interstitial lung disease with a high mortality rate. Putative drug targets in IPF have failed to translate into effective therapies at the clinical level. We identify TRAF2- and NCK-interacting kinase (TNIK) as an anti-fibrotic target using a predictive artificial intelligence (AI) approach. Using AI-driven methodology, we generated INS018_055, a small-molecule TNIK inhibitor, which exhibits desirable drug-like properties and anti-fibrotic activity across different organs in vivo through oral, inhaled or topical administration. INS018_055 possesses anti-inflammatory effects in addition to its anti-fibrotic profile, validated in multiple in vivo studies. Its safety and tolerability as well as pharmacokinetics were validated in a randomized, double-blinded, placebo-controlled phase I clinical trial (NCT05154240) involving 78 healthy participants. A separate phase I trial in China, CTR20221542, also demonstrated comparable safety and pharmacokinetic profiles. This work was completed in roughly 18 months from target discovery to preclinical candidate nomination and demonstrates the capabilities of our generative AI-driven drug-discovery pipeline. An AI-generated small-molecule inhibitor treats fibrosis in vivo and in phase I clinical trials.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41587-024-02143-0.pdf"}
{"paperId": "14faed00db373d87bf90e8ee8f2c0dbbeed768dd", "year": 2024, "title": "Generative artificial intelligence in supply chain and operations management: a capability-based framework for analysis and implementation", "authors": "Ilya Jackson, Dmitry A. Ivanov, Alexandre Dolgui, Jafar Namdar", "venue": "International Journal of Production Research", "citationCount": 178, "abstract": "This research examines the transformative potential of artificial intelligence (AI) in general and Generative AI (GAI) in particular in supply chain and operations management (SCOM). Through the lens of the resource-based view and based on key AI capabilities such as learning, perception, prediction, interaction, adaptation, and reasoning, we explore how AI and GAI can impact 13 distinct SCOM decision-making areas. These areas include but are not limited to demand forecasting, inventory management, supply chain design, and risk management. With its outcomes, this study provides a comprehensive understanding of AI and GAI's functionality and applications in the SCOM context, offering a practical framework for both practitioners and researchers. The proposed framework systematically identifies where and how AI and GAI can be applied in SCOM, focussing on decision-making enhancement, process optimisation, investment prioritisation, and skills development. Managers can use it as a guidance to evaluate their operational processes and identify areas where AI and GAI can deliver improved efficiency, accuracy, resilience, and overall effectiveness. The research underscores that AI and GAI, with their multifaceted capabilities and applications, open a revolutionary potential and substantial implications for future SCOM practices, innovations, and research.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/00207543.2024.2309309?needAccess=true"}
{"paperId": "30c5c481ded2686e21ce108925d4ecf9d0c62d05", "year": 2023, "title": "The impact of generative artificial intelligence on socioeconomic inequalities and policy making", "authors": "V. Capraro, Austin Lentsch, D. Acemoglu, Selin Akg\u00fcn, Aisel Akhmedova, E. Bilancini, Jean\u2010Fran\u00e7ois Bonnefon, Pablo Bra\u00f1as-Garza, Luigi Butera, Karen M. Douglas, Jim A.C. Everett, Gerd Gigerenzer, Christine Greenhow, Daniel A. Hashimoto, J. Holt\u2010Lunstad, J. Jetten, Simon Johnson, Chiara Longoni, Pete Lunn, Simone Natale, Iyad Rahwan, Neil Selwyn, Vivek Singh, Siddharth Suri, Jennifer Sutcliffe, Joe Tomlinson, S. V. D. Linden, Paul A. M. Van Lange, Friederike Wall, J. V. Bavel, Riccardo Viale", "venue": "PNAS Nexus", "citationCount": 173, "abstract": "Abstract Generative artificial intelligence (AI) has the potential to both exacerbate and ameliorate existing socioeconomic inequalities. In this article, we provide a state-of-the-art interdisciplinary overview of the potential impacts of generative AI on (mis)information and three information-intensive domains: work, education, and healthcare. Our goal is to highlight how generative AI could worsen existing inequalities while illuminating how AI may help mitigate pervasive social problems. In the information domain, generative AI can democratize content creation and access but may dramatically expand the production and proliferation of misinformation. In the workplace, it can boost productivity and create new jobs, but the benefits will likely be distributed unevenly. In education, it offers personalized learning, but may widen the digital divide. In healthcare, it might improve diagnostics and accessibility, but could deepen pre-existing inequalities. In each section, we cover a specific topic, evaluate existing research, identify critical gaps, and recommend research directions, including explicit trade-offs that complicate the derivation of a priori hypotheses. We conclude with a section highlighting the role of policymaking to maximize generative AI's potential to reduce inequalities while mitigating its harmful effects. We discuss strengths and weaknesses of existing policy frameworks in the European Union, the United States, and the United Kingdom, observing that each fails to fully confront the socioeconomic challenges we have identified. We propose several concrete policies that could promote shared prosperity through the advancement of generative AI. This article emphasizes the need for interdisciplinary collaborations to understand and address the complex challenges of generative AI.", "isOpenAccess": true, "url": "https://academic.oup.com/pnasnexus/article-pdf/3/6/pgae191/58184311/pgae191.pdf"}
{"paperId": "ebf0a3812d8c02b333bb0890a9387c60b7b5589f", "year": 2024, "title": "A critical review of GenAI policies in higher education assessment: a call to reconsider the \u201coriginality\u201d of students\u2019 work", "authors": "Jiahui Luo (Jess)", "venue": "Assessment &amp; Evaluation in Higher Education", "citationCount": 172, "abstract": "Abstract This study offers a critical examination of university policies developed to address recent challenges presented by generative AI (GenAI) to higher education assessment. Drawing on Bacchi\u2019s \u2018What\u2019s the problem represented to be\u2019 (WPR) framework, we analysed the GenAI policies of 20 world-leading universities to explore what are considered problems in this AI-mediated assessment landscape and how these problems are represented in policies. Although miscellaneous GenAI-related problems were mentioned in these policies (e.g. reliability of AI-generated outputs, equal access to GenAI), the primary problem represented is that students may not submit original work for assessment. In the current framing, GenAI is often viewed as a type of external assistance separate from the student\u2019s independent efforts and intellectual contribution, thereby undermining the originality of their work. We argue that such problem representation fails to acknowledge how the rise of GenAI further complicates the process of producing original work and what it means by originality in a time when knowledge production becomes increasingly distributed, collaborative and mediated by technology. Therefore, a critical silence in higher education policies concerns the evolving notion of originality in the digital age and a more inclusive approach to address the originality of students\u2019 work is required.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/02602938.2024.2309963?needAccess=true"}
{"paperId": "367a161324a3b6d1b64b75bb8b44a797fc6a948b", "year": 2023, "title": "Generative AI meets copyright", "authors": "Pamela Samuelson", "venue": "Science", "citationCount": 172, "abstract": "Description Ongoing lawsuits could affect everyone who uses generative AI Generative artificial intelligence (AI) is a disruptive technology that is widely adopted by members of the general public as well as scientists and technologists who are enthusiastic about the potential to accelerate research in a wide variety of fields. But some professional artists, writers, and programmers fiercely object to the use of their creations as training data for generative AI systems and to outputs that may compete with or displace their works (1, 2). Lack of attribution and compensation for use of their original creations are other sources of aggravation to critics of generative AI. Copyright lawsuits that are now underway in the United States have substantial implications for the future of generative AI systems. If the plaintiffs prevail, the only generative AI systems that may be lawful in the United States would be those trained on public domain works or under licenses, which will affect everyone who deploys generative AI, integrates it into their products, and uses it for scientific research.", "isOpenAccess": true, "url": "https://www.science.org/doi/pdf/10.1126/science.adi0656?download=true"}
{"paperId": "86312ea272f7a6f5e3b067c9aaa355a4f559f95e", "year": 2023, "title": "Best humans still outperform artificial intelligence in a creative divergent thinking task", "authors": "Mika Koivisto, Simone Grassini", "venue": "Scientific Reports", "citationCount": 169, "abstract": "Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n\u2009=\u2009256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-023-40858-3.pdf"}
{"paperId": "c68b786ccdddc6d902644bd594df9c815ec45b92", "year": 2023, "title": "Generative AI and Teachers\u2019 Perspectives on Its Implementation in Education", "authors": "Regina Kaplan\u2010Rakowski, Kimberly Grotewold, P. Hartwick, Kevin Papin", "venue": "The Journal of Interactive Learning Research", "citationCount": 168, "abstract": "While artificial intelligence (AI) has been integral in daily life for decades, the release of open generative AI (GAI) such as ChatGPT has considerably accelerated scholars\u2019 interest in the impact of GAI in education. Both promises and fears of GAI have been becoming apparent. This quantitative study explored teachers' perspectives on GAI and its potential implementation in education. A diverse group of teachers (N = 147) completed a validated survey sharing their views on GAI technology in terms of its use, integration, potential, and concerns. Overall, the teachers express positive perspectives towards GAI regardless of their teaching style. The findings of the study suggest that the more frequently teachers used GAI, the more positive their perspectives became. The teachers believed that GAI could enhance their professional development and could be a valuable tool for students. Although no guarantee exists that teachers\u2019 perspectives translate into actions, previous research shows that technology integration and diffusion is highly dependent on teachers\u2019 initial views (Ismail et al., 2010; Sugar et al., 2004). The findings of this study have implications on how GAI may be integrated in teaching and learning practices.", "isOpenAccess": false, "url": ""}
{"paperId": "90a1843a2c1259708a6b11df7f6701ec0643e6ae", "year": 2023, "title": "Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness", "authors": "Felix Friedrich, P. Schramowski, Manuel Brack, Lukas Struppek, Dominik Hintersdorf, Sasha Luccioni, K. Kersting", "venue": "arXiv.org", "citationCount": 168, "abstract": "Generative AI models have recently achieved astonishing results in quality and are consequently employed in a fast-growing number of applications. However, since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer from degenerated and biased human behavior, as we demonstrate. In fact, they may even reinforce such biases. To not only uncover but also combat these undesired effects, we present a novel strategy, called Fair Diffusion, to attenuate biases after the deployment of generative text-to-image models. Specifically, we demonstrate shifting a bias, based on human instructions, in any direction yielding arbitrarily new proportions for, e.g., identity groups. As our empirical evaluation demonstrates, this introduced control enables instructing generative image models on fairness, with no data filtering and additional training required.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2302.10893"}
{"paperId": "ffe35292dc950ff1e28bf482c586db1bcb176aa3", "year": 2023, "title": "Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages", "authors": "Elise Karinshak, S. Liu, J. Park, Jeffrey T. Hancock", "venue": "Proc. ACM Hum. Comput. Interact.", "citationCount": 167, "abstract": "Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.", "isOpenAccess": true, "url": "https://doi.org/10.1145/3579592"}
{"paperId": "cea4c7e52db428f4618e03d32a774cceb2bc570a", "year": 2023, "title": "Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers", "authors": "Staphord Bengesi, Hoda El-Sayed, Md Kamruzzaman Sarker, Yao Houkpati, John Irungu, T. Oladunni", "venue": "IEEE Access", "citationCount": 167, "abstract": "The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.", "isOpenAccess": true, "url": "https://doi.org/10.1109/access.2024.3397775"}
{"paperId": "c532f1df90925e5c69789f0cd99248d8a2a2e5bc", "year": 2023, "title": "My AI Wants to Know if This Will Be on the Exam: Testing OpenAI\u2019s Codex on CS2 Programming Exercises", "authors": "James Finnie-Ansley, Paul Denny, Andrew Luxton-Reilly, E. Santos, J. Prather, Brett A. Becker", "venue": "IFAC Symposium on Advances in Control Education", "citationCount": 166, "abstract": "The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex\u2019s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3576123.3576134"}
{"paperId": "a6af8c13a3a12735f9cbe855ccc265f77765c3e9", "year": 2023, "title": "The Janus Effect of Generative AI: Charting the Path for Responsible Conduct of Scholarly Activities in Information Systems", "authors": "Anjana Susarla, R. Gopal, J. Thatcher, Suprateek Sarker", "venue": "Information systems research", "citationCount": 166, "abstract": "Funding: A. Susarla was funded by an R01 grant from the National Library of Medicine, through [Grant R01LM013443].", "isOpenAccess": true, "url": "https://wrap.warwick.ac.uk/176247/1/WRAP-The-Janus-effect-generative-AI-23%20.pdf"}
{"paperId": "addc34e1db56c46c399a3b319153be0b73186d19", "year": 2024, "title": "The benefits, risks and bounds of personalizing the alignment of large language models to individuals", "authors": "Hannah Rose Kirk, Bertie Vidgen, Paul R\u00f6ttger, Scott A. Hale", "venue": "Nature Machine Intelligence", "citationCount": 165, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "4973b3f6289b55548a9d65b30ae490fc4eae4811", "year": 2023, "title": "Economics of ChatGPT: A Labor Market View on the Occupational Impact of Artificial Intelligence", "authors": "Ali Zarifhonarvar", "venue": "Social Science Research Network", "citationCount": 165, "abstract": "PurposeThe study investigates the influence of ChatGPT on the labor market dynamics, aiming to provide a structured understanding of the changes induced by generative AI technologies.Design/methodology/approachAn analysis of existing literature serves as the foundation for understanding the impact, while the supply and demand model helps assess the effects of ChatGPT. A text-mining approach is utilized to analyze the International Standard Occupation Classification, identifying occupations most susceptible to disruption by ChatGPT.FindingsThe study reveals that 32.8% of occupations could be fully impacted by ChatGPT, while 36.5% might experience a partial impact and 30.7% are likely to remain unaffected.Research limitations/implicationsWhile this study offers insights into the potential influence of ChatGPT and other generative AI services on the labor market, it is essential to note that these findings represent potential implications rather than realized labor market effects. Further research is needed to track actual changes in employment patterns and job market dynamics where these AI services are widely adopted.Originality/valueThis paper contributes to the field by systematically categorizing the level of impact on different occupations, providing a nuanced perspective on the short- and long-term implications of ChatGPT and similar generative AI services on the labor market.", "isOpenAccess": true, "url": "https://www.econstor.eu/bitstream/10419/268826/1/Main%20Text%20%28Economics%20of%20ChatGPT%29%20SSRN.pdf"}
{"paperId": "a2f03ff74dc1ee8bd8b6ccfbcbb931f58c93db4b", "year": 2024, "title": "Investigation of the moderation effect of gender and study level on the acceptance and use of generative AI by higher education students: Comparative evidence from Poland and Egypt", "authors": "Artur Strzelecki, Sara ElArabawy", "venue": "British Journal of Educational Technology", "citationCount": 162, "abstract": "This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT\u2014performance expectancy, effort expectancy, social influence and facilitating conditions\u2014to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education.\n\nChatGPT is a tool that is quickly gaining worldwide recognition.\nChatGPT helps with writing essays and solving assignments.\nChatGPT raises ethical concerns about authorship, plagiarism and ethics.\n\n\nThis study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously.\nWe used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students.\nWe conducted a multiple study in Poland and Egypt based on sampling strategy from six universities.\n\n\nChatGPT is a global game changer and should be incorporated into study programmes.\nThe limitations of ChatGPT should be well explained and known since it is prone to making mistakes.\nHigher education teachers should be aware of ChatGPT's capabilities.\n", "isOpenAccess": false, "url": ""}
{"paperId": "d3b1fd3348f040814effaada60c1b6761ef0170f", "year": 2024, "title": "Generative AI in Higher Education: A Global Perspective of Institutional Adoption Policies and Guidelines", "authors": "Yueqiao Jin, Lixiang Yan, Vanessa Echeverr\u00eda, D. Ga\u0161evi\u0107, Roberto Mart\u00ednez Maldonado", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 158, "abstract": "Integrating generative AI (GAI) into higher education is crucial for preparing a future generation of GAI-literate students. Yet a thorough understanding of the global institutional adoption policy remains absent, with most of the prior studies focused on the Global North and the promises and challenges of GAI, lacking a theoretical lens. This study utilizes the Diffusion of Innovations Theory to examine GAI adoption strategies in higher education across 40 universities from six global regions. It explores the characteristics of GAI innovation, including compatibility, trialability, and observability, and analyses the communication channels and roles and responsibilities outlined in university policies and guidelines. The findings reveal a proactive approach by universities towards GAI integration, emphasizing academic integrity, teaching and learning enhancement, and equity. Despite a cautious yet optimistic stance, a comprehensive policy framework is needed to evaluate the impacts of GAI integration and establish effective communication strategies that foster broader stakeholder engagement. The study highlights the importance of clear roles and responsibilities among faculty, students, and administrators for successful GAI integration, supporting a collaborative model for navigating the complexities of GAI in education. This study contributes insights for policymakers in crafting detailed strategies for its integration.", "isOpenAccess": false, "url": ""}
{"paperId": "e64d60855db9691caea22e0ec21f35d060933801", "year": 2023, "title": "Artificial intelligence in healthcare: Complementing, not replacing, doctors and healthcare providers", "authors": "Emre Sezgin", "venue": "Digital Health", "citationCount": 157, "abstract": "The utilization of artificial intelligence (AI) in clinical practice has increased and is evidently contributing to improved diagnostic accuracy, optimized treatment planning, and improved patient outcomes. The rapid evolution of AI, especially generative AI and large language models (LLMs), have reignited the discussions about their potential impact on the healthcare industry, particularly regarding the role of healthcare providers. Concerning questions, \u201ccan AI replace doctors?\u201d and \u201cwill doctors who are using AI replace those who are not using it?\u201d have been echoed. To shed light on this debate, this article focuses on emphasizing the augmentative role of AI in healthcare, underlining that AI is aimed to complement, rather than replace, doctors and healthcare providers. The fundamental solution emerges with the human\u2013AI collaboration, which combines the cognitive strengths of healthcare providers with the analytical capabilities of AI. A human-in-the-loop (HITL) approach ensures that the AI systems are guided, communicated, and supervised by human expertise, thereby maintaining safety and quality in healthcare services. Finally, the adoption can be forged further by the organizational process informed by the HITL approach to improve multidisciplinary teams in the loop. AI can create a paradigm shift in healthcare by complementing and enhancing the skills of healthcare providers, ultimately leading to improved service quality, patient outcomes, and a more efficient healthcare system.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/20552076231186520"}
{"paperId": "49fff1d586f5e05ba81bddf5caf528c67ea535cb", "year": 2024, "title": "Empowering student self-regulated learning and science education through ChatGPT: A pioneering pilot study", "authors": "D. Ng, Chee-Wei Tan, J. Leung", "venue": "British Journal of Educational Technology", "citationCount": 156, "abstract": "In recent years, AI technologies have been developed to promote students' self\u2010regulated learning (SRL) and proactive learning in digital learning environments. This paper discusses a comparative study between generative AI\u2010based (SRLbot) and rule\u2010based AI chatbots (Nemobot) in a 3\u2010week science learning experience with 74 Secondary 4 students in Hong Kong. The experimental group used SRLbot to maintain a regular study habit and facilitate their SRL, while the control group utilized rule\u2010based AI chatbots. Results showed that SRLbot effectively enhanced students' science knowledge, behavioural engagement and motivation. Quantile regression analysis indicated that the number of interactions significantly predicted variations in SRL. Students appreciated the personalized recommendations and flexibility of SRLbot, which adjusted responses based on their specific learning and SRL scenarios. The ChatGPT\u2010enhanced instructional design reduced learning anxiety and promoted learning performance, motivation and sustained learning habits. Students' feedback on learning challenges, psychological support and self\u2010regulation behaviours provided insights into their progress and experience with this technology. SRLbot's adaptability and personalized approach distinguished it from rule\u2010based chatbots. The findings offer valuable evidence for AI developers and educators to consider generative AI settings and chatbot design, facilitating greater success in online science learning.\nWhat is already known about this topic\n\nAI technologies have been used to support student self\u2010regulated learning (SRL) across subjects.\nSRL has been identified as an important aspect of student learning that can be developed through technological support.\nGenerative AI technologies like ChatGPT have shown potential for enhancing student learning by providing personalized guidance and feedback.\nWhat this paper adds\n\nThis paper reports on a case study that specifically examines the effectiveness of ChatGPT in promoting SRL among secondary students.\nThe study provides evidence that ChatGPT can enhance students' science knowledge, motivation and SRL compared to a rule\u2010based AI chatbot.\nThe study offers insights into how ChatGPT can be used as a tool to facilitate SRL and promote sustained learning habits.\nImplications for practice and/or policy\n\nThe findings of this study suggest that educators should consider the potential of ChatGPT and other generative AI technologies to support student learning and SRL.\nEducators and students should be aware of the limitations of AI technologies and ensure that they are used appropriately to generate desired responses.\nIt is also important to equip teachers and students with AI competencies to enable them to use AI for learning and teaching.\n\n", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13454"}
{"paperId": "1875879c3b85289f8f7da0b9aa4d35343225be8e", "year": 2023, "title": "The Challenges and Opportunities of AI-Assisted Writing: Developing AI Literacy for the AI Age", "authors": "P. Cardon, Carolin Fleischmann, Jolanta Aritz, Minna Logemann, Jeanette Heidewald", "venue": "Business and Professional Communication Quarterly", "citationCount": 156, "abstract": "Generative AI may significantly disrupt the teaching and practice of business communication. This study of 343 communication instructors revealed a collective view that AI-assisted writing will be widely adopted in the workplace and will require significant changes to instruction. Key perceived challenges include less critical thinking and authenticity in writing. Key perceived benefits include more efficiency and better idea generation in writing. Students will need to develop AI literacy\u2014composed of application, authenticity, accountability, and agency\u2014to succeed in the workplace. Recommendations are provided for instructors and administrators to ensure the benefits of AI-assisted writing can outweigh the challenges.", "isOpenAccess": false, "url": ""}
{"paperId": "c7ed921c1f10ef2274f6de4534a6aa33b8a4d0b0", "year": 2023, "title": "What Do We Mean by GenAI? A Systematic Mapping of The Evolution, Trends, and Techniques Involved in Generative AI", "authors": "F. Garc\u00eda-Pe\u00f1alvo, Andrea V\u00e1zquez-Ingelmo", "venue": "Int. J. Interact. Multim. Artif. Intell.", "citationCount": 155, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.9781/ijimai.2023.07.006"}
{"paperId": "96159eea50588975893787d2f13e21e38ed4615a", "year": 2024, "title": "Artificial intelligence in neuro-oncology: advances and challenges in brain tumor diagnosis, prognosis, and precision treatment", "authors": "S. Khalighi, Kartik Reddy, Abhishek Midya, K. Pandav, A. Madabhushi, M. Abedalthagafi", "venue": "npj Precision Oncology", "citationCount": 155, "abstract": "This review delves into the most recent advancements in applying artificial intelligence (AI) within neuro-oncology, specifically emphasizing work on gliomas, a class of brain tumors that represent a significant global health issue. AI has brought transformative innovations to brain tumor management, utilizing imaging, histopathological, and genomic tools for efficient detection, categorization, outcome prediction, and treatment planning. Assessing its influence across all facets of malignant brain tumor management- diagnosis, prognosis, and therapy- AI models outperform human evaluations in terms of accuracy and specificity. Their ability to discern molecular aspects from imaging may reduce reliance on invasive diagnostics and may accelerate the time to molecular diagnoses. The review covers AI techniques, from classical machine learning to deep learning, highlighting current applications and challenges. Promising directions for future research include multimodal data integration, generative AI, large medical language models, precise tumor delineation and characterization, and addressing racial and gender disparities. Adaptive personalized treatment strategies are also emphasized for optimizing clinical outcomes. Ethical, legal, and social implications are discussed, advocating for transparency and fairness in AI integration for neuro-oncology and providing a holistic understanding of its transformative impact on patient care.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41698-024-00575-0.pdf"}
{"paperId": "a653040e98acdd2b6bc87f64985b5ace8646de88", "year": 2023, "title": "The false positives and false negatives of generative AI detection tools in education and academic research: The case of ChatGPT", "authors": "D. Dalalah, Osama M.A. Dalalah", "venue": "The International Journal of Management Education", "citationCount": 152, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "6487ec82f6d8082a5b402a5416ea03009acb1679", "year": 2023, "title": "State of the Art on Diffusion Models for Visual Computing", "authors": "Ryan Po, Wang Yifan, Vladislav Golyanik, Kfir Aberman, J. Barron, Amit Bermano, E. R. Chan, Tali Dekel, Aleksander Holynski, Angjoo Kanazawa, C. K. Liu, Lingjie Liu, B. Mildenhall, M. Nie\u00dfner, Bjorn Ommer, C. Theobalt, Peter Wonka, Gordon Wetzstein", "venue": "Computer graphics forum (Print)", "citationCount": 152, "abstract": "The field of visual computing is rapidly advancing due to the emergence of generative artificial intelligence (AI), which unlocks unprecedented capabilities for the generation, editing, and reconstruction of images, videos, and 3D scenes. In these domains, diffusion models are the generative AI architecture of choice. Within the last year alone, the literature on diffusion\u2010based tools and applications has seen exponential growth and relevant papers are published across the computer graphics, computer vision, and AI communities with new works appearing daily on arXiv. This rapid growth of the field makes it difficult to keep up with all recent developments. The goal of this state\u2010of\u2010the\u2010art report (STAR) is to introduce the basic mathematical concepts of diffusion models, implementation details and design choices of the popular Stable Diffusion model, as well as overview important aspects of these generative AI tools, including personalization, conditioning, inversion, among others. Moreover, we give a comprehensive overview of the rapidly growing literature on diffusion\u2010based generation and editing, categorized by the type of generated medium, including 2D images, videos, 3D objects, locomotion, and 4D scenes. Finally, we discuss available datasets, metrics, open challenges, and social implications. This STAR provides an intuitive starting point to explore this exciting topic for researchers, artists, and practitioners alike.", "isOpenAccess": false, "url": ""}
{"paperId": "5eb0850336e5cb952999dc8522d21799e815ec5f", "year": 2023, "title": "Generative AI and ChatGPT in School Children\u2019s Education: Evidence from a School Lesson", "authors": "Jussi S. Jauhiainen, Agust\u00edn Garagorry Guerra", "venue": "Sustainability", "citationCount": 152, "abstract": "In 2023, the global use of generative AI, particularly ChatGPT-3.5 and -4, witnessed a significant surge, sparking discussions on its sustainable implementation across various domains, including education from primary schools to universities. However, practical testing and evaluation in school education are still relatively unexplored. This article examines the utilization of generative AI in primary school education. The study involved 110 pupils, aged 8\u201314 years old, studying in the 4th\u20136th grades across four classes in two schools. Using laptops, pupils participated in test lessons where content, text, figures, and exercises were generated and modified using generative AI, specifically ChatGPT-3.5. The results demonstrated that it was possible to use ChatGPT-3.5, as one example of generative AI, to personify learning material so that it would meet the knowledge and learning skills of pupils with different levels of knowledge. A clear majority of pupils enjoyed learning the generative AI-modified material. There is a promising potential of generative AI use in school education, supporting pupils\u2019 motivated learning and skills development. However, these tools need to be developed, refined and optimized to ensure proper adaptation and to create impactful, inclusive, and sustainable learning in schools to benefit pupils, teachers and education managers alike.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/15/18/14025/pdf?version=1695347129"}
{"paperId": "a61249a0dffb33292bbd75d289b7b7bd846b4765", "year": 2024, "title": "Google Gemini as a next generation AI educational tool: a review of emerging educational technology", "authors": "Muhammad Imran, N. Almusharraf", "venue": "Smart Learning Environments", "citationCount": 151, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "8368a9b5f6e4929ce8e0a7264429a0f06060fa4e", "year": 2024, "title": "Machine learning techniques for IoT security: Current research and future vision with generative AI and large language models", "authors": "Fatima Alwahedi, Alyazia Aldhaheri, M. Ferrag, A. Battah, Norbert Tihanyi", "venue": "Internet of Things and Cyber-Physical Systems", "citationCount": 151, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.iotcps.2023.12.003"}
{"paperId": "5c96740dbcc3a50d9280c81ab8128b025cf05879", "year": 2024, "title": "Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners\u2019 AI adoption and experiences", "authors": "G. Liu, Ron Darvin, Chaojun Ma", "venue": "Computer Assisted Language Learning", "citationCount": 151, "abstract": "Abstract Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners\u2019 adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/09588221.2024.2310288?needAccess=true"}
{"paperId": "b1841e0ba9ee1726938081467f2aa7b5e7480a4e", "year": 2023, "title": "Generative Artificial Intelligence in Education and Its Implications for Assessment", "authors": "Jin Mao, Baiyun Chen, J. Liu", "venue": "TechTrends", "citationCount": 150, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "4de290467d903b9977e31b3d4084006789bd6ebd", "year": 2023, "title": "One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era", "authors": "Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim, Seonghyeon Kim, J. Choi, Gyeong-Moon Park, S. Bae, Lik-Hang Lee, Pan Hui, In-So Kweon, Choong-Seon Hong", "venue": "arXiv.org", "citationCount": 150, "abstract": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.", "isOpenAccess": false, "url": ""}
{"paperId": "d4eb4adfa36b5dd0480793f1d0a89a43a8847661", "year": 2024, "title": "The promise and challenges of generative AI in education", "authors": "Michail N. Giannakos, Roger Azevedo, Peter Brusilovsky, Mutlu Cukurova, Y. Dimitriadis, Davinia Hern\u00e1ndez Leo, Sanna J\u00e4rvel\u00e4, M. Mavrikis, Bart Rienties", "venue": "Behavior and Information Technology", "citationCount": 149, "abstract": "ABSTRACT Generative artificial intelligence (GenAI) tools, such as large language models (LLMs), generate natural language and other types of content to perform a wide range of tasks. This represents a significant technological advancement that poses opportunities and challenges to educational research and practice. This commentary brings together contributions from nine experts working in the intersection of learning and technology and presents critical reflections on the opportunities, challenges, and implications related to GenAI technologies in the context of education. In the commentary, it is acknowledged that GenAI\u2019s capabilities can enhance some teaching and learning practices, such as learning design, regulation of learning, automated content, feedback, and assessment. Nevertheless, we also highlight its limitations, potential disruptions, ethical consequences, and potential misuses. The identified avenues for further research include the development of new insights into the roles human experts can play, strong and continuous evidence, human-centric design of technology, necessary policy, and support and competence mechanisms. Overall, we concur with the general skeptical optimism about the use of GenAI tools such as LLMs in education. Moreover, we highlight the danger of hastily adopting GenAI tools in education without deep consideration of the efficacy, ecosystem-level implications, ethics, and pedagogical soundness of such practices.", "isOpenAccess": true, "url": "https://doi.org/10.1080/0144929x.2024.2394886"}
{"paperId": "df50e8e876919821db7a28e7330fa30f3db79bd6", "year": 2024, "title": "The impending disruption of creative industries by generative AI: Opportunities, challenges, and research agenda", "authors": "Joseph Amankwah\u2010Amoah, Samar Abdalla, Emmanuel Mogaji, Amany Elbanna, Yogesh K. Dwivedi", "venue": "International Journal of Information Management", "citationCount": 148, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "0e41ae9360a962430650d5bb174de223aa8deea5", "year": 2023, "title": "Navigating the Complexity of Generative AI Adoption in Software Engineering", "authors": "Daniel Russo", "venue": "ACM Transactions on Software Engineering and Methodology", "citationCount": 148, "abstract": "This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares\u2013Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3652154"}
{"paperId": "a80d106b4536884af8da68078babc70086b1a607", "year": 2023, "title": "Evaluating the Social Impact of Generative AI Systems in Systems and Society", "authors": "Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal Daum'e, Jesse Dodge, Ellie Evans, Felix Friedrich, Usman Gohar, Sara Hooker, Yacine Jernite, A. Luccioni, Alberto Lusoli, Jennifer Mickel, Margaret Mitchell, J. Newman, Marie-Therese Png, Andrew Strait, Apostol T. Vassilev, Arjun Subramonian", "venue": "arXiv.org", "citationCount": 147, "abstract": "Generative AI systems across modalities, ranging from text (including code), image, audio, and video, have broad social impacts, but there is no official standard for means of evaluating those impacts or for which impacts should be evaluated. In this paper, we present a guide that moves toward a standard approach in evaluating a base generative AI system for any modality in two overarching categories: what can be evaluated in a base system independent of context and what can be evaluated in a societal context. Importantly, this refers to base systems that have no predetermined application or deployment context, including a model itself, as well as system components, such as training data. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to listed generative modalities and analyses of the limitations of existing evaluations serve as a starting point for necessary investment in future evaluations. We offer five overarching categories for what can be evaluated in a broader societal context, each with its own subcategories: trustworthiness and autonomy; inequality, marginalization, and violence; concentration of authority; labor and creativity; and ecosystem and environment. Each subcategory includes recommendations for mitigating harm.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.05949"}
{"paperId": "421193bfb4a1fc21866d65f80e8f8e8806e1f35b", "year": 2023, "title": "How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research? An exploratory study", "authors": "F. Megahed, Ying-Ju Chen, Joshua A. Ferris, S. Knoth, L. A. Jones\u2010Farmer", "venue": "Quality Engineering", "citationCount": 147, "abstract": "Abstract Generative Artificial Intelligence (AI) models such as OpenAI\u2019s ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research. However, these tools are in the early stages of development and can be easily misused or misunderstood. In this paper, we give an overview of the development of Generative AI. Specifically, we explore ChatGPT\u2019s ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research. By investigating responses to structured prompts, we highlight the benefits and limitations of the results. Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch. We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive. However, in their current stages of development, some results are misleading and wrong. Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/08982112.2023.2206479?needAccess=true&role=button"}
{"paperId": "f6943500f55c8b67b2396238ea71d2b18f574323", "year": 2023, "title": "Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education", "authors": "Adele Smolansky, Andrew Cram, Corina Raduescu, S. Zeivots, E. Huber, Ren\u00e9 F. Kizilcec", "venue": "ACM Conference on Learning @ Scale", "citationCount": 145, "abstract": "The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.", "isOpenAccess": false, "url": ""}
{"paperId": "ed2db05074b86da6fbcb01b45bd0f1693baa93c4", "year": 2023, "title": "Reducing the Carbon Impact of Generative AI Inference (today and in 2035)", "authors": "A. Chien, Liuzixuan Lin, H. Nguyen, V. Rao, Tristan Sharma, Rajini Wijayawardana", "venue": "HotCarbon", "citationCount": 145, "abstract": "Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts. Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71%.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3604930.3605705"}
{"paperId": "e8113869163d47043ef1278777f2fb8b93ca2346", "year": 2024, "title": "Modelling Generative AI Acceptance, Perceived Teachers' Enthusiasm and Self\u2010Efficacy to English as a Foreign Language Learners' Well\u2010Being in the Digital Era", "authors": "Fangwei Huang, Yongliang Wang, Haijing Zhang", "venue": "European Journal of Education", "citationCount": 145, "abstract": "As artificial intelligence (AI) has been integrated into foreign language (FL) education, learners' well\u2010being is influenced by various factors, including technological, personal and contextual elements. However, few studies explored how external and internal factors jointly shape FL learners' well\u2010being in the era of generative AI. To fill this gap, this study explores the effects of generative AI acceptance, perceived teachers' enthusiasm and self\u2010efficacy on FL learners' well\u2010being by investigating 613 university learners of English as a foreign language (EFL). The structural equation modelling results reveal that (1) generative AI acceptance positively predicts EFL learners' well\u2010being and self\u2010efficacy; (2) perceived teachers' enthusiasm does not predict learners' well\u2010being and positively predicts EFL learners' self\u2010efficacy; and (3) the self\u2010efficacy for receptive skills mediates the relationship between generative AI acceptance/perceived teachers' enthusiasm and EFL learners' well\u2010being, whereas self\u2010efficacy for productive skills does not play the mediation role. This research broadens the understanding of the antecedents of EFL learners' well\u2010being and extends the application of self\u2010efficacy theory in the AI\u2010driven educational environment, providing significant pedagogical implications.", "isOpenAccess": false, "url": ""}
{"paperId": "996be611b62c9bb9ef7d02e364f62660425d49a1", "year": 2023, "title": "The Impact of Multimodal Large Language Models on Health Care\u2019s Future", "authors": "B. Mesk\u00f3", "venue": "Journal of Medical Internet Research", "citationCount": 143, "abstract": "When large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode\u2014text. As medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality\u2014meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents\u2014can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care\u2019s future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care\u2014empathy, understanding, and the doctor-patient relationship\u2014when deploying AI.", "isOpenAccess": true, "url": "https://doi.org/10.2196/52865"}
{"paperId": "1e2f50c030a85d3b8ac6ae8218a625ed76723da0", "year": 2025, "title": "Artificial intelligence in drug development", "authors": "Kang Zhang, Xin Yang, Yifei Wang, Yunfang Yu, Niu Huang, Gen Li, Xiaokun Li, Joseph C Wu, Shengyong Yang", "venue": "Nature Medicine", "citationCount": 143, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "0f75ec8510247bbaf95ca6e4474976fc40bf2b51", "year": 2023, "title": "Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods", "authors": "Volker Bilgram, F. Laarmann", "venue": "IEEE Engineering Management Review", "citationCount": 143, "abstract": "Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.", "isOpenAccess": true, "url": "https://doi.org/10.1109/emr.2023.3272799"}
{"paperId": "5aa35e2d7b2ab889ca003f6a2c09f5d6f25d8896", "year": 2024, "title": "Generative AI: A systematic review using topic modelling techniques", "authors": "Priyanka Gupta, Bosheng Ding, Chong Guan, Ding Ding", "venue": "Data and Information Management", "citationCount": 141, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.dim.2024.100066"}
{"paperId": "1a450fcd40aeea64544fad08844de1119c33f03f", "year": 2023, "title": "Natural scene reconstruction from fMRI signals using generative latent diffusion", "authors": "Furkan Ozcelik, Rufin VanRullen", "venue": "Scientific Reports", "citationCount": 140, "abstract": "In neural decoding research, one of the most intriguing topics is the reconstruction of perceived natural images based on fMRI signals. Previous studies have succeeded in re-creating different aspects of the visuals, such as low-level properties (shape, texture, layout) or high-level features (category of objects, descriptive semantics of scenes) but have typically failed to reconstruct these properties together for complex scene images. Generative AI has recently made a leap forward with latent diffusion models capable of generating high-complexity images. Here, we investigate how to take advantage of this innovative technology for brain decoding. We present a two-stage scene reconstruction framework called \u201cBrain-Diffuser\u201d. In the first stage, starting from fMRI signals, we reconstruct images that capture low-level properties and overall layout using a VDVAE (Very Deep Variational Autoencoder) model. In the second stage, we use the image-to-image framework of a latent diffusion model (Versatile Diffusion) conditioned on predicted multimodal (text and visual) features, to generate final reconstructed images. On the publicly available Natural Scenes Dataset benchmark, our method outperforms previous models both qualitatively and quantitatively. When applied to synthetic fMRI patterns generated from individual ROI (region-of-interest) masks, our trained model creates compelling \u201cROI-optimal\u201d scenes consistent with neuroscientific knowledge. Thus, the proposed methodology can have an impact on both applied (e.g. brain\u2013computer interface) and fundamental neuroscience.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-023-42891-8.pdf"}
{"paperId": "08a4e7a22d52f78e11b53f13415324a86f2a0497", "year": 2023, "title": "Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study", "authors": "Kostis Giannakopoulos, Argyro Kavadella, Anas Aaqel Salim, Vassilis Stamatopoulos, E. Kaklamanos", "venue": "Journal of Medical Internet Research", "citationCount": 140, "abstract": "Background The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy. Objective This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry. Methods The LLMs were queried with 20 open-type, clinical dentistry\u2013related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs\u2019 answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs\u2019 answers. Results Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate. Conclusions This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist\u2019s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.", "isOpenAccess": true, "url": "https://www.jmir.org/2023/1/e51580/PDF"}
{"paperId": "7d2f897255412922f631e60cddeec815edd392b3", "year": 2023, "title": "The Caring Machine: Feeling AI for Customer Care", "authors": "Ming-Hui Huang, R. Rust", "venue": "Journal of Marketing", "citationCount": 138, "abstract": "Customer care is important for its role in relationship building. This role has traditionally been performed by human customer agents; however, the emergence of interactive generative AI (GenAI) shows potential for using AI for customer care in emotionally charged interactions. Bridging practice and the academic literatures in marketing and computer science, this article develops an AI-enabled customer care journey, from accurate emotion recognition to empathetic response, emotional management support, and, finally, the establishment of an emotional connection. Marketing requirements for each of the stages are derived from in-depth interviews with top managers and a survey of chief marketing officers. By juxtaposing these requirements against the current feeling capabilities of GenAI, the authors highlight the technological challenges engineers must tackle. The article concludes with a set of marketing tenets for implementing and researching the caring machine. These include verifying emotion recognition accuracy using marketing emotion theories through multiple emotion signals and methods, utilizing prompt engineering to enhance GenAI\u2019s emotion understanding, employing \u201cresponse engineering\u201d to personalize emotion management recommendations, and strategically deploying GenAI for emotional connection to simultaneously enhance customer emotional well-being and customer lifetime value.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/00222429231224748"}
{"paperId": "4a1d533193d8e6607c381d231aaea06a5522622a", "year": 2024, "title": "A Systematic Review of Synthetic Data Generation Techniques Using Generative AI", "authors": "Mandeep Goyal, Q. Mahmoud", "venue": "Electronics", "citationCount": 138, "abstract": "Synthetic data are increasingly being recognized for their potential to address serious real-world challenges in various domains. They provide innovative solutions to combat the data scarcity, privacy concerns, and algorithmic biases commonly used in machine learning applications. Synthetic data preserve all underlying patterns and behaviors of the original dataset while altering the actual content. The methods proposed in the literature to generate synthetic data vary from large language models (LLMs), which are pre-trained on gigantic datasets, to generative adversarial networks (GANs) and variational autoencoders (VAEs). This study provides a systematic review of the various techniques proposed in the literature that can be used to generate synthetic data to identify their limitations and suggest potential future research areas. The findings indicate that while these technologies generate synthetic data of specific data types, they still have some drawbacks, such as computational requirements, training stability, and privacy-preserving measures which limit their real-world usability. Addressing these issues will facilitate the broader adoption of synthetic data generation techniques across various disciplines, thereby advancing machine learning and data-driven solutions.", "isOpenAccess": true, "url": "https://doi.org/10.3390/electronics13173509"}
{"paperId": "eb22629ba7dd88761c39173f8abc69b589acc5cd", "year": 2023, "title": "Generative AI for Software Practitioners", "authors": "C. Ebert, Panos Louridas, C. Ebert", "venue": "IEEE Software", "citationCount": 137, "abstract": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.\u2014Christof Ebert", "isOpenAccess": false, "url": ""}
{"paperId": "91c24e12ca61268cd784309bfcb4fdd3f7eaa609", "year": 2023, "title": "Towards Adoption of Generative AI in Organizational Settings", "authors": "K. Agrawal", "venue": "Journal of Computational Information Systems", "citationCount": 137, "abstract": "ABSTRACT As an emerging technology, Generative Artificial Intelligence (AI) holds immense potential for application across various levels of business and management. However, current studies have not yet investigated the elements that impact the acceptance and implementation of generative AI tools, such as ChatGPT, within organizational settings. To fully leverage its benefits, organizations must embrace and integrate Generative AI at a comprehensive and profound level, making it a valuable area of study. This study aims to put forth and examine the influencing factors impacting the adoption of generative AI technology by utilizing the Technology-Organization-Environment framework in conjunction with the institutional theory and the diffusion of innovation theory. Data from 108 organizations in India is collected and analyzed, leading to valuable insights and implications that contribute to a deeper understanding of the key determinants of generative AI adoption. The study digs out valuable knowledge for organizations looking to embrace this technology.", "isOpenAccess": false, "url": ""}
{"paperId": "79adf90f279f05ffc53ded255f9c5825515e398a", "year": 2024, "title": "Generative AI for Customizable Learning Experiences", "authors": "Ivica Pesovski, Ricardo Santos, Roberto Henriques, V. Trajkovik", "venue": "Sustainability", "citationCount": 137, "abstract": "The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI\u2019s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student\u2019s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students\u2019 study time, especially for students who have not mastered the topic otherwise. The study\u2019s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/16/7/3034/pdf?version=1712310661"}
{"paperId": "32566efe68955837f5d677cde1cddff09dbad381", "year": 2025, "title": "DanceGRPO: Unleashing GRPO on Visual Generation", "authors": "Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu, Mengzhao Chen, Zhiheng Liu, Wei Liu, Qiushan Guo, Weilin Huang, Ping Luo", "venue": "arXiv.org", "citationCount": 137, "abstract": "Recent advances in generative AI have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. While Reinforcement Learning (RL) has emerged as a promising approach for fine-tuning generative models, existing methods like DDPO and DPOK face fundamental limitations - particularly their inability to maintain stable optimization when scaling to large and diverse prompt sets, severely restricting their practical utility. This paper presents DanceGRPO, a framework that addresses these limitations through an innovative adaptation of Group Relative Policy Optimization (GRPO) for visual generation tasks. Our key insight is that GRPO's inherent stability mechanisms uniquely position it to overcome the optimization challenges that plague prior RL-based approaches on visual generation. DanceGRPO establishes several significant advances: First, it demonstrates consistent and stable policy optimization across multiple modern generative paradigms, including both diffusion models and rectified flows. Second, it maintains robust performance when scaling to complex, real-world scenarios encompassing three key tasks and four foundation models. Third, it shows remarkable versatility in optimizing for diverse human preferences as captured by five distinct reward models assessing image/video aesthetics, text-image alignment, video motion quality, and binary feedback. Our comprehensive experiments reveal that DanceGRPO outperforms baseline methods by up to 181\\% across multiple established benchmarks, including HPS-v2.1, CLIP Score, VideoAlign, and GenEval. Our results establish DanceGRPO as a robust and versatile solution for scaling Reinforcement Learning from Human Feedback (RLHF) tasks in visual generation, offering new insights into harmonizing reinforcement learning and visual synthesis.", "isOpenAccess": false, "url": ""}
{"paperId": "1332261d94c1de6e5e9d5b6191644b0fe53eaa42", "year": 2023, "title": "Generative AI for Economic Research: Use Cases and Implications for Economists", "authors": "Anton Korinek", "venue": "Journal of Economic Literature", "citationCount": 137, "abstract": "Generative artificial intelligence (AI) has the potential to revolutionize research. I analyze how large language models (LLMs) such as ChatGPT can assist economists by describing dozens of use cases in six areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro-tasks. Moreover, these gains will grow as the performance of AI systems continues to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper explain how to get started and will provide regular updates on the latest capabilities of generative AI in economics. (JEL A11, C45, D83, I23, O33)", "isOpenAccess": false, "url": ""}
{"paperId": "dcd2d383eb900dea4e1643963d947a707fbaf6fc", "year": 2023, "title": "Diffusion-Based Reinforcement Learning for Edge-Enabled AI-Generated Content Services", "authors": "Hongyang Du, Zonghang Li, Dusist Niyato, Jiawen Kang, Zehui Xiong, Huawei Huang, Shiwen Mao", "venue": "IEEE Transactions on Mobile Computing", "citationCount": 135, "abstract": "As Metaverse emerges as the next-generation Internet paradigm, the ability to efficiently generate content is paramount. AI-Generated Content (AIGC) emerges as a key solution, yet the resource-intensive nature of large Generative AI (GAI) models presents challenges. To address this issue, we introduce an AIGC-as-a-Service (AaaS) architecture, which deploys AIGC models in wireless edge networks to ensure broad AIGC services accessibility for Metaverse users. Nonetheless, an important aspect of providing personalized user experiences requires carefully selecting AIGC Service Providers (ASPs) capable of effectively executing user tasks, which is complicated by environmental uncertainty and variability. Addressing this gap in current research, we introduce the AI-Generated Optimal Decision (AGOD) algorithm, a diffusion model-based approach for generating the optimal ASP selection decisions. Integrating AGOD with Deep Reinforcement Learning (DRL), we develop the Deep Diffusion Soft Actor-Critic (D2SAC) algorithm, enhancing the efficiency and effectiveness of ASP selection. Our comprehensive experiments demonstrate that D2SAC outperforms seven leading DRL algorithms. Furthermore, the proposed AGOD algorithm has the potential for extension to various optimization problems in wireless networks, positioning it as a promising approach for future research on AIGC-driven services.", "isOpenAccess": true, "url": "https://techrxiv.figshare.com/articles/preprint/Diffusion-based_Reinforcement_Learning_for_Edge-enabled_AI-Generated_Content_Services/24648723/1/files/43317999.pdf"}
{"paperId": "cf0431d680b75301506fce8e00aa872034bf0dd6", "year": 2023, "title": "Artificial Intelligence & Creativity: A Manifesto for Collaboration", "authors": "Florent Vinchon, T. Lubart, S. Bartolotta, Valentin Gironnay, Marion Botella, S. Bourgeois-Bougrine, Jean-Marie Burkhardt, N. Bonnardel, G. Corazza, V. Gl\u0103veanu, Michael Hanchett Hanson, Zorana Ivcevic, M. Karwowski, J. Kaufman, T. Okada, R. Reiter\u2010Palmon, A. Gaggioli", "venue": "The Journal of creative behavior", "citationCount": 135, "abstract": "With the advent of arti\ufb01cial intelligence (AI), the \ufb01eld of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human \u2013 machine collaboration on creative tasks and proposes \u201cfundamental laws of generative AI\u201d to reinforce the responsible and ethical use of AI in the creativity \ufb01eld. Four scenarios are proposed and discussed: \u201cCo-Cre-AI-tion,\u201d \u201cOrganic,\u201d \u201cPlagiarism 3.0,\u201d and \u201cShut down,\u201d each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI-generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlighted to ensure responsible use of AIs. The positive future of creativity and AI lies in a harmonious collaboration that can bene\ufb01t everyone, potentially leading to a new level of creative productivity respecting ethical considerations and human values during the creative process.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jocb.597"}
{"paperId": "7aead47e2bf590809cb3e235dd26f0de95b6fe92", "year": 2023, "title": "Hello GPT! Goodbye home examination? An exploratory study of AI chatbots impact on university teachers\u2019 assessment practices", "authors": "Alexandra Farazouli, T. Cerratto Pargman, K. Bolander-Laksov, C. McGrath", "venue": "Assessment &amp; Evaluation in Higher Education", "citationCount": 135, "abstract": "Abstract AI chatbots have recently fuelled debate regarding education practices in higher education institutions worldwide. Focusing on Generative AI and ChatGPT in particular, our study examines how AI chatbots impact university teachers\u2019 assessment practices, exploring teachers\u2019 perceptions about how ChatGPT performs in response to home examination prompts in undergraduate contexts. University teachers (n\u2009=\u200924) from four different departments in humanities and social sciences participated in Turing Test-inspired experiments, where they blindly assessed student and ChatGPT-written responses to home examination questions. Additionally, we conducted semi-structured interviews in focus groups with the same teachers examining their reflections about the quality of the texts they assessed. Regarding chatbot-generated texts, we found a passing rate range across the cohort (37.5\u2009\u2212\u200985.7%) and a chatbot-written suspicion range (14\u201323%). Regarding the student-written texts, we identified patterns of downgrading, suggesting that teachers were more critical when grading student-written texts. Drawing on post-phenomenology and mediation theory, we discuss AI chatbots as a potentially disruptive technology in higher education practices.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/02602938.2023.2241676?needAccess=true&role=button"}
{"paperId": "c713ade0d479355c8e155ca720fbe36c34e9e2f6", "year": 2024, "title": "Sentiment Analysis in the Age of Generative AI", "authors": "Jan Ole Krugmann, Jochen Hartmann", "venue": "Customer Needs and Solutions", "citationCount": 133, "abstract": "In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs\u2019 proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s40547-024-00143-4.pdf"}
{"paperId": "7fe4667dbe9edd488c8ae88842044ba27c93e654", "year": 2023, "title": "Artificial intelligence and increasing misinformation", "authors": "S. Monteith, T. Glenn, John R. Geddes, P. Whybrow, Eric Achtyes, Michael Bauer", "venue": "British Journal of Psychiatry", "citationCount": 133, "abstract": "Summary With the recent advances in artificial intelligence (AI), patients are increasingly exposed to misleading medical information. Generative AI models, including large language models such as ChatGPT, create and modify text, images, audio and video information based on training data. Commercial use of generative AI is expanding rapidly and the public will routinely receive messages created by generative AI. However, generative AI models may be unreliable, routinely make errors and widely spread misinformation. Misinformation created by generative AI about mental illness may include factual errors, nonsense, fabricated sources and dangerous advice. Psychiatrists need to recognise that patients may receive misinformation online, including about medicine and psychiatry.", "isOpenAccess": true, "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/DCCE0EB214E3D375A3006AA69FFB210D/S0007125023001368a.pdf/div-class-title-artificial-intelligence-and-increasing-misinformation-div.pdf"}
{"paperId": "ecede1602cb72756a2220cbc39a2b1150fe8cdac", "year": 2023, "title": "Prompt Problems: A New Programming Exercise for the Generative AI Era", "authors": "Paul Denny, Juho Leinonen, J. Prather, Andrew Luxton-Reilly, Thezyrie Amarouche, Brett A. Becker, Brent N. Reeves", "venue": "Technical Symposium on Computer Science Education", "citationCount": 131, "abstract": "Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3626252.3630909"}
{"paperId": "1a61b1f46ef6afb58ee2ecb689c757f8ad2f84d0", "year": 2023, "title": "Disco: Disentangled Control for Realistic Human Dance Generation", "authors": "Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, Lijuan Wang", "venue": "Computer Vision and Pattern Recognition", "citationCount": 131, "abstract": "Generative AI has made significant strides in computer vision, particularly in text-driven image/video synthesis (T2I/T2V). Despite the notable advancements, it remains challenging in human-centric content synthesis such as realistic dance generation. Current methodologies, primarily tailored for human motion transfer, encounter difficulties when confronted with real-world dance scenarios (e.g., social media dance), which require to generalize across a wide spectrum of poses and intricate human details. In this paper, we depart from the traditional paradigm of human motion transfer and emphasize two additional critical attributes for the synthesis of human dance content in social media contexts: (i) Generalizability: the model should be able to generalize beyond generic human viewpoints as well as unseen human subjects, backgrounds, and poses; (ii) Compositionality: it should allow for the seamless composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce Disco, which includes a novel model architecture with disentangled control to improve the compositionality of dance synthesis, and an effective human attribute pre-training for better generalizability to unseen humans. Extensive qualitative and quantitative results demonstrate that DISCO can generate high-quality human dance images and videos with diverse appearances and flexible motions. Code is available at https://disco-dance.github.io/.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.00040"}
{"paperId": "5dcd4581c979bc97b165a1e2d55cc434d9136351", "year": 2023, "title": "Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses", "authors": "Jaromir Savelka, Arav Agarwal, Marshall An, C. Bogart, M. Sakr", "venue": "International Computing Education Research Workshop", "citationCount": 130, "abstract": "This paper studies recent developments in large language models\u2019 (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class\u2019 assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4\u2019s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3568813.3600142"}
{"paperId": "f2154bedb033b07b838d9ac90a657b4ab4243be4", "year": 2023, "title": "A survey of Generative AI Applications", "authors": "Roberto Gozalo-Brizuela, Eduardo C. Garrido-Merch'an", "venue": "Journal of Computer Science", "citationCount": 129, "abstract": "Generative AI has experienced remarkable growth in recent years, leading to a wide array of applications across diverse domains. In this paper, we present a comprehensive survey of more than 350 generative AI applications, providing a structured taxonomy and concise descriptions of various unimodal and even multimodal generative AIs. The survey is organized into sections, covering a wide range of unimodal generative AI applications such as text, images, video, gaming and brain information. Our survey aims to serve as a valuable resource for researchers and practitioners to navigate the rapidly expanding landscape of generative AI, facilitating a better understanding of the current state-of-the-art and fostering further innovation in the field.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.02781"}
{"paperId": "cc29e49baab11caeb7df80bb220e5f559b709a6c", "year": 2023, "title": "Why and how to embrace AI such as ChatGPT in your academic life", "authors": "Zhicheng Lin", "venue": "Royal Society Open Science", "citationCount": 129, "abstract": "Generative artificial intelligence (AI), including large language models (LLMs), is poised to transform scientific research, enabling researchers to elevate their research productivity. This article presents a how-to guide for employing LLMs in academic settings, focusing on their unique strengths, constraints and implications through the lens of philosophy of science and epistemology. Using ChatGPT as a case study, I identify and elaborate on three attributes contributing to its effectiveness\u2014intelligence, versatility and collaboration\u2014accompanied by tips on crafting effective prompts, practical use cases and a living resource online (https://osf.io/8vpwu/). Next, I evaluate the limitations of generative AI and its implications for ethical use, equality and education. Regarding ethical and responsible use, I argue from technical and epistemic standpoints that there is no need to restrict the scope or nature of AI assistance, provided that its use is transparently disclosed. A pressing challenge, however, lies in detecting fake research, which can be mitigated by embracing open science practices, such as transparent peer review and sharing data, code and materials. Addressing equality, I contend that while generative AI may promote equality for some, it may simultaneously exacerbate disparities for others\u2014an issue with potentially significant yet unclear ramifications as it unfolds. Lastly, I consider the implications for education, advocating for active engagement with LLMs and cultivating students' critical thinking and analytical skills. The how-to guide seeks to empower researchers with the knowledge and resources necessary to effectively harness generative AI while navigating the complex ethical dilemmas intrinsic to its application.", "isOpenAccess": true, "url": "https://doi.org/10.1098/rsos.230658"}
{"paperId": "6659bf805608b0ac911cd501ac89ac93f3765be8", "year": 2024, "title": "How Generative AI Can Augment Human Creativity", "authors": "T. Eapen, Daniel J. Finkenstadt, Josh Folk, Lokesh Venkataswamy", "venue": "Social Science Research Network", "citationCount": 129, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "4130156e2aecb8e102ef7e065dd4384df75e7ada", "year": 2023, "title": "Advancing Requirements Engineering through Generative AI: Assessing the Role of LLMs", "authors": "Chetan Arora, John C. Grundy, Mohamed Abdelrazek", "venue": "arXiv.org", "citationCount": 129, "abstract": "Requirements Engineering (RE) is a critical phase in software development including the elicitation, analysis, specification, and validation of software requirements. Despite the importance of RE, it remains a challenging process due to the complexities of communication, uncertainty in the early stages and inadequate automation support. In recent years, large-language models (LLMs) have shown significant promise in diverse domains, including natural language processing, code generation, and program understanding. This chapter explores the potential of LLMs in driving RE processes, aiming to improve the efficiency and accuracy of requirements-related tasks. We propose key directions and SWOT analysis for research and development in using LLMs for RE, focusing on the potential for requirements elicitation, analysis, specification, and validation. We further present the results from a preliminary evaluation, in this context.", "isOpenAccess": false, "url": ""}
{"paperId": "22bbfe33c33513492b12052b82f9616451a72517", "year": 2023, "title": "Generative Artificial Intelligence Acceptance Scale: A Validity and Reliability Study", "authors": "F. Yilmaz, Ramazan Y\u0131lmaz, Mehmet Ceylan", "venue": "International journal of human computer interactions", "citationCount": 129, "abstract": "Abstract The purpose of this study is to formulate an acceptance scale grounded in the Unified Theory of Acceptance and Use of Technology (UTAUT) model. The scale is designed to scrutinize students\u2019 acceptance of generative artificial intelligence (AI) applications. This tool assesses students\u2019 acceptance levels toward generative AI applications. The scale development study was conducted in three phases, encompassing 627 university students from various faculties who have utilized generative AI tools such as ChatGPT during the 2022\u20132023 academic year. To evaluate the face and content validity of the scale, input was sought from professionals with expertise in the field. The initial sample group (n = 338) underwent exploratory factor analysis (EFA) to explore the underlying factors, while the subsequent sample group (n = 250) underwent confirmatory factor analysis (CFA) for the verification of factor structure. Later, it was seen that four factors comprising 20 items accounted for 78.349% of total variance due to EFA. CFA results confirmed that structure of the scale, featuring 20 items and four factors (performance expectancy, effort expectancy, facilitating conditions, and social influence), was compatible with the obtained data. Reliability analysis yielded Cronbach\u2019s alpha coefficient of 0.97, and the test\u2013retest method demonstrated a reliability coefficient of 0.95. To evaluate the discriminative power of the items, a comparative analysis was conducted between the lower 27% and upper 27% of participants, with subsequent calculation of corrected item-total correlations. The results demonstrate that the generative AI acceptance scale exhibits robust validity and reliability, thus affirming its effectiveness as a robust measurement instrument.", "isOpenAccess": false, "url": ""}
{"paperId": "15d04a7c607785c6f264cf3369d9fad01f6e319e", "year": 2024, "title": "The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers", "authors": "James Prather, Brent N. Reeves, Juho Leinonen, Stephen Macneil, Arisoa S. Randrianasolo, Brett A. Becker, Bailey Kimmel, Jared Wright, Ben Briggs", "venue": "International Computing Education Research Workshop", "citationCount": 129, "abstract": "Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2405.17739"}
{"paperId": "2b7bd0491c31407342aa85c82163ede304d0e850", "year": 2023, "title": "\u201cHOT\u201d ChatGPT: The Promise of ChatGPT in Detecting and Discriminating Hateful, Offensive, and Toxic Comments on Social Media", "authors": "Lingyao Li, Lizhou Fan, Shubham Atreja, Libby Hemphill", "venue": "ACM Transactions on the Web", "citationCount": 128, "abstract": "Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies \u201chateful\u201d and \u201coffensive\u201d as subsets of \u201ctoxic.\u201d Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.10619"}
{"paperId": "6f01ca395514bfe216aade6b2d3c5c43f1e9dd42", "year": 2024, "title": "Privacy and Security Concerns in Generative AI: A Comprehensive Survey", "authors": "Abenezer Golda, K. Mekonen, Amit Pandey, Anushka Singh, Vikas Hassija, V. Chamola, Biplab Sikdar", "venue": "IEEE Access", "citationCount": 127, "abstract": "Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10478883.pdf"}
{"paperId": "b08d575f4d8afab06bb7e6fb89827124ed25da8c", "year": 2023, "title": "Mapping out a research agenda for generative artificial intelligence in tertiary education", "authors": "J. Lodge, Kate Thompson, L. Corrin", "venue": "Australasian Journal of Educational Technology", "citationCount": 126, "abstract": "Generative artificial intelligence (AI) has taken the world by storm. In this editorial, we outline some of the key areas of tertiary education impacted by large language models and associated applications that will require re-thinking and research to address in the short to medium term. Given how rapidly generative AI developments are currently occurring, this editorial is speculative. Although there is a long history of research on AI in education, the current situation is both unprecedented and seemingly not something that the AI in education community fully predicted. We also outline the editorial position of AJET in regards to generative AI to assist authors using tools such as ChatGPT as any part of the research or writing process. This is a rapidly evolving space. We have attempted to provide some clarity in this editorial while acknowledging that we may need to revisit some or all of what we offer here in the weeks and months ahead.", "isOpenAccess": true, "url": "https://ajet.org.au/index.php/AJET/article/download/8695/1987"}
{"paperId": "6d38f381c01f8b943a3eaacb76be7b58a99dee07", "year": 2023, "title": "Generative AI for Integrated Sensing and Communication: Insights From the Physical Layer Perspective", "authors": "Jiacheng Wang, Hongyang Du, D. Niyato, Jiawen Kang, Shuguang Cui, Xuemin Shen, Ping Zhang", "venue": "IEEE wireless communications", "citationCount": 126, "abstract": "As generative artificial intelligence (GAl) models continue to evolve, their generative capabilities are increasingly enhanced, and being used exten-sively in content generation. Furthermore, GAl also excels in data modeling and analysis, benefiting wireless communication systems. In this article, we investigate applications of GAI in the physical layer and analyze its support for integrated sensing and communications (ISAC) systems. Specifically, we first provide an overview of GAI and ISAC, touching on GAl's potential support across multi-ple layers of ISAC. We then thoroughly investigate GAl's applications in the physical layer, such as channel estimation, which demonstrates the benefits that GAl-enhanced physical layer technologies bring to ISAC systems. Finally, in the case study, we present a diffusion model-based method for estimating signal direction of arrival in near-field scenarios using uniform linear arrays with antenna spacing over half the wavelength. With a mean square error of 1.03 degrees, the method confirms GAl's support for the physical layer in near-field sensing and communications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.01036"}
{"paperId": "b229fe5912caf7daca6d15b9ddbcfdfac818d326", "year": 2024, "title": "A Comprehensive Review on Generative AI for Education", "authors": "Uday Mittal, Siva Sai, V. Chamola, Devika Sangwan", "venue": "IEEE Access", "citationCount": 125, "abstract": "Artificial Intelligence (AI) has immense potential for personalized learning experiences, content generation, and vivid educational support. This paper delves into generative AI (GAI) and its potential applications within GAI, specifically mentioning generative adversarial networks (GANs). The article delves into the transformative impact of GAI in education, underscoring its expertise in creating diverse instructional materials, from texts and images to videos. Adaptive learning, one of the chief abilities of GAI, has been highlighted, emphasizing its capability to select content customized to individual student profiles, learning habits, and preferences. The paper further explores the fusion of GAI with innovative education systems, highlighting how these models can mimic conversational interfaces, promoting an engaging, customized learning journey. The exploration doesn\u2019t stop at the benefits; it delves into challenges like ensuring data privacy, mitigating biases, and ensuring accountability in AI-driven educational systems. The conclusion contemplates the potential limitations and assurances of embedding GAI within educational setups. An appeal has been made for more profound research and enhancement of AI\u2019s educational function. The intersection of pedagogical insights and effective human-AI collaboration is pivotal in this journey. This paper serves as a compass, guiding educators, researchers, and policymakers toward harnessing GAI\u2019s potential to sculpt enriched, immersive educational landscapes.", "isOpenAccess": true, "url": "https://doi.org/10.1109/access.2024.3468368"}
{"paperId": "07e738d7c10505b8562d0b282a3cae94b485b24a", "year": 2023, "title": "The Gradient of Generative AI Release: Methods and Considerations", "authors": "Irene Solaiman", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 125, "abstract": "As increasingly powerful generative AI systems are developed, the release method greatly varies. We propose a framework to assess six levels of access to generative AI systems: fully closed; gradual or staged access; hosted access; cloud-based or API access; downloadable access; and fully open. Each level, from fully closed to fully open, can be viewed as an option along a gradient. We outline key considerations across this gradient: release methods come with tradeoffs, especially around the tension between concentrating power and mitigating risks. Diverse and multidisciplinary perspectives are needed to examine and mitigate risk in generative AI systems from conception to deployment. We show trends in generative system release over time, noting closedness among large companies for powerful systems and openness among organizations founded on principles of openness. We also enumerate safety controls and guardrails for generative systems and necessary investments to improve future releases.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2302.04844"}
{"paperId": "98211267094891259ad9bd84eaac7da3baaf4507", "year": 2024, "title": "Generative AI for designing and validating easily synthesizable and structurally novel antibiotics", "authors": "Kyle Swanson, Gary Liu, Denise B. Catacutan, Autumn Arnold, James Y. Zou, Jonathan M. Stokes", "venue": "Nature Machine Intelligence", "citationCount": 124, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "722ae1415e102ff258d5cbf31cfaacd6fd31d99f", "year": 2024, "title": "Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers", "authors": "Peng Gao, Le Zhuo, Ziyi Lin, Chris Liu, Junsong Chen, Ruoyi Du, Enze Xie, Xu Luo, Longtian Qiu, Yuhang Zhang, Chen Lin, Rongjie Huang, Shijie Geng, Renrui Zhang, Junlin Xi, Wenqi Shao, Zhengkai Jiang, Tianshuo Yang, Weicai Ye, He Tong, Jingwen He, Y. Qiao, Hongsheng Li", "venue": "arXiv.org", "citationCount": 124, "abstract": "Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details. In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions. By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions. This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference. Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens. This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions. We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community.", "isOpenAccess": false, "url": ""}
{"paperId": "0c5fbcd73343d7527863ddd15c91fbcb774fca49", "year": 2023, "title": "Large Generative AI Models for Telecom: The Next Big Thing?", "authors": "Lina Bariah, Qiyang Zhao, Han Zou, Yu Tian, F. Bader, M. Debbah", "venue": "IEEE Communications Magazine", "citationCount": 123, "abstract": "The evolution of generative artificial intelligence (GenAI) constitutes a turning point in reshaping the future of technology in different aspects. Wireless networks, in particular, with the blooming of self-evolving networks, represent a rich field for exploiting GenAI and reaping several benefits that can fundamentally change the way wireless networks are designed and operated nowadays. To be specific, large GenAI models are envisioned to open up a new era of autonomous wireless networks, in which multi-modal GenAI models trained over various Telecom data, can be fine-tuned to perform several downstream tasks, eliminating the need for building and training dedicated AI models for each specific task, and paving the way for the realization of artificial general intelligence (AGI)-empowered wireless networks. In this article, we aim to unfold the opportunities that can be reaped from integrating large GenAI models into the Telecom domain. In particular, we first highlight the applications of large GenAI models in future wireless networks, defining potential use-cases and revealing insights on the associated theoretical and practical challenges. Furthermore, we unveil how 6G can open up new opportunities through connecting multiple on-device large GenAI models, and hence, pave the way to the collective intelligence paradigm. Finally, we put a forward-looking vision of how large GenAI models will be the key to realize self-evolving networks.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2306.10249"}
{"paperId": "f6d60ef6317a9f6de13e03b38c5c9bb8e6717d49", "year": 2023, "title": "ChatGPT: More Than a \u201cWeapon of Mass Deception\u201d Ethical Challenges and Responses from the Human-Centered Artificial Intelligence (HCAI) Perspective", "authors": "A. Sison, Marco Tulio Daza, Roberto Gozalo-Brizuela, E.C. Garrido-Merch\u00e1n", "venue": "International journal of human computer interactions", "citationCount": 122, "abstract": "Abstract This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a \u201cgrand challenge,\u201d thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a \u201cweapon of mass deception\u201d (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparency, educator considerations, HITL) to mitigate ChatGPT misuse or abuse and recommend best uses (creative writing, non-creative writing, teaching and learning). We conclude with considerations regarding the role of hu mans in ensuring the proper use of ChatGPT for individual and social wellbeing.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.11215"}
{"paperId": "ca2f5a4599c978a6cb6bc3242faf0037d0d981fc", "year": 2023, "title": "Effects of Generative Chatbots in Higher Education", "authors": "Galina Ilieva, Tania Yankova, Stanislava Klisarova-Belcheva, Angel Dimitrov, Marin Bratkov, Delian Angelov", "venue": "Inf.", "citationCount": 122, "abstract": "Learning technologies often do not meet the university requirements for learner engagement via interactivity and real-time feedback. In addition to the challenge of providing personalized learning experiences for students, these technologies can increase the workload of instructors due to the maintenance and updates required to keep the courses up-to-date. Intelligent chatbots based on generative artificial intelligence (AI) technology can help overcome these disadvantages by transforming pedagogical activities and guiding both students and instructors interactively. In this study, we explore and compare the main characteristics of existing educational chatbots. Then, we propose a new theoretical framework for blended learning with intelligent chatbots integration enabling students to interact online and instructors to create and manage their courses using generative AI tools. The advantages of the proposed framework are as follows: (1) it provides a comprehensive understanding of the transformative potential of AI chatbots in education and facilitates their effective implementation; (2) it offers a holistic methodology to enhance the overall educational experience; and (3) it unifies the applications of intelligent chatbots in teaching\u2013learning activities within universities.", "isOpenAccess": true, "url": "https://www.mdpi.com/2078-2489/14/9/492/pdf?version=1694069191"}
{"paperId": "b19dc16f5a3218d01f1246aa8068fc245880a10b", "year": 2024, "title": "Generative AI design for building structures", "authors": "Wenjie Liao, Xinzheng Lu, Yifan Fei, Yi Gu, Yuli Huang", "venue": "Automation in Construction", "citationCount": 122, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "3c2c924b788ef620b9e4a0fdf789a12a5bde5129", "year": 2023, "title": "ChatGPT in education: a discourse analysis of worries and concerns on social media", "authors": "Lingyao Li, Zihui Ma, Lizhou Fan, Sanggyu Lee, Huizi Yu, Libby Hemphill", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 122, "abstract": "The rapid advancements in generative AI models present new opportunities in the education sector. However, it is imperative to acknowledge and address the potential risks and concerns that may arise with their use. We analyzed Twitter data to identify critical concerns related to the use of ChatGPT in education. We employed BERT-based topic modeling to conduct a discourse analysis and social network analysis to identify influential users in the conversation. While Twitter users generally expressed a positive attitude toward using ChatGPT, their concerns converged into five categories: academic integrity, impact on learning outcomes and skill development, limitation of capabilities, policy and social concerns, and workforce challenges. We also found that users from the tech, education, and media fields were often implicated in the conversation, while education and tech individual users led the discussion of concerns. Based on these findings, the study provides several implications for policymakers, tech companies and individuals, educators, and media agencies. In summary, our study underscores the importance of responsible and ethical use of AI in education and highlights the need for collaboration among stakeholders to regulate AI policy.", "isOpenAccess": false, "url": ""}
{"paperId": "09b7e2d4e0ca51667197faa54bf9227a91e3b656", "year": 2023, "title": "Towards social generative AI for education: theory, practices and ethics", "authors": "M. Sharples", "venue": "Learning: Research and Practice", "citationCount": 122, "abstract": "ABSTRACT This opinion paper explores educational interactions involving humans and artificial intelligences not as sequences of prompts and responses, but as a social process of conversation and exploration. In this conception, learners continually converse with AI language models and other human learners within a dynamic computational medium of internet tools and resources. Learning happens when this distributed human-AI system sets goals, builds meaning from data, consolidates understanding, reconciles differences, and transfers knowledge to new domains. Building social generative AI for education will require development of powerful AI systems that can converse with each other as well as humans, construct external representations such as knowledge maps, access and contribute to internet resources, and act as teachers, learners, guides and mentors. This raises fundamental problems of ethics. Such systems should be aware of their limitations, their responsibility to learners and the integrity of the internet, and their respect for human teachers and experts. We need to consider how to design and constrain social generative AI for education.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/23735082.2023.2261131?needAccess=true"}
{"paperId": "8094e5c04947eb6722168142548e57a1cebb4ef7", "year": 2023, "title": "Social Dynamics of AI Support in Creative Writing", "authors": "K. Gero, Tao Long, Lydia B. Chilton", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 121, "abstract": "Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer\u2019s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.", "isOpenAccess": true, "url": "https://doi.org/10.1145/3544548.3580782"}
{"paperId": "6ea2e402d9d573b6303db35a8347b2a002074fd4", "year": 2023, "title": "Challenges for higher education in the era of widespread access to Generative AI", "authors": "K. Walczak, W. Cellary", "venue": "Economics and Business Review", "citationCount": 121, "abstract": "Abstract The aim of this paper is to discuss the role and impact of Generative Artificial Intelligence (AI) systems in higher education. The proliferation of AI models such as GPT-4, Open Assistant and DALL-E presents a paradigm shift in information acquisition and learning. This transformation poses substantial challenges for traditional teaching approaches and the role of educators. The paper explores the advantages and potential threats of using Generative AI in education and necessary changes in curricula. It further discusses the need to foster digital literacy and the ethical use of AI. The paper\u2019s findings are based on a survey conducted among university students exploring their usage and perception of these AI systems. Finally, recommendations for the use of AI in higher education are offered, which emphasize the need to harness AI\u2019s potential while mitigating its risks. This discourse aims at stimulating policy and strategy development to ensure relevant and effective education in the rapidly evolving digital landscape.", "isOpenAccess": true, "url": "https://journals.ue.poznan.pl/ebr/article/download/743/568"}
{"paperId": "6d533b0f318fd22d664356b56b68023560d3c60f", "year": 2024, "title": "Generative AI Agents With Large Language Model for Satellite Networks via a Mixture of Experts Transmission", "authors": "Ruichen Zhang, Hongyang Du, Yinqiu Liu, Dusist Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour, Dong In Kim", "venue": "IEEE Journal on Selected Areas in Communications", "citationCount": 121, "abstract": "In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2404.09134"}
{"paperId": "23f4c8d980d8288131f80cbdb4173f05a21e8724", "year": 2023, "title": "RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions", "authors": "Yunlong Wang, Shuyuan Shen, Brian Y. Lim", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 121, "abstract": "Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2302.09466"}
{"paperId": "c11dad59cbca5cc4875391ebf5360f945aec933a", "year": 2023, "title": "Identifying and Mitigating the Security Risks of Generative AI", "authors": "Clark W. Barrett, Bradley L Boyd, Ellie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu, Anupam Datta, S. Feizi, Kathleen Fisher, Tatsunori Hashimoto, Dan Hendrycks, S. Jha, Daniel Kang, F. Kerschbaum, E. Mitchell, John C. Mitchell, Zulfikar Ramzan, K. Shams, D. Song, Ankur Taly, Diyi Yang", "venue": "Found. Trends Priv. Secur.", "citationCount": 120, "abstract": "Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks. This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interesting problems that the research community can work to address.", "isOpenAccess": false, "url": ""}
{"paperId": "8d1211cbbdf161feaae2c87832ede063346e76dd", "year": 2023, "title": "Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI", "authors": "Mahyar Abbasian, Elahe Khatibi, Iman Azimi, David Oniani, Zahra Shakeri Hossein Abad, Alexander Thieme, Ram Sriram, Zhongqi Yang, Yanshan Wang, Bryant Lin, Olivier Gevaert, Li-Jia Li, Ramesh C. Jain, Amir M. Rahmani", "venue": "npj Digital Medicine", "citationCount": 119, "abstract": "Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, dynamic scheduling of follow-ups, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients\u2019 well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present a comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-024-01074-z.pdf"}
{"paperId": "449ab79be2d6086b88832cfc9c5d502524c8524f", "year": 2023, "title": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors", "authors": "Tung Phung, Victor-Alexandru P\u0103durean, J. Cambronero, Sumit Gulwani, Tobias Kohn, R. Majumdar, A. Singla, Gustavo Soares", "venue": "International Computing Education Research Workshop", "citationCount": 119, "abstract": "Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI\u2019s ChatGPT [8] and GPT-4 [9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning [1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education [4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI\u2019s Codex [3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student\u2019s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student\u2019s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org [5] (see Figure 1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors\u2019 performance for several scenarios.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2306.17156"}
{"paperId": "229dc7283514bb87340c72615abc73202d1f9489", "year": 2023, "title": "ChatGPT: A Case Study on Copyright Challenges for Generative Artificial Intelligence Systems", "authors": "N. Lucchi", "venue": "European Journal of Risk Regulation", "citationCount": 119, "abstract": "Abstract This article focuses on copyright issues pertaining to generative artificial intelligence (AI) systems, with particular emphasis on the ChatGPT case study as a primary exemplar. In order to generate high-quality outcomes, generative AI systems require substantial quantities of training data, which may frequently comprise copyright-protected information. This prompts inquiries into the legal principles of fair use, the creation of derivative works and the lawfulness of data gathering and utilisation. The utilisation of input data for the purpose of training and enhancing AI models presents significant concerns regarding potential violations of copyright. This paper offers suggestions for safeguarding the interests of copyright holders and competitors, while simultaneously addressing legal challenges and expediting the advancement of AI technologies. This study analyses the ChatGPT platform as a case example to explore the necessary modifications that copyright regulations must undergo to adequately tackle the intricacies of authorship and ownership in the realm of AI-generated creative content.", "isOpenAccess": true, "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/CEDCE34DED599CC4EB201289BB161965/S1867299X23000594a.pdf/div-class-title-chatgpt-a-case-study-on-copyright-challenges-for-generative-artificial-intelligence-systems-div.pdf"}
{"paperId": "ed152e3e47524ef43a9aedc39a96365433384535", "year": 2023, "title": "Generative artificial intelligence empowers digital twins in drug discovery and clinical trials", "authors": "Maria Bordukova, Nikita Makarov, Raul Rodriguez-Esteban, Fabian Schmich, Michael P Menden", "venue": "Expert Opinion on Drug Discovery", "citationCount": 118, "abstract": "ABSTRACT Introduction The concept of Digital Twins (DTs) translated to drug development and clinical trials describes virtual representations of systems of various complexities, ranging from individual cells to entire humans, and enables in silico simulations and experiments. DTs increase the efficiency of drug discovery and development by digitalizing processes associated with high economic, ethical, or social burden. The impact is multifaceted: DT models sharpen disease understanding, support biomarker discovery and accelerate drug development, thus advancing precision medicine. One way to realize DTs is by generative artificial intelligence (AI), a cutting-edge technology that enables the creation of novel, realistic and complex data with desired properties. Areas covered The authors provide a brief introduction to generative AI and describe how it facilitates the modeling of DTs. In addition, they compare existing implementations of generative AI for DTs in drug discovery and clinical trials. Finally, they discuss technical and regulatory challenges that should be addressed before DTs can transform drug discovery and clinical trials. Expert opinion The current state of DTs in drug discovery and clinical trials does not exploit the entire power of generative AI yet and is limited to simulation of a small number of characteristics. Nonetheless, generative AI has the potential to transform the field by leveraging recent developments in deep learning and customizing models for the needs of scientists, physicians and patients.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/17460441.2023.2273839?needAccess=true"}
{"paperId": "496dab67b98785b46867173f0d777eaa9a32ca9c", "year": 2023, "title": "Detection of GPT-4 Generated Text in Higher Education: Combining Academic Judgement and Software to Identify Generative AI Tool Misuse", "authors": "Mike Perkins, Jasper Roe, Darius Postma, James McGaughran, Don Hickerson British University Vietnam, Vietnam, James Cook University Singapore, Singapore", "venue": "Journal of Academic Ethics", "citationCount": 118, "abstract": "This study explores the capability of academic staff assisted by the Turnitin Artificial Intelligence (AI) detection tool to identify the use of AI-generated content in university assessments. 22 different experimental submissions were produced using Open AI\u2019s ChatGPT tool, with prompting techniques used to reduce the likelihood of AI detectors identifying AI-generated content. These submissions were marked by 15 academic staff members alongside genuine student submissions. Although the AI detection tool identified 91% of the experimental submissions as containing AI-generated content, only 54.8% of the content was identified as AI-generated, underscoring the challenges of detecting AI content when advanced prompting techniques are used. When academic staff members marked the experimental submissions, only 54.5% were reported to the academic misconduct process, emphasising the need for greater awareness of how the results of AI detectors may be interpreted. Similar performance in grades was obtained between student submissions and AI-generated content (AI mean grade: 52.3, Student mean grade: 54.4), showing the capabilities of AI tools in producing human-like responses in real-life assessment situations. Recommendations include adjusting the overall strategies for assessing university students in light of the availability of new Generative AI tools. This may include reducing the overall reliance on assessments where AI tools may be used to mimic human writing, or by using AI-inclusive assessments. Comprehensive training must be provided for both academic staff and students so that academic integrity may be preserved.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.18081"}
{"paperId": "6159549f986c63e160a678feef2130a2a4b93feb", "year": 2023, "title": "Generative Recommendation: Towards Next-generation Recommender Paradigm", "authors": "Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, Tat-seng Chua", "venue": "arXiv.org", "citationCount": 117, "abstract": "Recommender systems typically retrieve items from an item corpus for personalized recommendations. However, such a retrieval-based recommender paradigm faces two limitations: 1) the human-generated items in the corpus might fail to satisfy the users' diverse information needs, and 2) users usually adjust the recommendations via inefficient passive feedback, e.g., clicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success, offering the potential to overcome these limitations: 1) generative AI can produce personalized items to satisfy users' information needs, and 2) the newly emerged large language models significantly reduce the efforts of users to precisely express information needs via natural language instructions. In this light, the boom of AIGC points the way towards the next-generation recommender paradigm with two new objectives: 1) generating personalized content through generative AI, and 2) integrating user instructions to guide content generation. To this end, we propose a novel Generative Recommender paradigm named GeneRec, which adopts an AI generator to personalize content generation and leverages user instructions. Specifically, we pre-process users' instructions and traditional feedback via an instructor to output the generation guidance. Given the guidance, we instantiate the AI generator through an AI editor and an AI creator to repurpose existing items and create new items. Eventually, GeneRec can perform content retrieval, repurposing, and creation to satisfy users' information needs. Besides, to ensure the trustworthiness of the generated items, we emphasize various fidelity checks. Moreover, we provide a roadmap to envision future developments of GeneRec and several domain-specific applications of GeneRec with potential research tasks. Lastly, we study the feasibility of implementing AI editor and AI creator on micro-video generation.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.03516"}
{"paperId": "073a9c27bba15de9f6abe80c94bbdb2e57618175", "year": 2023, "title": "How AI can distort human beliefs", "authors": "Celeste Kidd, Abeba Birhane", "venue": "Science", "citationCount": 117, "abstract": "Models can convey biases and false information to users Individual humans form their beliefs by sampling a small subset of the available data in the world. Once those beliefs are formed with high certainty, they can become stubborn to revise. Fabrication and bias in generative artificial intelligence (AI) models are established phenomena that can occur as part of regular system use, in the absence of any malevolent forces seeking to push bias or disinformation. However, transmission of false information and bias from these models to people has been prominently absent from the discourse. Overhyped, unrealistic, and exaggerated capabilities permeate how generative AI models are presented, which contributes to the popular misconception that these models exceed human-level reasoning and exacerbates the risk of transmission of false information and negative stereotypes to people.", "isOpenAccess": false, "url": ""}
{"paperId": "ff809cfc1351ef20cd667533cbc51d0ce6b6e16c", "year": 2023, "title": "Generative AI-Driven Semantic Communication Networks: Architecture, Technologies, and Applications", "authors": "Chengsi Liang, Hongyang Du, Yao Sun, Dusist Niyato, Jiawen Kang, Dezong Zhao, M. Imran", "venue": "IEEE Transactions on Cognitive Communications and Networking", "citationCount": 116, "abstract": "Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning. In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.", "isOpenAccess": false, "url": ""}
{"paperId": "4b6216e0fcaf3c50edcb279d9d618f085c057e2f", "year": 2023, "title": "What ChatGPT Tells Us about Gender: A Cautionary Tale about Performativity and Gender Biases in AI", "authors": "Nicole Gross", "venue": "The social science", "citationCount": 116, "abstract": "Large language models and generative AI, such as ChatGPT, have gained influence over people\u2019s personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper\u2019s central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to \u2018undo gender\u2019.", "isOpenAccess": true, "url": "https://www.mdpi.com/2076-0760/12/8/435/pdf?version=1690954844"}
{"paperId": "2986b2b06173e065c94bae49c7a9a3718dad486c", "year": 2024, "title": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation", "authors": "Patrice Bechard, Orlando Marquez Ayala", "venue": "North American Chapter of the Association for Computational Linguistics", "citationCount": 116, "abstract": "A common and fundamental limitation of Generative AI (GenAI) is its propensity to hallucinate. While large language models (LLM) have taken the world by storm, without eliminating or at least reducing hallucinations, real-world GenAI systems may face challenges in user adoption. In the process of deploying an enterprise application that produces workflows based on natural language requirements, we devised a system leveraging Retrieval Augmented Generation (RAG) to greatly improve the quality of the structured output that represents such workflows. Thanks to our implementation of RAG, our proposed system significantly reduces hallucinations in the output and improves the generalization of our LLM in out-of-domain settings. In addition, we show that using a small, well-trained retriever encoder can reduce the size of the accompanying LLM, thereby making deployments of LLM-based systems less resource-intensive.", "isOpenAccess": false, "url": ""}
{"paperId": "c886d0e3bffa478bf5e01f2b9f4231d1d5e3fbd0", "year": 2023, "title": "How ChatGPT Will Change Software Engineering Education", "authors": "Marian Daun, Jennifer Brings", "venue": "Annual Conference on Innovation and Technology in Computer Science Education", "citationCount": 115, "abstract": "This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.", "isOpenAccess": false, "url": ""}
{"paperId": "5d2f65749187c7369072d7ecbe37784295ac5acd", "year": 2024, "title": "How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey", "authors": "Matthew S. Bower, Jodie Torrington, Jennifer W. M. Lai, P. Petocz, Mark Alfano", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 115, "abstract": "There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n\u2009=\u2009318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an \u2018ignorance effect\u2019. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10639-023-12405-0.pdf"}
{"paperId": "916ffbf18036025e71d9384ea5a726a95f08589d", "year": 2023, "title": "From fiction to fact: the growing role of generative AI in business and finance", "authors": "Boyang Chen, Zongxiao Wu, Ruoran Zhao", "venue": "Journal of Chinese Economic and Business Studies", "citationCount": 113, "abstract": "ABSTRACT Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms\u2019 risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance.", "isOpenAccess": true, "url": "https://www.pure.ed.ac.uk/ws/files/374019625/ChenEtal2023JCEBSFromFictionToFact.pdf"}
{"paperId": "c6e2837894bb545fc62ef41d7dadcd6e1bb51dc5", "year": 2024, "title": "PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement", "authors": "Zhijie Wang, Yuheng Huang, Da Song, Lei Ma, Tianyi Zhang", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 112, "abstract": "The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model\u2019s interpretation and the user\u2019s intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user\u2019s initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model\u2019s attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user\u2019s expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642803"}
{"paperId": "6c0d7495b2fffb3233c9a22acd719db0637dc07d", "year": 2023, "title": "Designing Participatory AI: Creative Professionals\u2019 Worries and Expectations about Generative AI", "authors": "Nanna Inie, Jeanette Falk, Steve Tanimoto", "venue": "CHI Extended Abstracts", "citationCount": 112, "abstract": "Generative AI, i.e., the group of technologies that automatically generate visual or written content based on text prompts, has undergone a leap in complexity and become widely available within just a few years. Such technologies potentially introduce a massive disruption to creative fields. This paper presents the results of a qualitative survey (N = 23) investigating how creative professionals think about generative AI. The results show that the advancement of these AI models prompts important reflections on what defines creativity and how creatives imagine using AI to support their workflows. Based on these reflections, we discuss how we might design participatory AI in the domain of creative expertise with the goal of empowering creative professionals in their present and future coexistence with AI.", "isOpenAccess": true, "url": "https://pure.itu.dk/portal/files/102402921/arXiv_version.pdf"}
{"paperId": "68dc625a7a15107381639f56d33397d0f2c562ce", "year": 2023, "title": "Generative AI in higher education: Seeing ChatGPT through universities' policies, resources, and guidelines", "authors": "Hui Wang, Anh Dang, Zihao Wu, Son Mac", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 112, "abstract": null, "isOpenAccess": true, "url": "https://arxiv.org/pdf/2312.05235"}
{"paperId": "d933f21acd5308a10e6b4729b72098ade33733c1", "year": 2023, "title": "When ChatGPT Gives Incorrect Answers: The Impact of Inaccurate Information by Generative AI on Tourism Decision-Making", "authors": "Jeong Hyun Kim, Jungkeun Kim, Jooyoung Park, Changju Kim, J. Jhang, Brian King", "venue": "Journal of Travel Research", "citationCount": 111, "abstract": "This study investigates how inaccurate information provided by ChatGPT impacts travelers\u2019 acceptance of recommendations. Six experiments were conducted based on the accessibility-diagnosticity framework. These examined the moderating role of the prominence and type of incorrect information and their effects on decision-making. The results show that participants perceived more accuracy and trustworthiness, leading to stronger intentions to visit when incorrect information was absent. However, there was a decline in their intentions to visit when incorrect information was present and more prominent or in the same domain. This effect diminished when multiple domains were involved or when participants were focused on the initial task. The research highlights that both the prominence and type of incorrect information are boundary conditions and provides insights into AI applications in tourism. Furthermore, it offers practical implications for online travel agencies in terms of user interface and user experience design planning.", "isOpenAccess": false, "url": ""}
{"paperId": "a824d990e6f930760bf9dc56ca1599dc8e488191", "year": 2023, "title": "Chatbots and Mental Health: Insights into the Safety of Generative AI", "authors": "Julian De Freitas, A. U\u011furalp, Zeliha O\u011fuz\u2010U\u011furalp, Stefano Puntoni", "venue": "Journal of Consumer Psychology", "citationCount": 111, "abstract": "Chatbots are now able to engage in sophisticated conversations with consumers. Due to the \u2018black box\u2019 nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and \u201ccompanion AI\u201d: applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a non\u2010negligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies.", "isOpenAccess": false, "url": ""}
{"paperId": "64fe5a9abfcde0c7f345ef636bd70547dd212ac3", "year": 2024, "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation", "authors": "Orit Shaer, Angel Cooper, O. Mokryn, Andrew L. Kun, Hagit Ben Shoshan", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 111, "abstract": "The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process \u2013 the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642414"}
{"paperId": "4e9fefd759c0d0f920533cd70676a59e291729e2", "year": 2024, "title": "Collaborative Working and Critical Thinking: Adoption of Generative Artificial Intelligence Tools in Higher Education", "authors": "Lena Ivannova Ruiz-Rojas, Luis Salvador-Ullauri, Patricia Acosta-Vargas", "venue": "Sustainability", "citationCount": 111, "abstract": "This study explores the impact of generative artificial intelligence tools on critical thinking and collaboration among university students, highlighting the importance of investigating these technologies due to their increasing integration into higher education and their potential to transform traditional pedagogical practices. A predominantly female sample was surveyed to assess their familiarity with and experience and perceptions of these tools. A total of 87% of the respondents had prior knowledge of generative AI tools, with 38% using them occasionally. Among the most popular tools are Canva 2024 (33%), Chat PDF (26%), and YOU.COM (24%). Additionally, 64% of the respondents believe that these tools significantly improve their critical thinking ability. Despite their high familiarity with and occasional use of these tools, the need for continuous training and technical support was identified. While generative AI tools show promising potential for enhancing collaboration and critical thinking in higher education, previous research has limitations, such as the lack of longitudinal data and the inadequacy in addressing ethical considerations and potential biases. More comprehensive research is needed to understand their long-term impact better and maximize their potential benefits.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/16/13/5367/pdf?version=1719229432"}
{"paperId": "0b9d0bee85e4ef4261147f35be885010e62ad1fb", "year": 2024, "title": "Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations", "authors": "Siva Sai, Aanchal Gaur, Revant Sai, V. Chamola, Mohsen Guizani, J. Rodrigues", "venue": "IEEE Access", "citationCount": 111, "abstract": "Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10440330.pdf"}
{"paperId": "0019e876188f781fdca0c0ed3bca39d0c70c2ad2", "year": 2023, "title": "Artificial intelligence prompt engineering as a new digital competence: Analysis of generative AI technologies such as ChatGPT", "authors": "P. Korzy\u0144ski, G. Mazurek, Pamela Krzypkowska, Artur Kurasi\u0144ski", "venue": "Entrepreneurial Business and Economics Review", "citationCount": 111, "abstract": "Objective: The article aims to offer a thorough examination and comprehension of the challenges and pro\u2010 spects connected with artificial intelligence (AI) prompt engineering. Our research aimed to create a theoret\u2010 ical framework that would highlight optimal approaches in the field of AI prompt engineering. Research Design & Methods: This research utilized a narrative and critical literature review and established a conceptual framework derived from existing literature taking into account both academic and practitioner sources. This article should be regarded as a conceptual work that emphasizes the best practices in the domain of AI prompt engineering. Findings: Based on the conducted deep and extensive query of academic and practitioner literature on the subject, as well as professional press and Internet portals, we identified various insights for effective AI prompt engineering. We provide specific prompting strategies. Implications & Recommendations: The study revealed the profound implications of AI prompt engineering across various domains such as entrepreneurship, art, science, and healthcare. We demonstrated how the effective crafting of prompts can significantly enhance the performance of large language models (LLMs), gen\u2010 erating more accurate and contextually relevant results. Our findings offer valuable insights for AI practition\u2010 ers, researchers, educators, and organizations integrating AI into their operations, emphasizing the need to invest time and resources in prompt engineering. Moreover, we contributed the AI PROMPT framework to the field, providing clear and actionable guidelines for text\u2010to\u2010text prompt engineering. Contribution & Value Added: The value of this study lies in its comprehensive exploration of AI prompt engineer\u2010 ing as a digital competence. By building upon existing research and prior literature, this study aimed to provide a deeper understanding of the intricacies involved in AI prompt engineering and its role as a digital competence. Article", "isOpenAccess": true, "url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2142/863"}
{"paperId": "a38b56083e730b53a55fc40867854169f5350d14", "year": 2024, "title": "The effects of generative AI on initial language teacher education: The perceptions of teacher educators", "authors": "Benjamin Luke Moorhouse, Lucas Kohnke", "venue": "System (Link\u00f6ping)", "citationCount": 110, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.system.2024.103290"}
{"paperId": "4fda99880cdbf8f178f01eb4c8dbdae7f959ea94", "year": 2024, "title": "Red-Teaming for Generative AI: Silver Bullet or Security Theater?", "authors": "Michael Feffer, Anusha Sinha, Zachary Chase Lipton, Hoda Heidari", "venue": "AAAI/ACM Conference on AI, Ethics, and Society", "citationCount": 110, "abstract": "In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming\u2019s central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.", "isOpenAccess": false, "url": ""}
{"paperId": "e5c8ec5c8edaaa1417e68b30f59e9c2234dcdf4a", "year": 2024, "title": "Generative AI\u2019s environmental costs are soaring \u2014 and mostly secret", "authors": "Kate Crawford", "venue": "Nature", "citationCount": 109, "abstract": null, "isOpenAccess": true, "url": "https://www.nature.com/articles/d41586-024-00478-x.pdf"}
{"paperId": "cf1d8cdbacf8f922e24e0f99a28905b1157519e0", "year": 2024, "title": "Generative AI Based Secure Wireless Sensing for ISAC Networks", "authors": "Jiacheng Wang, Hongyang Du, Yinqiu Liu, Geng Sun, D. Niyato, Shiwen Mao, Dong In Kim, Xuemin Shen", "venue": "IEEE Transactions on Information Forensics and Security", "citationCount": 109, "abstract": "Integrated sensing and communications (ISAC) is one of the crucial technologies for 6G, and channel state information (CSI) based sensing serves as an essential part of ISAC. However, current research on ISAC focuses mainly on improving sensing performance, overlooking security issues, particularly the unauthorized sensing of users. Hence, this paper proposes a diffusion model based secure sensing system (DFSS). Specifically, we first propose a discrete conditional diffusion model to generate graphs with nodes and edges, which guides the ISAC system to appropriately activate wireless links and nodes, ensuring the sensing performance while minimizing the operation cost. Using the activated links and nodes, DFSS then employs the continuous conditional diffusion model to generate safeguarding signals, which are next modulated onto the pilot at the transmitter to mask fluctuations caused by user activities. As such, only authorized ISAC devices with the safeguarding signals can extract the true CSI for sensing, while unauthorized devices are unable to perform the effective sensing. Experiment results demonstrate that DFSS can reduce the activity recognition accuracy of the unauthorized devices by approximately 70%, effectively shield the user from the illegitimate surveillance.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2408.11398"}
{"paperId": "17f5fb4c300b11eb816acc79d2cb79b11d8930b9", "year": 2024, "title": "Artificial intelligence and consumer behavior: From predictive to generative AI", "authors": "Erik Hermann, Stefano Puntoni", "venue": "Journal of business research", "citationCount": 109, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "04266c4ef791e7d9682d609cd0fa7877c5c5ef6d", "year": 2023, "title": "Generative AI-Empowered Simulation for Autonomous Driving in Vehicular Mixed Reality Metaverses", "authors": "Minrui Xu, Dusist Niyato, Junlong Chen, Hongliang Zhang, Jiawen Kang, Zehui Xiong, Shiwen Mao, Zhu Han", "venue": "IEEE Journal on Selected Topics in Signal Processing", "citationCount": 109, "abstract": "In the vehicular mixed reality (MR) Metaverse, the discrepancy between physical and virtual entities can be overcome by fusing the physical and virtual environments with multi-dimensional communications in autonomous driving systems. Assisted by digital twin (DT) technologies, connected autonomous vehicles (AVs), roadside units (RSUs), and virtual simulators can maintain the vehicular MR Metaverse via simulations for sharing data and making driving decisions collaboratively. However, it is challenging and costly to enable large-scale traffic and driving simulation via realistic data collection and fusion from the physical world for online prediction and offline training in autonomous driving systems. In this paper, we propose an autonomous driving architecture, where generative AI is leveraged to synthesize unlimited conditioned traffic and driving data via simulations for improving driving safety and traffic control efficiency. First, we propose a multi-task DT offloading model for the reliable execution of heterogeneous DT tasks with different requirements at RSUs. Then, based on the preferences of AV's DTs and real-world data, virtual simulators can synthesize unlimited conditioned driving and traffic datasets for improved robustness. Finally, we propose a multi-task enhanced auction-based mechanism to provide fine-grained incentives for RSUs on providing resources for autonomous driving. The property analysis and experimental results demonstrate that the proposed mechanism and architecture are strategy-proof and effective.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2302.08418"}
{"paperId": "02b910aa9e5f9928f2ae0b0d2c0adeb5478e138c", "year": 2024, "title": "The Rapid Adoption of Generative AI", "authors": "Alexander Bick, A. Blandin, David J. Deming", "venue": "Social Science Research Network", "citationCount": 109, "abstract": "Generative artificial intelligence (AI) is a potentially important new technology, but its impact on the economy depends on the speed and intensity of adoption. This paper reports results from a series of nationally representative U", "isOpenAccess": false, "url": ""}
{"paperId": "3edfc47bb4e37a031636ad82b5c4a8f27a2eee1f", "year": 2024, "title": "Three Epochs of Artificial Intelligence in Health Care.", "authors": "Michael D Howell, G. Corrado, Karen B. DeSalvo", "venue": "Journal of the American Medical Association (JAMA)", "citationCount": 108, "abstract": "Importance\nInterest in artificial intelligence (AI) has reached an all-time high, and health care leaders across the ecosystem are faced with questions about where, when, and how to deploy AI and how to understand its risks, problems, and possibilities.\n\n\nObservations\nWhile AI as a concept has existed since the 1950s, all AI is not the same. Capabilities and risks of various kinds of AI differ markedly, and on examination 3 epochs of AI emerge. AI 1.0 includes symbolic AI, which attempts to encode human knowledge into computational rules, as well as probabilistic models. The era of AI 2.0 began with deep learning, in which models learn from examples labeled with ground truth. This era brought about many advances both in people's daily lives and in health care. Deep learning models are task-specific, meaning they do one thing at a time, and they primarily focus on classification and prediction. AI 3.0 is the era of foundation models and generative AI. Models in AI 3.0 have fundamentally new (and potentially transformative) capabilities, as well as new kinds of risks, such as hallucinations. These models can do many different kinds of tasks without being retrained on a new dataset. For example, a simple text instruction will change the model's behavior. Prompts such as \"Write this note for a specialist consultant\" and \"Write this note for the patient's mother\" will produce markedly different content.\n\n\nConclusions and Relevance\nFoundation models and generative AI represent a major revolution in AI's capabilities, ffering tremendous potential to improve care. Health care leaders are making decisions about AI today. While any heuristic omits details and loses nuance, the framework of AI 1.0, 2.0, and 3.0 may be helpful to decision-makers because each epoch has fundamentally different capabilities and risks.", "isOpenAccess": false, "url": ""}
{"paperId": "97d8be9c22d9bc76b5febbd989a7b48ecb951b81", "year": 2023, "title": "Empowering Education through Generative AI: Innovative Instructional Strategies for Tomorrow's Learners", "authors": "Kadaruddin Kadaruddin", "venue": "International Journal of Business, Law, and Education", "citationCount": 107, "abstract": "As the educational landscape endures continuous change, artificial intelligence (AI) has presented unprecedented opportunities to revolutionize instructional methods. Among these cutting-edge AI technologies, Generative AI has emerged as a promising instrument with the potential to empower educators and students through innovative instructional strategies. This article aims to investigate the various applications of Generative AI in education and cast light on its role in shaping the future of education. The objectives of this study are twofold: first, to investigate the various instructional strategies that can be enhanced by employing Generative AI, and second, to assess the potential impact of these strategies on student learning outcomes. To accomplish these goals, a comprehensive literature review was conducted analyzing existing studies and applications of Generative AI in educational settings. The results and discussions emphasize the numerous educational benefits of Generative AI. Educators can personalize learning experiences, create interactive content, and facilitate adaptive assessments by leveraging the capabilities of Generative AI. This individualized strategy has the potential to boost learner engagement and knowledge retention. However, despite the numerous advantages, ethical concerns and difficulties arise. The responsible incorporation of Generative AI in education requires addressing issues such as data privacy, algorithmic bias, and the educator's role in directing AI-driven learning experiences. The research concludes by emphasizing that Generative AI holds enormous promise for empowering education and transforming instructional practices. The findings highlight the importance of ongoing collaboration between educators, policymakers, and AI developers to ensure the ethical and equitable integration of Generative AI into educational environments. By embracing the potential of Generative AI while remaining vigilant regarding its challenges, the field of education can unlock novel opportunities to nurture an inclusive, adaptive, and learner-centric pedagogical landscape for tomorrow's learners. \n\u00a0", "isOpenAccess": true, "url": "https://ijble.com/index.php/journal/article/download/215/225"}
{"paperId": "88cdca57a248f7d1d9a0667834dc9f9af24bd2be", "year": 2024, "title": "Understanding the role and impact of Generative Artificial Intelligence (AI) hallucination within consumers\u2019 tourism decision-making processes", "authors": "Jeff Christensen, Jared M. Hansen, Paul Wilson", "venue": "Current Issues in Tourism", "citationCount": 107, "abstract": "ABSTRACT ChatGPT, which launched only a year ago, is the fastest-growing website in the world today. When generative AI software such as ChatGPT generates ideas for people, they often generate false ideas. This occurrence has been called \u2018AI Hallucination\u2019. It can include generating false text output that is extremely believable to completely gibberish. This source of potential misinformation has significant potential implications for the travel and tourism industry. Using survey responses from 900 consumers, this empirical study contributes to theorizing and examination of how consumers\u2019 awareness of AI Hallucination potential combines with existing concepts from the Technology Acceptance Model (TAM) and Theory of Planned Behaviour (TPB) when it comes to the decision to use generative AI platforms such as ChatGPT for tourism planning. This research also examines if the consumers are actually able to discern AI Hallucination and why they select to use AI technologies over other tourism information sources, such as aggregated peer review websites like TripAdvisor, government tourism websites, or social media influencers. The results indicate that many consumers chose error-filled AI tourism itineraries over other options because they trust the AI to be more impartial and customized than the other sources.", "isOpenAccess": false, "url": ""}
{"paperId": "59ed2890101dcf539fec8e701e9aea10ff5fcb56", "year": 2023, "title": "Unlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education", "authors": "Henner Gimpel, K. Hall, S. Decker, Torsten Eymann, Luis L\u00e4mmermann, Alexander M\u00e4dche, Maximilian R\u00f6glinger, Caroline Ruiner, Manfred Schoch, M. Schoop, Nils Urbach, Steffen Vandirk", "venue": "", "citationCount": 107, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "497d1aaa0f80b90b72e1a7519f1e4d1aefa2e429", "year": 2025, "title": "Optimizing generative AI by backpropagating language model feedback", "authors": "Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Pan Lu, Zhi Huang, Carlos Guestrin, James Zou", "venue": "Nature", "citationCount": 107, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "2a814b6605b137a9b2705fe68feae6c47248cddf", "year": 2024, "title": "The Effects of Generative AI on Design Fixation and Divergent Thinking", "authors": "Samangi Wadinambiarachchi, Ryan M. Kelly, Saumya Pareek, Qiushi Zhou, Eduardo Velloso", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 107, "abstract": "Generative AI systems have been heralded as tools for augmenting human creativity and inspiring divergent thinking, though with little empirical evidence for these claims. This paper explores the effects of exposure to AI-generated images on measures of design fixation and divergent thinking in a visual ideation task. Through a between-participants experiment (N=60), we found that support from an AI image generator during ideation leads to higher fixation on an initial example. Participants who used AI produced fewer ideas, with less variety and lower originality compared to a baseline. Our qualitative analysis suggests that the effectiveness of co-ideation with AI rests on participants\u2019 chosen approach to prompt creation and on the strategies used by participants to generate ideas in response to the AI\u2019s suggestions. We discuss opportunities for designing generative AI systems for ideation support and incorporating these AI tools into ideation workflows.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642919"}
{"paperId": "dd01b37aa5a25defb272ef95f720a33904d8d5ff", "year": 2024, "title": "The Crowdless Future? Generative AI and Creative Problem-Solving", "authors": "L\u00e9onard Boussioux, Jacqueline N. Lane, Miaomiao Zhang, Vladimir Jacimovic, Karim R. Lakhani", "venue": "Organization science (Providence, R.I.)", "citationCount": 106, "abstract": "The rapid advances in generative artificial intelligence (AI) open up attractive opportunities for creative problem-solving through human-guided AI partnerships. To explore this potential, we initiated a crowdsourcing challenge focused on sustainable, circular economy business ideas generated by the human crowd (HC) and collaborative human-AI efforts using two alternative forms of solution search. The challenge attracted 125 global solvers from various industries, and we used strategic prompt engineering to generate the human-AI solutions. We recruited 300 external human evaluators to judge a randomized selection of 13 out of 234 solutions, totaling 3,900 evaluator-solution pairs. Our results indicate that while human crowd solutions exhibited higher novelty\u2014both on average and for highly novel outcomes\u2014human-AI solutions demonstrated superior strategic viability, financial and environmental value, and overall quality. Notably, human-AI solutions cocreated through differentiated search, where human-guided prompts instructed the large language model to sequentially generate outputs distinct from previous iterations, outperformed solutions generated through independent search. By incorporating \u201cAI in the loop\u201d into human-centered creative problem-solving, our study demonstrates a scalable, cost-effective approach to augment the early innovation phases and lays the groundwork for investigating how integrating human-AI solution search processes can drive more impactful innovations. Funding: This work was supported by Harvard Business School (Division of Research and Faculty Development) and the Laboratory for Innovation Science at Harvard (LISH) at the Digital Data and Design (D3) Institute at Harvard. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.18430 .", "isOpenAccess": false, "url": ""}
{"paperId": "c650d58aaf13cb0847e2a10dc955843ef3e709b6", "year": 2024, "title": "ShieldGemma: Generative AI Content Moderation Based on Gemma", "authors": "Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez", "venue": "arXiv.org", "citationCount": 106, "abstract": "We present ShieldGemma, a comprehensive suite of LLM-based safety content moderation models built upon Gemma2. These models provide robust, state-of-the-art predictions of safety risks across key harm types (sexually explicit, dangerous content, harassment, hate speech) in both user input and LLM-generated output. By evaluating on both public and internal benchmarks, we demonstrate superior performance compared to existing models, such as Llama Guard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%). Additionally, we present a novel LLM-based data curation pipeline, adaptable to a variety of safety-related tasks and beyond. We have shown strong generalization performance for model trained mainly on synthetic data. By releasing ShieldGemma, we provide a valuable resource to the research community, advancing LLM safety and enabling the creation of more effective content moderation solutions for developers.", "isOpenAccess": false, "url": ""}
{"paperId": "a221f7fd6b40168123e6577d983cdd0d51c54297", "year": 2023, "title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"", "authors": "Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang, Jillian R. Fisher, Abhilasha Ravichander, Khyathi Raghavi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin Choi", "venue": "International Conference on Learning Representations", "citationCount": 106, "abstract": "The recent wave of generative AI has sparked unprecedented global attention, with both excitement and concern over potentially superhuman levels of artificial intelligence: models now take only seconds to produce outputs that would challenge or exceed the capabilities even of expert humans. At the same time, models still show basic errors in understanding that would not be expected even in non-expert humans. This presents us with an apparent paradox: how do we reconcile seemingly superhuman capabilities with the persistence of errors that few humans would make? In this work, we posit that this tension reflects a divergence in the configuration of intelligence in today's generative models relative to intelligence in humans. Specifically, we propose and test the Generative AI Paradox hypothesis: generative models, having been trained directly to reproduce expert-like outputs, acquire generative capabilities that are not contingent upon -- and can therefore exceed -- their ability to understand those same types of outputs. This contrasts with humans, for whom basic understanding almost always precedes the ability to generate expert-level outputs. We test this hypothesis through controlled experiments analyzing generation vs. understanding in generative models, across both language and image modalities. Our results show that although models can outperform humans in generation, they consistently fall short of human capabilities in measures of understanding, as well as weaker correlation between generation and understanding performance, and more brittleness to adversarial inputs. Our findings support the hypothesis that models' generative capability may not be contingent upon understanding capability, and call for caution in interpreting artificial intelligence by analogy to human intelligence.", "isOpenAccess": false, "url": ""}
{"paperId": "6dd1859af3f4856a0d3f9cca81c8d2121fb3979a", "year": 2023, "title": "A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI", "authors": "Chenshuang Zhang, Chaoning Zhang, Sheng Zheng, Mengchun Zhang, Maryam Qamar, S. Bae, In-So Kweon", "venue": "arXiv.org", "citationCount": 106, "abstract": "Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction. With the diffusion model as the most popular generative model, numerous works have attempted two active tasks: text to speech and speech enhancement. This work conducts a survey on audio diffusion model, which is complementary to existing surveys that either lack the recent progress of diffusion-based speech synthesis or highlight an overall picture of applying diffusion model in multiple fields. Specifically, this work first briefly introduces the background of audio and diffusion model. As for the text-to-speech task, we divide the methods into three categories based on the stage where diffusion model is adopted: acoustic model, vocoder and end-to-end framework. Moreover, we categorize various speech enhancement tasks by either certain signals are removed or added into the input speech. Comparisons of experimental results and discussions are also covered in this survey.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.13336"}
{"paperId": "47bef342b9e1204a1360ef087556bd1243c65e59", "year": 2024, "title": "The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market", "authors": "Xiang Hui, O. Reshef, Luofeng Zhou", "venue": "Social Science Research Network", "citationCount": 106, "abstract": "Generative artificial intelligence (AI) holds the potential to either complement workers by enhancing their productivity or substitute them. We examine the short-term effects of the recently released generative AI models (ChatGPT, DALL-E 2, and Midjourney) on the employment outcomes of freelancers on a large online platform. We find that freelancers in highly affected occupations suffer from the introduction of generative AI, experiencing reductions in both employment and earnings. We find similar effects studying the release of other image-based generative AI models. Exploring the heterogeneity by freelancers\u2019 employment history, we do not find evidence that high-quality service, measured by their past performance and employment, moderates the adverse effects on employment. In fact, we find suggestive evidence that top freelancers are disproportionately affected by AI. These results suggest that generative AI may transform the role of human capital in the organization and reduce overall demand for workers. Supplemental Material: The online appendices are available at https://doi.org/10.1287/orsc.2023.18441 .", "isOpenAccess": true, "url": "https://www.econstor.eu/bitstream/10419/279352/1/cesifo1_wp10601.pdf"}
{"paperId": "db5dc8a44511654dc7e0bbebd44f7b502e5e90be", "year": 2023, "title": "Generative AI for Medical Imaging: extending the MONAI Framework", "authors": "W. H. Pinaya, M. Graham, E. Kerfoot, Petru-Daniel Tudosiu, Jessica Dafflon, Virginia Fernandez, Pedro Sanchez, Julia Wolleb, P. F. D. Costa, Ashay Patel, Hyungjin Chung, Can Zhao, Wei Peng, Zelong Liu, X. Mei, Oeslle Lucena, Jong-Chul Ye, S. Tsaftaris, Prerna Dogra, Andrew Feng, M. Modat, P. Nachev, S. Ourselin, M. Cardoso", "venue": "arXiv.org", "citationCount": 105, "abstract": "Recent advances in generative AI have brought incredible breakthroughs in several areas, including medical imaging. These generative models have tremendous potential not only to help safely share medical data via synthetic datasets but also to perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due to the complexity of these models, their implementation and reproducibility can be difficult. This complexity can hinder progress, act as a use barrier, and dissuade the comparison of new methods with existing works. In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-art studies in a standardised way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalisable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (like CT, MRI, and X-Ray data) and from different anatomical areas. Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.15208"}
{"paperId": "27b4d4a9c6717b5ef062ddc472383b65db17932a", "year": 2023, "title": "The importance of transparency: Declaring the use of generative artificial intelligence (AI) in academic writing.", "authors": "A. Tang, K. Li, K. Kwok, Liujiao Cao, Stanley Luong, W. Tam", "venue": "Journal of Nursing Scholarship", "citationCount": 105, "abstract": "The integration of generative artificial intelligence (AI) into academic research writing has revolutionized the field, offering powerful tools like ChatGPT and Bard to aid researchers in content generation and idea enhancement. We explore the current state of transparency regarding generative AI use in nursing academic research journals, emphasizing the need for explicitly declaring the use of generative AI by authors in the manuscript. Out of 125 nursing studies journals, 37.6% required explicit statements about generative AI use in their authors' guidelines. No significant differences in impact factors or journal categories were found between journals with and without such requirement. A similar evaluation of medicine, general and internal journals showed a lower percentage (14.5%) including the information about generative AI usage. Declaring generative AI tool usage is crucial for maintaining the transparency and credibility in academic writing. Additionally, extending the requirement for AI usage declarations to journal reviewers can enhance the quality of peer review and combat predatory journals in the academic publishing landscape. Our study highlights the need for active participation from nursing researchers in discussions surrounding standardization of generative AI declaration in academic research writing.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jnu.12938"}
{"paperId": "615590460db7ac1fed59f6ff6c3fcae434cc6b9a", "year": 2024, "title": "Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT", "authors": "Le Zhuo, Ruoyi Du, Han Xiao, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, Lirui Zhao, Fu-Yun Wang, Zhanyu Ma, Xu Luo, Zehan Wang, Kaipeng Zhang, Xiangyang Zhu, Si Liu, Xiangyu Yue, Dingning Liu, Wanli Ouyang, Ziwei Liu, Y. Qiao, Hongsheng Li, Peng Gao", "venue": "Neural Information Processing Systems", "citationCount": 104, "abstract": "Lumina-T2X is a nascent family of Flow-based Large Diffusion Transformers that establishes a unified framework for transforming noise into various modalities, such as images and videos, conditioned on text instructions. Despite its promising capabilities, Lumina-T2X still encounters challenges including training instability, slow inference, and extrapolation artifacts. In this paper, we present Lumina-Next, an improved version of Lumina-T2X, showcasing stronger generation performance with increased training and inference efficiency. We begin with a comprehensive analysis of the Flag-DiT architecture and identify several suboptimal components, which we address by introducing the Next-DiT architecture with 3D RoPE and sandwich normalizations. To enable better resolution extrapolation, we thoroughly compare different context extrapolation methods applied to text-to-image generation with 3D RoPE, and propose Frequency- and Time-Aware Scaled RoPE tailored for diffusion transformers. Additionally, we introduced a sigmoid time discretization schedule to reduce sampling steps in solving the Flow ODE and the Context Drop method to merge redundant visual tokens for faster network evaluation, effectively boosting the overall sampling speed. Thanks to these improvements, Lumina-Next not only improves the quality and efficiency of basic text-to-image generation but also demonstrates superior resolution extrapolation capabilities and multilingual generation using decoder-based LLMs as the text encoder, all in a zero-shot manner. To further validate Lumina-Next as a versatile generative framework, we instantiate it on diverse tasks including visual recognition, multi-view, audio, music, and point cloud generation, showcasing strong performance across these domains. By releasing all codes and model weights, we aim to advance the development of next-generation generative AI capable of universal modeling.", "isOpenAccess": false, "url": ""}
{"paperId": "d0718a1e28fab2da6f35d9b7aedbb178596dafac", "year": 2024, "title": "A Systematic Review of Generative AI for Teaching and Learning Practice", "authors": "Bayode Ogunleye, K. Zakariyyah, Oluwaseun Ajao, Olakunle Olayinka, Hemlata Sharma", "venue": "Education sciences", "citationCount": 103, "abstract": "The use of generative artificial intelligence (GenAI) in academia is a subjective and hotly debated topic. Currently, there are no agreed guidelines towards the usage of GenAI systems in higher education (HE) and, thus, it is still unclear how to make effective use of the technology for teaching and learning practice. This paper provides an overview of the current state of research on GenAI for teaching and learning in HE. To this end, this study conducted a systematic review of relevant studies indexed by Scopus, using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines. The search criteria revealed a total of 625 research papers, of which 355 met the final inclusion criteria. The findings from the review showed the current state and the future trends in documents, citations, document sources/authors, keywords, and co-authorship. The research gaps identified suggest that while some authors have looked at understanding the detection of AI-generated text, it may be beneficial to understand how GenAI can be incorporated into supporting the educational curriculum for assessments, teaching, and learning delivery. Furthermore, there is a need for additional interdisciplinary, multidimensional studies in HE through collaboration. This will strengthen the awareness and understanding of students, tutors, and other stakeholders, which will be instrumental in formulating guidelines, frameworks, and policies for GenAI usage.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/14/6/636/pdf?version=1718350322"}
{"paperId": "8e1a8be0e6681a3940d5104b7baec09c5b632fb7", "year": 2024, "title": "Will generative AI replace teachers in higher education? A study of teacher and student perceptions", "authors": "Cecilia Ka Yuk Chan, Louisa H.Y. Tsi", "venue": "Studies in Educational Evaluation", "citationCount": 103, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "10a1df9191e88d17299ba32773f759792b558a51", "year": 2024, "title": "Opportunities and Challenges of Generative AI in Construction Industry: Focusing on Adoption of Text-Based Models", "authors": "Prashnna Ghimire, Kyungki Kim, Manoj Acharya", "venue": "Buildings", "citationCount": 103, "abstract": "In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLMs) like OpenAI\u2019s GPT, Google\u2019s PaLM, and Meta\u2019s Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI\u2019s early stage adoption within the construction sector. Given GenAI\u2019s unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors\u2019 opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture and engineering domains.", "isOpenAccess": true, "url": "https://www.mdpi.com/2075-5309/14/1/220/pdf?version=1705217602"}
{"paperId": "02885a292c3ae194cc46a8d9da6a8efdc20b0b43", "year": 2023, "title": "ChatGPT-A double-edged sword for healthcare education? Implications for assessments of dental students.", "authors": "K. Ali, Noha Barhom, F. Tamimi, M. Duggal", "venue": "European journal of dental education", "citationCount": 103, "abstract": "INTRODUCTION\nOpen-source generative artificial intelligence (AI) applications are fast-transforming access to information and allow students to prepare assignments and offer quite accurate responses to a wide range of exam questions which are routinely used in assessments of students across the board including undergraduate dental students. This study aims to evaluate the performance of Chat Generative Pre-trained Transformer (ChatGPT), a generative AI-based application, on a wide range of assessments used in contemporary healthcare education and discusses the implications for undergraduate dental education.\n\n\nMATERIALS AND METHODS\nThis was an exploratory study investigating the accuracy of ChatGPT to attempt a range of recognised assessments in healthcare education curricula. A total of 50 independent items encompassing 50 different learning outcomes (n\u2009=\u200910 per item) were developed by the research team. These included 10 separate items based on each of the five commonly used question formats including multiple-choice questions (MCQs); short-answer questions (SAQs); short essay questions (SEQs); single true/false questions; and fill in the blanks items. Chat GPT was used to attempt each of these 50 questions. In addition, ChatGPT was used to generate reflective reports based on multisource feedback; research methodology; and critical appraisal of the literature.\n\n\nRESULTS\nChatGPT application provided accurate responses to majority of knowledge-based assessments based on MCQs, SAQs, SEQs, true/false and fill in the blanks items. However, it was only able to answer text-based questions and did not allow processing of questions based on images. Responses generated to written assignments were also satisfactory apart from those for critical appraisal of literature. Word count was the key limitation observed in outputs generated by the free version of ChatGPT.\n\n\nCONCLUSION\nNotwithstanding their current limitations, generative AI-based applications have the potential to revolutionise virtual learning. Instead of treating it as a threat, healthcare educators need to adapt teaching and assessments in medical and dental education to the benefits of the learners while mitigating against dishonest use of AI-based technology.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/eje.12937"}
{"paperId": "de0d20742bb37f866324fb6c1db9736a76ecdbec", "year": 2023, "title": "Invisible Image Watermarks Are Provably Removable Using Generative AI", "authors": "Xuandong Zhao, Kexun Zhang, Yu-Xiang Wang, Lei Li", "venue": "Neural Information Processing Systems", "citationCount": 102, "abstract": "Invisible watermarks safeguard images' copyrights by embedding hidden messages only detectable by owners. They also prevent people from misusing images, especially those generated by AI models. We propose a family of regeneration attacks to remove these invisible watermarks. The proposed attack method first adds random noise to an image to destroy the watermark and then reconstructs the image. This approach is flexible and can be instantiated with many existing image-denoising algorithms and pre-trained generative models such as diffusion models. Through formal proofs and extensive empirical evaluations, we demonstrate that pixel-level invisible watermarks are vulnerable to this regeneration attack. Our results reveal that, across four different pixel-level watermarking schemes, the proposed method consistently achieves superior performance compared to existing attack techniques, with lower detection rates and higher image quality. However, watermarks that keep the image semantically similar can be an alternative defense against our attacks. Our finding underscores the need for a shift in research/industry emphasis from invisible watermarks to semantic-preserving watermarks. Code is available at https://github.com/XuandongZhao/WatermarkAttacker", "isOpenAccess": false, "url": ""}
{"paperId": "275fb93244b5a465d7e30fc6111e3403b47557be", "year": 2023, "title": "scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI", "authors": "Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Bo Wang", "venue": "bioRxiv", "citationCount": 102, "abstract": "Generative pre-trained models have achieved remarkable success in various domains such as natural language processing and computer vision. Specifically, the combination of large-scale diverse datasets and pre-trained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between linguistic constructs and cellular biology \u2014 where texts comprise words, similarly, cells are defined by genes \u2014 our study probes the applicability of foundation models to advance cellular biology and genetics research. Utilizing the burgeoning single-cell sequencing data, we have pioneered the construction of a foundation model for single-cell biology, scGPT, which is based on generative pre-trained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT, a generative pre-trained transformer, effectively distills critical biological insights concerning genes and cells. Through the further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell-type annotation, multi-batch integration, multi-omic integration, genetic perturbation prediction, and gene network inference. The scGPT codebase is publicly available at https://github.com/bowang-lab/scGPT.", "isOpenAccess": true, "url": "https://www.biorxiv.org/content/biorxiv/early/2023/07/02/2023.04.30.538439.full.pdf"}
{"paperId": "25a56b6ee239f814ef63e9b4692a8467456a5b3c", "year": 2024, "title": "ADMET-AI: a machine learning ADMET platform for evaluation of large-scale chemical libraries", "authors": "Kyle Swanson, Parker Walther, Jeremy Leitz, S. Mukherjee, Joseph C. Wu, Rabindra V. Shivnaraine, James Zou", "venue": "Bioinform.", "citationCount": 102, "abstract": "Abstract Motivation The emergence of large chemical repositories and combinatorial chemical spaces, coupled with high-throughput docking and generative AI, have greatly expanded the chemical diversity of small molecules for drug discovery. Selecting compounds for experimental validation requires filtering these molecules based on favourable druglike properties, such as Absorption, Distribution, Metabolism, Excretion, and Toxicity (ADMET). Results We developed ADMET-AI, a machine learning platform that provides fast and accurate ADMET predictions both as a website and as a Python package. ADMET-AI has the highest average rank on the TDC ADMET Leaderboard, and it is currently the fastest web-based ADMET predictor, with a 45% reduction in time compared to the next fastest public ADMET web server. ADMET-AI can also be run locally with predictions for one million molecules taking just 3.1\u2009h. Availability and implementation The ADMET-AI platform is freely available both as a web server at admet.ai.greenstonebio.com and as an open-source Python package for local batch prediction at github.com/swansonk14/admet_ai (also archived on Zenodo at doi.org/10.5281/zenodo.10372930). All data and models are archived on Zenodo at doi.org/10.5281/zenodo.10372418.", "isOpenAccess": true, "url": "https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btae416/58319615/btae416.pdf"}
{"paperId": "cde759cb4b07234bbac5b2fa17207aea87d6392f", "year": 2023, "title": "CreativeConnect: Supporting Reference Recombination for Graphic Design Ideation with Generative AI", "authors": "DaEun Choi, Sumin Hong, Jeongeon Park, John Joon Young Chung, Juho Kim", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 101, "abstract": "Graphic designers often get inspiration through the recombination of references. Our formative study (N=6) reveals that graphic designers focus on conceptual keywords during this process, and want support for discovering the keywords, expanding them, and exploring diverse recombination options of them, while still having room for designers\u2019 creativity. We propose CreativeConnect, a system with generative AI pipelines that helps users discover useful elements from the reference image using keywords, recommends relevant keywords, generates diverse recombination options with user-selected keywords, and shows recombinations as sketches with text descriptions. Our user study (N=16) showed that CreativeConnect helped users discover keywords from the reference and generate multiple ideas based on them, ultimately helping users produce more design ideas with higher self-reported creativity, compared to the baseline system without generative pipelines. While CreativeConnect was shown effective in ideation, we discussed how CreativeConnect can be extended to support other types of tasks in creativity support.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642794"}
{"paperId": "c0ab30ffc79952911aa13f8dd2ad226a54473d03", "year": 2023, "title": "Smiling Women Pitching Down: Auditing Representational and Presentational Gender Biases in Image Generative AI", "authors": "Luhang Sun, Mian Wei, Yibing Sun, Yoo Ji Suh, Liwei Shen, Sijia Yang", "venue": "J. Comput. Mediat. Commun.", "citationCount": 100, "abstract": "\n Generative Artificial Intelligence (AI) models like DALL\u00b7E 2 can interpret prompts and generate high-quality images that exhibit human creativity. Though public enthusiasm is booming, systematic auditing of potential gender biases in AI-generated images remains scarce. We addressed this gap by examining the prevalence of two occupational gender biases (representational and presentational biases) in 15,300 DALL\u00b7E 2 images spanning 153 occupations. We assessed potential bias amplification by benchmarking against the 2021 U.S. census data and Google Images. Our findings reveal that DALL\u00b7E 2 underrepresents women in male-dominated fields while overrepresenting them in female-dominated occupations. Additionally, DALL\u00b7E 2 images tend to depict more women than men with smiles and downward-pitching heads, particularly in female-dominated (versus male-dominated) occupations. Our algorithm auditing study demonstrates more pronounced representational and presentational biases in DALL\u00b7E 2 compared to Google Images and calls for feminist interventions to curtail the potential impacts of such biased AI-generated images on the media ecology.", "isOpenAccess": true, "url": "https://academic.oup.com/jcmc/article-pdf/29/1/zmad045/56546560/zmad045.pdf"}
{"paperId": "073e120d783e9b0b9fc6cbe60898bc5d4365a4c8", "year": 2023, "title": "Combating Misinformation in the Era of Generative AI Models", "authors": "Danni Xu, Shaojing Fan, Mohan Kankanhalli", "venue": "ACM Multimedia", "citationCount": 99, "abstract": "Misinformation has been a persistent and harmful phenomenon affecting our society in various ways, including individuals' physical health and economic stability. With the rise of short video platforms and related applications, the spread of multi-modal misinformation, encompassing images, texts, audios, and videos have exacerbated these concerns. The introduction of generative AI models like ChatGPT and Stable Diffusion has further complicated matters, giving rise to Artificial Intelligence Generated Content (AIGC) and presenting new challenges in detecting and mitigating misinformation. Consequently, traditional approaches to misinformation detection and intervention have become inadequate in this evolving landscape. This paper explores the challenges posed by AIGC in the context of misinformation. It examines the issue from psychological and societal perspectives, and explores the subtle manipulation traces found in AIGC at signal, perceptual, semantic, and human levels. By scrutinizing manipulation traces such as signal manipulation, semantic inconsistencies, logical incoherence, and psychological strategies, our objective is to tackle AI-generated misinformation and provide a conceptual design of systematic explainable solution. Ultimately, we aim for this paper to contribute valuable insights into combating misinformation, particularly in the era of AIGC.", "isOpenAccess": false, "url": ""}
{"paperId": "fcfc993f47d4b328aaf208b40624eaffa20dd646", "year": 2024, "title": "Improving elementary EFL speaking skills with generative AI chatbots: Exploring individual and paired interactions", "authors": "Tzu-Yu Tai, Howard Hao-Jan Chen", "venue": "Comput. Educ.", "citationCount": 98, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "796b67fd1f1c839c61170b01ca5caec42575a21c", "year": 2023, "title": "Design implications of generative AI systems for visual storytelling for young learners", "authors": "Ariel Han, Zhenyao Cai", "venue": "International Conference on Interaction Design and Children", "citationCount": 98, "abstract": "The study examines the design implications of leveraging generative AI tools such as ChatGPT, Stable Diffusion, Midjourney for literacy development and creative expression for children [6, 8, 18]. We sought to elicit insights on the applicability of generative AI for educational purposes from various stakeholders (i.e., parents, teachers, and AI researchers). We recruited nine participants to elicit their perspectives on designing a visual narrative app with generative AI. We examined the opportunities and limitations of the current generative AI tools. Using the implications from our evaluation, we propose AIStory, an AI-powered visual storytelling application prototype that can be used for children\u2019s creative expression, storytelling, and literacy development.", "isOpenAccess": false, "url": ""}
{"paperId": "752710bda78d91ff3a5a9f1c9a9cc5440a605673", "year": 2024, "title": "Exploring the impact of generative AI-based technologies on learning performance through self-efficacy, fairness & ethics, creativity, and trust in higher education", "authors": "Muhammad Farrukh Shahzad, Shuo Xu, Hira Zahid", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 98, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "5ee0f9333f49fe32c8417c0feb7a90a3b9ac4e12", "year": 2024, "title": "The Interplay of Learning, Analytics, and Artificial Intelligence in Education", "authors": "Mutlu Cukurova", "venue": "British Journal of Educational Technology", "citationCount": 98, "abstract": "This paper presents a multidimensional view of AI's role in education, emphasising the intricate interplay among AI, analytics and human learning processes. Here, I challenge the prevalent narrow conceptualisation of AI as tools in Education, exemplified in generative AI tools, and argue for the importance of alternative conceptualisations of AI for achieving human\u2013AI hybrid intelligence. I highlight the differences between human intelligence and artificial information processing, the importance of hybrid human\u2013AI systems to extend human cognition and posit that AI can also serve as an instrument for understanding human learning. Early learning sciences and AI in Education Research (AIED), which saw AI as an analogy for human intelligence, have diverged from this perspective, prompting a need to rekindle this connection. The paper presents three unique conceptualisations of AI: the externalisation of human cognition, the internalisation of AI models to influence human mental models and the extension of human cognition via tightly coupled human\u2013AI hybrid intelligence systems. Examples from current research and practice are examined as instances of the three conceptualisations in education, highlighting the potential value and limitations of each conceptualisation for human competence development, as well as the perils of overemphasis on approaches that replace human learning opportunities with AI tools. The paper concludes with advocacy for a broader approach to AIED that goes beyond considerations on the design and development of AI and includes educating people about AI and innovating educational systems to remain relevant in an AI ubiquitous world.", "isOpenAccess": false, "url": ""}
{"paperId": "07ee3807eb7a67dca8ed7b472c1af4110d97e95a", "year": 2023, "title": "The Foundation Model Transparency Index", "authors": "Rishi Bommasani, Kevin Klyman, S. Longpre, Sayash Kapoor, Nestor Maslej, Betty Xiong, Daniel Zhang, Percy Liang", "venue": "arXiv.org", "citationCount": 98, "abstract": "Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.", "isOpenAccess": false, "url": ""}
{"paperId": "b53bdf4562c06d78f260036c3f62dc34eaa0a6b8", "year": 2023, "title": "Trust in Generative AI among Students: An exploratory study", "authors": "Matin Amoozadeh, David Daniels, Daye Nam, Stella Chen, Michael Hilton, Sruti Srinivasa Ragavan, Mohammad Amin Alipour", "venue": "Technical Symposium on Computer Science Education", "citationCount": 97, "abstract": "Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.04631"}
{"paperId": "e01ed6611f9c998c237cda814ff8366a5acb6c3d", "year": 2023, "title": "Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era", "authors": "Chenghao Li, Chaoning Zhang, Atish Waghwase, Lik-Hang Lee, Fran\u00e7ois Rameau, Yang Yang, S. Bae, Choong-Seon Hong", "venue": "arXiv.org", "citationCount": 96, "abstract": "Generative AI has made significant progress in recent years, with text-guided content generation being the most practical as it facilitates interaction between human instructions and AI-generated content (AIGC). Thanks to advancements in text-to-image and 3D modeling technologies, like neural radiance field (NeRF), text-to-3D has emerged as a nascent yet highly active research field. Our work conducts a comprehensive survey on this topic and follows up on subsequent research progress in the overall field, aiming to help readers interested in this direction quickly catch up with its rapid development. First, we introduce 3D data representations, including both Structured and non-Structured data. Building on this pre-requisite, we introduce various core technologies to achieve satisfactory text-to-3D results. Additionally, we present mainstream baselines and research directions in recent text-to-3D technology, including fidelity, efficiency, consistency, controllability, diversity, and applicability. Furthermore, we summarize the usage of text-to-3D technology in various applications, including avatar generation, texture generation, scene generation and 3D editing. Finally, we discuss the agenda for the future development of text-to-3D.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.06131"}
{"paperId": "9bdb6d5bb94479a8612c41657d55bceef4898f98", "year": 2023, "title": "Evading Watermark based Detection of AI-Generated Content", "authors": "Zhengyuan Jiang, Jinghuai Zhang, N. Gong", "venue": "Conference on Computer and Communications Security", "citationCount": 96, "abstract": "A generative AI model can generate extremely realistic-looking content, posing growing challenges to the authenticity of information. To address the challenges, watermark has been leveraged to detect AI-generated content. Specifically, a watermark is embedded into an AI-generated content before it is released. A content is detected as AI-generated if a similar watermark can be decoded from it. In this work, we perform a systematic study on the robustness of such watermark-based AI-generated content detection. We focus on AI-generated images. Our work shows that an attacker can post-process a watermarked image via adding a small, human-imperceptible perturbation to it, such that the post-processed image evades detection while maintaining its visual quality. We show the effectiveness of our attack both theoretically and empirically. Moreover, to evade detection, our adversarial post-processing method adds much smaller perturbations to AI-generated images and thus better maintain their visual quality than existing popular post-processing methods such as JPEG compression, Gaussian blur, and Brightness/Contrast. Our work shows the insufficiency of existing watermark-based detection of AI-generated content, highlighting the urgent needs of new methods. Our code is publicly available: https://github.com/zhengyuan-jiang/WEvade.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.03807"}
{"paperId": "ec9e1baf7f7f2fdc529790edf9af23c320581d67", "year": 2023, "title": "Digital deception: generative artificial intelligence in social engineering and phishing", "authors": "Marc Schmitt, Ivan Flechais", "venue": "Artificial Intelligence Review", "citationCount": 95, "abstract": "The advancement of Artificial Intelligence (AI) and Machine Learning (ML) has profound implications for both the utility and security of our digital interactions. This paper investigates the transformative role of Generative AI in Social Engineering (SE) attacks. We conduct a systematic review of social engineering and AI capabilities and use a theory of social engineering to identify three pillars where Generative AI amplifies the impact of SE attacks: Realistic Content Creation, Advanced Targeting and Personalization, and Automated Attack Infrastructure. We integrate these elements into a conceptual model designed to investigate the complex nature of AI-driven SE attacks\u2014the Generative AI Social Engineering Framework. We further explore human implications and potential countermeasures to mitigate these risks. Our study aims to foster a deeper understanding of the risks, human implications, and countermeasures associated with this emerging paradigm, thereby contributing to a more secure and trustworthy human-computer interaction.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10973-2.pdf"}
{"paperId": "e58231569f45704a2460bb6de3ec6f52efc5cf95", "year": 2023, "title": "Automated Annotation with Generative AI Requires Validation", "authors": "Nicholas Pangakis, Samuel Wolken, Neil Fasching", "venue": "arXiv.org", "citationCount": 95, "abstract": "Generative large language models (LLMs) can be a powerful tool for augmenting text annotation procedures, but their performance varies across annotation tasks due to prompt quality, text data idiosyncrasies, and conceptual difficulty. Because these challenges will persist even as LLM technology improves, we argue that any automated annotation process using an LLM must validate the LLM's performance against labels generated by humans. To this end, we outline a workflow to harness the annotation potential of LLMs in a principled, efficient way. Using GPT-4, we validate this approach by replicating 27 annotation tasks across 11 datasets from recent social science articles in high-impact journals. We find that LLM performance for text annotation is promising but highly contingent on both the dataset and the type of annotation task, which reinforces the necessity to validate on a task-by-task basis. We make available easy-to-use software designed to implement our workflow and streamline the deployment of LLMs for automated annotation.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.00176"}
{"paperId": "b045d8a7f44f5137139f354c2905ea3f86488f81", "year": 2024, "title": "Exploring Students\u2019 Generative AI-Assisted Writing Processes: Perceptions and Experiences from Native and Nonnative English Speakers", "authors": "Chaoran Wang", "venue": "Technology, Knowledge and Learning", "citationCount": 95, "abstract": "Generative artificial intelligence (AI) can create sophisticated textual and multimodal content readily available to students. Writing intensive courses and disciplines that use writing as a major form of assessment are significantly impacted by advancements in generative AI, as the technology has the potential to revolutionize how students write and how they perceive writing as a fundamental literacy skill. However, educators are still at the beginning stage of understanding students\u2019 integration of generative AI in their actual writing process. This study addresses the urgent need to uncover how students engage with ChatGPT throughout different components of their writing processes and their perceptions of the opportunities and challenges of generative AI. Adopting a phenomenological research design, the study explored the writing practices of six students, including both native and nonnative English speakers, in a first-year writing class at a higher education institution in the US. Thematic analysis of students\u2019 written products, self-reflections, and interviews suggests that students utilized ChatGPT for brainstorming and organizing ideas as well as assisting with both global (e.g., argument, structure, coherence) and local issues of writing (e.g., syntax, diction, grammar), while they also had various ethical and practical concerns about the use of ChatGPT. The study brought to front two dilemmas encountered by students in their generative AI-assisted writing: (1) the challenging balance between incorporating AI to enhance writing and maintaining their authentic voice, and (2) the dilemma of weighing the potential loss of learning experiences against the emergence of new learning opportunities accompanying AI integration. These dilemmas highlight the need to rethink learning in an increasingly AI-mediated educational context, emphasizing the importance of fostering students\u2019 critical AI literacy to promote their authorial voice and learning in AI-human collaboration.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10758-024-09744-3.pdf"}
{"paperId": "7b5432e589b5f801d99bd27c00349ac651d308e4", "year": 2023, "title": "A New Era of Learning: Considerations for ChatGPT as a Tool to Enhance Statistics and Data Science Education", "authors": "Amanda R. Ellis, E. Slade", "venue": "Journal of Statistics and Data Science Education", "citationCount": 95, "abstract": "Abstract ChatGPT is one of many generative artificial intelligence (AI) tools that has emerged recently, creating controversy in the education community with concerns about its potential to be used for plagiarism and to undermine students\u2019 ability to think independently. Recent publications have criticized the use of ChatGPT and other generative AI tools in the classroom, with little focus on the potential benefits. This article focuses on the potential of ChatGPT as an educational tool for statistics and data science. It encourages readers to consider the history of trepidation surrounding introducing new technology in the classroom, such as the calculator. We explore the possibility of leveraging ChatGPT\u2019s capabilities in statistics and data science education, providing examples of how ChatGPT can aid in developing course materials and suggestions for how educators can prompt students to interact with ChatGPT responsibly. As educators, we can guide the use of generative AI tools in statistics and data science classrooms so that students and educators can leverage the benefits of this technology.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/26939169.2023.2223609?needAccess=true&role=button"}
{"paperId": "39d26fd00ba7b6bd7a642a10a0287234157cb3e7", "year": 2024, "title": "GenAI et al.: Cocreation, Authorship, Ownership, Academic Ethics and Integrity in a Time of Generative AI", "authors": "Aras Bozkurt", "venue": "Open Praxis", "citationCount": 95, "abstract": "This paper investigates the complex interplay between generative artificial intelligence (AI) and human intellect in academic writing and publishing. It examines the \u2018organic versus synthetic\u2019 paradox, emphasizing the implications of using generative AI tools in educational and academic integrity contexts. The paper critiques the prevalent \u2018publish or perish\u2019 culture in academia, highlighting the need for systemic reevaluation due to generative AI\u2019s emerging role in academic writing and reporting. It delves into the legal and ethical challenges of authorship and ownership, especially in relation to copyright laws and AI-generated content. The paper discusses generative AI\u2019s diverse roles and advocates for transparent reporting to uphold academic integrity. Additionally, it calls for a broader examination of generative AI tools and stresses the need for new mechanisms to identify generative AI use and ensure adherence to academic integrity and ethics. The implications of generative AI are also explored, suggesting the need for innovative AI-inclusive strategies in academia. The paper concludes by emphasizing the significance of generative AI in various information-processing domains, highlighting the urgency to adapt and transform academic practices in an era of rapid generative AI-driven", "isOpenAccess": true, "url": "https://storage.googleapis.com/jnl-up-j-op-files/journals/1/articles/654/65bcd00a4e478.pdf"}
{"paperId": "a4a08c52416390eb02da9648aff1c1cf9dfebb4d", "year": 2024, "title": "Multimodal Whole Slide Foundation Model for Pathology", "authors": "Tong Ding, Sophia J. Wagner, Andrew H. Song, Richard J. Chen, Ming Y. Lu, Andrew Zhang, Anurag Vaidya, Guillaume Jaume, Muhammad Shaban, Ahrong Kim, Drew F. K. Williamson, Bowen Chen, Cristina Almagro-P\u00e9rez, Paul Doucet, S. Sahai, Chengkuan Chen, D. Komura, Akihiro Kawabe, S. Ishikawa, Georg K. Gerber, Tingying Peng, L. Le, Faisal Mahmood", "venue": "arXiv.org", "citationCount": 94, "abstract": "The field of computational pathology has been transformed with recent advances in foundation models that encode histopathology region-of-interests (ROIs) into versatile and transferable feature representations via self-supervised learning (SSL). However, translating these advancements to address complex clinical challenges at the patient and slide level remains constrained by limited clinical data in disease-specific cohorts, especially for rare clinical conditions. We propose TITAN, a multimodal whole slide foundation model pretrained using 335,645 WSIs via visual self-supervised learning and vision-language alignment with corresponding pathology reports and 423,122 synthetic captions generated from a multimodal generative AI copilot for pathology. Without any finetuning or requiring clinical labels, TITAN can extract general-purpose slide representations and generate pathology reports that generalize to resource-limited clinical scenarios such as rare disease retrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and find that TITAN outperforms both ROI and slide foundation models across machine learning settings such as linear probing, few-shot and zero-shot classification, rare cancer retrieval and cross-modal retrieval, and pathology report generation.", "isOpenAccess": false, "url": ""}
{"paperId": "4abb9aeb5c5b7312f747badb17b930b361fc3871", "year": 2024, "title": "Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity", "authors": "Claudio Novelli, F. Casolari, Philipp Hacker, Giorgio Spedicato, Luciano Floridi", "venue": "Social Science Research Network", "citationCount": 94, "abstract": "The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models, ensuring they align with the EU's evolving digital landscape and legal standards.", "isOpenAccess": true, "url": "https://cris.unibo.it/bitstream/11585/994881/3/Generative%20AI%20in%20EU%20law%3a%20Liability%2c%20privacy%2c%20intellectual%20property%2c%20and%20cybersecurity.pdf"}
{"paperId": "362855e7652f0f07f05a51fbd94e88a5fd2597ba", "year": 2023, "title": "The Artificial Intelligence Assessment Scale (AIAS): A Framework for Ethical Integration of Generative AI in Educational Assessment", "authors": "Mike Perkins, Leon Furze, Jasper Roe, Jason MacVaugh British University Vietnam, Deakin University, James Cook University Singapore", "venue": "Journal of University Teaching and Learning Practice", "citationCount": 94, "abstract": "Recent developments in Generative Artificial Intelligence (GenAI) have created a paradigm shift in multiple areas of society, and the use of these technologies is likely to become a defining feature of education in coming decades. GenAI offers transformative pedagogical opportunities, while simultaneously posing ethical and academic challenges. Against this backdrop, we outline a practical, simple, and sufficiently comprehensive tool to allow for the integration of GenAI tools into educational assessment: the AI Assessment Scale (AIAS). The AIAS empowers educators to select the appropriate level of GenAI usage in assessments based on the learning outcomes they seek to address. The AIAS offers greater clarity and transparency for students and educators, provides a fair and equitable policy tool for institutions to work with, and offers a nuanced approach which embraces the opportunities of GenAI while recognising that there are instances where such tools may not be pedagogically appropriate or necessary. By adopting a practical, flexible approach that can be implemented quickly, the AIAS can form a much-needed starting point to address the current uncertainty and anxiety regarding GenAI in education. As a secondary objective, we engage with the current literature and advocate for a refocused discourse on GenAI tools in education, one which foregrounds how technologies can help support and enhance teaching and learning, which contrasts with the current focus on GenAI as a facilitator of academic misconduct.", "isOpenAccess": true, "url": "https://open-publishing.org/journals/index.php/jutlp/article/download/810/769"}
{"paperId": "d69953ae182aaa1925a56c5ffe8c8be14f7c6cc8", "year": 2024, "title": "A classification tool to foster self-regulated learning with generative artificial intelligence by applying self-determination theory: a case of ChatGPT", "authors": "T. Chiu", "venue": "Educational technology research and development", "citationCount": 93, "abstract": "Generative AI such as ChatGPT provides an instant and individualized learning environment, and may have the potential to motivate student self-regulated learning (SRL), more effectively than other non-AI technologies. However, the impact of ChatGPT on student motivation, SRL, and needs satisfaction is unclear. Motivation and the SRL process can be explained using self-determination theory (SDT) and the three phases of forethought, performance, and self-reflection, respectively. Accordingly, a Delphi design was employed in this study to determine how ChatGPT-based learning activities satisfy students\u2019 each SDT need, and foster each SRL phase from a teacher perspective. We involved 36 SDT school teachers with extensive expertise in technology enhanced learning to develop a classification tool for learning activities that affect student needs satisfaction and SRL phases using ChatGPT. We collaborated with the teachers in three rounds to investigate and identify the activities, and we revised labels, descriptions, and explanations. The major finding is that a classification tool for 20 learning activities using ChatGPT was developed. The tool suggests how ChatGPT better satisfy SDT-based needs, and fosters the three SRL phrases. This classification tool can assist researchers in replicating, implementing, and integrating successful ChatGPT in education research and development projects. The tool can inspire teachers to modify the activities using generative AI for their own teaching, and inform policymakers on how to develop guidelines for AI in education.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11423-024-10366-w.pdf"}
{"paperId": "6c544c918f73d36335f916ed7a81daf9531393fc", "year": 2023, "title": "Why open-source generative AI models are an ethical way forward for science", "authors": "A. Spirling", "venue": "Nature", "citationCount": 93, "abstract": null, "isOpenAccess": true, "url": "https://www.nature.com/articles/d41586-023-01295-4.pdf"}
{"paperId": "65df79aaaa61a549cd774177d3d1ffcfa9ab3c5c", "year": 2024, "title": "Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education", "authors": "Mohammed Jaboob, Manar Hazaimeh, A. Al-Ansi", "venue": "International journal of human computer interactions", "citationCount": 93, "abstract": "Abstract The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students\u2019 cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country\u2019s universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students\u2019 cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students\u2019 interaction with and utility of these applications show high satisfactory level of their impact on students\u2019 behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.", "isOpenAccess": false, "url": ""}
{"paperId": "e731072ac62efc68aa208ea4a0f0de8e0f1a9ea1", "year": 2023, "title": "AI\u2019s Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia", "authors": "Rida Qadri, R. Shelby, Cynthia L. Bennett, Remi Denton", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 92, "abstract": "This paper presents a community-centered study of cultural limitations of text-to-image (T2I) models in the South Asian context. We theorize these failures using scholarship on dominant media regimes of representations and locate them within participants\u2019 reporting of their existing social marginalizations. We thus show how generative AI can reproduce an outsiders gaze for viewing South Asian cultures, shaped by global and regional power inequities. By centering communities as experts and soliciting their perspectives on T2I limitations, our study adds rich nuance into existing evaluative frameworks and deepens our understanding of the culturally-specific ways AI technologies can fail in non-Western and Global South settings. We distill lessons for responsible development of T2I models, recommending concrete pathways forward that can allow for recognition of structural inequalities.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3593013.3594016"}
{"paperId": "db6b5baa8390e065e7823a85010f952850ad8729", "year": 2023, "title": "DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models", "authors": "Yongchan Kwon, Eric Wu, Kevin Wu, James Zou", "venue": "International Conference on Learning Representations", "citationCount": 92, "abstract": "Quantifying the impact of training data points is crucial for understanding the outputs of machine learning models and for improving the transparency of the AI pipeline. The influence function is a principled and popular data attribution method, but its computational cost often makes it challenging to use. This issue becomes more pronounced in the setting of large language models and text-to-image models. In this work, we propose DataInf, an efficient influence approximation method that is practical for large-scale generative AI models. Leveraging an easy-to-compute closed-form expression, DataInf outperforms existing influence computation algorithms in terms of computational and memory efficiency. Our theoretical analysis shows that DataInf is particularly well-suited for parameter-efficient fine-tuning techniques such as LoRA. Through systematic empirical evaluations, we show that DataInf accurately approximates influence scores and is orders of magnitude faster than existing methods. In applications to RoBERTa-large, Llama-2-13B-chat, and stable-diffusion-v1.5 models, DataInf effectively identifies the most influential fine-tuning examples better than other approximate influence scores. Moreover, it can help to identify which data points are mislabeled.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.00902"}
{"paperId": "96907f7dfa554375b2d8ffc4166b7e59f3fcff20", "year": 2023, "title": "Generative AI-Enabled Vehicular Networks: Fundamentals, Framework, and Case Study", "authors": "Ruichen Zhang, Ke Xiong, Hongyang Du, Fellow Ieee Dusit Niyato, Jiawen Kang, Fellow Ieee Xuemin Shen, L. F. I. H. Vincent Poor", "venue": "IEEE Network", "citationCount": 92, "abstract": "Recognizing the tremendous improvements that the integration of generative artificial intelligence (AI) can bring to intelligent transportation systems, this article explores the integration of generative AI technologies in vehicular networks, focusing on their potential applications and challenges. Generative AI, with its capabilities of generating realistic data and facilitating advanced decision-making processes, enhances various applications when combined with vehicular networks, such as navigation optimization, traffic prediction, data generation, and evaluation. Despite these promising applications, the integration of generative AI with vehicular networks faces several challenges, such as real-time data processing and decision-making, adapting to dynamic and unpredictable environments, as well as privacy and security concerns. To address these challenges, we propose a multi-modality semantic-aware framework to enhance the service quality of generative AI. By leveraging multi-modal and semantic communication technologies, the framework enables the use of text and image data for creating multi-modal content, providing more reliable guidance to receiving vehicles and ultimately improving system usability and efficiency. To further improve the reliability and efficiency of information transmission and reconstruction within the framework, taking generative AI-enabled vehicle-to-vehicle (V2V) as a case study, a deep reinforcement learning (DRL)-based approach is proposed for resource allocation. Finally, we discuss potential research directions and anticipated advancements in the field of generative AI-enabled vehicular networks.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.11098"}
{"paperId": "ed90ca3acf39066225e9f8e1d6d5b5de2a878361", "year": 2024, "title": "A Primer on Generative Artificial Intelligence", "authors": "Faisal Kalota", "venue": "Education sciences", "citationCount": 91, "abstract": "Many educators and professionals in different industries may need to become more familiar with the basic concepts of artificial intelligence (AI) and generative artificial intelligence (Gen-AI). Therefore, this paper aims to introduce some of the basic concepts of AI and Gen-AI. The approach of this explanatory paper is first to introduce some of the underlying concepts, such as artificial intelligence, machine learning, deep learning, artificial neural networks, and large language models (LLMs), that would allow the reader to better understand generative AI. The paper also discusses some of the applications and implications of generative AI on businesses and education, followed by the current challenges associated with generative AI.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/14/2/172/pdf?version=1707311959"}
{"paperId": "e6a4de0d86ab55e1e8ba20418229ec885aca38dd", "year": 2023, "title": "Human favoritism, not AI aversion: People\u2019s perceptions (and bias) toward generative AI, human experts, and human\u2013GAI collaboration in persuasive content generation", "authors": "Yunhao Zhang, Ren\u00e9e Gosline", "venue": "Judgment and Decision Making", "citationCount": 91, "abstract": "\n With the wide availability of large language models and generative AI, there are four primary paradigms for human\u2013AI collaboration: human-only, AI-only (ChatGPT-4), augmented human (where a human makes the final decision with AI output as a reference), or augmented AI (where the AI makes the final decision with human output as a reference). In partnership with one of the world\u2019s leading consulting firms, we enlisted professional content creators and ChatGPT-4 to create advertising content for products and persuasive content for campaigns following the aforementioned paradigms. First, we find that, contrary to the expectations of some of the existing algorithm aversion literature on conventional predictive AI, the content generated by generative AI and augmented AI is perceived as of higher quality than that produced by human experts and augmented human experts. Second, revealing the source of content production reduces\u2014but does not reverse\u2014the perceived quality gap between human- and AI-generated content. This bias in evaluation is predominantly driven by human favoritism rather than AI aversion: Knowing that the same content is created by a human expert increases its (reported) perceived quality, but knowing that AI is involved in the creation process does not affect its perceived quality. Further analysis suggests this bias is not due to a \u2018quality prime\u2019 as knowing the content they are about to evaluate comes from competent creators (e.g., industry professionals and state-of-the-art AI) without knowing exactly that the creator of each piece of content does not increase participants\u2019 perceived quality.", "isOpenAccess": true, "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/419C4BD9CE82673EAF1D8F6C350C4FA8/S1930297523000372a.pdf/div-class-title-human-favoritism-not-ai-aversion-people-s-perceptions-and-bias-toward-generative-ai-human-experts-and-human-gai-collaboration-in-persuasive-content-generation-div.pdf"}
{"paperId": "a6db55d1cf2372d11ee7e2a924b6b78bf42bb7aa", "year": 2023, "title": "How will AI text generation and processing impact sustainability reporting? Critical analysis, a conceptual framework and avenues for future research", "authors": "C. de Villiers, Ruth Dimes, Matteo Molinari", "venue": "Sustainability Accounting, Management and Policy Journal", "citationCount": 91, "abstract": "\nPurpose\nThe ability of generative artificial intelligence (AI) tools such as ChatGPT to produce convincing, human-like text has major implications for the future of corporate reporting, including sustainability reporting. As the importance of sustainability reporting continues to grow, this study aims to critically analyse the benefits and pitfalls of automated text generation and processing.\n\n\nDesign/methodology/approach\nThis study develops a conceptual framework to delineate the field, assess the implications and form the basis for the generation of research questions. This study uses Alvesson and Deetz\u2019s critical framework, considering insight (a review of literature and practice in the field), critique (consideration of the influences on the production and use of non-financial information and the implications for assurers of such information) and transformative redefinition (considering the implications of generative AI for sustainability reporting and proposing a research agenda).\n\n\nFindings\nThis study highlights the implications of generative AI for sustainability accounting, reporting, assurance and report usage, including the risk of AI facilitating greenwashing, and the importance of more research on the use of AI for these matters.\n\n\nPractical implications\nThe paper highlights to stakeholders the implications of AI for all aspects of sustainability reporting, including accounting, reporting, assurance and usage of reports.\n\n\nSocial implications\nThe implications of AI need to be understood in society, which this paper facilitates.\n\n\nOriginality/value\nThis study critically analyses the potential use of AI for sustainability reporting, construct a conceptual framework to delineate the field and develop a research agenda.\n", "isOpenAccess": true, "url": "https://kar.kent.ac.uk/102917/3/DeVilliersetal2023SAMPJAIandSustainabilityAccounting-acceptedversion.pdf"}
{"paperId": "999e64cf92fe72297e2011f6285180d4bc30f4b5", "year": 2025, "title": "Randomized Trial of a Generative AI Chatbot for Mental Health Treatment", "authors": "Michael V. Heinz, Daniel M. Mackin, Brianna M. Trudeau, Sukanya Bhattacharya, Yinzhou Wang, Haley A. Banta, Abi D. Jewett, Abigail J. Salzhauer, Tess Z. Griffin, Nicholas C. Jacobson", "venue": "NEJM AI", "citationCount": 91, "abstract": "BACKGROUND Generative artificial intelligence (Gen-AI) chatbots hold promise for building highly personalized, effective mental health treatments at scale, while also addressing user engagement and retention issues common among digital therapeutics. We present a randomized controlled trial (RCT) testing an expert\u2013fine-tuned Gen-AI\u2013powered chatbot, Therabot, for mental health treatment. METHODS We conducted a national, randomized controlled trial of adults (N=210) with clinically significant symptoms of major depressive disorder (MDD), generalized anxiety disorder (GAD), or at clinically high risk for feeding and eating disorders (CHR-FED). Participants were randomly assigned to a 4-week Therabot intervention (N=106) or waitlist control (WLC; N=104). WLC participants received no app access during the study period but gained access after its conclusion (8 weeks). Participants were stratified into one of three groups based on mental health screening results: those with clinically significant symptoms of MDD, GAD, or CHR-FED. Primary outcomes were symptom changes from baseline to postintervention (4 weeks) and to follow-up (8 weeks). Secondary outcomes included user engagement, acceptability, and therapeutic alliance (i.e., the collaborative patient and therapist relationship). Cumulative-link mixed models examined differential changes. Cohen\u2019s d effect sizes were unbounded and calculated based on the log-odds ratio, representing differential change between groups.", "isOpenAccess": false, "url": ""}
{"paperId": "875e80b2c36c890f9ea434ca1270ecbf1833aab8", "year": 2023, "title": "How can artificial intelligence decrease cognitive and work burden for front line practitioners?", "authors": "Tejal K Gandhi, D. Classen, C. Sinsky, D. Rhew, Nikki Vande Garde, Andrew Roberts, F. Federico", "venue": "JAMIA Open", "citationCount": 91, "abstract": "Abstract Artificial intelligence (AI) has tremendous potential to improve the cognitive and work burden of clinicians across a range of clinical activities, which could lead to reduced burnout and better clinical care. The recent explosion of generative AI nicely illustrates this potential. Developers and organizations deploying AI have a responsibility to ensure AI is designed and implemented with end-user input, has mechanisms to identify and potentially reduce bias, and that the impact on cognitive and work burden is measured, monitored, and improved. This article focuses specifically on the role AI can play in reducing cognitive and work burden, outlines the critical issues associated with the use of AI, and serves as a call to action for vendors and users to work together to develop functionality that addresses these challenges.", "isOpenAccess": true, "url": "https://academic.oup.com/jamiaopen/article-pdf/6/3/ooad079/51305145/ooad079.pdf"}
{"paperId": "5bea14c265e81127f282298ee1274f2b8c2de160", "year": 2024, "title": "Developing evaluative judgement for a time of generative artificial intelligence", "authors": "M. Bearman, Joanna Tai, P. Dawson, D. Boud, R. Ajjawi", "venue": "Assessment &amp; Evaluation in Higher Education", "citationCount": 91, "abstract": "Abstract Generative artificial intelligence (AI) has rapidly increased capacity for producing textual, visual and auditory outputs, yet there are ongoing concerns regarding the quality of those outputs. There is an urgent need to develop students\u2019 evaluative judgement \u2013 the capability to judge the quality of work of self and others \u2013 in recognition of this new reality. In this conceptual paper, we describe the intersection between evaluative judgement and generative AI with a view to articulating how assessment practices can help students learn to work productively with generative AI. We propose three foci: (1) developing evaluative judgement of generative AI outputs; (2) developing evaluative judgement of generative AI processes; and (3) generative AI assessment of student evaluative judgements. We argue for developing students\u2019 capabilities to identify and calibrate quality of work \u2013 uniquely human capabilities at a time of technological acceleration \u2013 through existing formative assessment strategies. These approaches circumvent and interrupt students\u2019 uncritical usage of generative AI. The relationship between evaluative judgement and generative AI is more than just the application of human judgement to machine outputs. We have a collective responsibility, as educators and learners, to ensure that humans do not relinquish their roles as arbiters of quality.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/02602938.2024.2335321?needAccess=true"}
{"paperId": "928e790f91226adee08049e601c64e47143de1ec", "year": 2024, "title": "Generative AI for Visualization: State of the Art and Future Directions", "authors": "Yilin Ye, Jianing Hao, Yihan Hou, Zhan Wang, Shishi Xiao, Yuyu Luo, Wei Zeng", "venue": "Visual Informatics", "citationCount": 90, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.visinf.2024.04.003"}
{"paperId": "850a5c74833054824ce2280cb0d7226cbaac8b46", "year": 2024, "title": "A Survey of AI-Generated Content (AIGC)", "authors": "Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Phillp S. Yu, Lichao Sun", "venue": "ACM Computing Surveys", "citationCount": 90, "abstract": "Recently, Artificial Intelligence Generated Content (AIGC) has gained significant attention from society, especially with the rise of Generative AI (GAI) techniques such as ChatGPT, GPT-4 [165], DALL-E-3 [184], and Sora [137]. AIGC involves using AI models to create digital content, such as images, music, and natural language, with the goal of making the content creation process more efficient and accessible. Large-scale models have become increasingly important in AIGC as they provide better intent extraction and generation results. This survey provides a comprehensive review of the history of generative models and recent advances in AIGC, focusing on both unimodal and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, the survey discusses the existing open problems and future challenges in AIGC. Overall, this survey serves as a valuable resource for individuals interested in understanding the background and secrets behind the impressive performance of AIGC techniques.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3704262"}
{"paperId": "47663f81e71ec289ae4512b08da0cf7c7dafa413", "year": 2023, "title": "ChatGPT, AI Advertising, and Advertising Research and Education", "authors": "J. Huh, M. Nelson, C. Russell", "venue": "Journal of Advertising", "citationCount": 90, "abstract": "Since ChatGPT was released on November 30, 2022, followed by Microsoft\u2019s announcement of its artificial intelligence (AI)\u2013powered new Bing search engine on February 7, 2023, and Google\u2019s Bard release on March 21, 2023, it seems AI generally has taken over conversations across all sectors of society. In a very short time span, consumers and a wide range of organizations have adopted generative AI technologies with astonishing capabilities (Bove 2023). These new technological developments have accelerated the integration of AI into many tools, apps, and areas of our daily life, but the transformative AI technology is perhaps most deeply impacting the world of advertising. AI-enabled advertising spending worldwide in 2022 was estimated to be $370 billion, with predictions of $1.3 trillion in the next ten years (Statista 2023). While the viral sensation and enormous popularity of ChatGPT are generating unprecedented attention and interest in AI right now, AI, as both a theoretical concept and version of its technological implementations and applications, has a long history with its origin going back to the 1950s. In the advertising field, the first research article on the topic of AI in connection to advertising was published in 1988 (Cook and Schleede 1988). The authors described \u201cdecision support systems\u201d (i.e., expert systems) as probably the \u201cmost widely implemented and well-known applications of AI\u201d (48). As described, these systems used databases and models to solve problems, such as help with direct-mail systems and newspaper advertising placement. Since then, AI has changed the business of media and advertising and attracted attention from both advertising practitioners and scholars. Although there is no standard definition, Rodgers (2021) defined AI advertising as \u201cbrand communication that uses a range of machine functions that learn to carry out tasks with intent to persuade with input by humans, machines, or both\u201d (2) and positioned AI advertising as a subdiscipline of advertising \u201csituated at the intersection of cognitive science, computer science, and advertising\u201d (2). Advertisers are using AI technologies in automated market segmentation and targeting, ad creative development and personalization, improving ad buying and placement, and optimizing advertising investment (Kietzmann, Paschen, and Treen 2018). Following the trend of increasing AI adoption in advertising, advertising scholars have organized sessions at the American Academy of Advertising (AAA) conference, such as the 2014 preconference, \u201cBig Data for Advertising Research and Education,\u201d and the joint AAA-ANA Educational Foundation luncheon panel with the provocative title, \u201cThe Future of Advertising\u2014Will We Be Replaced by Robots?\u201d in 2018. The Journal of Advertising (JA) has published multiple themed collections on AI-related topics, starting with a Special Section on Artificial Intelligence and Advertising, guest-edited by Hairong Li (2019). This collection of articles explored the potential and actual application of AI technologies to enhance advertising efficiency, effects, and effectiveness across the entire spectrum of the advertising campaign process, from situation analysis and consumer insight generation to advertising message creation, to media planning and buying, and to advertising effect assessment (see the Journal of Advertising, vol. 48, no. 4). Another Special Section on Advances in Computational Advertising in 2020, guest edited by Jisu Huh and Ed Malthouse (2020), addressed broad implications of evolving computer science technologies for data-driven, AI-powered computational advertising, and proposed a future research agenda in the areas of macro and exogenous factors, consumers\u2019 roles in computational advertising, AI-powered ad content generation, computational advertising media planning strategy shifts from purchasing exposure to focusing on meaningful consumer engagement, and computational advertising measurement systems (see the Journal of Advertising, vol. 49, no. 4). A year later, JA published an up-to-date comprehensive Themed Issue on Promises and Perils of Artificial Intelligence and Advertising (2021, vol. 50, no. 1). In her editorial, the previous editor, Shelly Rodgers (2021) proposed an AI classification schema to systematically understand and develop subdomains", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/00913367.2023.2227013?needAccess=true&role=button"}
{"paperId": "b705e3cca48f1e61ae7052a4208f8e97606de95e", "year": 2024, "title": "AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM Experts", "authors": "Shaona Ghosh, Prasoon Varshney, Erick Galinkin, Christopher Parisien", "venue": "arXiv.org", "citationCount": 89, "abstract": "As Large Language Models (LLMs) and generative AI become more widespread, the content safety risks associated with their use also increase. We find a notable deficiency in high-quality content safety datasets and benchmarks that comprehensively cover a wide range of critical safety areas. To address this, we define a broad content safety risk taxonomy, comprising 13 critical risk and 9 sparse risk categories. Additionally, we curate AEGISSAFETYDATASET, a new dataset of approximately 26, 000 human-LLM interaction instances, complete with human annotations adhering to the taxonomy. We plan to release this dataset to the community to further research and to help benchmark LLM models for safety. To demonstrate the effectiveness of the dataset, we instruction-tune multiple LLM-based safety models. We show that our models (named AEGISSAFETYEXPERTS), not only surpass or perform competitively with the state-of-the-art LLM-based safety models and general purpose LLMs, but also exhibit robustness across multiple jail-break attack categories. We also show how using AEGISSAFETYDATASET during the LLM alignment phase does not negatively impact the performance of the aligned models on MT Bench scores. Furthermore, we propose AEGIS, a novel application of a no-regret online adaptation framework with strong theoretical guarantees, to perform content moderation with an ensemble of LLM content safety experts in deployment", "isOpenAccess": false, "url": ""}
{"paperId": "918a603933ae9957236d68ef6b6d75e05e259c39", "year": 2023, "title": "Generative AI for Space-Air-Ground Integrated Networks", "authors": "Ruichen Zhang, Hongyang Du, D. Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour, Ping Zhang, Dong In Kim", "venue": "IEEE wireless communications", "citationCount": 89, "abstract": "Recently, generative AI technologies have emerged as significant advancements in the artificial intelligence field, renowned for their language and image generation capabilities. Meantime, the space-air-ground integrated network (SAGIN) is an integral part of future B5G/6G for achieving ubiquitous connectivity. Inspired by this, this article explores an integration of generative AI in SAGIN, focusing on potential applications and a case study. We first provide a comprehensive review of SAGIN and generative AI models, highlighting their capabilities and opportunities for their integration. Benefiting from generative AI's ability to generate useful data and facilitate advanced decision-making processes, it can be applied to various scenarios of SAGIN. Accordingly, we present a brief survey on their integration, including channel modeling and channel state information (CSI) estimation, joint air-space-ground resource allocation, intelligent network deployment, semantic communications, image extraction and processing, and security and privacy enhancement. Next, we propose a framework that utilizes a generative diffusion model (GDM) to construct a channel information map to enhance quality of service for SAGIN. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we discuss potential research directions for generative AI-enabled SAGIN.", "isOpenAccess": false, "url": ""}
{"paperId": "087c74522fda4bc178eb23bebc988bf46007f4fb", "year": 2024, "title": "Design2Code: How Far Are We From Automating Front-End Engineering?", "authors": "Chenglei Si, Yanzhe Zhang, Ryan Li, Zhengyuan Yang, Ruibo Liu, Diyi Yang", "venue": "arXiv.org", "citationCount": 89, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "a9c0d7bad124697e370a1b345508b6bc618a4f64", "year": 2023, "title": "Ethics of generative AI", "authors": "Hazem Zohny, J. McMillan, M. King", "venue": "Journal of Medical Ethics", "citationCount": 88, "abstract": "Artificial intelligence (AI) and its introduction into clinical pathways presents an array of ethical issues that are being discussed in the JME. The development of AI technologies that can produce text that will pass plagiarism detectors and are capable of appearing to be written by a human author present new issues for medical ethics. One set of worries concerns authorship and whether it will now be possible to know that an author or student in fact produced submitted work. That seems likely to be a general worry for secondary and higher education, as well as for all academic journals. Thus far generative AI chatbots do not seem to be able to produce a fully referenced and wellargued ethics article, but they probably could generate a blog or student essay that would be hard to detect after very minor edits. Many schools and universities have moved to online forms of assessment, and it seems likely that generative AI might cast doubt on the integrity of them and we might see a reversion to handwritten examinations as a solution. As well as these immediate and perhaps obvious ethical concerns, generative AI highlights conceptual challenges that pose more profound ethical questions. JME is committed to publishing highquality articles that further the ethical analysis of an issue within healthcare. Some of the content that the journal publishes reports empirical findings. An article that, for example, describes qualitative findings and then develops an analysis of some normative issues could not be solely authored by generative AI: it cannot do qualitative research. However, generative AI can find publicly available sources and produce ethical arguments and syllogisms. What does that imply about the nature of ethical analysis? If ethical analysis, fundamentally, involves assembling, organising and evaluating words, then perhaps generative AI could replace ethicists. At present, generative AI cannot produce the nuance, depth or originality of a quality ethics article, but it may be a matter of time before they pass a medical ethics version of the Turing test. While those who rely on more analytic approaches to ethics might view this as an ethical apocalypse, there are more subtler ways in which generative AI might be used in authorship that are more positive. For instance, if you experiment with ChatGPT for a while, you might find that when you know what you want to say in a paragraph or subsection, you can prompt it to form the argument you want to make and it will generate a fairly welldrafted paragraph. For authors and for postgraduate students, this might be useful for \u2018throat clearing\u2019 sections which are just laying the terrain for the reader before proceeding. AI chatbots might also play a helpful devil\u2019s advocate: once you make a point in a paragraph, you can ask it to generate a rebuttal. If you experiment with ChatGPT you might find that it can be helpful in that not only does it generate obvious counters, but it often raises things that you might not have immediately thought of. So perhaps generative AI has the potential to pose questions like those that might be raised at a seminar while a paper or book is being refined. Much of the work involved in writing good, innovative and original ethical analysis involves wrestling with high level ideas. If generative AI can aid authors in drafting articles then perhaps they save intellectual effort that could be directed toward the \u2018big picture\u2019? Many publishers, including the BMJ, are committed to encouraging authors from the Global South to write for journals where the authorship has been primarily from the Global North. Publishing in journals such as the JME can be more difficult when English is not an author\u2019s first language. Because of the speed at which generative AI can present an author\u2019s ideas in what is close to idiomatic English, they have the potential to significantly open up authorship, especially for humanities style journals like the JME. Journal and copy editors might also save time and effort when correcting articles. These potential benefits will no doubt come with tradeoffs. For instance, those who struggle to articulate a point in writing may find that to be part of a process that leads to a new insight. Perhaps generative AI runs the risk of making that part of the writing process too easy and lead to missing out on opportunities for insight. While that seems like a valid worry, it might be that this is analogous to the changes in writing that resulted from journals being readily available online. Those of us who are old enough to recall writing before online publishing will have spent time trudging between library stacks and searching hard copies of journals to find a paper and stumbling across other papers and journals, which may have led to new ideas. Complete reliance on online databases has probably reduced those moments but the tradeoff clearly still favours their use. Universities, publishers and journals are likely to be exercised about what this will mean for authorship. How can we know whether work was created by the author or by generative AI? While understandable, these worries might be overstated given what they can do at present. While they might find some publicly available sources to support claims, at present they cannot adequately cite, and the quality of the content they produce is wholly dependent on you asking the right questions or having the right ideas. At present, they can be seen as a very sophisticated thesaurus and we do not worry about authors using those. Perhaps the biggest concern is that some predatory journals may feed off the speed by which lowquality manuscripts can now be generated with AI chatbots, and use the phenomenon to publish huge numbers of mostly useless or misleading ethical analyses. This could flood the journal market and undermine trust in research publications. This may be curbed by introducing the use of AI output detectors, though it may also encourage greater (and much needed) scepticism towards publications, with readers and news writers paying greater attention to where the paper they are reporting on was published, and what the publisher\u2019s standards are. Editorially, journals need to and will continue to be concerned with authorship, but our main focus is on the quality and originality of ideas. It seems likely that generative AI is here to stay and will develop, so journals will need to find ways of figuring out how to work with them. Bioethics Centre, The University of Otago, Dunedin, New Zealand", "isOpenAccess": true, "url": "https://jme.bmj.com/content/medethics/49/2/79.full.pdf"}
{"paperId": "58c21b7488ec9d5cdf51507c740277acacf10f3d", "year": 2024, "title": "Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education", "authors": "Ariel Han, Xiaofei Zhou, Zhenyao Cai, Shenshen Han, Richard Ko, Seth Corrigan, Kylie A Peppler", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 88, "abstract": "The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder\u2019s perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students\u2019 agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students\u2019 agency over writing projects.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642438"}
{"paperId": "adfcc00814fbb55a4b0c430c5c004bf7988734cb", "year": 2024, "title": "Unlocking de novo antibody design with generative artificial intelligence", "authors": "Amir Shanehsazzadeh, S. Bachas, George Kasun, J. Sutton, A. Steiger, Richard W. Shuai, Christa Kohnert, Alex Morehead, Amber Brown, Chelsea Chung, Breanna K. Luton, Nicolas Diaz, Matt McPartlon, Bailey Knight, Macey Radach, K. Bateman, David A. Spencer, Jovan Cejovic, Gaelin Kopec-Belliveau, Robel Haile, Edriss Yassine, Cailen M. McCloskey, Monica Natividad, Dalton Chapman, Luka Stojanovic, G. Rakocevic, G. Hannum, Engin Yapici, Katherine M. Moran, Rodante Caguiat, S. Abdulhaqq, Zheyuan Guo, Lillian R. Klug, Miles Gander, Joshua Meier", "venue": "bioRxiv", "citationCount": 87, "abstract": "Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of \u223c106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with \u223c3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.", "isOpenAccess": true, "url": "https://www.biorxiv.org/content/biorxiv/early/2023/03/29/2023.01.08.523187.full.pdf"}
{"paperId": "42cc614a2e380004c7678e4ded0f8a88ec6837b9", "year": 2024, "title": "Strategies for Integrating Generative AI into Higher Education: Navigating Challenges and Leveraging Opportunities", "authors": "Gila Kurtz, Meital Amzalag, N. Shaked, Yanay Zaguri, Dan Kohen-Vacs, E. Gal, Gideon Zailer, Eran Barak-Medina", "venue": "Education sciences", "citationCount": 87, "abstract": "The recent emergence of generative AI (GenAI) tools such as ChatGPT, Midjourney, and Gemini have introduced revolutionary capabilities that are predicted to transform numerous facets of society fundamentally. In higher education (HE), the advent of GenAI presents a pivotal moment that may profoundly alter learning and teaching practices in aspects such as inaccuracy, bias, overreliance on technology and algorithms, and limited access to educational AI resources that require in-depth investigation. To evaluate the implications of adopting GenAI in HE, a team of academics and field experts have co-authored this paper, which analyzes the potential for the responsible integration of GenAI into HE and provides recommendations about this integration. This paper recommends strategies for integrating GenAI into HE to create the following positive outcomes: raise awareness about disruptive change, train faculty, change teaching and assessment practices, partner with students, impart AI learning literacies, bridge the digital divide, and conduct applied research. Finally, we propose four preliminary scale levels of a GenAI adoption for faculty. At each level, we suggest courses of action to facilitate progress to the next stage in the adoption of GenAI. This study offers a valuable set of recommendations to decision-makers and faculty, enabling them to prepare for the responsible and judicious integration of GenAI into HE.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/14/5/503/pdf?version=1715092275"}
{"paperId": "cedb9896241e88bd72bc8582846b4e9c758af555", "year": 2024, "title": "Generative AI and human\u2013robot interaction: implications and future agenda for business, society and ethics", "authors": "Bojan Obrenovic, Xiaochuan Gu, Guoyu Wang, Danijela Godinic, Ilimdorjon J. Jakhongirov", "venue": "Ai & Society", "citationCount": 86, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "cea012c01f09ac382fe67ede5215a85175753487", "year": 2023, "title": "The Social Impact of Generative AI: An Analysis on ChatGPT", "authors": "M. T. Baldassarre, D. Caivano, Berenice Fern\u00e1ndez Nieto, Domenico Gigante, Azzurra Ragone", "venue": "Conference on Information Technology for Social Good", "citationCount": 86, "abstract": "In recent months, the impact of Artificial Intelligence (AI) on citizens\u2019 lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3582515.3609555"}
{"paperId": "4d7bb2aaeca9398cfc97a830b133dfba8a362452", "year": 2024, "title": "Cheating in the age of generative AI: A high school survey study of cheating behaviors before and after the release of ChatGPT", "authors": "Victor R. Lee, Denise Pope, Sarah Miles, Rosalia Zarate", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 86, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100253"}
{"paperId": "4d71e5d1b47b207d5545fa1ec272c6053596da4c", "year": 2023, "title": "May the force of text data analysis be with you: Unleashing the power of generative AI for social psychology research", "authors": "Mohammed Salah, Hussam Al Halbusi, Fadi Abdelfattah", "venue": "Computers in Human Behavior", "citationCount": 86, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.chbah.2023.100006"}
{"paperId": "0294429d82dfc985ed6877e9333a48b37f9306d8", "year": 2023, "title": "Creativity in the age of generative AI", "authors": "Janet Rafner, R. Beaty, James C. Kaufman, T. Lubart, J. Sherson", "venue": "Nature Human Behaviour", "citationCount": 86, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "8d531cb8cf51eec3b8f1106d189295fa3c81c02a", "year": 2023, "title": "Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing", "authors": "Kai Wang, Fei Yang, Shiqi Yang, Muhammad Atif Butt, Joost van de Weijer", "venue": "Neural Information Processing Systems", "citationCount": 85, "abstract": "Large-scale text-to-image generative models have been a ground-breaking development in generative AI, with diffusion models showing their astounding ability to synthesize convincing images following an input text prompt. The goal of image editing research is to give users control over the generated images by modifying the text prompt. Current image editing techniques are susceptible to unintended modifications of regions outside the targeted area, such as on the background or on distractor objects which have some semantic or visual relationship with the targeted object. According to our experimental findings, inaccurate cross-attention maps are at the root of this problem. Based on this observation, we propose Dynamic Prompt Learning (DPL) to force cross-attention maps to focus on correct noun words in the text prompt. By updating the dynamic tokens for nouns in the textual input with the proposed leakage repairment losses, we achieve fine-grained image editing over particular objects while preventing undesired changes to other image regions. Our method DPL, based on the publicly available Stable Diffusion, is extensively evaluated on a wide range of images, and consistently obtains superior results both quantitatively (CLIP score, Structure-Dist) and qualitatively (on user-evaluation). We show improved prompt editing results for Word-Swap, Prompt Refinement, and Attention Re-weighting, especially for complex multi-object scenes.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.15664"}
{"paperId": "7d7f20d8822e4dd444fb5788c1fa354a3f2a0401", "year": 2024, "title": "Generative artificial intelligence in primary care: an online survey of UK general practitioners", "authors": "C. Blease, Cosima Locher, Jens Gaab, M. H\u00e4gglund, K. Mandl", "venue": "BMJ Health & Care Informatics", "citationCount": 85, "abstract": "Objectives Following the launch of ChatGPT in November 2022, interest in large language model-powered chatbots has soared with increasing focus on the clinical potential of these tools. We sought to measure general practitioners\u2019 (GPs) current use of this new generation of chatbots to assist with any aspect of clinical practice in the UK. Methods An online survey was distributed to a non-probability sample of GPs registered with the clinician marketing service Doctors.net.uk. The study was launched as a monthly \u2018omnibus survey\u2019 which has a predetermined sample size of 1000 participants. Results 531 (53%) respondents were men, 544 (54%) were 46 years or older. 20% (205) reported using generative artificial intelligence (AI) tools in clinical practice; of those who answered affirmatively and were invited to clarify further, 29% (47) reported using these tools to generate documentation after patient appointments and 28% (45) to suggest a differential diagnosis. Discussion Administered a year after ChatGPT was launched, this is the largest survey we know of conducted into doctors\u2019 use of generative AI in clinical practice. Findings suggest that GPs may derive value from these tools, particularly with administrative tasks and to support clinical reasoning. Conclusion Despite a lack of guidance about these tools and unclear work policies, GPs report using generative AI to assist with their job. The medical community will need to find ways to both educate physicians and trainees and guide patients about the safe adoption of these tools.", "isOpenAccess": true, "url": "https://doi.org/10.1136/bmjhci-2024-101102"}
{"paperId": "46694f750ff97513e48b5eb8b52c2184d5840b2b", "year": 2024, "title": "The persuasive effects of political microtargeting in the age of generative artificial intelligence", "authors": "Almog Simchon, Matthew Edwards, Stephan Lewandowsky", "venue": "PNAS Nexus", "citationCount": 85, "abstract": "Abstract The increasing availability of microtargeted advertising and the accessibility of generative artificial intelligence (AI) tools, such as ChatGPT, have raised concerns about the potential misuse of large language models in scaling microtargeting efforts for political purposes. Recent technological advancements, involving generative AI and personality inference from consumed text, can potentially create a highly scalable \u201cmanipulation machine\u201d that targets individuals based on their unique vulnerabilities without requiring human input. This paper presents four studies examining the effectiveness of this putative \u201cmanipulation machine.\u201d The results demonstrate that personalized political ads tailored to individuals\u2019 personalities are more effective than nonpersonalized ads (studies 1a and 1b). Additionally, we showcase the feasibility of automatically generating and validating these personalized ads on a large scale (studies 2a and 2b). These findings highlight the potential risks of utilizing AI and microtargeting to craft political messages that resonate with individuals based on their personality traits. This should be an area of concern to ethicists and policy makers.", "isOpenAccess": true, "url": "https://academic.oup.com/pnasnexus/advance-article-pdf/doi/10.1093/pnasnexus/pgae035/56444902/pgae035.pdf"}
{"paperId": "350e719b0b15d0d061d26fa398509af392eff3e3", "year": 2023, "title": "Humans as Creativity Gatekeepers: Are We Biased Against AI Creativity?", "authors": "Federico Magni, Jiyoung Park, Melody M. Chao", "venue": "Journal of business and psychology", "citationCount": 85, "abstract": "With artificial intelligence (AI) increasingly involved in the creation of organizational and commercial artifacts, human evaluators\u2019 role as creativity gatekeepers of AI-produced artifacts will become critical for innovation processes. However, when humans evaluate creativity, their judgment is clouded by biases triggered by the characteristics of the creator. Drawing from folk psychology and algorithm aversion research, we examine whether the identity of the producer of a given artifact as artificial intelligence (AI) or human is a source of bias affecting people\u2019s creativity evaluation of such artifact and what drives this effect. With four experimental studies (N\u2009=\u20092039), of which two were pre-registered, using different experimental designs and evaluation targets, we found that people sometimes\u2014but not always\u2014ascribe lower creativity to a product when they are told that the producer is an AI rather than a human. In addition, we found that people consistently perceive generative AI to exert less effort than humans in the creation of a given artifact, which drives the lower creativity ratings ascribed to generative AI producers. We discuss the implication of these findings for organizational creativity and innovation in the context of human-AI interaction.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10869-023-09910-x.pdf"}
{"paperId": "1f3502199f040e823584ee18555569270b33265e", "year": 2023, "title": "Artificial intelligence research in hospitality: a state-of-the-art review and future directions", "authors": "R. Law, K. Lin, Huiyue Ye, D. Fong", "venue": "International Journal of Contemporary Hospitality Management", "citationCount": 85, "abstract": "\nPurpose\nThe purpose of this study is to analyze state-of-the-art knowledge of artificial intelligence (AI) research in hospitality.\n\n\nDesign/methodology/approach\nThis study adopts the theory-context-methods framework to systematically review 100 AI-related articles recently published (i.e. from 2021 to April 2023) in three top-tier hospitality journals, namely, the International Journal of Contemporary Hospitality Management, International Journal of Hospitality Management and Journal of Hospitality Marketing and Management.\n\n\nFindings\nFindings suggest that studies of AI applications in hospitality are mostly theory-driven, whereas most AI methods research adopts a data-driven approach. State-of-the-art AI applications research exhibits the most interest in service robots. In AI methods research, little attention was paid to the amid-service/experience.\n\n\nResearch limitations/implications\nThis study reveals inadequacies in theory, context and methods in contemporary AI research. More research from hospitality suppliers\u2019 perspectives and research on generative AI applications are advocated in response to the unveiled research gaps and recent AI developments.\n\n\nOriginality/value\nThis study classifies the most recent AI research in hospitality into two main streams \u2013 AI applications research and AI methods research \u2013 and discusses the gaps in each research stream and latest AI developments. The paper then suggests future research directions to guide researchers in advancing AI research in hospitality.\n", "isOpenAccess": false, "url": ""}
{"paperId": "07ebf1e98018d286ecf004911fe691d2aa703b76", "year": 2023, "title": "Integrating generative AI in knowledge building", "authors": "Bodong Chen, Xinran Zhu, F. Castillo", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 85, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2023.100184"}
{"paperId": "ca4610272b429d34aef2da7507dcd13ba9841b51", "year": 2024, "title": "Generative AI and Higher Education: Trends, Challenges, and Future Directions from a Systematic Literature Review", "authors": "Jo\u00e3o Batista, A. Mesquita, Gon\u00e7alo Carnaz", "venue": "Inf.", "citationCount": 84, "abstract": "(1) Background: The development of generative artificial intelligence (GAI) is transforming higher education. This systematic literature review synthesizes recent empirical studies on the use of GAI, focusing on its impact on teaching, learning, and institutional practices. (2) Methods: Following PRISMA guidelines, a comprehensive search strategy was employed to locate scientific articles on GAI in higher education published by Scopus and Web of Science between January 2023 and January 2024. (3) Results: The search identified 102 articles, with 37 meeting the inclusion criteria. These studies were grouped into three themes: the application of GAI technologies, stakeholder acceptance and perceptions, and specific use situations. (4) Discussion: Key findings include GAI\u2019s versatility and potential use, student acceptance, and educational enhancement. However, challenges such as assessment practices, institutional strategies, and risks to academic integrity were also noted. (5) Conclusions: The findings help identify potential directions for future research, including assessment integrity and pedagogical strategies, ethical considerations and policy development, the impact on teaching and learning processes, the perceptions of students and instructors, technological advancements, and the preparation of future skills and workforce readiness. The study has certain limitations, particularly due to the short time frame and the search criteria, which might have varied if conducted by different researchers.", "isOpenAccess": true, "url": "https://doi.org/10.3390/info15110676"}
{"paperId": "7772380e6c6501c522974302389056a9c9320bf0", "year": 2023, "title": "The Prompt Artists", "authors": "Minsuk Chang, Stefania Druga, Alexander J. Fiannaca, P. Vergani, Chinmay Kulkarni, Carrie J. Cai, Michael Terry", "venue": "Creativity & Cognition", "citationCount": 84, "abstract": "This paper examines the art practices, artwork, and motivations of prolific users of the latest generation of text-to-image models. Through interviews, observations, and a user survey, we present a sampling of the artistic styles and describe the developed community of practice around generative AI. We find that: 1) artists hold the text prompt and the resulting image can be considered collectively as a form of artistic expression (prompts as art), and 2) prompt templates (prompts with \u201cslots\u201d for others to fill in with their own words) are developed to create generative art styles. We discover that the value placed by this community on unique outputs leads to artists seeking specialized vocabulary to produce distinctive art pieces (e.g., by reading architectural blogs to find phrases to describe images). We also find that some artists use \u201cglitches\u201d in the model that can be turned into artistic styles of their own right. From these findings, we outline specific implications for design regarding future prompting and image editing options.", "isOpenAccess": false, "url": ""}
{"paperId": "4d19a473b1e4e1152bba5db7cf0037267faa9824", "year": 2024, "title": "At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence", "authors": "A. \u00c7elik, Ahmed M. Eltawil", "venue": "IEEE Open Journal of the Communications Society", "citationCount": 84, "abstract": "As we transition from the 5G epoch, a new horizon beckons with the advent of 6G, seeking a profound fusion with novel communication paradigms and emerging technological trends, bringing once-futuristic visions to life along with added technical intricacies. Although analytical models lay the foundations and offer systematic insights, we have recently witnessed a noticeable surge in research suggesting machine learning (ML) and artificial intelligence (AI) can efficiently deal with complex problems by complementing or replacing model-based approaches. The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, autoregressive GMs, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including 1) physical layer design; 2) network optimization, organization, and management; 3) network traffic analytics; 4) cross-layer network security; and 5) localization & positioning. Furthermore, we outline the central role of GMs in pioneering areas of 6G network research, including semantic communications, integrated sensing and communications, THz communications, extremely large antenna arrays, near-field communications, digital twins, AI-generated content services, mobile edge computing and edge AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the multifarious challenges ahead, suggesting potential strategies and promising remedies. Given its depth and breadth, we are confident that this tutorial-cum-survey will serve as a pivotal reference for researchers and professionals delving into this dynamic and promising domain.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/8782661/8901158/10422716.pdf"}
{"paperId": "122e083d97979683274924426fdbbe3b12015255", "year": 2024, "title": "Uses of Generative AI in the Newsroom: Mapping Journalists\u2019 Perceptions of Perils and Possibilities", "authors": "Hannes Cools, Nicholas Diakopoulos", "venue": "Journalism Practice", "citationCount": 84, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1080/17512786.2024.2394558"}
{"paperId": "0b045680f51b0adcde488ce5aace12516954c86b", "year": 2023, "title": "Generative AI in Health Care and Liability Risks for Physicians and Safety Concerns for Patients.", "authors": "M. Duffourc, S. Gerke", "venue": "Journal of the American Medical Association (JAMA)", "citationCount": 84, "abstract": "\n This Viewpoint discusses the potential use of generative artificial intelligence (AI) in medical care and the liability risks for physicians using the technology, as well as offers suggestions for safeguards to protect patients.\n", "isOpenAccess": true, "url": "https://zenodo.org/record/8178629/files/Generative%20AI%20in%20Health%20Care%20and%20Liability%20Nunez%20Gerke%20JAMA%20accepted%20paper.pdf"}
{"paperId": "06f52b5bde025a6f32ab4522b2a9c40068137603", "year": 2025, "title": "TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models", "authors": "Yangguang Li, Zi-Xin Zou, Zexiang Liu, Dehu Wang, Yuan Liang, Zhipeng Yu, Xingchao Liu, Yuanchen Guo, Ding Liang, Wanli Ouyang, Yan-Pei Cao", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citationCount": 84, "abstract": "Recent advancements in diffusion techniques have propelled image and video generation to unprecedented levels of quality, significantly accelerating the deployment and application of generative AI. However, 3D shape generation technology has so far lagged behind, constrained by limitations in 3D data scale, complexity of 3D data processing, and insufficient exploration of advanced techniques in the 3D domain. Current approaches to 3D shape generation face substantial challenges in terms of output quality, generalization capability, and alignment with input conditions. We present TripoSG, a new streamlined shape diffusion paradigm capable of generating high-fidelity 3D meshes with precise correspondence to input images. Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data. 2) A hybrid supervised training strategy combining SDF, normal, and eikonal losses for 3D VAE, achieving high-quality 3D reconstruction performance. 3) A data processing pipeline to generate 2 million high-quality 3D samples, highlighting the crucial rules for data quality and quantity in training 3D generative models. Through comprehensive experiments, we have validated the effectiveness of each component in our new framework. The seamless integration of these parts has enabled TripoSG to achieve state-of-the-art performance in 3D shape generation. The resulting 3D shapes exhibit enhanced detail due to high-resolution capabilities and demonstrate exceptional fidelity to input images. Moreover, TripoSG demonstrates improved versatility in generating 3D models from diverse image styles and contents, showcasing strong generalization capabilities. To foster progress and innovation in the field of 3D generation.", "isOpenAccess": false, "url": ""}
{"paperId": "93ea53eb0619a507345a641119ffc1f4660d2b7b", "year": 2023, "title": "Do you trust ChatGPTs? Effects of the ethical and quality issues of generative AI on travel decisions", "authors": "Jeong Hyun Kim, Jungkeun Kim, Changju Kim, S. Kim", "venue": "Journal of Travel &amp; Tourism Marketing", "citationCount": 83, "abstract": "ABSTRACT This study investigated the impact of ChatGPT\u2019s recommendation quality and ethical concerns on travelers\u2019 acceptance, satisfaction, and perceived trustworthiness. Results showed that when quality and ethical concerns were prominent, acceptance of and satisfaction with ChatGPT\u2019s recommendations decreased significantly, and the negative effects were mediated by perceived trustworthiness. This study also identified that message framing containing ChatGPT\u2019s errors, and the information types delivered by ChatGPT, acted as moderators of the positive effect of its recommendations. These findings underscore the significance of addressing ethical and quality concerns in using AI (Artificial intelligence)-powered chatbots, with implications for AI acceptance and satisfaction.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/10548408.2023.2293006?needAccess=true"}
{"paperId": "8b910aaa410dd1a5b3c0be5134394af23bc6b848", "year": 2024, "title": "Future of software development with generative AI", "authors": "Jaakko Sauvola, Sasu Tarkoma, Mika Klemettinen, J. Riekki, David S. Doermann", "venue": "International Conference on Automated Software Engineering", "citationCount": 83, "abstract": "Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10515-024-00426-z.pdf"}
{"paperId": "59d8a1b6fef5cb9f8167b7c60f3cce56edd4ffeb", "year": 2023, "title": "Investigating and Designing for Trust in AI-powered Code Generation Tools", "authors": "Ruotong Wang, Ruijia Cheng, Denae Ford, Thomas Zimmermann", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 83, "abstract": "Trust is a crucial factor for the adoption and responsible usage of generative AI tools in complex tasks such as software engineering. However, we have a limited understanding of how software developers evaluate the trustworthiness of AI-powered code generation tools in real-world settings. To address this gap, we conducted Study 1, an interview study with 17 developers who use AI-powered code generation tools in professional or personal settings. We found that developers\u2019 trust is rooted in the AI tool\u2019s perceived ability, integrity, and benevolence, and is situational, varying according to the context of usage. Existing AI code generation tools lack the affordances for developers to efficiently and effectively evaluate the trustworthiness of AI-powered code generation tools. To explore designs that can augment the existing interface of AI-powered code generation tools, we explored three sets of design concepts (suggestion quality indicators, usage stats, and control mechanisms) that derived from Study 1 findings. In Study 2, a design probe study with 12 developers, we investigated the potential of these design concepts to help developers make effective trust judgments. We discuss the implication of our findings on the design of AI-powered code generation tools and future research on trust in AI.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658984"}
{"paperId": "2e3f31f31f25525ca6efdc19bd5481fc2099118e", "year": 2024, "title": "\"ChatGPT seems too good to be true\": College students' use and perceptions of generative AI", "authors": "Clare Baek, Tamara P. Tate, M. Warschauer", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 83, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100294"}
{"paperId": "1d8cb727f1b03b2434cce774e0826c19831add08", "year": 2023, "title": "Adopting and expanding ethical principles for generative artificial intelligence from military to healthcare", "authors": "David Oniani, Jordan Hilsman, Yifan Peng, Ronald K. Poropatich, Jeremy C. Pamplin, Gary L Legault, Yanshan Wang", "venue": "npj Digit. Medicine", "citationCount": 83, "abstract": "In 2020, the U.S. Department of Defense officially disclosed a set of ethical principles to guide the use of Artificial Intelligence (AI) technologies on future battlefields. Despite stark differences, there are core similarities between the military and medical service. Warriors on battlefields often face life-altering circumstances that require quick decision-making. Medical providers experience similar challenges in a rapidly changing healthcare environment, such as in the emergency department or during surgery treating a life-threatening condition. Generative AI, an emerging technology designed to efficiently generate valuable information, holds great promise. As computing power becomes more accessible and the abundance of health data, such as electronic health records, electrocardiograms, and medical images, increases, it is inevitable that healthcare will be revolutionized by this technology. Recently, generative AI has garnered a lot of attention in the medical research community, leading to debates about its application in the healthcare sector, mainly due to concerns about transparency and related issues. Meanwhile, questions around the potential exacerbation of health disparities due to modeling biases have raised notable ethical concerns regarding the use of this technology in healthcare. However, the ethical principles for generative AI in healthcare have been understudied. As a result, there are no clear solutions to address ethical concerns, and decision-makers often neglect to consider the significance of ethical principles before implementing generative AI in clinical practice. In an attempt to address these issues, we explore ethical principles from the military perspective and propose the \u201cGREAT PLEA\u201d ethical principles, namely Governability, Reliability, Equity, Accountability, Traceability, Privacy, Lawfulness, Empathy, and Autonomy for generative AI in healthcare. Furthermore, we introduce a framework for adopting and expanding these ethical principles in a practical way that has been useful in the military and can be applied to healthcare for generative AI, based on contrasting their ethical concerns and risks. Ultimately, we aim to proactively address the ethical dilemmas and challenges posed by the integration of generative AI into healthcare practice.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-023-00965-x.pdf"}
{"paperId": "1d49e46a8ec63f95c289c2d9db5fcacc4210e39a", "year": 2023, "title": "Generative AI and the Automating of Academia", "authors": "R. Watermeyer, L. Phipps, Donna Lanclos, Cathryn Knight", "venue": "Postdigital Science and Education", "citationCount": 83, "abstract": "The neoliberal transformation of higher education in the UK and an intertwined focus on the productive efficiency and prestige value of universities has led to an epidemic of overwork and precarity among academics. Many are found to be struggling with lofty performance expectations and an insistence that all dimensions of their work consistently achieve positional gains despite ferocious competition and the omnipresent threat of failure. Working under the current audit culture present across education, academics are thus found to overwork or commit to accelerated labour as pre-emptive compensation for the habitual inclemency of peer-review and vagaries of student evaluation, in accommodating the copiousness of \u2018invisible\u2019 tasks, and in eluding the myriad crevasses of their precarious labour. The proliferation of generative artificial intelligence (GAI) tools and more specifically, large language models (LLMs) like ChatGPT, offers potential relief for academics and a means to offset intensive demands and discover more of a work-based equilibrium. Through a recent survey of n\u2009=\u2009284 UK academics and their use of GAI, we discover, however, that the digitalisation of higher education through GAI tools no more alleviates than extends the dysfunctions of neoliberal logic and deepens academia\u2019s malaise. Notwithstanding, we argue that the proliferating use of GAI tools by academics may be harnessed as a source of positive disruption to the industrialisation of their labour and catalyst of (re)engagement with scholarly craftsmanship.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s42438-023-00440-6.pdf"}
{"paperId": "0703f5f1d99e794a158cd5b69030fd5ed807727a", "year": 2024, "title": "The rapid rise of generative AI and its implications for academic integrity: Students' perceptions and use of chatbots for assistance with assessments", "authors": "Jan Henrik Gruenhagen, Peter M. Sinclair, Julie-Anne Carroll, Philip R.A. Baker, Ann Wilson, Daniel Demant", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 83, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100273"}
{"paperId": "fe5d55584aba445fd6017a0de0700354dcba6a56", "year": 2024, "title": "Unlocking the potential of generative AI in drug discovery.", "authors": "Amit Gangwal, Antonio Lavecchia", "venue": "Drug Discovery Today", "citationCount": 82, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.drudis.2024.103992"}
{"paperId": "a012f39750f446e9f45d064c4fc6a284c485b091", "year": 2024, "title": "Applying generative AI with retrieval augmented generation to summarize and extract key clinical information from electronic health records", "authors": "M. Alkhalaf, Ping Yu, M. Yin, C. Deng", "venue": "Journal of Biomedical Informatics", "citationCount": 82, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.jbi.2024.104662"}
{"paperId": "7d470ec61bbc8e442f8eb7fe3df4a731723f0b45", "year": 2023, "title": "Applications of large language models in cancer care: current evidence and future perspectives", "authors": "G. M. Iannantuono, Dara Bracken-Clarke, C. Floudas, M. Roselli, J. Gulley, F. Karzai", "venue": "Frontiers in Oncology", "citationCount": 82, "abstract": "The development of large language models (LLMs) is a recent success in the field of generative artificial intelligence (AI). They are computer models able to perform a wide range of natural language processing tasks, including content generation, question answering, or language translation. In recent months, a growing number of studies aimed to assess their potential applications in the field of medicine, including cancer care. In this mini review, we described the present published evidence for using LLMs in oncology. All the available studies assessed ChatGPT, an advanced language model developed by OpenAI, alone or compared to other LLMs, such as Google Bard, Chatsonic, and Perplexity. Although ChatGPT could provide adequate information on the screening or the management of specific solid tumors, it also demonstrated a significant error rate and a tendency toward providing obsolete data. Therefore, an accurate, expert-driven verification process remains mandatory to avoid the potential for misinformation and incorrect evidence. Overall, although this new generative AI-based technology has the potential to revolutionize the field of medicine, including that of cancer care, it will be necessary to develop rules to guide the application of these tools to maximize benefits and minimize risks.", "isOpenAccess": true, "url": "https://www.frontiersin.org/articles/10.3389/fonc.2023.1268915/pdf?isPublishedV2=False"}
{"paperId": "50a8e13366d19625e1ce60a3fe51c79f6b5a6a34", "year": 2024, "title": "An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization", "authors": "Minshuo Chen, Song Mei, Jianqing Fan, Mengdi Wang", "venue": "arXiv.org", "citationCount": 82, "abstract": "Diffusion models, a powerful and universal generative AI technology, have achieved tremendous success in computer vision, audio, reinforcement learning, and computational biology. In these applications, diffusion models provide flexible high-dimensional data modeling, and act as a sampler for generating new samples under active guidance towards task-desired properties. Despite the significant empirical success, theory of diffusion models is very limited, potentially slowing down principled methodological innovations for further harnessing and improving diffusion models. In this paper, we review emerging applications of diffusion models, understanding their sample generation under various controls. Next, we overview the existing theories of diffusion models, covering their statistical properties and sampling capabilities. We adopt a progressive routine, beginning with unconditional diffusion models and connecting to conditional counterparts. Further, we review a new avenue in high-dimensional structured optimization through conditional diffusion models, where searching for solutions is reformulated as a conditional sampling problem and solved by diffusion models. Lastly, we discuss future directions about diffusion models. The purpose of this paper is to provide a well-rounded theoretical exposure for stimulating forward-looking theories and methods of diffusion models.", "isOpenAccess": false, "url": ""}
{"paperId": "1c5f99712b584e48ce6bf47b06625c932b2e9897", "year": 2024, "title": "Beginning and first-year language teachers' readiness for the generative AI age", "authors": "Benjamin Luke Moorhouse", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 82, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100201"}
{"paperId": "191df526eb5373215e2767ca0df5b4ec7d8db844", "year": 2024, "title": "Mapping the Ethics of Generative AI: A Comprehensive Scoping Review", "authors": "Thilo Hagendorff", "venue": "Minds and Machines", "citationCount": 82, "abstract": "The advent of generative artificial intelligence and the widespread adoption of it in society engendered intensive debates about its ethical implications and risks. These risks often differ from those associated with traditional discriminative machine learning. To synthesize the recent discourse and map its normative concepts, we conducted a scoping review on the ethics of generative artificial intelligence, including especially large language models and text-to-image models. Our analysis provides a taxonomy of 378 normative issues in 19 topic areas and ranks them according to their prevalence in the literature. The study offers a comprehensive overview for scholars, practitioners, or policymakers, condensing the ethical debates surrounding fairness, safety, harmful content, hallucinations, privacy, interaction risks, security, alignment, societal impacts, and others. We discuss the results, evaluate imbalances in the literature, and explore unsubstantiated risk scenarios.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s11023-024-09694-w"}
{"paperId": "f860061e8dfdff2b4f4e0214c339e3ba01382aa8", "year": 2024, "title": "Applications of generative AI and future organizational performance: The mediating role of explorative and exploitative innovation and the moderating role of ethical dilemmas and environmental dynamism", "authors": "Kuldeep Singh, Sheshadri Chatterjee, Marcello M. Mariani", "venue": "Technovation", "citationCount": 81, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.technovation.2024.103021"}
{"paperId": "be383979c7f74ebfb52637fbf8100e1955aac46b", "year": 2023, "title": "Generative AI and the end of corpus-assisted data-driven learning? Not so fast!", "authors": "P. Crosthwaite, V. Baisa", "venue": "Applied Corpus Linguistics", "citationCount": 81, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.acorp.2023.100066"}
{"paperId": "8d4148d3926326758fee8ff0b0a948545a8e1a00", "year": 2023, "title": "Wireless Network Digital Twin for 6G: Generative AI as a Key Enabler", "authors": "Zhenyu Tao, Wei Xu, Yongming Huang, Xiaoyun Wang, Xiaohu You", "venue": "IEEE wireless communications", "citationCount": 81, "abstract": "Digital twin, which enables emulation, evaluation, and optimization of physical entities through synchronized digital replicas, has gained increasing attention as a promising technology for intricate wireless networks. For 6G, numerous innovative wireless technologies and network architectures have posed new challenges in establishing wireless network digital twins. To tackle these challenges, artificial intelligence (AI), particularly the flourishing generative AI, emerges as a potential solution. In this article, we discuss emerging prerequisites for wireless network digital twins, considering the complicated network architecture, tremendous network scale, extensive coverage, and diversified application scenarios in the 6G era. We further explore the applications of generative AI, such as transformer and diffusion models, to empower the 6G digital twin from multiple perspectives, including physical-digital modeling, synchronization, and slicing capability. Subsequently, we propose a hierarchical generative AI-enabled wireless network digital twin at both the message-level and policy-level, and provide a typical use case with numerical results to validate effectiveness and efficiency. Finally, open research issues for wireless network digital twins in the 6G era are discussed.", "isOpenAccess": false, "url": ""}
{"paperId": "7e018624508e7cebe01b5bbd7c758bba85827a15", "year": 2024, "title": "Generative AI in Higher Education", "authors": "C. Chan, T. Colloton", "venue": "", "citationCount": 81, "abstract": null, "isOpenAccess": true, "url": "https://api.taylorfrancis.com/content/books/oa-mono/download?identifierName=doi&identifierValue=10.4324/9781003459026&type=webpdf"}
{"paperId": "673b0cc3c9f97965295bc6fc88887df4795410c9", "year": 2023, "title": "Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study", "authors": "Zohar Elyoseph, Elad Refoua, K. Asraf, Maya Lvovsky, Yoav Shimoni, D. Hadar-Shoval", "venue": "JMIR Mental Health", "citationCount": 81, "abstract": "Background Mentalization, which is integral to human cognitive processes, pertains to the interpretation of one\u2019s own and others\u2019 mental states, including emotions, beliefs, and intentions. With the advent of artificial intelligence (AI) and the prominence of large language models in mental health applications, questions persist about their aptitude in emotional comprehension. The prior iteration of the large language model from OpenAI, ChatGPT-3.5, demonstrated an advanced capacity to interpret emotions from textual data, surpassing human benchmarks. Given the introduction of ChatGPT-4, with its enhanced visual processing capabilities, and considering Google Bard\u2019s existing visual functionalities, a rigorous assessment of their proficiency in visual mentalizing is warranted. Objective The aim of the research was to critically evaluate the capabilities of ChatGPT-4 and Google Bard with regard to their competence in discerning visual mentalizing indicators as contrasted with their textual-based mentalizing abilities. Methods The Reading the Mind in the Eyes Test developed by Baron-Cohen and colleagues was used to assess the models\u2019 proficiency in interpreting visual emotional indicators. Simultaneously, the Levels of Emotional Awareness Scale was used to evaluate the large language models\u2019 aptitude in textual mentalizing. Collating data from both tests provided a holistic view of the mentalizing capabilities of ChatGPT-4 and Bard. Results ChatGPT-4, displaying a pronounced ability in emotion recognition, secured scores of 26 and 27 in 2 distinct evaluations, significantly deviating from a random response paradigm (P<.001). These scores align with established benchmarks from the broader human demographic. Notably, ChatGPT-4 exhibited consistent responses, with no discernible biases pertaining to the sex of the model or the nature of the emotion. In contrast, Google Bard\u2019s performance aligned with random response patterns, securing scores of 10 and 12 and rendering further detailed analysis redundant. In the domain of textual analysis, both ChatGPT and Bard surpassed established benchmarks from the general population, with their performances being remarkably congruent. Conclusions ChatGPT-4 proved its efficacy in the domain of visual mentalizing, aligning closely with human performance standards. Although both models displayed commendable acumen in textual emotion interpretation, Bard\u2019s capabilities in visual emotion interpretation necessitate further scrutiny and potential refinement. This study stresses the criticality of ethical AI development for emotional recognition, highlighting the need for inclusive data, collaboration with patients and mental health experts, and stringent governmental oversight to ensure transparency and protect patient privacy.", "isOpenAccess": true, "url": "https://mental.jmir.org/2024/1/e54369/PDF"}
{"paperId": "63dcc16b918c6fced2b10e721a8c4bf09d5582be", "year": 2024, "title": "Higher Education Students' Task Motivation in the Generative Artificial Intelligence Context: The Case of ChatGPT", "authors": "Mohammad Hmoud, Hadeel Swaity, Nardin Hamad, Omar Karram, Wajeeh M. Daher", "venue": "Inf.", "citationCount": 81, "abstract": "Artificial intelligence has been attracting the attention of educational researchers recently, especially ChatGPT as a generative artificial intelligence tool. The context of generative artificial intelligence could impact different aspects of students\u2019 learning, such as the motivational aspect. The present research intended to investigate the characteristics of students\u2019 task motivation in the artificial intelligence context, specifically in the ChatGPT context. The researchers interviewed 15 students about their experiences with ChatGPT to collect data. The researchers used inductive and deductive content analysis to investigate students\u2019 motivation when learning with ChatGPT. To arrive at the categories and sub-categories of students\u2019 motivation, the researchers used the MAXQDA 2022. Five main categories emerged: task enjoyment, reported effort, result assessment, perceived relevance, and interaction. Each category comprised at least two sub-categories, and each sub-category was further organized into codes. The results indicated more positive characteristics of motivation than negative ones. The previous results could be due to the conversational or social aspect of the chatbot, enabling relationships with humans and enabling the maintenance of good quality conversations with them. We conclude that a generative AI could be utilized in educational settings to promote students\u2019 motivation to learn and thus raise their learning achievement.", "isOpenAccess": true, "url": "https://www.mdpi.com/2078-2489/15/1/33/pdf?version=1704717982"}
{"paperId": "5535a3cd501e5639657e2683011043813069d89f", "year": 2024, "title": "Recent Advances in Generative AI and Large Language Models: Current Status, Challenges, and Perspectives", "authors": "D. Hagos, Rick Battle, Danda B. Rawat", "venue": "IEEE Transactions on Artificial Intelligence", "citationCount": 81, "abstract": "The emergence of generative artificial intelligence (AI) and large language models (LLMs) has marked a new era of natural language processing (NLP), introducing unprecedented capabilities that are revolutionizing various domains. This article explores the current state of these cutting-edge technologies, demonstrating their remarkable advancements and wide-ranging applications. Our article contributes to providing a holistic perspective on the technical foundations, practical applications, and emerging challenges within the evolving landscape of generative AI and LLMs. We believe that understanding the generative capabilities of AI systems and the specific context of LLMs is crucial for researchers, practitioners, and policymakers to collaboratively shape the responsible and ethical integration of these technologies into various domains. Furthermore, we identify and address main research gaps, providing valuable insights to guide future research endeavors within the AI research community.", "isOpenAccess": false, "url": ""}
{"paperId": "c840f690f0e1ab5ed6c23d79140d0709e13c4d09", "year": 2024, "title": "\u201cIt happened to be the perfect thing\u201d: experiences of generative AI chatbots for mental health", "authors": "Steve Siddals, J. Torous, Astrid Coxon", "venue": "npj Mental Health Research", "citationCount": 80, "abstract": "The global mental health crisis underscores the need for accessible, effective interventions. Chatbots based on generative artificial intelligence (AI), like ChatGPT, are emerging as novel solutions, but research on real-life usage is limited. We interviewed nineteen individuals about their experiences using generative AI chatbots for mental health. Participants reported high engagement and positive impacts, including better relationships and healing from trauma and loss. We developed four themes: (1) a sense of \u2018emotional sanctuary\u2019, (2) \u2018insightful guidance\u2019, particularly about relationships, (3) the \u2018joy of connection\u2019, and (4) comparisons between the \u2018AI therapist\u2019 and human therapy. Some themes echoed prior research on rule-based chatbots, while others seemed novel to generative AI. Participants emphasised the need for better safety guardrails, human-like memory and the ability to lead the therapeutic process. Generative AI chatbots may offer mental health support that feels meaningful to users, but further research is needed on safety and effectiveness.", "isOpenAccess": true, "url": "https://doi.org/10.1038/s44184-024-00097-4"}
{"paperId": "095a1d8e58091a44f4416673277d573b4b2926d5", "year": 2023, "title": "Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version)", "authors": "Katherine Lee, A. F. Cooper, James Grimmelmann", "venue": "Symposium on Computer Science and Law", "citationCount": 80, "abstract": "\"Does generative AI infringe copyright?\" is an urgent question. It is also a difficult question, for two reasons. First, \"generative AI\" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies. These systems behave differently and raise different legal issues. Second, copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, and fair use, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. We aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data into generations. The supply chain reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes. This article is a much-abbreviated version of a forthcoming law review article at The Journal of the Copyright Society.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3614407.3643696"}
{"paperId": "dfc73a8a906e2e72a52eec35912bf7e87b1693da", "year": 2024, "title": "Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models", "authors": "Zhiyuan Yu, Xiaogeng Liu, Shunning Liang, Zach Cameron, Chaowei Xiao, Ning Zhang", "venue": "USENIX Security Symposium", "citationCount": 79, "abstract": "Recent advancements in generative AI have enabled ubiquitous access to large language models (LLMs). Empowered by their exceptional capabilities to understand and generate human-like text, these models are being increasingly integrated into our society. At the same time, there are also concerns on the potential misuse of this powerful technology, prompting defensive measures from service providers. To overcome such protection, jailbreaking prompts have recently emerged as one of the most effective mechanisms to circumvent security restrictions and elicit harmful content originally designed to be prohibited. Due to the rapid development of LLMs and their ease of access via natural languages, the frontline of jailbreak prompts is largely seen in online forums and among hobbyists. To gain a better understanding of the threat landscape of semantically meaningful jailbreak prompts, we systemized existing prompts and measured their jailbreak effectiveness empirically. Further, we conducted a user study involving 92 participants with diverse backgrounds to unveil the process of manually creating jailbreak prompts. We observed that users often succeeded in jailbreak prompts generation regardless of their expertise in LLMs. Building on the insights from the user study, we also developed a system using AI as the assistant to automate the process of jailbreak prompt generation.", "isOpenAccess": false, "url": ""}
{"paperId": "d798cc0c15857e4c7701d142712b0aa8301ae928", "year": 2024, "title": "Enhancing trust in online grocery shopping through generative AI chatbots", "authors": "Debarun Chakraborty, Arpan Kumar Kar, Smruti Patre, Shivam Gupta", "venue": "Journal of business research", "citationCount": 79, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.jbusres.2024.114737"}
{"paperId": "ceccf5077ff16baf7df97abe9ba48e0e1ec267a0", "year": 2023, "title": "Deepfakes, Misinformation, and Disinformation in the Era of Frontier AI, Generative AI, and Large AI Models", "authors": "Mohamed R. Shoaib, Ze Wang, Milad Taleby Ahvanooey, Jun Zhao", "venue": "International Conferences on Computing Advancements", "citationCount": 79, "abstract": "With the advent of sophisticated artificial intelligence (AI) technologies, the proliferation of deepfakes and the spread of m/disinformation have emerged as formidable threats to the integrity of information ecosystems worldwide. This paper provides an overview of the current literature. Within the frontier AI\u2019s crucial application in developing defense mechanisms for detecting deepfakes, we highlight the mechanisms through which generative AI based on large models (LM-based GenAI) craft seemingly convincing yet fabricated contents. We explore the multifaceted implications of LM-based GenAI on society, politics, and individual privacy violations, underscoring the urgent need for robust defense strategies. To address these challenges, in this study, we introduce an integrated framework that combines advanced detection algorithms, cross-platform collaboration, and policy-driven initiatives to mitigate the risks associated with AI-Generated Content (AIGC). By leveraging multi-modal analysis, digital watermarking, and machine learning-based authentication techniques, we propose a defense mechanism adaptable to AI capabilities of ever-evolving nature. Furthermore, the paper advocates for a global consensus on the ethical usage of GenAI and implementing cyber-wellness educational programs to enhance public awareness and resilience against m/disinformation. Our findings suggest that a proactive and collaborative approach involving technological innovation and regulatory oversight is essential for safeguarding netizens while interacting with cyberspace against the insidious effects of deepfakes and GenAI-enabled m/disinformation campaigns.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2311.17394"}
{"paperId": "b7691dcbcbfe1de684936f4c04f825f1c9a0ddbb", "year": 2024, "title": "Revolutionizing personalized medicine with generative AI: a systematic review", "authors": "Isaias Ghebrehiwet, Nazar Zaki, Rafat Damseh, Mohd Saberi Mohamad", "venue": "Artificial Intelligence Review", "citationCount": 79, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "9b87033a6ec15aa3cd254c68f2feda770cf28933", "year": 2023, "title": "ADMET-AI: A machine learning ADMET platform for evaluation of large-scale chemical libraries", "authors": "Kyle Swanson, Parker Walther, Jeremy Leitz, S. Mukherjee, Joseph C. Wu, Rabindra V. Shivnaraine, James Y. Zou", "venue": "bioRxiv", "citationCount": 79, "abstract": null, "isOpenAccess": true, "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10793392"}
{"paperId": "6435d547f29b6f5e02f7373e3a9b0638a5f2a463", "year": 2023, "title": "Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition.", "authors": "N. Ayoub, Yu-Jin Lee, D. Grimm, V. Divi", "venue": "Otolaryngology Head & Neck Surgery", "citationCount": 79, "abstract": "OBJECTIVE\nChat Generative Pretrained Transformer (ChatGPT) is the newest iteration of OpenAI's generative artificial intelligence (AI) with the potential to influence many facets of life, including health care. This study sought to assess ChatGPT's capabilities as a source of medical knowledge, using Google Search as a comparison.\n\n\nSTUDY DESIGN\nCross-sectional analysis.\n\n\nSETTING\nOnline using ChatGPT, Google Seach, and Clinical Practice Guidelines (CPG).\n\n\nMETHODS\nCPG Plain Language Summaries for 6 conditions were obtained. Questions relevant to specific conditions were developed and input into ChatGPT and Google Search. All questions were written from the patient perspective and sought (1) general medical knowledge or (2) medical recommendations, with varying levels of acuity (urgent or emergent vs routine clinical scenarios). Two blinded reviewers scored all passages and compared results from ChatGPT and Google Search, using the Patient Education Material Assessment Tool (PEMAT-P) as the primary outcome. Additional customized questions were developed that assessed the medical content of the passages.\n\n\nRESULTS\nThe overall average PEMAT-P score for medical advice was 68.2% (standard deviation [SD]: 4.4) for ChatGPT and 89.4% (SD: 5.9) for Google Search (p\u2009<\u2009.001). There was a statistically significant difference in the PEMAT-P score by source (p\u2009<\u2009.001) but not by urgency of the clinical situation (p\u2009=\u2009.613). ChatGPT scored significantly higher than Google Search (87% vs 78%, p\u2009=\u2009.012) for patient education questions.\n\n\nCONCLUSION\nChatGPT fared better than Google Search when offering general medical knowledge, but it scored worse when providing medical recommendations. Health care providers should strive to understand the potential benefits and ramifications of generative AI to guide patients appropriately.", "isOpenAccess": false, "url": ""}
{"paperId": "26fbf886ea26591536056b3d4a1724187356789f", "year": 2023, "title": "Educational data augmentation in physics education research using ChatGPT", "authors": "Fabian Kieser, P. Wulff, Jochen Kuhn, S. K\u00fcchemann", "venue": "Physical Review Physics Education Research", "citationCount": 79, "abstract": "Generative AI technologies such as large language models show novel potentials to enhance educational research. For example, generative large language models were shown to be capable to solve quantitative reasoning tasks in physics and concept tests such as the Force Concept Inventory. Given the importance of such concept inventories for physics education research, and the challenges in developing them such as field testing with representative populations, this study seeks to examine to what extent a generative large language model could be utilized to generate a synthetic data set for the FCI that exhibits content-related variability in responses. We use the recently introduced ChatGPT based on the GPT 4 generative large language model and investigate to what extent ChatGPT could solve the FCI accurately (RQ1) and could be prompted to solve the FCI as-if it were a student belonging to a different cohort (RQ2). Furthermore, we study, to what extent ChatGPT could be prompted to solve the FCI as-if it were a student having a different force- and mechanics-related misconception (RQ3). In alignment with other research, we found the ChatGPT could accurately solve the FCI. We furthermore found that prompting ChatGPT to respond to the inventory as-if it belonged to a different cohort yielded no variance in responses, however, responding as-if it had a certain misconception introduced much variance in responses that approximate real human responses on the FCI in some regards.", "isOpenAccess": true, "url": "http://link.aps.org/pdf/10.1103/PhysRevPhysEducRes.19.020150"}
{"paperId": "166210c24ea400d0fa8b13f0733df8baa2534c45", "year": 2023, "title": "The impact of generative AI tools on researchers and research: Implications for academia in higher education", "authors": "Abdulrahman M. Al-Zahrani", "venue": "Innovations in Education & Teaching International", "citationCount": 79, "abstract": "ABSTRACT This study explores the impact of Generative AI tools on researchers and research in the context of higher education in Saudi Arabia. An online survey questionnaire was used to collect data on higher education students\u2019 perspectives (N\u2009=\u2009505). The findings indicate that participants hold positive attitudes and possess a high level of awareness regarding GenAI in research. They recognise the potential of these tools to revolutionise academic research. Participants report highly beneficial experiences using GenAI tools to expand project scope and improve efficiency. Additionally, participants expressed optimism about the future role of GenAI tools, expecting them to become more prevalent and transform the research landscape. However, participants emphasised the importance of adequate training, support, and guidance in using GenAI tools. Ethical considerations emerged as a significant concern, highlighting the participants\u2019 commitment to responsible research practices and the need for transparency and addressing potential biases associated with these tools.", "isOpenAccess": false, "url": ""}
{"paperId": "04a97c2be21047b8e152e3b9066f17f3191e27b1", "year": 2024, "title": "Generative AI in Education: Pedagogical, Theoretical, and Methodological Perspectives", "authors": "O. Noroozi, Saba Soleimani, Mohammadreza Farrokhnia, S. K. Banihashem", "venue": "International Journal of Technology in Education", "citationCount": 79, "abstract": "Recently, ChatGPT, a cutting-edge large language model, has emerged as a powerful Generative Artificial Intelligence (GenAI) tool with the capacity to influence education. ChatGPT provides ample opportunities for learners, researchers, educators, and practitioners to achieve the intended learning outcomes in various disciplines. This special issue examines the diverse applications and implications of GenAI tools including ChatGPT in education, highlighting their potential to enhance teaching and learning across various contexts. Key findings from seventeen studies collected in this special issue demonstrate that GenAI tools can significantly improve educational outcomes by providing personalized feedback, facilitating language learning, and supporting both qualitative and quantitative research methodologies. The findings emphasize GenAI\u2019s capacity to increase learner engagement and motivation, yet also underscore the need for robust ethical guidelines and human oversight due to potential issues with privacy, bias, and accuracy. This special issue also highlights the challenges GenAI faces, such as limitations in contextual understanding and its impact on critical thinking skills. In addition, it provides a foundational framework for exploring effective and responsible GenAI integration, aiming to enrich educational experiences. We conclude that future research should focus on the longitudinal effects of GenAI tools on learning outcomes, developing ethical frameworks for their use, and ensuring their adaptability to diverse learner populations to promote inclusive educational practices.", "isOpenAccess": true, "url": "https://ijte.net/index.php/ijte/article/download/845/pdf"}
{"paperId": "febafb92f1c5243649993f6201df825877bc1058", "year": 2024, "title": "When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting in a Creative Design Task", "authors": "Yuanning Han, Ziyi Qiu, Jiale Cheng, Ray Lc", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 78, "abstract": "Studies of Generative AI (GenAI)-assisted creative workflows have focused on individuals overcoming challenges of prompting to produce what they envisioned. When designers work in teams, how do collaboration and prompting influence each other, and how do users perceive generative AI and their collaborators during the co-prompting process? We engaged students with design or performance backgrounds, and little exposure to GenAI, to work in pairs with GenAI to create stage designs based on a creative theme. We found two patterns of collaborative prompting focused on generating story descriptions first, or visual imagery first. GenAI tools helped participants build consensus in the task, and allowed for discussion of the prompting strategies. Participants perceived GenAI as efficient tools rather than true collaborators, suggesting that human partners reduced the reliance on their use. This work highlights the importance of human-human collaboration when working with GenAI tools, suggesting systems that take advantage of shared human expertise in the prompting process.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642133"}
{"paperId": "fc5a8fa2bac9208de9a30a7f4b45d5b6457f1bf4", "year": 2024, "title": "Exploring Collaborative Decision-Making: A Quasi-Experimental Study of Human and Generative AI Interaction", "authors": "Xinyue Hao, E. Demir, D. Eyers", "venue": "Technology and Society", "citationCount": 78, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.techsoc.2024.102662"}
{"paperId": "d81f4ae0d54f47c58af0ff77e153bc58d2ae35e9", "year": 2023, "title": "Generative AI in mobile networks: a survey", "authors": "Athanasios Karapantelakis, Pegah Alizadeh, Abdulrahman Alabassi, Kaushik Dey, Alexandros Nikou", "venue": "Annals of Telecommunications", "citationCount": 78, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "8ea21903605f2671b1d0dc64f9a1779151d30659", "year": 2023, "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction", "authors": "Rose E. Wang, Dorottya Demszky", "venue": "Workshop on Innovative Use of NLP for Building Educational Applications", "citationCount": 78, "abstract": "Coaching, which involves classroom observation and expert feedback, is a widespread and fundamental part of teacher training. However, the majority of teachers do not have access to consistent, high quality coaching due to limited resources and access to expertise. We explore whether generative AI could become a cost-effective complement to expert feedback by serving as an automated teacher coach. In doing so, we propose three teacher coaching tasks for generative AI: (A) scoring transcript segments based on classroom observation instruments, (B)identifying highlights and missed opportunities for good instructional strategies, and (C) providing actionable suggestions for eliciting more student reasoning. We recruit expert math teachers to evaluate the zero-shot performance of ChatGPT on each of these tasks for elementary math classroom transcripts. Our results reveal that ChatGPT generates responses that are relevant to improving instruction, but they are often not novel or insightful. For example, 82% of the model\u2019s suggestions point to places in the transcript where the teacher is already implementing that suggestion. Our work highlights the challenges of producing insightful, novel and truthful feedback for teachers while paving the way for future research to address these obstacles and improve the capacity of generative AI to coach teachers.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.03090"}
{"paperId": "7062f69a56f2f9be1324b4f395080a067d0a7987", "year": 2023, "title": "Federated Learning-Empowered AI-Generated Content in Wireless Networks", "authors": "Xumin Huang, Peichun Li, Hongyang Du, Jiawen Kang, D. Niyato, Dong In Kim, Yuehua Wu", "venue": "IEEE Network", "citationCount": 78, "abstract": "Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning, and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as a collaborative learning framework where the model training is distributed to cooperative data owners without the need for data sharing, can be leveraged to simultaneously improve learning efficiency and achieve privacy protection for AIGC. To this end, we present FL-based techniques for empowering AIGC, and aim to enable users to generate diverse, personalized, and high-quality content. Furthermore, we conduct a case study of FL-aided AIGC fine-tuning by using the state-of-the-art AIGC model, i.e., stable diffusion model. Numerical results show that our scheme achieves advantages in effectively reducing the communication cost and training latency, and providing privacy protection. Finally, we highlight several major research directions and open issues for the convergence of FL and AIGC.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.07146"}
{"paperId": "0f7871beeaa1b28e0df6298108f611eba56d7789", "year": 2024, "title": "Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study", "authors": "Wenhan Lyu, Yimeng Wang, Tingting Chung, Yifan Sun, Yixuan Zhang", "venue": "ACM Conference on Learning @ Scale", "citationCount": 78, "abstract": "The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the \"CodeTutor group\" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the \"control group\"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2404.13414"}
{"paperId": "ed7ac159eb1850491a812b074cf37157600c5b13", "year": 2023, "title": "Generative AI entails a credit\u2013blame asymmetry", "authors": "Sebastian Porsdam Mann, B. Earp, Sven Nyholm, J. Danaher, Nikolaj M\u00f8ller, Hilary Bowman-Smart, Joshua Hatherley, Julian Koplin, Monika Plozza, Daniel Rodger, Peter V. Treit, Gregory Renard, J. McMillan, Julian Savulescu", "venue": "Nature Machine Intelligence", "citationCount": 77, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "d2d1e26ab7807b37b6f92966dcdacd6b4a97212d", "year": 2023, "title": "ChatGPT and generative AI chatbots: challenges and opportunities for science, medicine and medical leaders", "authors": "E. Loh", "venue": "BMJ Leader", "citationCount": 77, "abstract": "\u00a9 Author(s) (or their employer(s)) 2023. Reuse permitted under CC BYNC. No commercial reuse. See rights and permissions. Published by BMJ. INTRODUCTION By now, most readers will have heard of the Chat Generative Pretrained Transformer (ChatGPT) artificial intelligence (AI) chatbot tool released to the public by the AI company OpenAI on 30 November 2022, to be used for free (at least for now), and which, by January 2023, had reached over 100 million users, making it the fastest growing consumer application to date. The ability of ChatGPT and other similar generative AI tools to generate text that appear to be similar to those created by human has led to both critics and supporters of this new technology. These new AI technologies have created challenges for medical leaders in the health system and offer new opportunities as well. This paper summarises these challenges and opportunities and provides a potential way forward. The main concern that AI tools such as ChatGPT raise is their ability to generate blocks of text that are so fluent and wellwritten that they are indistinguishable from content authored by human beings, which raises concerns of its use in fraud and plagiarism. Part of the problem is that ChatGPTgenerated text can be difficult to distinguish from humangenerated ones even for specialist AItext detection software, leading to its creator, OpenAI, to release its own AI detection tool; however, this tool itself is not entirely accurate as it concluded that the first few text passages from the Bible were likely to be AIgenerated during a test.", "isOpenAccess": true, "url": "https://bmjleader.bmj.com/content/leader/early/2023/05/02/leader-2023-000797.full.pdf"}
{"paperId": "a567f5bd6e6a32963e428bb97dec9c52ad75f059", "year": 2024, "title": "The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing", "authors": "Zhuoyan Li, Chen Liang, Jing Peng, Ming Yin", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 77, "abstract": "Recent advances in generative AI technologies like large language models raise both excitement and concerns about the future of human-AI co-creation in writing. To unpack people\u2019s attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people\u2019s writing perceptions and performance. Our results suggest that people are willing to forgo financial payments to receive writing assistance from AI, especially if AI can provide direct content generation assistance and the writing task is highly creative. Generative AI-powered assistance is found to offer benefits in increasing people\u2019s productivity and confidence in writing. However, direct content generation assistance offered by AI also comes with risks, including decreasing people\u2019s sense of accountability and diversity in writing. We conclude by discussing the implications of our findings.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642625"}
{"paperId": "0e95fe89d1ebdd6e857bd4e7e0497beac66a4283", "year": 2023, "title": "Collaborative Diffusion: Boosting Designerly Co-Creation with Generative AI", "authors": "Mathias Peter Verheijden, M. Funk", "venue": "CHI Extended Abstracts", "citationCount": 77, "abstract": "Visual communication in collaborative design provides common ground and a tangible trace of thoughts. Yet, it is often underused due to a lack of visualization skills and time needed to sketch and detail. Current visual co-creation tools can support this with existing images, whereas generative AI can produce entirely new images from textual prompts, allowing for highly specific, personalized results. In this paper, we explore how AI image generation can be used to enhance inspiration and communication throughout collaborative design. We introduce BrainFax, a tool that facilitates generating, editing, and sharing images with AI through a chat bot and online whiteboard. Through co-creation with designers in the field, we found that AI image generation can boost designerly co-creation, yet needs careful embedding into a workflow to leverage inspirational and communicative creations. We close with a critical perspective on the implications of this technology for design and discuss limitations and future work.", "isOpenAccess": true, "url": "https://doi.org/10.1145/3544549.3585680"}
{"paperId": "f556f359812c8eb577d993aae903deea7b0d97ba", "year": 2024, "title": "How Beginning Programmers and Code LLMs (Mis)read Each Other", "authors": "S. Nguyen, Hannah McLean Babe, Yangtian Zi, Arjun Guha, C. Anderson, Molly Q. Feldman", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 76, "abstract": "Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642706"}
{"paperId": "fe38824068270ab5254d1c8b9c09db0261cc5154", "year": 2024, "title": "Impact of misinformation from generative AI on user information processing: How people understand misinformation from generative AI", "authors": "Donghee Shin, Amy Koerber, Joon Soo Lim", "venue": "New Media & Society", "citationCount": 75, "abstract": "This study examines the impact of artificial intelligence (AI) on the ways in which users process and respond to misinformation in generative artificial intelligence (GenAI) contexts. Drawing on the heuristic\u2013systematic model and the concept of diagnosticity, our approach examines a cognitive model for processing misinformation in GenAI. The study\u2019s findings revealed that users with a high-heuristic processing mechanism, which affects positive diagnostic perception, were more likely to proactively discern misinformation than users with low-heuristic processing and low-perceived diagnosticity. When exposed to misinformation from GenAI, users\u2019 perceived diagnosticity of misinformation can be accurately predicted by the ways in which they perform heuristic systematic evaluations. With this focus on misinformation processing, this study provides theoretical insights and relevant recommendations for firms to be more resilient in protecting users from the detrimental impacts of misinformation.", "isOpenAccess": false, "url": ""}
{"paperId": "f710896031d29efc4aaa2abe302db3c6f8332248", "year": 2024, "title": "A Human-Centered Learning and Teaching Framework Using Generative Artificial Intelligence for Self-Regulated Learning Development Through Domain Knowledge Learning in K\u201312 Settings", "authors": "Siu-Cheung Kong, Yin Yang", "venue": "IEEE Transactions on Learning Technologies", "citationCount": 75, "abstract": "The advent of generative artificial intelligence (AI) has ignited an increase in discussions about generative AI tools in education. In this study, a human-centered learning and teaching framework that uses generative AI tools for self-regulated learning development through domain knowledge learning was proposed to catalyze changes in educational practices. The framework illustrates how generative AI tools can revolutionize educational practices and transform the processes of teaching and learning to become human-centered. It emphasizes the evolving roles of teachers, who increasingly become skillful facilitators and humanistic storytellers who craft differentiated instructions and attempt to develop students\u2019 individualized learning. Drawing upon insights from neuroscience, the framework guides students to employ generative AI tools to augment their attentiveness, stimulate active engagement in learning, receive immediate feedback, and encourage self-reflection. The pedagogical approach is also reimagined; teachers equipped with generative AI tools and AI literacy can refine their teaching strategies to better equip students to meet future challenges. The practical application of the framework is demonstrated in a case study involving the development of Chinese language writing ability among primary students within a K\u201312 educational context. This article also reports the results of a 60-h development programme for teachers. Specifically, providing in-service teachers with cases involving uses of the proposed framework helped them to better understand the generative AI concepts and integrate them into their teaching and learning and increased their perceived ability to design AI-integrated courses that would enhance students\u2019 attention, engagement, confidence, and satisfaction.", "isOpenAccess": true, "url": "https://doi.org/10.1109/tlt.2024.3392830"}
{"paperId": "f3bf096ccda887b5e0a0980a74b8aee36fd7bc1b", "year": 2023, "title": "Into the LAIONs Den: Investigating Hate in Multimodal Datasets", "authors": "Abeba Birhane, Vinay Prabhu, Sang Han, Vishnu Naresh Boddeti, A. Luccioni", "venue": "Neural Information Processing Systems", "citationCount": 75, "abstract": "'Scale the model, scale the data, scale the compute' is the reigning sentiment in the world of generative AI today. While the impact of model scaling has been extensively studied, we are only beginning to scratch the surface of data scaling and its consequences. This is especially of critical importance in the context of vision-language datasets such as LAION. These datasets are continually growing in size and are built based on large-scale internet dumps such as the Common Crawl, which is known to have numerous drawbacks ranging from quality, legality, and content. The datasets then serve as the backbone for large generative models, contributing to the operationalization and perpetuation of harmful societal and historical biases and stereotypes. In this paper, we investigate the effect of scaling datasets on hateful content through a comparative audit of two datasets: LAION-400M and LAION-2B. Our results show that hate content increased by nearly 12% with dataset scale, measured both qualitatively and quantitatively using a metric that we term as Hate Content Rate (HCR). We also found that filtering dataset contents based on Not Safe For Work (NSFW) values calculated based on images alone does not exclude all the harmful content in alt-text. Instead, we found that trace amounts of hateful, targeted, and aggressive text remain even when carrying out conservative filtering. We end with a reflection and a discussion of the significance of our results for dataset curation and usage in the AI community. Code and the meta-data assets curated in this paper are publicly available at https://github.com/vinayprabhu/hate_scaling. Content warning: This paper contains examples of hateful text that might be disturbing, distressing, and/or offensive.", "isOpenAccess": false, "url": ""}
{"paperId": "e1bec44a7fda796145f68751a46977b49121339e", "year": 2023, "title": "ChatGPT and mental healthcare: balancing benefits with risks of harms", "authors": "C. Blease, J. Torous", "venue": "BMJ Mental Health", "citationCount": 75, "abstract": "Against the global need for increased access to mental services, health organisations are looking to technological advances to improve the delivery of care and lower costs. Since November 2022, with the public launch of OpenAI\u2019s ChatGPT, the field of generative artificial intelligence (AI) has received expanding attention. Although generative AI itself is not new, technical advances and the increased accessibility of large language models (LLMs) (eg, OpenAI\u2019s GPT-4 and Google\u2019s Bard) suggest use of these tools could be clinically significant. LLMs are an application of generative AI technology that can summarise and generate content based on training on vast data sets. Unlike search engines, which provide internet links in response to typed entries, chatbots that rely on generative language models can simulate dialogue that resembles human conversations. We examine the potential promise and the risks of using LLMs in mental healthcare today, focusing on their scope to impact mental healthcare, including global equity in the delivery of care. Although we caution that LLMs should not be used to disintermediate mental health clinicians, we signal how\u2014if carefully implemented\u2014in the long term these tools could reap benefits for patients and health professionals.", "isOpenAccess": true, "url": "https://mentalhealth.bmj.com/content/ebmental/26/1/e300884.full.pdf"}
{"paperId": "95b56abc2f23b1332af11daf5e074232a6aabbe5", "year": 2023, "title": "Health Disinformation Use Case Highlighting the Urgent Need for Artificial Intelligence Vigilance: Weapons of Mass Disinformation.", "authors": "B. Menz, N. Modi, M. Sorich, A. Hopkins", "venue": "JAMA Internal Medicine", "citationCount": 75, "abstract": "Importance\nAlthough artificial intelligence (AI) offers many promises across modern medicine, it may carry a significant risk for the mass generation of targeted health disinformation. This poses an urgent threat toward public health initiatives and calls for rapid attention by health care professionals, AI developers, and regulators to ensure public safety.\n\n\nObservations\nAs an example, using a single publicly available large-language model, within 65 minutes, 102 distinct blog articles were generated that contained more than 17\u202f000 words of disinformation related to vaccines and vaping. Each post was coercive and targeted at diverse societal groups, including young adults, young parents, older persons, pregnant people, and those with chronic health conditions. The blogs included fake patient and clinician testimonials and obeyed prompting for the inclusion of scientific-looking referencing. Additional generative AI tools created an accompanying 20 realistic images in less than 2 minutes. This process was undertaken by health care professionals and researchers with no specialized knowledge in bypassing AI guardrails, relying solely on publicly available information.\n\n\nConclusions and Relevance\nThese observations demonstrate that when the guardrails of AI tools are insufficient, the ability to rapidly generate diverse and large amounts of convincing disinformation is profound. Beyond providing 2 example scenarios, these findings demonstrate an urgent need for robust AI vigilance. The AI tools are rapidly progressing; alongside these advancements, emergent risks are becoming increasingly apparent. Key pillars of pharmacovigilance-including transparency, surveillance, and regulation-may serve as valuable examples for managing these risks and safeguarding public health.", "isOpenAccess": false, "url": ""}
{"paperId": "8ae19bc11757398234378e1001f42361f3c6b72c", "year": 2024, "title": "The paradoxes of generative AI-enabled customer service: A guide for managers", "authors": "Carla Ferraro, Vladimir Demsar, S. Sands, Mariluz Restrepo, Colin Campbell", "venue": "Business Horizons", "citationCount": 75, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.bushor.2024.04.013"}
{"paperId": "7f5391908d2274a1df73cea7b4cd1956119ce964", "year": 2024, "title": "How to use generative AI as a human resource management assistant", "authors": "Herman Aguinis, Jose R. Beltran, Amando Cope", "venue": "Organizational Dynamics", "citationCount": 75, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.orgdyn.2024.101029"}
{"paperId": "297600808c1b1a05d311aa73214cb193ff03c256", "year": 2024, "title": "The Impact of Different Conversational Generative AI Chatbots on EFL Learners: an Analysis of Willingness to Communicate, Foreign Language Speaking Anxiety, and Self-perceived Communicative Competence", "authors": "Chenghao Wang, Bin Zou, Yiran Du, Zixun Wang", "venue": "System (Link\u00f6ping)", "citationCount": 75, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "abd42a2ae6dfe4b3a4e657c9239a903a904568cb", "year": 2024, "title": "Fine-Tuned 'Small' LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in Text Classification", "authors": "Martin Bucher, Marco Martini", "venue": "arXiv.org", "citationCount": 74, "abstract": "Generative AI offers a simple, prompt-based alternative to fine-tuning smaller BERT-style LLMs for text classification tasks. This promises to eliminate the need for manually labeled training data and task-specific model training. However, it remains an open question whether tools like ChatGPT can deliver on this promise. In this paper, we show that smaller, fine-tuned LLMs (still) consistently and significantly outperform larger, zero-shot prompted models in text classification. We compare three major generative AI models (ChatGPT with GPT-3.5/GPT-4 and Claude Opus) with several fine-tuned LLMs across a diverse set of classification tasks (sentiment, approval/disapproval, emotions, party positions) and text categories (news, tweets, speeches). We find that fine-tuning with application-specific training data achieves superior performance in all cases. To make this approach more accessible to a broader audience, we provide an easy-to-use toolkit alongside this paper. Our toolkit, accompanied by non-technical step-by-step guidance, enables users to select and fine-tune BERT-like LLMs for any classification task with minimal technical and computational effort.", "isOpenAccess": false, "url": ""}
{"paperId": "aa9735002aad8d877c14ffe5619742bd437ec0bb", "year": 2023, "title": "Generative AI and Marketing Education: What the Future Holds", "authors": "Abhijit Guha, Dhruv Grewal, Stephen Atlas", "venue": "Journal of Marketing Education", "citationCount": 74, "abstract": "To understand why and how marketing educators can best use generative artificial intelligence (AI), such as ChatGPT, this article integrates a literature survey, interviews with both marketing educators and managers, and surveys of both marketing educators and students. In leveraging these inputs, the authors argue that generative AI can significantly shape and improve the future of marketing education. Specifically, by including ChatGPT in their lessons, marketing educators can both materially enhance learning experiences and better prepare students for future jobs with marketing firms that rely on ChatGPT in practice. Noting that ChatGPT has downsides, this research identifies several steps educators should take to minimize the risks. Finally, the authors propose an agenda for continued research into how marketing educators can and should use ChatGPT, with the explicit recognition that ChatGPT is evolving rapidly, so that, the research agenda will need to adapt as well.", "isOpenAccess": false, "url": ""}
{"paperId": "668e092f3783af99a776b9aee22114f37fa41bb7", "year": 2024, "title": "First-year students AI-competence as a predictor for intended and de facto use of AI-tools for supporting learning processes in higher education", "authors": "Jan Delcker, Joana Heil, Dirk Ifenthaler, Sabine Seufert, Lukas Spirgi", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 74, "abstract": "The influence of Artificial Intelligence on higher education is increasing. As important drivers for student retention and learning success, generative AI-tools like translators, paraphrasers and most lately chatbots can support students in their learning processes. The perceptions and expectations of first-years students related to AI-tools have not yet been researched in-depth. The same can be stated about necessary requirements and skills for the purposeful use of AI-tools. The research work examines the relationship between first-year students\u2019 knowledge, skills and attitudes and their use of AI-tools for their learning processes. Analysing the data of 634 first-year students revealed that attitudes towards AI significantly explains the intended use of AI tools. Additionally, the perceived benefits of AI-technology are predictors for students\u2019 perception of AI-robots as cooperation partners for humans. Educators in higher education must facilitate students\u2019 AI competencies and integrate AI-tools into instructional designs. As a result, students learning processes will be improved.", "isOpenAccess": true, "url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-024-00452-7"}
{"paperId": "4e3cf7e4bf27ead052eba05720c133276a12286c", "year": 2024, "title": "Promoting sustainable development goals through generative artificial intelligence in the digital supply chain: Insights from Chinese tourism SMEs", "authors": "Shaofeng Wang, Hao Zhang", "venue": "Sustainable Development", "citationCount": 74, "abstract": "Interdisciplinary advancements, such as generative artificial intelligence (AI) and digital supply chains, can significantly contribute to achieving sustainable development goals (SDGs), particularly within tourism. This paper illuminates how it works well, focusing on the underexplored area of Environmental, Social, and Governance (ESG) performance within small and medium\u2010sized tourism enterprises (SMEs) in China. Through a survey of\u00a0429 international SMEs, we apply the Resource\u2010Based View and Dynamic Capabilities Theory to investigate how generative AI, such as ChatGPT, in digital supply chains can enhance innovation, collaboration, and, ultimately, ESG performance. The empirical findings underscore the pivotal role of generative AI in augmenting ESG performance via bolstering innovation and collaboration within digital supply chains. Additionally, the moderating effect of customer involvement positively influences the relationship between the digital supply chain and ESG performance. By demonstrating these relations, our study contributes to theoretical and practical efforts toward sustainable tourism and the broader achievement of the SDGs.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/sd.3152"}
{"paperId": "3ad3e240cabb3f3471770d25a7414a81175aa0db", "year": 2024, "title": "Explainable Generative AI (GenXAI): a survey, conceptualization, and research agenda", "authors": "Johannes Schneider", "venue": "Artificial Intelligence Review", "citationCount": 74, "abstract": "Generative AI (GenAI) represents a shift from AI\u2019s ability to \u201crecognize\u201d to its ability to \u201cgenerate\u201d solutions for a wide range of tasks. As generated solutions and applications grow more complex and multi-faceted, new needs, objectives, and possibilities for explainability (XAI) have emerged. This work elaborates on why XAI has gained importance with the rise of GenAI and the challenges it poses for explainability research. We also highlight new and emerging criteria that explanations should meet, such as verifiability, interactivity, security, and cost considerations. To achieve this, we focus on surveying existing literature. Additionally, we provide a taxonomy of relevant dimensions to better characterize existing XAI mechanisms and methods for GenAI. We explore various approaches to ensure XAI, ranging from training data to prompting. Our paper provides a concise technical background of GenAI for non-technical readers, focusing on text and images to help them understand new or adapted XAI techniques for GenAI. However, due to the extensive body of work on GenAI, we chose not to delve into detailed aspects of XAI related to the evaluation and usage of explanations. Consequently, the manuscript appeals to both technical experts and professionals from other fields, such as social scientists and information systems researchers. Our research roadmap outlines over ten directions for future investigation.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s10462-024-10916-x"}
{"paperId": "31cc5247ccb280bd8aceea4c5126f0b0dcf1a616", "year": 2025, "title": "Could AI Ethical Anxiety, Perceived Ethical Risks and Ethical Awareness About AI Influence University Students\u2019 Use of Generative AI Products? An Ethical Perspective", "authors": "Wenjuan Zhu, Lei Huang, Xinni Zhou, Xiaoya Li, Gaojun Shi, Jingxin Ying, Chaoyue Wang", "venue": "International journal of human computer interactions", "citationCount": 74, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "14ec5ef5c46f305fc704dc308ca4bf64ab28befe", "year": 2024, "title": "Generative AI in innovation and marketing processes: A roadmap of research opportunities", "authors": "Paola Cillo, Gaia Rubera", "venue": "Journal of the Academy of Marketing Science", "citationCount": 74, "abstract": "Nowadays, we are witnessing the exponential growth of Generative AI (GenAI), a group of AI models designed to produce new content. This technology is poised to revolutionize marketing research and practice. Since the marketing literature about GenAI is still in its infancy, we offer a technical overview of how GenAI models are trained and how they produce content. Following this, we construct a roadmap for future research on GenAI in marketing, divided into two main domains. The first domain focuses on how firms can harness the potential of GenAI throughout the innovation process. We begin by discussing how GenAI changes consumer behavior and propose research questions at the consumer level. We then connect these emerging consumer insights with corresponding firm marketing strategies, presenting research questions at the firm level. The second set of research questions examines the likely consequences of using GenAI to analyze: (1) the relationship between market-based assets and firm value, and (2) consumer skills, preferences, and role in marketing processes.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s11747-024-01044-7"}
{"paperId": "dacc604afd110f44f1dcd4451f887fbad20117a6", "year": 2023, "title": "DesignAID: Using Generative AI and Semantic Diversity for Design Inspiration", "authors": "Alice Cai, Steven R. Rick, Jennifer L. Heyman, Yanxia Zhang, Alexandre L. S. Filipowicz, Matthew K. Hong, Matt Klenk, Thomas W. Malone", "venue": "International Conference on Climate Informatics", "citationCount": 73, "abstract": "Designers often struggle to sufficiently explore large design spaces, which can lead to design fixation and suboptimal outcomes. Here we introduce DesignAID, a generative AI tool that supports broader design space exploration by first using large language models to produce a range of diverse ideas expressed in words, and then using image generation software to create images from these words. This innovative combination of AI-based capabilities allows human-computer pairs to rapidly create a diverse set of visual concepts without time-consuming drawing. In a study with 87 crowd-sourced designers, we found that designers rated the automatic generation of images from words as significantly more inspirational, enjoyable, and useful than a conventional baseline condition of image search using Pinterest. Surprisingly, however, we found that automatically generating highly diverse ideas had less value. For image generation, the high diversity condition was somewhat better in inspiration but no better in the other dimensions, and for image search it was significantly worse in all dimensions.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3582269.3615596"}
{"paperId": "af16ab7db8e69a6ec55ffb2d391ceb67a2875693", "year": 2024, "title": "Assessing the nexus of Generative AI adoption, ethical considerations and organizational performance", "authors": "Nripendra P. Rana, Rajasshrie Pillai, Brijesh Sivathanu, Nishtha Malik", "venue": "Technovation", "citationCount": 73, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.technovation.2024.103064"}
{"paperId": "a1abf4d8bad5694621e4d8cd09e41c80cdbba318", "year": 2023, "title": "From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape", "authors": "Timothy R. Mcintosh, Teo Su\u0161njak, Tong Liu, Paul A. Watters, Malka N. Halgamuge", "venue": "Technologies", "citationCount": 73, "abstract": "This comprehensive survey explored the evolving landscape of generative Artificial Intelligence (AI), with a specific focus on the recent technological breakthroughs and the gathering advancements toward possible Artificial General Intelligence (AGI). It critically examined the current state and future trajectory of generative AI, exploring how innovations in developing actionable and multimodal AI agents with the ability scale their \u201cthinking\u201d in solving complex reasoning tasks are reshaping research priorities and applications across various domains, while the survey also offers an impact analysis on the generative AI research taxonomy. This work has assessed the computational challenges, scalability, and real-world implications of these technologies while highlighting their potential in driving significant progress in fields like healthcare, finance, and education. Our study also addressed the emerging academic challenges posed by the proliferation of both AI-themed and AI-generated preprints, examining their impact on the peer-review process and scholarly communication. The study highlighted the importance of incorporating ethical and human-centric methods in AI development, ensuring alignment with societal norms and welfare, and outlined a strategy for future AI research that focuses on a balanced and conscientious use of generative AI as its capabilities continue to scale.", "isOpenAccess": false, "url": ""}
{"paperId": "a0968924129aee94ca2070004e657df3d34a41dd", "year": 2023, "title": "Academic publisher guidelines on AI usage: A ChatGPT supported thematic analysis", "authors": "Mike Perkins, Jasper Roe", "venue": "F1000Research", "citationCount": 73, "abstract": "Background As Artificial Intelligence (AI) technologies such as Generative AI (GenAI) have become more common in academic settings, it is necessary to examine how these tools interact with issues of authorship, academic integrity, and research methodologies. The current landscape lacks cohesive policies and guidelines for regulating AI\u2019s role in academic research which has prompted discussions among publishers, authors, and institutions. Methods This study employs inductive thematic analysis to explore publisher policies regarding AI-assisted authorship and academic work. Our methods involved a two-fold analysis using both AI-assisted and traditional unassisted techniques to examine the available policies from leading academic publishers and other publishing or academic entities. The framework was designed to offer multiple perspectives, harnessing the strengths of AI for pattern recognition while leveraging human expertise for nuanced interpretation. The results of these two analyses are combined to form the final themes. Results Our findings indicate six overall themes, three of which were independently identified in both the AI-assisted and unassisted, manual analysis using common software tools. A broad consensus appears among publishers that human authorship remains paramount and that the use of GenAI tools is permissible but must be disclosed. However, GenAI tools are increasingly acknowledged for their supportive roles, including text generation and data analysis. The study also discusses the inherent limitations and biases of AI-assisted analysis, necessitating rigorous scrutiny by authors, reviewers, and editors. Conclusions There is a growing recognition of AI\u2019s role as a valuable auxiliary tool in academic research, but one that comes with caveats pertaining to integrity, accountability, and interpretive limitations. This study used a novel analysis supported by GenAI tools to identify themes emerging in the policy landscape, underscoring the need for an informed, flexible approach to policy formulation that can adapt to the rapidly evolving landscape of AI technologies.", "isOpenAccess": true, "url": "https://f1000research.com/articles/12-1398/pdf"}
{"paperId": "667ee6cc2d47a88cbbf6c8ad2b5269c3f37367fc", "year": 2023, "title": "Generative AI for brain image computing and brain network computing: a review", "authors": "Changwei Gong, Changhong Jing, Xuhang Chen, Chi-Man Pun, Guoli Huang, Ashirbani Saha, M. Nieuwoudt, Han-Xiong Li, Yong Hu, Shuqiang Wang", "venue": "Frontiers in Neuroscience", "citationCount": 73, "abstract": "Recent years have witnessed a significant advancement in brain imaging techniques that offer a non-invasive approach to mapping the structure and function of the brain. Concurrently, generative artificial intelligence (AI) has experienced substantial growth, involving using existing data to create new content with a similar underlying pattern to real-world data. The integration of these two domains, generative AI in neuroimaging, presents a promising avenue for exploring various fields of brain imaging and brain network computing, particularly in the areas of extracting spatiotemporal brain features and reconstructing the topological connectivity of brain networks. Therefore, this study reviewed the advanced models, tasks, challenges, and prospects of brain imaging and brain network computing techniques and intends to provide a comprehensive picture of current generative AI techniques in brain imaging. This review is focused on novel methodological approaches and applications of related new methods. It discussed fundamental theories and algorithms of four classic generative models and provided a systematic survey and categorization of tasks, including co-registration, super-resolution, enhancement, classification, segmentation, cross-modality, brain network analysis, and brain decoding. This paper also highlighted the challenges and future directions of the latest work with the expectation that future research can be beneficial.", "isOpenAccess": true, "url": "https://www.frontiersin.org/articles/10.3389/fnins.2023.1203104/pdf"}
{"paperId": "452bd6c66bfe08a2f2f1fb6feba00d79619ad5b0", "year": 2023, "title": "How Knowledge Workers Think Generative AI Will (Not) Transform Their Industries", "authors": "Allison Woodruff, Renee Shelby, Patrick Gage Kelley, Steven Rousso-Schindler, Jamila Smith-Loud, Lauren Wilcox", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 73, "abstract": "Generative AI is expected to have transformative effects in multiple knowledge industries. To better understand how knowledge workers expect generative AI may affect their industries in the future, we conducted participatory research workshops for seven different industries, with a total of 54 participants across three US cities. We describe participants\u2019 expectations of generative AI\u2019s impact, including a dominant narrative that cut across the groups\u2019 discourse: participants largely envision generative AI as a tool to perform menial work, under human review. Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives. Participants do however envision generative AI may amplify four social forces currently shaping their industries: deskilling, dehumanization, disconnection, and disinformation. We describe these forces, and then we provide additional detail regarding attitudes in specific knowledge industries. We conclude with a discussion of implications and research challenges for the HCI community.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642700"}
{"paperId": "24c5450d8fa785e5f85d9427d2d65cf66476ac3a", "year": 2023, "title": "Toward General Design Principles for Generative AI Applications 130-144", "authors": "Justin D. Weisz, Michael J. Muller, Jessica He, Stephanie Houde", "venue": "IUI Workshops", "citationCount": 73, "abstract": "Generative AI technologies are growing in power, utility, and use. As generative technologies are being incorporated into mainstream applications, there is a need for guidance on how to design those applications to foster productive and safe use. Based on recent research on human-AI co-creation within the HCI and AI communities, we present a set of seven principles for the design of generative AI applications. These principles are grounded in an environment of generative variability. Six principles are focused on designing for characteristics of generative AI: multiple outcomes&imperfection; exploration&control; and mental models&explanations. In addition, we urge designers to design against potential harms that may be caused by a generative model's hazardous output, misuse, or potential for human displacement. We anticipate these principles to usefully inform design decisions made in the creation of novel human-AI applications, and we invite the community to apply, revise, and extend these principles to their own work.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2301.05578"}
{"paperId": "09e94b984ae0593ef8b752344001a6416b4aee1f", "year": 2024, "title": "Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review", "authors": "Nan Wang, Xiao Wang, Yu-Sheng Su", "venue": "Asia Pacific Journal of Education", "citationCount": 73, "abstract": "ABSTRACT Generative artificial intelligence has been regarded as a transformative tool. While responsible and ethical applications could bring opportunities to education, their misuse could pose demanding challenges. It is necessary to clarify the technological affordances and challenges in a normative way to lay the foundation for future development. This study addressed the dearth of literature by performing a systematic review, aiming to (i) explore the utility and availability from the technological affordances perspective; (ii) summarize the current challenges in risks prevention; and (iii) propose possible directions for future research and practice. A total of 27 academic articles published in core journals between 2020 and 2023 were analyzed, and the inductive grounded approach was used to categorize the coding schemes. The findings revealed four technological affordances: accessibility, personalization, automation, and interactivity; and five challenges: academic integrity risk, response errors and bias, over-dependence risk, the widening digital divide, and privacy and security. We propose future directions, encourage educational organizations to formulate guidelines for the ethical use of AI in education, call on educators to embrace future trends in AI education instead of shunning its use, and guide students to treat it as a thought aid and reference, rather than relying on it entirely.", "isOpenAccess": false, "url": ""}
{"paperId": "a63bdd35d225bbefc6563bc9398b59b42e9d383c", "year": 2023, "title": "Using Generative Artificial Intelligence for Language Education Research: Insights from Using OpenAI's ChatGPT", "authors": "Austin Pack, J. Maloney", "venue": "TESOL Quarterly (Print)", "citationCount": 72, "abstract": "Progress made in Natural Language Processing (NLP) and Artificial Intelligence (AI) in recent years has resulted in these tools becoming more accessible for individuals who lack professional training. Of particular note are large language models, such as OpenAI's GPT\u20103.5. Discussions of utilizing AI for language education usually focus on the impact the technology will have on students and teachers. Less frequently the center of attention is how generative AI tools can empower researchers. The purpose of this paper is to raise awareness by demonstrating and discussing examples of how OpenAI's chatbot, ChatGPT, can be leveraged as a tool for language education researchers. After briefly introducing the use of AI generative tools in the field, this paper demonstrates how a researcher, without any understanding of NLP or AI, may use ChatGPT to assist with research through multiple means, including approaches to its use for compiling and summarizing information, and as a research assistant throughout multiple steps of research. This is followed by a discussion of potential ethical concerns of using AI for research in the field. We conclude by issuing a call for further work examining how researchers can harness the potential of this technology in ethical ways.", "isOpenAccess": false, "url": ""}
{"paperId": "9de8ff688c908f8244aef33d38e3ee6a5198ffb1", "year": 2024, "title": "How organizations can innovate with generative AI", "authors": "J. Holmstr\u00f6m, Noel Carroll", "venue": "Business Horizons", "citationCount": 72, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "9c100ab379bd5ed3b92b1161ad64abf4e8d04996", "year": 2023, "title": "ChatGPT and Generative AI Technology: A Mixed Bag of Concerns and New Opportunities", "authors": "Judy Lambert, Mark J. Stevens", "venue": "Computers in The Schools", "citationCount": 72, "abstract": "Abstract ChatGPT has garnered unprecedented popularity since its release in November 2022. This artificial intelligence (AI) large language model (LLM) is designed to generate human-like text based on patterns found in massive amounts of data scraped from the internet. ChatGPT is significantly different from previous versions of GPT by its quality of output, capability to interact and hold human-like conversations, enormous speed, and ability to have its output refined by users or experts. New iterations of ChatGPT as well as open source and alternative LLMs, and ChatGPT plugins extend the current capabilities of ChatGPT and offer unlimited opportunities to change how we do things. Despite its newfound popularity and capabilities, ChatGPT is fraught with concerns such as cheating, misinformation, bias, abuse and misuse, and privacy and safety. On the other hand, the integration of ChatGPT in the classroom prompts us to envision better ways of providing instruction and assessment of writing skills. ChatGPT also provides unparalleled approaches for personalized learning. As educators, we must consider and deal with the serious concerns of using ChatGPT but simultaneously explore how this AI technology can enhance and extend current methods of instruction. In this paper, authors explain what ChatGPT is and how it works, and future iterations of ChatGPT. They also present concerns and opportunities, and educational implications of using ChatGPT in the classroom.", "isOpenAccess": false, "url": ""}
{"paperId": "8e1472452201fca90a15582ee356d9cf2783d90a", "year": 2023, "title": "Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model", "authors": "Chenru Duan, Yuanqi Du, Haojun Jia, Heather J. Kulik", "venue": "Nature Computational Science", "citationCount": 72, "abstract": "Transition state search is key in chemistry for elucidating reaction mechanisms and exploring reaction networks. The search for accurate 3D transition state structures, however, requires numerous computationally intensive quantum chemistry calculations due to the complexity of potential energy surfaces. Here we developed an object-aware SE(3) equivariant diffusion model that satisfies all physical symmetries and constraints for generating sets of structures\u2014reactant, transition state and product\u2014in an elementary reaction. Provided reactant and product, this model generates a transition state structure in seconds instead of hours, which is typically required when performing quantum-chemistry-based optimizations. The generated transition state structures achieve a median of 0.08\u2009\u212b root mean square deviation compared to the true transition state. With a confidence scoring model for uncertainty quantification, we approach an accuracy required for reaction barrier estimation (2.6\u2009kcal\u2009mol\u20131) by only performing quantum chemistry-based optimizations on 14% of the most challenging reactions. We envision usefulness for our approach in constructing large reaction networks with unknown mechanisms. A diffusion model that generates chemical reactions in 3D with all desired symmetries preserved is established and shown to reduce transition state search from days to seconds and complement intuition-based reaction exploration with generative AI.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.06174"}
{"paperId": "8402f9bbc38a1786c3cd7974db6c82c823e84f92", "year": 2024, "title": "The Effects of Generative AI on Computing Students\u2019 Help-Seeking Preferences", "authors": "Irene Hou, Sophia Mettille, Owen Man, Zhuo Li, Cynthia Zastudil, Stephen Macneil", "venue": "IFAC Symposium on Advances in Control Education", "citationCount": 72, "abstract": "Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "775889071de3cc3d403054736b1307d578392418", "year": 2023, "title": "An expectancy value theory (EVT) based instrument for measuring student perceptions of generative AI", "authors": "C. Chan, Wenxin Zhou", "venue": "Smart Learning Environments", "citationCount": 72, "abstract": "This study examines the relationship between student perceptions and their intention to use generative artificial intelligence (GenAI) in higher education. With a sample of 405 students participating in the study, their knowledge, perceived value, and perceived cost of using the technology were measured by an Expectancy-Value Theory (EVT) instrument. The scales were first validated and the correlations between the different components were subsequently estimated. The results indicate a strong positive correlation between perceived value and intention to use generative AI, and a weak negative correlation between perceived cost and intention to use. As we continue to explore the implications of GenAI in education and other domains, it is crucial to carefully consider the potential long-term consequences and the ethical dilemmas that may arise from widespread adoption.", "isOpenAccess": true, "url": "https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00284-4"}
{"paperId": "5d4ebca8bd90fef7f07ac72ab897ef45c0381d5f", "year": 2023, "title": "\u2018Words Are Flowing Out Like Endless Rain Into a Paper Cup\u2019: ChatGPT & Law School Assessments", "authors": "Stuart Hargreaves", "venue": "Social Science Research Network", "citationCount": 72, "abstract": "ChatGPT is a sophisticated large-language model able to answer high-level questions in a way that is does not trigger conventional plagiarism detectors. Concerns have been raised that and similar forms of \u2018generative AI\u2019 pose a significant threat to academic integrity in higher education. To evaluate this risk in the context of legal education specifically, this project had ChatGPT (using the GPT3.5 model available in January 2023) generate answers to twenty-four different exams from an English-language law school based in a common law jurisdiction. It found that the system performed best on exams that were essay-based and asked students to discuss international legal instruments or general legal principles not necessarily specific to any jurisdiction. It performed worst on exams that featured problem-style or \u201cissue spotting\u201d questions asking students to apply an invented factual scenario to local legislation or jurisprudence. While the project suggests that for the most part conventional law school assessments are for the time being relatively immune from the threat generative AI brings, the project provides only a baseline snapshot of how large-language models tackle assessment in higher education. As both the technology improves and students learn how to harness it, increasingly fewer forms of assessment will be beyond its reach. However, rather than attempt to block students from using AI as part of learning and assessment, this paper instead proposes three ways students may be taught to use it in appropriate and ethical ways. While it is clear that generative AI will change how universities teach and assess (across disciplines), a solution of prevention or denial is no solution at all.", "isOpenAccess": false, "url": ""}
{"paperId": "5cbd1465476ad4dcc3635cf7be71a2e030afae75", "year": 2024, "title": "Generative AI Literacy: Twelve Defining Competencies", "authors": "Ravinithesh Annapureddy, Alessandro Fornaroli, D. Gatica-Perez", "venue": "Digit. Gov. Res. Pract.", "citationCount": 72, "abstract": "This article introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These 12 competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to become familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3685680"}
{"paperId": "186b620393a2e3f1d0e9b0ec0620a80b5ea55af5", "year": 2024, "title": "The dark side of artificial intelligence in services", "authors": "D. Belanche, Russell W. Belk, L. Casal\u00f3, C. Flavi\u00e1n", "venue": "Service Industries Journal", "citationCount": 72, "abstract": "ABSTRACT Artificial intelligence (AI) initiatives, including Generative AI, are being increasingly implemented in service industries, and are having a great impact on service operations and on customers\u2019 reactions and behaviors. Previous literature is overoptimistic about AI implementation, and there is still a need to explore the dark side of this technology; that is, its potential negative impacts on consumers, businesses, and society, as well as the moral concerns associated with AI use in services. To establish some fundamental insights related to this research domain, this paper contributes to previous AI based-services literature by proposing a three-part conceptual model inspired by Belanche et al. (2020a), comprised of AI design, customers, and the service encounter. Specifically, we identify key factors and research gaps within each category that need to be addressed. The final research questions provide a research agenda to guide scholars and help practitioners implement AI-based services while avoiding their potential negative outcomes.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/02642069.2024.2305451?needAccess=true"}
{"paperId": "dcf2e723ee9c3270c98ff768b139cca75d29242e", "year": 2023, "title": "A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture", "authors": "Cheonsu Jeong", "venue": "Advances in Artificial Intelligence and Machine Learning", "citationCount": 71, "abstract": "This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings.", "isOpenAccess": true, "url": "https://doi.org/10.54364/aaiml.2023.1191"}
{"paperId": "8c43c39a6dba44df22ad730e41527fc356149119", "year": 2023, "title": "Preliminary Evidence of the Use of Generative AI in Health Care Clinical Services: Systematic Narrative Review", "authors": "Dobin Yim, J. Khuntia, V. Parameswaran, Arlen Meyers", "venue": "JMIR Medical Informatics", "citationCount": 71, "abstract": "Background Generative artificial intelligence tools and applications (GenAI) are being increasingly used in health care. Physicians, specialists, and other providers have started primarily using GenAI as an aid or tool to gather knowledge, provide information, train, or generate suggestive dialogue between physicians and patients or between physicians and patients\u2019 families or friends. However, unless the use of GenAI is oriented to be helpful in clinical service encounters that can improve the accuracy of diagnosis, treatment, and patient outcomes, the expected potential will not be achieved. As adoption continues, it is essential to validate the effectiveness of the infusion of GenAI as an intelligent technology in service encounters to understand the gap in actual clinical service use of GenAI. Objective This study synthesizes preliminary evidence on how GenAI assists, guides, and automates clinical service rendering and encounters in health care The review scope was limited to articles published in peer-reviewed medical journals. Methods We screened and selected 0.38% (161/42,459) of articles published between January 1, 2020, and May 31, 2023, identified from PubMed. We followed the protocols outlined in the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to select highly relevant studies with at least 1 element on clinical use, evaluation, and validation to provide evidence of GenAI use in clinical services. The articles were classified based on their relevance to clinical service functions or activities using the descriptive and analytical information presented in the articles. Results Of 161 articles, 141 (87.6%) reported using GenAI to assist services through knowledge access, collation, and filtering. GenAI was used for disease detection (19/161, 11.8%), diagnosis (14/161, 8.7%), and screening processes (12/161, 7.5%) in the areas of radiology (17/161, 10.6%), cardiology (12/161, 7.5%), gastrointestinal medicine (4/161, 2.5%), and diabetes (6/161, 3.7%). The literature synthesis in this study suggests that GenAI is mainly used for diagnostic processes, improvement of diagnosis accuracy, and screening and diagnostic purposes using knowledge access. Although this solves the problem of knowledge access and may improve diagnostic accuracy, it is oriented toward higher value creation in health care. Conclusions GenAI informs rather than assisting or automating clinical service functions in health care. There is potential in clinical service, but it has yet to be actualized for GenAI. More clinical service\u2013level evidence that GenAI is used to streamline some functions or provides more automated help than only information retrieval is needed. To transform health care as purported, more studies related to GenAI applications must automate and guide human-performed services and keep up with the optimism that forward-thinking health care organizations will take advantage of GenAI.", "isOpenAccess": true, "url": "https://doi.org/10.2196/52073"}
{"paperId": "7223eb86633616cecf484006cad2584655fed90b", "year": 2024, "title": "Using ChatGPT for Science Learning: A Study on Pre-service Teachers' Lesson Planning", "authors": "Gyeong-Geon Lee, Xiaoming Zhai", "venue": "IEEE Transactions on Learning Technologies", "citationCount": 71, "abstract": "While ongoing efforts have continuously emphasized the integration of ChatGPT with science teaching and learning, there are limited empirical studies exploring its actual utility in the classroom. This study aims to fill this gap by analyzing the lesson plans developed by 29 pre-service elementary teachers and assessing how they integrated ChatGPT into science learning activities. We first examined how ChatGPT was integrated with the subject domains, teaching methods/strategies, and then evaluated the lesson plans using a generative artificial intelligence (AI)-technological pedagogical and content knowledge (TPACK)-based rubric. We further examined pre-service teachers' perceptions and concerns about integrating ChatGPT into science learning. Results show a diverse number of ChatGPT applications in different science domains\u2014e.g., Biology (9/29), Chemistry (7/29), and Earth Science (7/29). A total of 14 types of teaching methods/strategies were identified in the lesson plans. On average, the pre-service teachers' lesson plans scored high on the modified TPACK-based rubric (M = 3.29; SD = 0.91; on a 1\u20134 scale), indicating a reasonable envisage of integrating ChatGPT into science learning, particularly in \u201cinstructional strategies and ChatGPT\u201d (M = 3.48; SD = 0.99). However, they scored relatively lower on exploiting ChatGPT's functions toward its full potential (M = 3.00; SD = 0.93), compared to other aspects. We also identified several inappropriate use cases of ChatGPT in lesson planning (e.g., as a source of hallucinated Internet material and technically unsupported visual guidance). Pre-service teachers anticipated ChatGPT to afford high-quality questioning, self-directed learning, individualized learning support, and formative assessment. Meanwhile, they also expressed concerns about its accuracy and the risks that students may be overly dependent on ChatGPT. They further suggested solutions to systemizing classroom dynamics between teachers and students. The study underscores the need for more research on the roles of generative AI in actual classroom settings and provides insights for future AI-integrated science learning.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2402.01674"}
{"paperId": "61e8f674cd169558fd31e8008ea3ce2230f1add6", "year": 2024, "title": "Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification - Extended Abstract", "authors": "Janek Bevendorff, Xavier Bonet Casals, Berta Chulvi, Daryna Dementieva, Ashaf Elnagar, Dayne Freitag, Maik Fr\u00f6be, Damir Koren\u010di\u0107, Maximilian Mayerl, Animesh Mukherjee, Alexander Panchenko, Martin Potthast, Francisco Rangel, Paolo Rosso, Alisa Smirnova, E. Stamatatos, Benno Stein, M. Taul\u00e9, Dmitry Ustalov, Matti Wiegmann, Eva Zangerle", "venue": "European Conference on Information Retrieval", "citationCount": 71, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "3207424dba597acc4328eedb7c5e1aad37a0bf15", "year": 2024, "title": "CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars", "authors": "Hua Xuan Qin, Shan Jin, Ze Gao, Mingming Fan, Pan Hui", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 71, "abstract": "Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced immersion. Our findings support research on iterative creative processes and the growing potential of personalizable generative AI creativity support tools. We present design implications for leveraging chatbot avatars in the creative writing process.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642105"}
{"paperId": "265f224956509bf10a69e7a64c2df70a67e82008", "year": 2023, "title": "Unleashing the Potential of Generative AI, Conversational Agents and Chatbots in Educational Praxis: A Systematic Review and Bibliometric Analysis of GenAI in Education", "authors": "Aras Bozkurt", "venue": "Open Praxis", "citationCount": 71, "abstract": "In the rapidly evolving landscape of education, the pivotal axis around which transformation revolves is human-AI interaction. In this sense, this paper adopts a data mining and analytic approach to understand what the related literature tells us regarding the trends and patterns of generative AI research in educational praxis. Accordingly", "isOpenAccess": true, "url": "https://storage.googleapis.com/jnl-up-j-op-files/journals/1/articles/609/655cc015844da.pdf"}
{"paperId": "1b35339446c0f86d5e1e61b5051b65980a17bdba", "year": 2023, "title": "Generative AI in Computing Education: Perspectives of Students and Instructors", "authors": "Cynthia Zastudil, M. Rogalska, C. Kapp, Jennifer L. Vaughn, Stephen MacNeil", "venue": "Frontiers in Education Conference", "citationCount": 71, "abstract": "Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.04309"}
{"paperId": "0457350c86e20954fb3bd18aca1119b0b02efed9", "year": 2023, "title": "Occupational Heterogeneity in Exposure to Generative AI", "authors": "E. Felten, Manav Raj, Robert C. Seamans", "venue": "Social Science Research Network", "citationCount": 71, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "f3c05611b4b67ab73044b0ce16c8899aa2977301", "year": 2023, "title": "RECIPE: How to Integrate ChatGPT into EFL Writing Education", "authors": "Jieun Han, Haneul Yoo, Y. Kim, Junho Myung, Minsun Kim, Hyunseung Lim, Juho Kim, T. Lee, Hwajung Hong, So-Yeon Ahn, Alice H. Oh", "venue": "ACM Conference on Learning @ Scale", "citationCount": 70, "abstract": "The integration of generative AI in the field of education is actively being explored. In particular, ChatGPT has garnered significant interest, offering an opportunity to examine its effectiveness in English as a foreign language (EFL) education. To address this need, we present a novel learning platform called RECIPE (Revising an Essay with ChatGPT on an Interactive Platform for EFL learners). Our platform features two types of prompts that facilitate conversations between ChatGPT and students: (1) a hidden prompt for ChatGPT to take an EFL teacher role and (2) an open prompt for students to initiate a dialogue with a self-written summary of what they have learned. We deployed this platform for 213 undergraduate and graduate students enrolled in EFL writing courses and seven instructors. For this study, we collect students' interaction data from RECIPE, including students' perceptions and usage of the platform, and user scenarios are examined with the data. We also conduct a focus group interview with six students and an individual interview with one EFL instructor to explore design opportunities for leveraging generative AI models in the field of EFL education.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.11583"}
{"paperId": "efacfe7e734e5c8cedddf5ee02c3afb25f6401f2", "year": 2024, "title": "FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models", "authors": "Zhipei Xu, Xuanyu Zhang, Runyi Li, Zecheng Tang, Qing Huang, Jian Zhang", "venue": "International Conference on Learning Representations", "citationCount": 70, "abstract": "The rapid development of generative AI is a double-edged sword, which not only facilitates content creation but also makes image manipulation easier and more difficult to detect. Although current image forgery detection and localization (IFDL) methods are generally effective, they tend to face two challenges: \\textbf{1)} black-box nature with unknown detection principle, \\textbf{2)} limited generalization across diverse tampering methods (e.g., Photoshop, DeepFake, AIGC-Editing). To address these issues, we propose the explainable IFDL task and design FakeShield, a multi-modal framework capable of evaluating image authenticity, generating tampered region masks, and providing a judgment basis based on pixel-level and image-level tampering clues. Additionally, we leverage GPT-4o to enhance existing IFDL datasets, creating the Multi-Modal Tamper Description dataSet (MMTD-Set) for training FakeShield's tampering analysis capabilities. Meanwhile, we incorporate a Domain Tag-guided Explainable Forgery Detection Module (DTE-FDM) and a Multi-modal Forgery Localization Module (MFLM) to address various types of tamper detection interpretation and achieve forgery localization guided by detailed textual descriptions. Extensive experiments demonstrate that FakeShield effectively detects and localizes various tampering techniques, offering an explainable and superior solution compared to previous IFDL methods. The code is available at https://github.com/zhipeixu/FakeShield.", "isOpenAccess": false, "url": ""}
{"paperId": "8103c7a84433a31ee232e848c5ca52d7c31af0e8", "year": 2024, "title": "The Manifesto for Teaching and Learning in a Time of Generative AI: A Critical Collective Stance to Better Navigate the Future", "authors": "Aras Bozkurt, Junhong Xiao, Robert Farrow, J. Bai, C. Nerantzi, Stephanie L. Moore, Jon Dron, Christian M. Stracke, Lenandlar Singh, Helen Crompton, Apostolos Koutropoulos, Evgenii Terentev, Angelica Pazurek, Mark Nichols, Alexander M. Sidorkin, Eamon Costello, Steven Watson, D\u00f3nal Mulligan, Sarah Honeychurch, Charles B. Hodges, Mike Sharples, Andrew Swindell, Isak Frumin, A. Tlili, Patricia J. Slagter van Tryon, Melissa Bond, Maha Bali, Jing Leng, Kai Zhang, Mutlu Cukurova, T. Chiu, Kyungmee Lee, Stefan Hrastinski, Manuel B. Garcia, R. C. Sharma, Bryan Alexander, Olaf Zawacki-Richter, Henk Huijser, P. Jandri\u0107, Chanjin Zheng, Peter Shea, J. Duart, Chryssa Themeli, A. Vorochkov, S. Sani-Bozkurt, R. Moore, T. Asino", "venue": "Open Praxis", "citationCount": 70, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "7c629ca898fb8c87dd363a16d43f29f6ed44dfa8", "year": 2023, "title": "Generative AI Text Classification using Ensemble LLM Approaches", "authors": "Harika Abburi, Michael Suesserman, Nirmala Pudota, B. Veeramani, Edward Bowen, Sanmitra Bhattacharya", "venue": "IberLEF@SEPLN", "citationCount": 70, "abstract": "Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it. For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked in first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.07755"}
{"paperId": "6aa004140bf0f3c4b609a6fe3430f1bd468029c2", "year": 2025, "title": "Generative AI in Higher Education: Balancing Innovation and Integrity", "authors": "Nigel J. Francis, Sue Jones, David P. Smith", "venue": "British Journal of Biomedical Science", "citationCount": 70, "abstract": "Generative Artificial Intelligence (GenAI) is rapidly transforming the landscape of higher education, offering novel opportunities for personalised learning and innovative assessment methods. This paper explores the dual-edged nature of GenAI\u2019s integration into educational practices, focusing on both its potential to enhance student engagement and learning outcomes and the significant challenges it poses to academic integrity and equity. Through a comprehensive review of current literature, we examine the implications of GenAI on assessment practices, highlighting the need for robust ethical frameworks to guide its use. Our analysis is framed within pedagogical theories, including social constructivism and competency-based learning, highlighting the importance of balancing human expertise and AI capabilities. We also address broader ethical concerns associated with GenAI, such as the risks of bias, the digital divide, and the environmental impact of AI technologies. This paper argues that while GenAI can provide substantial benefits in terms of automation and efficiency, its integration must be managed with care to avoid undermining the authenticity of student work and exacerbating existing inequalities. Finally, we propose a set of recommendations for educational institutions, including developing GenAI literacy programmes, revising assessment designs to incorporate critical thinking and creativity, and establishing transparent policies that ensure fairness and accountability in GenAI use. By fostering a responsible approach to GenAI, higher education can harness its potential while safeguarding the core values of academic integrity and inclusive education.", "isOpenAccess": true, "url": "https://doi.org/10.3389/bjbs.2024.14048"}
{"paperId": "5ac5cf1e0c2186c43c067ca04a24d80d6194a56a", "year": 2023, "title": "VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models", "authors": "Sheng-Yen Chou, Pin-Yu Chen, Tsung-Yi Ho", "venue": "Neural Information Processing Systems", "citationCount": 70, "abstract": "Diffusion Models (DMs) are state-of-the-art generative models that learn a reversible corruption process from iterative noise addition and denoising. They are the backbone of many generative AI applications, such as text-to-image conditional generation. However, recent studies have shown that basic unconditional DMs (e.g., DDPM and DDIM) are vulnerable to backdoor injection, a type of output manipulation attack triggered by a maliciously embedded pattern at model input. This paper presents a unified backdoor attack framework (VillanDiffusion) to expand the current scope of backdoor analysis for DMs. Our framework covers mainstream unconditional and conditional DMs (denoising-based and score-based) and various training-free samplers for holistic evaluations. Experiments show that our unified framework facilitates the backdoor analysis of different DM configurations and provides new insights into caption-based backdoor attacks on DMs.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.06874"}
{"paperId": "38a063945846606059a5d9db518f559e4b6e799e", "year": 2024, "title": "Estimating the environmental impact of Generative-AI services using an LCA-based methodology", "authors": "Adrien Berthelot, Eddy Caron, Mathilde Jay, Laurent Lef\u00e8vre", "venue": "Procedia CIRP", "citationCount": 70, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.procir.2024.01.098"}
{"paperId": "0223d77aa79957097b09fb8d83fc44a61b00d076", "year": 2023, "title": "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks", "authors": "Mehrdad Saberi, Vinu Sankar Sadasivan, Keivan Rezaei, Aounon Kumar, Atoosa Malemir Chegini, Wenxiao Wang, S. Feizi", "venue": "International Conference on Learning Representations", "citationCount": 70, "abstract": "In light of recent advancements in generative AI models, it has become essential to distinguish genuine content from AI-generated one to prevent the malicious usage of fake materials as authentic ones and vice versa. Various techniques have been introduced for identifying AI-generated images, with watermarking emerging as a promising approach. In this paper, we analyze the robustness of various AI-image detectors including watermarking and classifier-based deepfake detectors. For watermarking methods that introduce subtle image perturbations (i.e., low perturbation budget methods), we reveal a fundamental trade-off between the evasion error rate (i.e., the fraction of watermarked images detected as non-watermarked ones) and the spoofing error rate (i.e., the fraction of non-watermarked images detected as watermarked ones) upon an application of diffusion purification attack. To validate our theoretical findings, we also provide empirical evidence demonstrating that diffusion purification effectively removes low perturbation budget watermarks by applying minimal changes to images. The diffusion purification attack is ineffective for high perturbation watermarking methods where notable changes are applied to images. In this case, we develop a model substitution adversarial attack that can successfully remove watermarks. Moreover, we show that watermarking methods are vulnerable to spoofing attacks where the attacker aims to have real images identified as watermarked ones, damaging the reputation of the developers. In particular, with black-box access to the watermarking method, a watermarked noise image can be generated and added to real images, causing them to be incorrectly classified as watermarked. Finally, we extend our theory to characterize a fundamental trade-off between the robustness and reliability of classifier-based deep fake detectors and demonstrate it through experiments.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.00076"}
{"paperId": "f71528fa10fc5a474227f1aeb2f836e673ced826", "year": 2023, "title": "Fostering AI Literacy in Elementary Science, Technology, Engineering, Art, and Mathematics (STEAM) Education in the Age of Generative AI", "authors": "S. Relmasira, Yiu Chi Lai, J. Donaldson", "venue": "Sustainability", "citationCount": 69, "abstract": "The advancement of generative AI technologies underscores the need for AI literacy, particularly in Southeast Asia\u2019s elementary Science, Technology, Engineering, Art, and Mathematics (STEAM) education. This study explores the development of AI literacy principles for elementary students. Utilizing existing AI literacy models, a three-session classroom intervention was implemented in an Indonesian school, grounded in constructivist, constructionist, and transformative learning theories. Through design-based research (DBR) and network analysis of reflection papers (n = 77), the intervention was evaluated and redesigned. Findings revealed clusters of interdependent elements of learner experiences, categorized into successes, struggles, and alignments with learning theories. These were translated into design moves for future intervention iterations, forming design principles for AI literacy development. The study contributes insights into optimizing the positive effects and minimizing the negative impacts of AI in education.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/15/18/13595/pdf?version=1694495556"}
{"paperId": "c7a687b73880ca2c34600ca5385be53628cfcb7b", "year": 2024, "title": "Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach", "authors": "Irina Jurenka, M. Kunesch, Kevin McKee, Daniel Gillick, Shaojian Zhu, Sara Wiltberger, Shubham Milind Phal, Katherine Hermann, Daniel Kasenberg, Avishkar Bhoopchand, Ankit Anand, M\u00eeruna Pislar, Stephanie Chan, Lisa Wang, Jennifer She, Parsa Mahmoudieh, Aliya Rysbek, Wei-Jen Ko, Andrea Huber, Brett Wiltshire, G. Elidan, Roni Rabin, Jasmin Rubinovitz, Amit Pitaru, Mac McAllister, Julia Wilkowski, David Choi, R. Engelberg, Lidan Hackmon, Adva Levin, Rachel Griffin, Michael Sears, Filip Bar, Mia Mesar, Mana Jabbour, Arslan Chaudhry, James Cohan, Sridhar Thiagarajan, Nir Levine, Ben Brown, Dilan Gorur, Svetlana Grant, Rachel Hashimoshoni, Laura Weidinger, Jieru Hu, Dawn Chen, Kuba Dolecki, Canfer Akbulut, Maxwell Bileschi, Laura Culp, Wen-Xin Dong, Nahema Marchal, Kelsi Van Deman, Hema Bajaj Misra, Michael Duah, Moran Ambar, Avi Caciularu, Sandra Lefdal, Christopher Summerfield, James An, P. Kamienny, Abhinit Mohdi, Theofilos Strinopoulous, Annie Hale, Wayne Anderson, Luis C. Cobo, Niv Efron, Muktha Ananda, Shakir Mohamed, Maureen Heymans, Z. Ghahramani, Yossi Matias, Ben Gomes, Lila Ibrahim", "venue": "arXiv.org", "citationCount": 69, "abstract": "A major challenge facing the world is the provision of equitable and universal access to quality education. Recent advances in generative AI (gen AI) have created excitement about the potential of new technologies to offer a personal tutor for every learner and a teaching assistant for every teacher. The full extent of this dream, however, has not yet materialised. We argue that this is primarily due to the difficulties with verbalising pedagogical intuitions into gen AI prompts and the lack of good evaluation practices, reinforced by the challenges in defining excellent pedagogy. Here we present our work collaborating with learners and educators to translate high level principles from learning science into a pragmatic set of seven diverse educational benchmarks, spanning quantitative, qualitative, automatic and human evaluations; and to develop a new set of fine-tuning datasets to improve the pedagogical capabilities of Gemini, introducing LearnLM-Tutor. Our evaluations show that LearnLM-Tutor is consistently preferred over a prompt tuned Gemini by educators and learners on a number of pedagogical dimensions. We hope that this work can serve as a first step towards developing a comprehensive educational evaluation framework, and that this can enable rapid progress within the AI and EdTech communities towards maximising the positive impact of gen AI in education.", "isOpenAccess": false, "url": ""}
{"paperId": "bae8d4f94809aa5a88f4ce07e63c269af2d39d21", "year": 2023, "title": "The Utility of Language Models in Cardiology: A Narrative Review of the Benefits and Concerns of ChatGPT-4", "authors": "Dhir Gala, A. Makaryus", "venue": "International Journal of Environmental Research and Public Health", "citationCount": 69, "abstract": "Artificial intelligence (AI) and language models such as ChatGPT-4 (Generative Pretrained Transformer) have made tremendous advances recently and are rapidly transforming the landscape of medicine. Cardiology is among many of the specialties that utilize AI with the intention of improving patient care. Generative AI, with the use of its advanced machine learning algorithms, has the potential to diagnose heart disease and recommend management options suitable for the patient. This may lead to improved patient outcomes not only by recommending the best treatment plan but also by increasing physician efficiency. Language models could assist physicians with administrative tasks, allowing them to spend more time on patient care. However, there are several concerns with the use of AI and language models in the field of medicine. These technologies may not be the most up-to-date with the latest research and could provide outdated information, which may lead to an adverse event. Secondly, AI tools can be expensive, leading to increased healthcare costs and reduced accessibility to the general population. There is also concern about the loss of the human touch and empathy as AI becomes more mainstream. Healthcare professionals would need to be adequately trained to utilize these tools. While AI and language models have many beneficial traits, all healthcare providers need to be involved and aware of generative AI so as to assure its optimal use and mitigate any potential risks and challenges associated with its implementation. In this review, we discuss the various uses of language models in the field of cardiology.", "isOpenAccess": true, "url": "https://www.mdpi.com/1660-4601/20/15/6438/pdf?version=1690262628"}
{"paperId": "b6b248d2ea09f437d6a536ca5b2bf311a2037474", "year": 2023, "title": "Best Practices for Using AI Tools as an Author, Peer Reviewer, or Editor", "authors": "Tiffany I Leung, Taiane de Azevedo Cardoso, A. Mavragani, G. Eysenbach", "venue": "Journal of Medical Internet Research", "citationCount": 69, "abstract": "The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution. In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications\u2019 editorial policies on these issues. We further detail JMIR Publications\u2019 approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.", "isOpenAccess": true, "url": "https://www.jmir.org/2023/1/e51584/PDF"}
{"paperId": "ad1dd2c84161c28e2f69e229ced0da96742a2f89", "year": 2024, "title": "Enhancing academic performance of business students using generative AI: An interactive-constructive-active-passive (ICAP) self-determination perspective", "authors": "Ziyin Gao, J. Cheah, X. Lim, Xi Luo", "venue": "The International Journal of Management Education", "citationCount": 69, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "62cc362617f1f747b25d7e8ca04c65255e675d8e", "year": 2024, "title": "Building entrepreneurial resilience during crisis using generative AI: An empirical study on SMEs", "authors": "Adam P. Shore, Manisha Tiwari, Priyanka Tandon, Cyril R. H. Foropon", "venue": "Technovation", "citationCount": 69, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.technovation.2024.103063"}
{"paperId": "5ec2d86dd3a4d51f8a442d6b26eeab2e1b46f9e1", "year": 2023, "title": "AI Empire: Unraveling the interlocking systems of oppression in generative AI's global order", "authors": "Jasmina Tacheva, Srividya Ramasubramanian", "venue": "Big Data & Society", "citationCount": 69, "abstract": "As artificial intelligence (AI) continues to captivate the collective imagination through the latest generation of generative AI models such as DALL-E and ChatGPT, the dehumanizing and harmful features of the technology industry that have plagued it since its inception only seem to deepen and intensify. Far from a \u201cglitch\u201d or unintentional error, these endemic issues are a function of the interlocking systems of oppression upon which AI is built. Using the analytical framework of \u201cEmpire,\u201d this paper demonstrates that we live not simply in the \u201cage of AI\u201d but in the age of AI Empire. Specifically, we show that this networked and distributed global order is rooted in heteropatriarchy, racial capitalism, white supremacy, and coloniality and perpetuates its influence through the mechanisms of extractivism, automation, essentialism, surveillance, and containment. Therefore, we argue that any attempt at reforming AI from within the same interlocking oppressive systems that created it is doomed to failure and, moreover, risks exacerbating existing harm. Instead, to advance justice, we must radically transform not just the technology itself, but our ideas about it, and develop it from the bottom up, from the perspectives of those who stand the most risk of being harmed.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/20539517231219241"}
{"paperId": "45073ad97f5c0e78b4f7cd80bbe2fd2be02c4c5a", "year": 2023, "title": "The rise of generative artificial intelligence (AI) language models - challenges and opportunities for geographical and environmental education", "authors": "C. Chang, G. Kidman", "venue": "International Research in Geographical and Environmental Education", "citationCount": 69, "abstract": "Much discussion has been surrounding generative AI language models, such as ChatGPT, and the advantages and threats they present to education. As an AI language model, ChatGPT has the potential to transform geography and environmental education. The extensive knowledge base and natural language processing abilities that ChatGPT possesses make it a perfect tool for this purpose; it can actively include students in conversation (as the chat in its name implies) while also providing them with quick feedback. Because of this, students are free to progress through the material at their own pace, using strategies that best suit them individually. Yet, this change has been criticised by others who worry about intellectual property violations and undermining academic integrity. As discussions continue about whether generative AI models are a boon or bane for education, we would like to focus on the problems and potential facing geography and environmental education in particular. We did a simple experiment and asked ChatGPT to: \"Write a short paragraph to explain how geographical education can support a child\u2019s development cognitively and affectively, in responding to the environmental challenges of our times.\" This was the result.", "isOpenAccess": false, "url": ""}
{"paperId": "37d7fd90943b76657ff88d030a9d28677914160f", "year": 2023, "title": "Investigating ChatGPT\u2019s Potential to Assist in Requirements Elicitation Processes", "authors": "Krishna Ronanki, Christian Berger, Jennifer Horkoff", "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications", "citationCount": 69, "abstract": "Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE) seeks to apply NLP tools, techniques, and resources to the RE process to increase the quality of the requirements. There is little research involving the utilization of Generative AI-based NLP tools and techniques for requirements elicitation. In recent times, Large Language Models (LLM) like ChatGPT have gained significant recognition due to their notably improved performance in NLP tasks. To explore the potential of ChatGPT to assist in requirements elicitation processes, we formulated six questions to elicit requirements using ChatGPT. Using the same six questions, we conducted interview-based surveys with five RE experts from academia and industry and collected 30 responses containing requirements. The quality of these 36 responses (human-formulated + ChatGPT-generated) was evaluated over seven different requirements quality attributes by another five RE experts through a second round of interview-based surveys. In comparing the quality of requirements generated by ChatGPT with those formulated by human experts, we found that ChatGPT-generated requirements are highly Abstract, Atomic, Consistent, Correct, and Understandable. Based on these results, we present the most pressing issues related to LLMs and what future research should focus on to leverage the emergent behaviour of LLMs more effectively in natural language-based RE activities.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.07381"}
{"paperId": "33b6b7fd5ec0d46ff133df59f72dc245fb582c26", "year": 2024, "title": "Leveraging generative AI for urban digital twins: a scoping review on the autonomous generation of urban data, scenarios, designs, and 3D city models for smart city advancement", "authors": "Haowen Xu, Femi Omitaomu, S. Sabri, S. Zlatanova, Xiao Li, Yongze Song", "venue": "Urban Informatics", "citationCount": 69, "abstract": "The digital transformation of modern cities by integrating advanced information, communication, and computing technologies has marked the epoch of data-driven smart city applications for efficient and sustainable urban management. Despite their effectiveness, these applications often rely on massive amounts of high-dimensional and multi-domain data for monitoring and characterizing different urban sub-systems, presenting challenges in application areas that are limited by data quality and availability, as well as costly efforts for generating urban scenarios and design alternatives. As an emerging research area in deep learning, Generative Artificial Intelligence (GenAI) models have demonstrated their unique values in content generation. This paper aims to explore the innovative integration of GenAI techniques and urban digital twins to address challenges in the planning and management of built environments with focuses on various urban sub-systems, such as transportation, energy, water, and building and infrastructure. The survey starts with the introduction of cutting-edge generative AI models, such as the Generative Adversarial Networks (GAN), Variational Autoencoders (VAEs), Generative Pre-trained Transformer (GPT), followed by a scoping review of the existing urban science applications that leverage the intelligent and autonomous capability of these techniques to facilitate the research, operations, and management of critical urban subsystems, as well as the holistic planning and design of the built environment. Based on the review, we discuss potential opportunities and technical strategies that integrate GenAI models into the next-generation urban digital twins for more intelligent, scalable, and automated smart city development and management.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s44212-024-00060-w"}
{"paperId": "0e08db83161990175aab97155bc3ac4d40d62664", "year": 2024, "title": "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences", "authors": "John Stamper, Ruiwei Xiao, Xinynig Hou", "venue": "AIED Companion", "citationCount": 69, "abstract": "The field of Artificial Intelligence in Education (AIED) focuses on the intersection of technology, education, and psychology, placing a strong emphasis on supporting learners' needs with compassion and understanding. The growing prominence of Large Language Models (LLMs) has led to the development of scalable solutions within educational settings, including generating different types of feedback in Intelligent Tutoring Systems. However, the approach to utilizing these models often involves directly formulating prompts to solicit specific information, lacking a solid theoretical foundation for prompt construction and empirical assessments of their impact on learning. This work advocates careful and caring AIED research by going through previous research on feedback generation in ITS, with emphasis on the theoretical frameworks they utilized and the efficacy of the corresponding design in empirical evaluations, and then suggesting opportunities to apply these evidence-based principles to the design, experiment, and evaluation phases of LLM-based feedback generation. The main contributions of this paper include: an avocation of applying more cautious, theoretically grounded methods in feedback generation in the era of generative AI; and practical suggestions on theory and evidence-based feedback design for LLM-powered ITS.", "isOpenAccess": false, "url": ""}
{"paperId": "0dace244851e9df0fd47e57529c3da32b4410aa1", "year": 2024, "title": "Endora: Video Generation Models as Endoscopy Simulators", "authors": "Chenxin Li, Hengyu Liu, Yifan Liu, Brandon Y. Feng, Wuyang Li, Xinyu Liu, Zhen Chen, Jing Shao, Yixuan Yuan", "venue": "arXiv.org", "citationCount": 69, "abstract": "Generative models hold promise for revolutionizing medical education, robot-assisted surgery, and data augmentation for machine learning. Despite progress in generating 2D medical images, the complex domain of clinical video generation has largely remained untapped.This paper introduces \\model, an innovative approach to generate medical videos that simulate clinical endoscopy scenes. We present a novel generative model design that integrates a meticulously crafted spatial-temporal video transformer with advanced 2D vision foundation model priors, explicitly modeling spatial-temporal dynamics during video generation. We also pioneer the first public benchmark for endoscopy simulation with video generation models, adapting existing state-of-the-art methods for this endeavor.Endora demonstrates exceptional visual quality in generating endoscopy videos, surpassing state-of-the-art methods in extensive testing. Moreover, we explore how this endoscopy simulator can empower downstream video analysis tasks and even generate 3D medical scenes with multi-view consistency. In a nutshell, Endora marks a notable breakthrough in the deployment of generative AI for clinical endoscopy research, setting a substantial stage for further advances in medical content generation. For more details, please visit our project page: https://endora-medvidgen.github.io/.", "isOpenAccess": false, "url": ""}
{"paperId": "fc6270c8cf781e799b9eaa1e41cb5185e0bef524", "year": 2024, "title": "Generative AI: is it a paradigm shift for higher education?", "authors": "X. O\u2019Dea", "venue": "Studies in Higher Education", "citationCount": 68, "abstract": "ABSTRACT In this special issue, we explore the opportunities and challenges of using Generative AI (GenAI), in particular, text generators in higher education learning and teaching. As GenAI has become increasingly popular with many staff and students, this special issue provides an overview of the current state of the field and offers insights into future research. This introduction paper consists of four parts. It begins by providing an overview of AI and Generative AI, identifying the gap and framing the special issue relating to the gaps. The second part explores the opportunities and challenges of GenAI in higher education, as identified in the literature. The third part provides an overview of the papers included in the special issue. The final part is the self-reflection of the lead author. The special issue aims to serve as a valuable resource for higher education stakeholders, such as students, practitioners, researchers and managers. We hope this collection will help advance knowledge and future research, encourage innovation and inform evidence-based policy and practices in the field of Generative AI in higher education.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/03075079.2024.2332944?needAccess=true"}
{"paperId": "f581374e825b0960fcdcbb8801a5df968d4ccfea", "year": 2023, "title": "Towards Understanding the Interplay of Generative Artificial Intelligence and the Internet", "authors": "Gonzalo Mart\u00ednez, Lauren Watson, P. Reviriego, Jos\u00e9 Alberto Hern\u00e1ndez, Marc Ju\u00e1rez, Rik Sarkar", "venue": "Epi UAI", "citationCount": 68, "abstract": "The rapid adoption of generative Artificial Intelligence (AI) tools that can generate realistic images or text, such as DALL-E, MidJourney, or ChatGPT, have put the societal impacts of these technologies at the center of public debate. These tools are possible due to the massive amount of data (text and images) that is publicly available through the Internet. At the same time, these generative AI tools become content creators that are already contributing to the data that is available to train future models. Therefore, future versions of generative AI tools will be trained with a mix of human-created and AI-generated content, causing a potential feedback loop between generative AI and public data repositories. This interaction raises many questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve and improve with the new data sets or on the contrary will they degrade? Will evolution introduce biases or reduce diversity in subsequent generations of generative AI tools? What are the societal implications of the possible degradation of these models? Can we mitigate the effects of this feedback loop? In this document, we explore the effect of this interaction and report some initial results using simple diffusion models trained with various image datasets. Our results show that the quality and diversity of the generated images can degrade over time suggesting that incorporating AI-created data can have undesired effects on future versions of generative models.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.06130"}
{"paperId": "b2aef0e3f57eca56f1433c9bddbfd864df096ff6", "year": 2024, "title": "Towards Generalizable Tumor Synthesis", "authors": "Qi Chen, Xiaoxi Chen, Haorui Song, Zhiwei Xiong, Alan L. Yuille, Chen Wei, Zongwei Zhou", "venue": "Computer Vision and Pattern Recognition", "citationCount": 68, "abstract": "Tumor synthesis enables the creation of artificial tumors in medical images, facilitating the training of AI models for tumor detection and segmentation. However, success in tumor synthesis hinges on creating visually realistic tumors that are generalizable across multiple organs and, furthermore, the resulting AI models being capable of detecting real tumors in images sourced from different domains (e.g., hospitals). This paper made a progressive stride toward generalizable tumor synthesis by leveraging a critical observation: early-stage tumors (< 2cm) tend to have similar imaging characteristics in computed tomography (CT), whether they originate in the liver, pancreas, or kidneys. We have ascertained that generative AI models, e.g., Diffusion Models, can create realistic tumors generalized to a range of organs even when trained on a limited number of tumor examples from only one organ. Moreover, we have shown that AI models trained on these synthetic tumors can be generalized to detect and segment real tumors from CT volumes, encompassing a broad spectrum of patient demographics, imaging protocols, and healthcare facilities.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2402.19470"}
{"paperId": "aeddde96937507fb04104017ff5cdf3e29f90fa1", "year": 2023, "title": "Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown", "authors": "Felix M. Simon, Sacha Altay, Hugo Mercier", "venue": "Harvard Kennedy School Misinformation Review", "citationCount": 68, "abstract": "Many observers of the current explosion of generative AI worry about its impact on our information environment, with concerns being raised about the increased quantity, quality, and personalization of misinformation. We assess these arguments with evidence from communication studies, cognitive science, and political science. We argue that current concerns about the effects of generative AI on the misinformation landscape are overblown.", "isOpenAccess": true, "url": "https://misinforeview.hks.harvard.edu/wp-content/uploads/2023/10/simon_generative_AI_fears_20231018.pdf"}
{"paperId": "9f14a491f9c50f1979234de702abe7d59ba92cb5", "year": 2023, "title": "Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation", "authors": "Tung Phung, Victor-Alexandru P\u0103durean, Anjali Singh, Christopher Brooks, J. Cambronero, Sumit Gulwani, A. Singla, Gustavo Soares", "venue": "International Conference on Learning Analytics and Knowledge", "citationCount": 68, "abstract": "Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a \u201ctutor\u201d model to generate hints \u2013 it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a \u201cstudent\u201d model to further validate the hint quality \u2013 it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3636555.3636846"}
{"paperId": "51ee6e799c1faae57b1736941d9d289fcce72b61", "year": 2024, "title": "Benchmarking the Robustness of Image Watermarks", "authors": "Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, Sicheng Zhu, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang", "venue": "International Conference on Machine Learning", "citationCount": 68, "abstract": "In the burgeoning age of generative AI, watermarks act as identifiers of provenance and artificial content. We present WAVES (Watermark Analysis Via Enhanced Stress-testing), a benchmark for assessing image watermark robustness, overcoming the limitations of current evaluation methods. WAVES integrates detection and identification tasks and establishes a standardized evaluation protocol comprised of a diverse range of stress tests. The attacks in WAVES range from traditional image distortions to advanced, novel variations of diffusive, and adversarial attacks. Our evaluation examines two pivotal dimensions: the degree of image quality degradation and the efficacy of watermark detection after attacks. Our novel, comprehensive evaluation reveals previously undetected vulnerabilities of several modern watermarking algorithms. We envision WAVES as a toolkit for the future development of robust watermarks. The project is available at https://wavesbench.github.io/", "isOpenAccess": false, "url": ""}
{"paperId": "285ef3ae610db8eae5cfe25bce9222e11e92903e", "year": 2023, "title": "Co-constructing knowledge with generative AI tools: Reflections from a CSCL perspective", "authors": "U. Cress, J. Kimmerle", "venue": "International Journal of Computer-Supported Collaborative Learning", "citationCount": 68, "abstract": "Generative Artificial Intelligence (AI) tools, such as ChatGPT, have received great attention from researchers, the media, and the public. They are gladly and frequently used for text production by many people. These tools have undeniable strengths but also weaknesses that must be addressed. In this squib we ask to what extent these tools can be employed by users for individual learning as well as for knowledge construction to spark a collective endeavor of developing new insights. We take a social, collective notion of knowledge as a basis and argue that users need to establish a dialog that goes beyond knowledge telling (simply writing what one knows) and stimulates knowledge transformation (converting knowledge into complex relational argumentation structures). Generative AI tools do not have any conceptual knowledge or conscious understanding, as they only use word transitions and rely on probabilities of word classes. We suggest, however, that argumentative dialogs among humans and AI tools can be achieved with appropriate prompts, where emergent processes of joint knowledge construction can take place. Based on this assumption, we inquire into the human and into the AI parts of communication and text production. For our line of argument, we borrow from research on individual and collaborative writing, group cognition, and the co-evolution of cognitive and social systems. We outline future CSCL research paths that might take the human-AI co-construction of knowledge into account in terms of terminology, theory, and methodology.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11412-023-09409-w.pdf"}
{"paperId": "0904f2c00036193871ef6d8fc088fa9c780f6a7d", "year": 2023, "title": "Generative AI meets Responsible AI: Practical Challenges and Opportunities", "authors": "K. Kenthapadi, Himabindu Lakkaraju, Nazneen Rajani", "venue": "Knowledge Discovery and Data Mining", "citationCount": 68, "abstract": "Generative AI models and applications are being rapidly developed and deployed across a wide spectrum of industries and applications ranging from writing and email assistants to graphic design and art generation to educational assistants to coding to drug discovery. However, there are several ethical and social considerations associated with generative AI models and applications. These concerns include lack of interpretability, bias and discrimination, privacy, lack of model robustness, fake and misleading content, copyright implications, plagiarism, and environmental impact associated with training and inference of generative AI models. In this tutorial, we first motivate the need for adopting responsible AI principles when developing and deploying large language models (LLMs) and other generative AI models, as part of a broader AI model governance and responsible AI framework, from societal, legal, user, and model developer perspectives, and provide a roadmap for thinking about responsible AI for generative AI in practice. We provide a brief technical overview of text and image generation models, and highlight the key responsible AI desiderata associated with these models. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We focus on real-world generative AI use cases spanning domains such as media generation, writing assistants, copywriting, code generation, and conversational assistants, present practical solution approaches / guidelines for applying responsible AI techniques effectively, discuss lessons learned from deploying responsible AI approaches for generative AI applications in practice, and highlight the key open research problems. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on responsible AI in the context of generative AI, and pave the way for building more reliable and trustworthy generative AI applications in the future.", "isOpenAccess": false, "url": ""}
{"paperId": "eba2b64a739abb64af322e18bcfd25433cc12fab", "year": 2024, "title": "Generative AI in higher education and beyond", "authors": "Nada Hashmi, Anjali S. Bal", "venue": "Business Horizons", "citationCount": 67, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "bfb390db278c69721e448df5e8539880cc7e9809", "year": 2023, "title": "Generative AI for Physical Layer Communications: A Survey", "authors": "Nguyen Van Huynh, Jiacheng Wang, Hongyang Du, D. Hoang, Dusist Niyato, Diep N. Nguyen, Dong In Kim, K. B. Letaief", "venue": "IEEE Transactions on Cognitive Communications and Networking", "citationCount": 67, "abstract": "The recent evolution of generative artificial intelligence (GAI) leads to the emergence of groundbreaking applications such as ChatGPT, which not only enhances the efficiency of digital content production, such as text, audio, video, or even network traffic data, but also enriches its diversity. Beyond digital content creation, GAI\u2019s capability in analyzing complex data distributions offers great potential for wireless communications, particularly amidst a rapid expansion of new physical layer communication technologies. For example, the diffusion model can learn input signal distributions and use them to improve the channel estimation accuracy, while the variational autoencoder can model channel distribution and infer latent variables for blind channel equalization. Therefore, this paper presents a comprehensive investigation of GAI\u2019s applications for communications at the physical layer, ranging from traditional issues, including signal classification, channel estimation, and equalization, to emerging topics, such as intelligent reflecting surfaces and joint source channel coding. We also compare GAI-enabled physical layer communications with those supported by traditional AI, highlighting GAI\u2019s inherent capabilities and unique contributions in these areas. Finally, the paper discusses open issues and proposes several future research directions, laying a foundation for further exploration and advancement of GAI in physical layer communications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2312.05594"}
{"paperId": "29075782bc7583449d1d7629749e9642487bc943", "year": 2023, "title": "ChatGPT and the future of legal education and practice", "authors": "Marjan Ajevski, Kim Barker, Andrew Gilbert, Liz Hardie, Francine Ryan", "venue": "The Law Teacher", "citationCount": 67, "abstract": "ABSTRACT The launch of ChatGPT, a natural language open-source AI platform, in November 2022 has taken the world by storm and artificial intelligence appears to be at a watershed moment in technological advancement. This article explores the emergence of ChatGPT and considers the implications for legal education and practice. It will examine how law schools can develop strategies for assessments to make them more challenging for generative AI while educating students on its potential in the workplace. All legal educators are now on a journey to navigate the complexities of open-source AI technology and comprehend its implications. We should not ignore or underestimate the potential impact on both legal education and legal practice, and we must consider new methods to incorporate AI technology into our teaching.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/03069400.2023.2207426?needAccess=true&role=button"}
{"paperId": "1e930677640d1ae31c63c689a95d3ea6187fbb02", "year": 2024, "title": "\u201cThey only care to show us the wheelchair\u201d: disability representation in text-to-image AI models", "authors": "Kelly Avery Mack, Rida Qadri, Remi Denton, Shaun K. Kane, Cynthia L. Bennett", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 67, "abstract": "This paper reports on disability representation in images output from text-to-image (T2I) generative AI systems. Through eight focus groups with 25 people with disabilities, we found that models repeatedly presented reductive archetypes for different disabilities. Often these representations reflected broader societal stereotypes and biases, which our participants were concerned to see reproduced through T2I. Our participants discussed further challenges with using these models including the current reliance on prompt engineering to reach satisfactorily diverse results. Finally, they offered suggestions for how to improve disability representation with solutions like showing multiple, heterogeneous images for a single prompt and including the prompt with images generated. Our discussion reflects on tensions and tradeoffs we found among the diverse perspectives shared to inform future research on representation-oriented generative AI system evaluation metrics and development processes.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642166"}
{"paperId": "f95927988eafe10d10759188bc82cd5e3e63aba5", "year": 2024, "title": "Edge Intelligence for Internet of Vehicles: A Survey", "authors": "Guozhi Yan, Kai Liu, Chunhui Liu, Jie Zhang", "venue": "IEEE transactions on consumer electronics", "citationCount": 66, "abstract": "The Internet of Vehicles (IoV) has become a fundamental platform for advancing Intelligent Transportation Systems (ITSs) and Intelligent Connected Vehicles (ICVs). However, the increasing volume of data generated by vehicle sensors and the computational demands of Artificial Intelligence (AI) algorithms present significant challenges for the platform. Edge Intelligence (EI), which brings intelligent computing and data processing closer to vehicles, has emerged as a potential solution. In this survey, we provide a comprehensive overview of Edge Intelligence for the Internet of Vehicles. We begin by discussing the motivations behind employing EI in the IoV for typical AI computations. To fully exploit the potential of EI in heterogeneous IoV environments, we present a layered vehicular EI architecture and discuss its benefits and challenges. Furthermore, we provide a taxonomy of EI approaches for vehicular networks, focusing on cooperative inference, distributed training, and collaborative sensing, in terms of their schemas and advanced frameworks. Finally, we explore emerging trends and research directions in this field, including vehicle-road-cloud integration, generative AI-driven IoV, and vehicular cyber-physical fusion. By offering insights into state-of-the-art techniques and trends, this survey aims to enable researchers to develop innovative solutions for transforming the intelligent IoV ecosystem.", "isOpenAccess": false, "url": ""}
{"paperId": "ee8a32a290641a9832c38009bd15fa1f663c40c3", "year": 2024, "title": "Rethinking Plagiarism in the Era of Generative AI", "authors": "James Hutson", "venue": "Journal of Intelligent Communication", "citationCount": 66, "abstract": "The emergence of generative artificial intelligence (AI) technologies, such as large language models (LLMs) like ChatGPT, has precipitated a paradigm shift in the realms of academic writing, plagiarism, and intellectual property. This article explores the evolving landscape of English composition courses, traditionally designed to develop critical thinking through writing. As AI becomes increasingly integrated into the academic sphere, it necessitates a reevaluation of originality in writing, the purpose of learning research and writing, and the frameworks governing intellectual property (IP) and plagiarism. The paper commences with a statistical analysis contrasting the actual use of LLMs in academic dishonesty with educator perceptions. It then examines the repercussions of AI-enabled content proliferation, referencing the limitation of three books self-published per day in September 2023 by Amazon due to a suspected influx of AI-generated material. The discourse extends to the potential of AI in accelerating research akin to the contributions of digital humanities and computational linguistics, highlighting its accessibility to the general public. The article further delves into the implications of AI on pedagogical approaches to research and writing, contemplating its impact on communication and critical thinking skills, while also considering its role in bridging the digital divide and socio-economic disparities. Finally, it proposes revisions to writing curricula, adapting to the transformative influence of AI in academic contexts.\u00a0", "isOpenAccess": true, "url": "https://ojs.ukscip.com/journals/jic/article/download/220/202"}
{"paperId": "aaf49c6cca6b8caf4671b28f2b43583545a35b5a", "year": 2023, "title": "Chatbots, generative AI, and scholarly manuscripts: WAME recommendations on chatbots and generative artificial intelligence in relation to scholarly publications", "authors": "Chris Zielinski, Margaret A Winker, Rakesh Aggarwal, Lorraine E Ferris, Markus Heinemann, J. F. Lape\u00f1a, Sanjay A. Pai, Edsel B. Ing, Leslie Citrome, Murad Alam, Michael Voight, F. Habibzadeh", "venue": "Current Medical Research and Opinion", "citationCount": 66, "abstract": "Introduction \nThis statement revises our earlier \u201cWAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications\u201d (January 20, 2023). The revision reflects the proliferation of chatbots and their expanding use in scholarly publishing over the last few months, as well as emerging concerns regarding lack of authenticity of content when using chatbots. These Recommendations are intended to inform editors and help them develop policies for the use of chatbots in papers published in their journals. They aim to help authors and reviewers understand how best to attribute the use of chatbots in their work, and to address the need for all journal editors to have access to manuscript screening tools. In this rapidly evolving field, we will continue to modify these recommendations as the software and its applications develop. \n\u00a0 \u00a0 \u00a0A chatbot is a tool \u201c[d]riven by [artificial intelligence], automated rules, natural-language processing (NLP), and machine learning (ML)\u2026[to] process data to deliver responses to requests of all kinds.\u201d1 Artificial intelligence (AI) is \u201cthe ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.\u201d2 \n\u00a0 \u00a0 \u00a0\u201cGenerative modeling is an artificial intelligence technique that generates synthetic artifacts by analyzing training examples; learning their patterns and distribution; and then creating realistic facsimiles. Generative AI (GAI) uses generative modeling and advances in deep learning (DL) to produce diverse content at scale by utilizing existing media such as text, graphics, audio, and video.\u201d3, 4 \n\u00a0 \u00a0 \u00a0Chatbots are activated by a plain-language instruction, or \u201cprompt,\u201d provided by the user. They generate responses using statistical and probability-based language models.5 This output has some characteristic properties. It is usually linguistically accurate and fluent but, to date, it is often compromised in various ways. For example, chatbot output currently carries the risk of including biases, distortions, irrelevancies, misrepresentations, and plagiarism many of which are caused by the algorithms governing its generation and heavily dependent on the contents of the materials used in its training. Consequently, there are concerns about the effects of chatbots on knowledge creation and dissemination \u2013 including their potential to spread and amplify mis- and disinformation6 \u2013 and their broader impact on jobs and the economy, as well as the health of individuals and populations. New legal issues have also arisen in connection with chatbots and generative AI.7 \n\u00a0 \u00a0 \u00a0Chatbots retain the information supplied to them, including content and prompts, and may use this information in future responses. Therefore, scholarly content that is generated or edited using AI would be retained and as a result, could potentially appear in future responses, further increasing the risk of inadvertent plagiarism on the part of the user and any future users of the technology. Anyone who needs to maintain confidentiality of a document, including authors, editors, and reviewers, should be aware of this issue before considering using chatbots to edit or generate work.9 \n\u00a0 \u00a0 \u00a0Chatbots and their applications illustrate the powerful possibilities of generative AI, as well as the risks. These Recommendations seek to suggest a workable approach to valid concerns about the use of chatbots in scholarly publishing.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/03007995.2023.2286102?needAccess=true"}
{"paperId": "9ace9636226c9e5e9e7d61f61ee389478dd8e4f2", "year": 2024, "title": "Developing language teachers\u2019 professional generative AI competence: An intervention study in an initial language teacher education course", "authors": "Benjamin Luke Moorhouse, Yuwei Wan, Chenze Wu, Lucas Kohnke, Tsz Ying Ho, Theresa Kwong", "venue": "System (Link\u00f6ping)", "citationCount": 66, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "99b1fd7dd675ee0c4c1ee69eccb9c415d1998fdc", "year": 2024, "title": "Identifying and Improving Disability Bias in GPT-Based Resume Screening", "authors": "Kate Glazko, Yusuf Mohammed, Ben Kosa, Venkatesh Potluri, Jennifer Mankoff", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 66, "abstract": "As Generative AI rises in adoption, its use has expanded to include domains such as hiring and recruiting. However, without examining the potential of bias, this may negatively impact marginalized populations, including people with disabilities. To address this important concern, we present a resume audit study, in which we ask ChatGPT (specifically, GPT-4) to rank a resume against the same resume enhanced with an additional leadership award, scholarship, panel presentation, and membership that are disability-related. We find that GPT-4 exhibits prejudice towards these enhanced CVs. Further, we show that this prejudice can be quantifiably reduced by training a custom GPTs on principles of DEI and disability justice. Our study also includes a unique qualitative analysis of the types of direct and indirect ableism GPT-4 uses to justify its biased decisions and suggest directions for additional bias mitigation work. Additionally, since these justifications are presumably drawn from training data containing real-world biased statements made by humans, our analysis suggests additional avenues for understanding and addressing human bias.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658933"}
{"paperId": "5a666a03efa128d6151be7be6ec0944feaa43cdd", "year": 2023, "title": "Assessing GPT-4 multimodal performance in radiological image analysis", "authors": "Dana Brin, Vera Sorin, Y. Barash, Eli Konen, Benjamin S. Glicksberg, Girish N. Nadkarni, E. Klang", "venue": "European Radiology", "citationCount": 66, "abstract": "This study aims to assess the performance of a multimodal artificial intelligence (AI) model capable of analyzing both images and textual data (GPT-4V), in interpreting radiological images. It focuses on a range of modalities, anatomical regions, and pathologies to explore the potential of zero-shot generative AI in enhancing diagnostic processes in radiology. We analyzed 230 anonymized emergency room diagnostic images, consecutively collected over 1 week, using GPT-4V. Modalities included ultrasound (US), computerized tomography (CT), and X-ray images. The interpretations provided by GPT-4V were then compared with those of senior radiologists. This comparison aimed to evaluate the accuracy of GPT-4V in recognizing the imaging modality, anatomical region, and pathology present in the images. GPT-4V identified the imaging modality correctly in 100% of cases (221/221), the anatomical region in 87.1% (189/217), and the pathology in 35.2% (76/216). However, the model\u2019s performance varied significantly across different modalities, with anatomical region identification accuracy ranging from 60.9% (39/64) in US images to 97% (98/101) and 100% (52/52) in CT and X-ray images (p\u2009<\u20090.001). Similarly, pathology identification ranged from 9.1% (6/66) in US images to 36.4% (36/99) in CT and 66.7% (34/51) in X-ray images (p\u2009<\u20090.001). These variations indicate inconsistencies in GPT-4V\u2019s ability to interpret radiological images accurately. While the integration of AI in radiology, exemplified by multimodal GPT-4, offers promising avenues for diagnostic enhancement, the current capabilities of GPT-4V are not yet reliable for interpreting radiological images. This study underscores the necessity for ongoing development to achieve dependable performance in radiology diagnostics. Although GPT-4V shows promise in radiological image interpretation, its high diagnostic hallucination rate (>\u200940%) indicates it cannot be trusted for clinical use as a standalone tool. Improvements are necessary to enhance its reliability and ensure patient safety. GPT-4V\u2019s capability in analyzing images offers new clinical possibilities in radiology. GPT-4V excels in identifying imaging modalities but demonstrates inconsistent anatomy and pathology detection. Ongoing AI advancements are necessary to enhance diagnostic reliability in radiological applications. GPT-4V\u2019s capability in analyzing images offers new clinical possibilities in radiology. GPT-4V excels in identifying imaging modalities but demonstrates inconsistent anatomy and pathology detection. Ongoing AI advancements are necessary to enhance diagnostic reliability in radiological applications.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s00330-024-11035-5"}
{"paperId": "40122892023311a361635cbe7eb550ff72f28b58", "year": 2024, "title": "Enhancing User Experience With a Generative AI Chatbot", "authors": "Jeong Soo Kim, Minseong Kim, Tae Hyun Baek", "venue": "International journal of human computer interactions", "citationCount": 66, "abstract": "Abstract With the rapid evolution of artificial intelligence (AI), this study aims to examine the interplay among the perceived usability, perceived enjoyment, perceived responsiveness, and intention to continue using ChatGPT. Structural equation modeling (SEM) was used to investigate our proposed model. We recruited 446 ChatGPT users through an online survey conducted on the Connect platform, powered by CloudResearch. Perceived usability (\u03b2\u2009=\u20090.254) and enjoyment (\u03b2\u2009=\u20090.438) significantly influence satisfaction with ChatGPT. However, perceived responsiveness is not significantly related to perceived attachment or satisfaction. Furthermore, we established that perceived attachment (\u03b2\u2009=\u20090.405) and satisfaction (\u03b2\u2009=\u20090.447) are pivotal in shaping users\u2019 intentions to continue using ChatGPT, providing insights into human\u2013AI interactions. The practical implications of our findings suggest that generative AI chatbots should be crafted with a focus on enjoyable, user-centered interfaces that foster long-term user satisfaction and engagement. AI developers should design AI conversation flows and chatbot personas to optimize the user experience.", "isOpenAccess": false, "url": ""}
{"paperId": "2523d9d7d736498ed947f2b1a07f0f32fd2e6053", "year": 2024, "title": "Transforming Teachers\u2019 Roles and Agencies in the Era of Generative AI: Perceptions, Acceptance, Knowledge, and Practices", "authors": "Xiaoming Zhai", "venue": "Journal of Science Education and Technology", "citationCount": 66, "abstract": "This paper explores the transformative impact of generative artificial intelligence (GenAI) on teachers\u2019 roles and agencies in education, presenting a comprehensive framework that addresses teachers\u2019 perceptions, knowledge, acceptance, and practices of GenAI. As GenAI technologies, such as ChatGPT, become increasingly integrated into educational settings, both in-service and future teachers are required to adapt to evolving classroom dynamics, where AI plays a significant role in content creation, personalized learning, and student engagement. However, existing literature often treats these factors in isolation, overlooking how they collectively influence teachers\u2019 ability to effectively integrate GenAI into their pedagogical practices. This paper fills this gap by proposing a framework that categorizes teachers (including both pre- and in-service teachers, hereafter) into four roles\u2014Observer, Adopter, Collaborator, and Innovator\u2014each representing different levels of GenAI engagement, outlining teachers\u2019 agencies in GenAI classrooms. By highlighting the need for quality teacher education programs, continuous professional development and institutional support, we use examples to demonstrate how teachers can evolve from basic GenAI users to co-creators of knowledge alongside GenAI systems. The findings emphasize that for GenAI to reach its full educational potential, teachers must not only accept and understand its capabilities but also integrate it deeply into their teaching practices. This study contributes to the growing literature on GenAI in education, offering practical implications for supporting both in-service and future teachers in navigating the complexities of GenAI adoption.", "isOpenAccess": false, "url": ""}
{"paperId": "f3b113a0f4200e9fde5583d14642b362d9f52326", "year": 2023, "title": "The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts", "authors": "Jaromir Savelka, Kevin D. Ashley", "venue": "Frontiers Artif. Intell.", "citationCount": 65, "abstract": "The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models' (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models' performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20\u00d7 more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts.", "isOpenAccess": true, "url": "https://www.frontiersin.org/articles/10.3389/frai.2023.1279794/pdf?isPublishedV2=False"}
{"paperId": "bf61d4b7f52d9573e5bced3216d6a36374df3661", "year": 2024, "title": "Language-based game theory in the age of artificial intelligence", "authors": "V. Capraro, Roberto Di Paolo, M. Perc, Veronica Pizziol", "venue": "Journal of the Royal Society Interface", "citationCount": 65, "abstract": "Understanding human behaviour in decision problems and strategic interactions has wide-ranging applications in economics, psychology and artificial intelligence. Game theory offers a robust foundation for this understanding, based on the idea that individuals aim to maximize a utility function. However, the exact factors influencing strategy choices remain elusive. While traditional models try to explain human behaviour as a function of the outcomes of available actions, recent experimental research reveals that linguistic content significantly impacts decision-making, thus prompting a paradigm shift from outcome-based to language-based utility functions. This shift is more urgent than ever, given the advancement of generative AI, which has the potential to support humans in making critical decisions through language-based interactions. We propose sentiment analysis as a fundamental tool for this shift and take an initial step by analysing 61 experimental instructions from the dictator game, an economic game capturing the balance between self-interest and the interest of others, which is at the core of many social interactions. Our meta-analysis shows that sentiment analysis can explain human behaviour beyond economic outcomes. We discuss future research directions. We hope this work sets the stage for a novel game-theoretical approach that emphasizes the importance of language in human decisions.", "isOpenAccess": true, "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2023.0720"}
{"paperId": "b9a36a50efc4d0a2402d2ecb405dcda1755900e5", "year": 2024, "title": "Can Artificial Intelligence Improve the Readability of Patient Education Materials on Aortic Stenosis? A Pilot Study", "authors": "Armaun D. Rouhi, Yazid K. Ghanem, Laman Yolchieva, Zena Saleh, Hansa Joshi, M. C. Moccia, A. Suarez-Pierre, Jason J. Han", "venue": "Cardiology and Therapy", "citationCount": 65, "abstract": "The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public. Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt \u201ctranslate to 5th-grade reading level\u201d. Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores. Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th\u201312th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (p\u2009<\u20090.001) to the approximately 6th\u20137th grade reading level. Bard successfully improved readability across all measures (p\u2009<\u20090.001) except for SMOGI (p\u2009=\u20090.729) to the approximately 8th\u20139th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all p\u2009<\u20090.001). AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s40119-023-00347-0.pdf"}
{"paperId": "64d839a6a7c252c0de2d3e72fe95caa2a4150b68", "year": 2024, "title": "University Teachers\u2019 Views on the Adoption and Integration of Generative AI Tools for Student Assessment in Higher Education", "authors": "Zuhair N. Khlaif, Abedalkarim Ayyoub, Bilal Hamamra, Elias Bensalem, M. Mitwally, Ahmad Ayyoub, M. Hattab, Fadi Shadid", "venue": "Education sciences", "citationCount": 65, "abstract": "This study examines the factors that may impact the adoption of generative artificial intelligence (Gen AI) tools for students\u2019 assessment in tertiary education from the perspective of early-adopter instructors in the Middle East. It utilized a self-administered online survey and the Unified Theory of Acceptance and Use of Technology (UTAUT) model to collect data from 358 faculty members from different countries in the Middle East. The Smart PLS software 4 was used to analyze the data. The findings of this study revealed that educators developed new strategies to integrate Gen AI into assessment and used a systematic approach to develop assignments. Moreover, the study demonstrated the importance of developing institutional policies for the integration of Gen AI in education, as a driver factor influencing the use of Gen AI in assessments. Additionally, the research identified significant factors, namely performance expectancy, effort expectancy, social influences, and hedonic motivation, shaping educators\u2019 behavioral intentions and actual use of Gen AI tools to assess students\u2019 performance. The findings reveal both the potential advantages of Gen AI, namely enhanced student engagement and reduced instructor workloads, and challenges, including concerns over academic integrity and the possible negative impact on students\u2019 writing and thinking skills. This study emphasizes the significance of targeted professional development and ethical criteria for the proper integration of Gen AI in educational assessment.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/14/10/1090/pdf?version=1728206750"}
{"paperId": "234159e46e429d0ccd3718110861ec81d9c5dfe1", "year": 2025, "title": "GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving", "authors": "Lloyd Russell, Anthony Hu, Lorenzo Bertoni, George Fedoseev, Jamie Shotton, Elahe Arani, Gianluca Corrado", "venue": "arXiv.org", "citationCount": 65, "abstract": "Generative models offer a scalable and flexible paradigm for simulating complex environments, yet current approaches fall short in addressing the domain-specific requirements of autonomous driving - such as multi-agent interactions, fine-grained control, and multi-camera consistency. We introduce GAIA-2, Generative AI for Autonomy, a latent diffusion world model that unifies these capabilities within a single generative framework. GAIA-2 supports controllable video generation conditioned on a rich set of structured inputs: ego-vehicle dynamics, agent configurations, environmental factors, and road semantics. It generates high-resolution, spatiotemporally consistent multi-camera videos across geographically diverse driving environments (UK, US, Germany). The model integrates both structured conditioning and external latent embeddings (e.g., from a proprietary driving model) to facilitate flexible and semantically grounded scene synthesis. Through this integration, GAIA-2 enables scalable simulation of both common and rare driving scenarios, advancing the use of generative world models as a core tool in the development of autonomous systems. Videos are available at https://wayve.ai/thinking/gaia-2.", "isOpenAccess": false, "url": ""}
{"paperId": "106cdc3f272e61d73a944aae9a4497ef67d0c6e1", "year": 2024, "title": "An Empirical Evaluation of a Generative Artificial Intelligence Technology Adoption Model from Entrepreneurs' Perspectives", "authors": "Varun Gupta", "venue": "Syst.", "citationCount": 65, "abstract": "Technologies, such as Chat Generative Pre-Trained Transformer (ChatGPT, Smart PLS version 4), are prime examples of Generative Artificial Intelligence (AI), which is a constantly evolving area. SMEs, particularly startups, can obtain a competitive edge, innovate their business models, gain business value, and undergo a digital transformation by implementing these technologies. Continuous but gradual experimentation with these technologies is the foundation for their adoption. The experience that comes from trying new technologies can help entrepreneurs adopt new technologies more strategically and experiment more with them. The urgent need for an in-depth investigation is highlighted by the paucity of previous research on ChatGPT uptake in the startup context, particularly from an entrepreneurial perspective. The objective of this research study is to empirically validate the Generative AI technology adoption model to establish the direction and strength of the correlations among the adoption factors from the perspectives of the entrepreneurs. The data are collected from 482 entrepreneurs who exhibit great diversity in their genders, the countries in which their startups are located, the industries their startups serve, their age, their educational levels, their work experience as entrepreneurs, and the length of time the startups have been on the market. Collected data are analyzed using the Partial Least Squares Structural Equation Modeling (PLS-SEM) technique, which results in a statistical examination of the relationships between the adoption model\u2019s factors. The results indicate that social influence, domain experience, technology familiarity, system quality, training and support, interaction convenience, and anthropomorphism are the factors that impact the pre-perception and perception phase of adoption. These factors motivate entrepreneurs to experiment more with the technology, thereby building perceptions of its usefulness, perceived ease of use, and perceived enjoyment, three factors that in turn affect emotions toward the technology and, finally, switching intentions. Control variables like age, gender, and educational attainment have no appreciable effect on switching intentions to alternatives of the Generative AI technology. Rather, the experience factor of running businesses shows itself to be a crucial one. The results have practical implications for entrepreneurs and other innovation ecosystem actors, including, for instance, technology providers, libraries, and policymakers. This research study enriches the Generative AI technology acceptance theory and extends the existing literature by introducing new adoption variables and stages specific to entrepreneurship.", "isOpenAccess": true, "url": "https://www.mdpi.com/2079-8954/12/3/103/pdf?version=1710867327"}
{"paperId": "ec65cc0c0f3186c43ee839e61a4f1ae30acd50e3", "year": 2024, "title": "Generative-AI-Driven Human Digital Twin in IoT Healthcare: A Comprehensive Survey", "authors": "Jiayuan Chen, You Shi, Changyan Yi, Hongyang Du, Jiawen Kang, Dusist Niyato", "venue": "IEEE Internet of Things Journal", "citationCount": 64, "abstract": "The Internet of Things (IoT) can significantly enhance the quality of human life, specifically in healthcare, attracting extensive attentions to IoT healthcare services. Meanwhile, the human digital twin (HDT) is proposed as an innovative paradigm that can comprehensively characterize the replication of the individual human body in the digital world and reflect its physical status in real time. Naturally, HDT is envisioned to empower IoT healthcare beyond the application of healthcare monitoring by acting as a versatile and vivid human digital testbed, simulating the outcomes and guiding the practical treatments. However, successfully establishing HDT requires high-fidelity virtual modeling and strong information interactions but possibly with scarce, biased, and noisy data. Fortunately, a recent popular technology called generative artificial intelligence (GAI) may be a promising solution because it can leverage advanced AI algorithms to automatically create, manipulate, and modify valuable while diverse data. This survey particularly focuses on the implementation of GAI-driven HDT in IoT healthcare. We start by introducing the background of IoT healthcare and the potential of GAI-driven HDT. Then, we delve into the fundamental techniques and present the overall framework of GAI-driven HDT. After that, we explore the realization of GAI-driven HDT in detail, including GAI-enabled data acquisition, communication, data management, digital modeling, and data analysis. Besides, we discuss typical IoT healthcare applications that can be revolutionized by GAI-driven HDT, namely, personalized health monitoring and diagnosis, personalized prescription, and personalized rehabilitation. Finally, we conclude this survey by highlighting some future research directions.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2401.13699"}
{"paperId": "bb6f75a3b81294379ff044d64c58e4dda9d3539f", "year": 2024, "title": "A survey of generative AI for de novo drug design: new frontiers in molecule and protein generation", "authors": "Xiangru Tang, Howard Dai, Elizabeth Knight, Fang Wu, Yunyang Li, Tianxiao Li, Mark Gerstein", "venue": "Briefings Bioinform.", "citationCount": 64, "abstract": "Abstract Artificial intelligence (AI)-driven methods can vastly improve the historically costly drug design process, with various generative models already in widespread use. Generative models for de novo drug design, in particular, focus on the creation of novel biological compounds entirely from scratch, representing a promising future direction. Rapid development in the field, combined with the inherent complexity of the drug design process, creates a difficult landscape for new researchers to enter. In this survey, we organize de novo drug design into two overarching themes: small molecule and protein generation. Within each theme, we identify a variety of subtasks and applications, highlighting important datasets, benchmarks, and model architectures and comparing the performance of top models. We take a broad approach to AI-driven drug design, allowing for both micro-level comparisons of various methods within each subtask and macro-level observations across different fields. We discuss parallel challenges and approaches between the two applications and highlight future directions for AI-driven de novo drug design as a whole. An organized repository of all covered sources is available at https://github.com/gersteinlab/GenAI4Drug.", "isOpenAccess": false, "url": ""}
{"paperId": "a504b4d9cdd39951291a822babedaddc7a5c7c53", "year": 2024, "title": "Smart product platforming powered by AI and Generative AI: Personalization for the circular economy", "authors": "Pervaiz Akhtar, Dr Arsalan Mujhaid Ghouri, Dr Aniqa Ashraf, Dr Jia Jia Lim, Dr Naveed R. Khan, M.A. Shuang", "venue": "International Journal of Production Economics", "citationCount": 64, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.ijpe.2024.109283"}
{"paperId": "9d0cc12f17174b9a0228ec9ea23731d378a22061", "year": 2023, "title": "YOLO-Based Semantic Communication With Generative AI-Aided Resource Allocation for Digital Twins Construction", "authors": "Baoxia Du, Hongyang Du, Haifeng Liu, Dusist Niyato, Peng Xin, Jun Yu, Mingyang Qi, You Tang", "venue": "IEEE Internet of Things Journal", "citationCount": 64, "abstract": "Digital Twins play a crucial role in bridging the physical and virtual worlds. Given the dynamic and evolving characteristics of the physical world, a huge volume of data transmission and exchange is necessary to attain synchronized updates in the virtual world. In this article, we propose a semantic communication framework based on you only look once (YOLO) to construct a virtual apple orchard with the aim of mitigating the costs associated with data transmission. Specifically, we first employ the YOLOv7-X object detector to extract semantic information from captured images of edge devices, thereby reducing the volume of transmitted data and saving transmission costs. Afterwards, we quantify the importance of each semantic information by the confidence generated through the object detector. Based on this, we propose two resource allocation schemes, i.e., the confidence-based scheme and the acrlong AI-generated scheme, aimed at enhancing the transmission quality of important semantic information. The proposed diffusion model generates an optimal allocation scheme that outperforms both the average allocation scheme and the confidence-based allocation scheme. Moreover, to obtain semantic information more effectively, we enhance the detection capability of the YOLOv7-X object detector by introducing new efficient layer aggregation network-horNet (ELAN-H) and SimAM attention modules, while reducing the model parameters and computational complexity, making it easier to run on edge devices with limited performance. The numerical results indicate that our proposed semantic communication framework and resource allocation schemes significantly reduce transmission costs while enhancing the transmission quality of important information in communication services.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2306.14138"}
{"paperId": "79833fab01c356ecb4d9c20ae6757ff3c5103859", "year": 2024, "title": "Theranostics and artificial intelligence: new frontiers in personalized medicine", "authors": "", "venue": "Theranostics", "citationCount": 64, "abstract": "The field of theranostics is rapidly advancing, driven by the goals of enhancing patient care. Recent breakthroughs in artificial intelligence (AI) and its innovative theranostic applications have marked a critical step forward in nuclear medicine, leading to a significant paradigm shift in precision oncology. For instance, AI-assisted tumor characterization, including automated image interpretation, tumor segmentation, feature identification, and prediction of high-risk lesions, improves diagnostic processes, offering a precise and detailed evaluation. With a comprehensive assessment tailored to an individual's unique clinical profile, AI algorithms promise to enhance patient risk classification, thereby benefiting the alignment of patient needs with the most appropriate treatment plans. By uncovering potential factors unseeable to the human eye, such as intrinsic variations in tumor radiosensitivity or molecular profile, AI software has the potential to revolutionize the prediction of response heterogeneity. For accurate and efficient dosimetry calculations, AI technology offers significant advantages by providing customized phantoms and streamlining complex mathematical algorithms, making personalized dosimetry feasible and accessible in busy clinical settings. AI tools have the potential to be leveraged to predict and mitigate treatment-related adverse events, allowing early interventions. Additionally, generative AI can be utilized to find new targets for developing novel radiopharmaceuticals and facilitate drug discovery. However, while there is immense potential and notable interest in the role of AI in theranostics, these technologies do not lack limitations and challenges. There remains still much to be explored and understood. In this study, we investigate the current applications of AI in theranostics and seek to broaden the horizons for future research and innovation.", "isOpenAccess": true, "url": "https://www.thno.org/v14p2367.pdf"}
{"paperId": "6abec4bd11e60496a248c85c48c1e3abde3657e0", "year": 2023, "title": "Generative AI and jobs : a global analysis of potential effects on job quantity and quality", "authors": "Pawe\u0142 Gmyrek, Janine Berg, David Bescond", "venue": "ILO working papers", "citationCount": 64, "abstract": "This study assesses the potential global exposure of occupations to Generative AI, particularly GPT-4. It predicts that the overwhelming effect of the technology will be to augment occupations, rather than to automate them. The greatest impact is likely to be in high and upper-middle income countries due to a higher share of employment in clerical occupations. As clerical jobs are an important source of female employment, the effects are highly gendered. Insights from this study underline the need for proactive policies that focus on job quality, ensure fair transitions, and that are based on dialogue and adequate regulation.", "isOpenAccess": true, "url": "https://www.econstor.eu/bitstream/10419/278614/1/1857683005.pdf"}
{"paperId": "47e9117dc5363a4f29bdd06f74cd03f8560a2a8b", "year": 2024, "title": "How generative AI Is shaping the future of marketing", "authors": "Dhruv Grewal, Cinthia B. Satornino, Thomas Davenport, Abhijit Guha", "venue": "Journal of the Academy of Marketing Science", "citationCount": 64, "abstract": "Generative AI (Gen AI) is shaping the future of marketing. In the next decade, Gen AI will influence how marketers interact and communicate with customers, help create and deliver marketing content (text, images, and video), and inform methods for researching and developing new products and services. In both service and sales settings, Gen AI will affect customers directly and significantly. Therefore, marketers, researchers, and public policy makers require a clear understanding of Gen AI and its potential, as well as its limitations. To assist marketers in thinking through the adoption and implementation of Gen AI, the current article presents a four-quadrant organizing framework that highlights trade-offs in both the nature of Gen AI inputs and the extent of human augmentation needed to deliver Gen AI\u2013generated outputs. This framework provides guidance for the selection and implementation of Gen AI tools, as well as recommendations for further research.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s11747-024-01064-3"}
{"paperId": "238ba8a8284c61dfd129a4c9c0781c6469c7d470", "year": 2025, "title": "Transform", "authors": "Amelia Di Paolo, Glendon Gardner, Kevin Millingham", "venue": "ASCILITE Publications", "citationCount": 64, "abstract": "This paper reports on the Innovation Lab: Transform, a six-month professional development program in the Learning Design and Technology unit at the University of Technology Sydney. Designed during a period of rapid change (generative AI, assessment security), the program created a structured, in-person space for experimentation through Creative Foundations workshops and a team-based Idea Accelerator. Co-created values and distributed facilitation helped establish psychological safety, while feedback showed gains in creative confidence, collaboration, and willingness to test bold ideas.\nThe success of the Transform program has since anchored a broader innovation agenda framed around three streams: Optimise (incremental improvements), Extend (modular innovation), and Transform (capability-building for radical change). This paper demonstrates how a single localised initiative can evolve into a multi-layered strategy, balancing day-to-day enhancement with capacity for systemic innovation. Insights are offered for third space professionals and leaders seeking to embed sustainable innovation in higher education.\n\u00a0\n\u00a0", "isOpenAccess": false, "url": ""}
{"paperId": "1e39f3ca4aff09dccc3b951cdd355c7d8e7cbc2f", "year": 2023, "title": "Generative AI tools in art education: Exploring prompt engineering and iterative processes for enhanced creativity", "authors": "Peter Cotroneo, James Hutson", "venue": "Metaverse", "citationCount": 64, "abstract": "The rapid development and adoption of generative artificial intelligence (AI) tools in the art and design education landscape have introduced both opportunities and challenges. This timely study addresses the need to effectively integrate these tools into the classroom while considering ethical implications and the importance of prompt engineering. By examining the iterative process of refining original ideas through multiple iterations, verbal expansion, and the use of OpenAI\u2019s DALL-E2 for generating diverse visual outcomes, researchers gain insights into the potential benefits and pitfalls of these tools in an educational context. Students in the digital at case study were taught prompt engineering techniques and were tasked with crafting multiple prompts, focusing on refining their ideas over time. Participants demonstrated an increased understanding of the potential and limitations of generative AI tools and how to manipulate subject matter for more effective results. The iterative process encouraged students to explore and experiment with their creative ideas, leading to a deeper understanding of the possibilities offered by AI tools. Despite acknowledging the ethical concerns regarding copyright and the potential replacement of artists, students appreciated the value of generative AI tools for enhancing their sketchbooks and ideation process. Through prompt engineering and iterative processes, students developed a more detail-oriented approach to their work. The challenge of using AI-generated images as final products was conceptually intriguing, requiring further investigation and consideration of the prompts. This study highlights the potential benefits and challenges of integrating generative AI tools into art and design classrooms, emphasizing the importance of prompt engineering, iterative processes, and ethical considerations as these technologies continue to evolve.", "isOpenAccess": true, "url": "https://doi.org/10.54517/m.v4i1.2164"}
{"paperId": "14715d934488c6f2002107f0d2bfda27acf276a1", "year": 2024, "title": "Harnessing Generative AI (GenAI) for Automated Feedback in Higher Education: A Systematic Review", "authors": "Sophia Soomin Lee, Robert L. Moore", "venue": "Online Learning", "citationCount": 64, "abstract": "In this systematic review, we synthesize ten empirical peer-reviewed articles published between 2019 and 2023 that used generative artificial intelligence (GenAI) for automated feedback in higher education. There are significant opportunities and challenges to integrate these tools effectively into learning environments as the demand for timely and personalized feedback grows. We examine the articles based on instructional contexts and system characteristics, identifying critical implementation possibilities for GenAI in automated feedback. Our findings reveal that GenAI provides diverse feedback across various contexts with multiple instructional purposes. GenAI systems can reduce instructor workload by automating routine grading and feedback tasks, allowing educators to focus on more complex teaching responsibilities with augmented capabilities. Additionally, these systems enhance communication, offer cognitive and emotional support, and improve accessibility by creating supportive, stress-free learning environments. Overall, implementing GenAI automated feedback systems improves educational outcomes and creates a more efficient and supportive learning environment for students and instructors. We conclude with future research directions to better integrate GenAI with human instruction by reconsidering instructors\u2019 roles, especially in providing feedback to create more effective educational experiences.", "isOpenAccess": true, "url": "https://doi.org/10.24059/olj.v28i3.4593"}
{"paperId": "f34d918d8630dd1adce642f7f2bea3e2eaeb7f76", "year": 2024, "title": "Conversational and generative artificial intelligence and human-chatbot interaction in education and research", "authors": "I. Akpan, Y. Kobara, Josiah Owolabi, A. A. Akpan, Onyebuchi Felix Offodile", "venue": "International Transactions in Operational Research", "citationCount": 63, "abstract": "Artificial intelligence (AI) as a disruptive technology is not new. However, its recent evolution, engineered by technological transformation, big data analytics, and quantum computing, produces conversational and generative AI (CGAI/GenAI) and human\u2010like chatbots that disrupt conventional operations and methods in different fields. This study investigates the scientific landscape of CGAI and human\u2013chatbot interaction/collaboration and evaluates use cases, benefits, challenges, and policy implications for multidisciplinary education and allied industry operations. The publications trend showed that just 4% (n = 75) occurred during 2006\u20132018, while 2019\u20132023 experienced astronomical growth (n = 1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for teaching, learning, and research activities occurred in computer science (multidisciplinary and AI; 32%), medical/healthcare (17%), engineering (7%), and business fields (6%). The intellectual structure shows strong collaboration among eminent multidisciplinary sources in business, information systems, and other areas. The thematic structure highlights prominent CGAI use cases, including improved user experience in human\u2013computer interaction, computer programs/code generation, and systems creation. Widespread CGAI usefulness for teachers, researchers, and learners includes syllabi/course content generation, testing aids, and academic writing. The concerns about abuse and misuse (plagiarism, academic integrity, privacy violations) and issues about misinformation, danger of self\u2010diagnoses, and patient privacy in medical/healthcare applications are prominent. Formulating strategies and policies to address potential CGAI challenges in teaching/learning and practice are priorities. Developing discipline\u2010based automatic detection of GenAI contents to check abuse is proposed. In operational/operations research areas, proper CGAI/GenAI integration with modeling and decision support systems requires further studies.", "isOpenAccess": false, "url": ""}
{"paperId": "ef11409304bfadcf8622f0351f4bd3b3cc05d670", "year": 2024, "title": "Evaluating the impact of students' generative AI use in educational contexts", "authors": "Dwayne Wood, Scott H. Moss", "venue": "Journal of Research in Innovative Teaching &amp; Learning", "citationCount": 63, "abstract": "PurposeThe purpose of the study was to evaluate the impact of generative artificial intelligence (GenAI) on students' learning experiences and perceptions through a master\u2019s-level course. The study specifically focused on student engagement, comfort with GenAI and ethical considerations.Design/methodology/approachThe study used an action research methodology employing qualitative data collection methods, including pre- and post-course surveys, reflective assignments, class discussions and a questionnaire. The AI-Ideas, Connections, Extensions (ICE) Framework, combining the ICE Model and AI paradigms, is used to assess students' cognitive engagement with GenAI.FindingsThe study revealed that incorporating GenAI in a master\u2019s-level instructional design course increased students' comfort with GenAI and their understanding of its ethical implications. The AI-ICE Framework demonstrated most students were at the initial engagement level, with growing awareness of GenAI\u2019s limitations and ethical issues. Course reflections highlighted themes of improved teaching strategies, personal growth and the practical challenges of integrating GenAI responsibly.Research limitations/implicationsThe small sample size poses challenges to the analytical power of the findings, potentially limiting the breadth and applicability of conclusions. This constraint may affect the generalizability of the results, as the participants may not fully represent the broader population of interest. The researchers are mindful of these limitations and suggest caution in interpreting the findings, acknowledging that they may offer more exploratory insights than definitive conclusions. Future research endeavors should aim to recruit a larger cohort to validate and expand upon the initial observations, ensuring a more robust understanding.Originality/valueThe study is original in its integration of GenAI into a master's-level instructional design course, assessing both the practical and ethical implications of its use in education. By utilizing the AI-ICE Framework to evaluate students' cognitive engagement and employing action research methodology, the study provides insights into how GenAI influences learning experiences and perceptions. This approach bridges the gap between theoretical understanding and the real-world application of GenAI, offering actionable strategies for its responsible use in educational settings.", "isOpenAccess": true, "url": "https://doi.org/10.1108/jrit-06-2024-0151"}
{"paperId": "dfdd8647d74e2080ff1991eb6148774740c969ca", "year": 2024, "title": "Does ChatGPT Help With Introductory Programming? An Experiment of Students Using ChatGPT in CS1", "authors": "Yuankai Xue, Hanlin Chen, Gina R. Bai, Robert Tairas, Yu Huang", "venue": "2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)", "citationCount": 63, "abstract": "Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey. With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3639474.3640076"}
{"paperId": "969a201f9b5d8fabdeb2bac751857760c45f721c", "year": 2023, "title": "Wireless Multi-Agent Generative AI: From Connected Intelligence to Collective Intelligence", "authors": "Han Zou, Qiyang Zhao, Lina Bariah, M. Bennis, M. Debbah", "venue": "arXiv.org", "citationCount": 63, "abstract": "The convergence of generative large language models (LLMs), edge networks, and multi-agent systems represents a groundbreaking synergy that holds immense promise for future wireless generations, harnessing the power of collective intelligence and paving the way for self-governed networks where intelligent decision-making happens right at the edge. This article puts the stepping-stone for incorporating multi-agent generative artificial intelligence (AI) in wireless networks, and sets the scene for realizing on-device LLMs, where multi-agent LLMs are collaboratively planning and solving tasks to achieve a number of network goals. We further investigate the profound limitations of cloud-based LLMs, and explore multi-agent LLMs from a game theoretic perspective, where agents collaboratively solve tasks in competitive environments. Moreover, we establish the underpinnings for the architecture design of wireless multi-agent generative AI systems at the network level and the agent level, and we identify the wireless technologies that are envisioned to play a key role in enabling on-device LLM. To demonstrate the promising potentials of wireless multi-agent generative AI networks, we highlight the benefits that can be achieved when implementing wireless generative agents in intent-based networking, and we provide a case study to showcase how on-device LLMs can contribute to solving network intents in a collaborative fashion. We finally shed lights on potential challenges and sketch a research roadmap towards realizing the vision of wireless collective intelligence.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.02757"}
{"paperId": "7164f67023761f0c5962bb88ffb775e725cb94de", "year": 2024, "title": "Escalation Risks from Language Models in Military and Diplomatic Decision-Making", "authors": "Juan-Pablo Rivera, Gabriel Mukobi, Anka Reuel, Max Lamparth, Chandler Smith, Jacquelyn G. Schneider", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 63, "abstract": "Governments are increasingly considering integrating autonomous AI agents in high-stakes military and foreign-policy decision-making, especially with the emergence of advanced generative AI models like GPT-4. Our work aims to scrutinize the behavior of multiple AI agents in simulated wargames, specifically focusing on their predilection to take escalatory actions that may exacerbate multilateral conflicts. Drawing on political science and international relations literature about escalation dynamics, we design a novel wargame simulation and scoring framework to assess the escalation risks of actions taken by these agents in different scenarios. Contrary to prior studies, our research provides both qualitative and quantitative insights and focuses on large language models (LLMs). We find that all five studied off-the-shelf LLMs show forms of escalation and difficult-to-predict escalation patterns. We observe that models tend to develop arms-race dynamics, leading to greater conflict, and in rare cases, even to the deployment of nuclear weapons. Qualitatively, we also collect the models\u2019 reported reasoning for chosen actions and observe worrying justifications based on deterrence and first-strike tactics. Given the high stakes of military and foreign-policy contexts, we recommend further examination and cautious consideration before deploying autonomous language model agents for strategic military or diplomatic decision-making.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658942"}
{"paperId": "6af902c7b5fb3e604c84ce7385abd1186f7ac3db", "year": 2023, "title": "Copyright Safety for Generative AI", "authors": "Matthew J. Sag", "venue": "Social Science Research Network", "citationCount": 63, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "6a753ae62473bf93f93d2b1f6c30716508212459", "year": 2024, "title": "Generative AI and the politics of visibility", "authors": "Tarleton Gillespie", "venue": "Big Data & Society", "citationCount": 63, "abstract": "Proponents of generative AI tools claim they will supplement, even replace, the work of cultural production. This raises questions about the politics of visibility: what kinds of stories do these tools tend to generate, and what do they generally not? Do these tools match the kind of diversity of representation that marginalized populations and non-normative communities have fought to secure in publishing and broadcast media? I tested three widely available generative AI tools with prompts designed to reveal these normative assumptions; I prompted the tools multiple times with each, to track the diversity of the outputs to the same query. I demonstrate that, as currently designed and trained, generative AI tools tend to reproduce normative identities and narratives, rarely representing less common arrangements and perspectives. When they do generate variety, it is often narrow, maintaining deeper normative assumptions in what remains absent.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/20539517241252131"}
{"paperId": "67455478e77c8672d0dd08f89735a8813bbfec65", "year": 2023, "title": "The FormAI Dataset: Generative AI in Software Security through the Lens of Formal Verification", "authors": "Norbert Tihanyi, Tam\u00e1s Bisztray, Ridhi Jain, M. Ferrag, L. Cordeiro, Vasileios Mavroeidis", "venue": "International Conference on Predictive Models in Software Engineering", "citationCount": 63, "abstract": "This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. We have associated the identified vulnerabilities with Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112,000 programs, accompanied by a separate file containing the vulnerabilities detected in each program, making the dataset ideal for training LLMs and machine learning algorithms. Our study unveiled that according to ESBMC, 51.24% of the programs generated by GPT-3.5 contained vulnerabilities, thereby presenting considerable risks to software safety and security.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3617555.3617874"}
{"paperId": "5c7a8d6e147d64a762a1055a0bbdf5a00bdfe164", "year": 2024, "title": "Privacy-Preserving Techniques in Generative AI and Large Language Models: A Narrative Review", "authors": "G. Feretzakis, Konstantinos Papaspyridis, A. Gkoulalas-Divanis, V. Verykios", "venue": "Inf.", "citationCount": 63, "abstract": "Generative AI, including large language models (LLMs), has transformed the paradigm of data generation and creative content, but this progress raises critical privacy concerns, especially when models are trained on sensitive data. This review provides a comprehensive overview of privacy-preserving techniques aimed at safeguarding data privacy in generative AI, such as differential privacy (DP), federated learning (FL), homomorphic encryption (HE), and secure multi-party computation (SMPC). These techniques mitigate risks like model inversion, data leakage, and membership inference attacks, which are particularly relevant to LLMs. Additionally, the review explores emerging solutions, including privacy-enhancing technologies and post-quantum cryptography, as future directions for enhancing privacy in generative AI systems. Recognizing that achieving absolute privacy is mathematically impossible, the review emphasizes the necessity of aligning technical safeguards with legal and regulatory frameworks to ensure compliance with data protection laws. By discussing the ethical and legal implications of privacy risks in generative AI, the review underscores the need for a balanced approach that considers performance, scalability, and privacy preservation. The findings highlight the need for ongoing research and innovation to develop privacy-preserving techniques that keep pace with the scaling of generative AI, especially in large language models, while adhering to regulatory and ethical standards.", "isOpenAccess": true, "url": "https://www.mdpi.com/2078-2489/15/11/697/pdf?version=1730704574"}
{"paperId": "4be3612b26dedc151685bc1f836020177ae619f1", "year": 2023, "title": "Beyond Reality: The Pivotal Role of Generative AI in the Metaverse", "authors": "V. Chamola, Gaurang Bansal, T. K. Das, Vikas Hassija, Siva Sai, Jiacheng Wang, S. Zeadally, Amir Hussain, F. R. Yu, Mohsen Guizani, D. Niyato", "venue": "IEEE Internet of Things Magazine", "citationCount": 63, "abstract": "The Metaverse, an interconnected network of immersive digital realms, is poised to reshape the future by seamlessly merging physical reality with virtual environments. Its potential to revolutionize diverse aspects of human existence, from entertainment to commerce, underscores its significance. At the heart of this transformation lies Generative AI, a branch of artificial intelligence focused on creating novel content. Generative AI serves as a catalyst, propelling the Metaverse's evolution by enhancing it with immersive experiences. The Metaverse is comprised of three pivotal domains, namely, text, visual, and audio. The Metaverse's fabric intertwines with Generative AI models, ushering in innovative interactions. Within Visual, the triad of image, video, and 3D Object generation sets the stage for engaging virtual landscapes. Key to this evolution is five generative models: Transformers, Diffusion, Autoencoders, Autoregressive, and Generative Adversarial Networks (GANs). These models empower the Metaverse, enhancing it with dynamic and diverse content. Notably, technologies like BARD, Point-E, Stable Diffusion, DALL-E, GPT, and AIVA, among others, wield these models to enrich the Metaverse across domains. By discussing the technical issues and real-world applications, this study reveals the intricate tapestry of AI's role in the Metaverse. Anchoring these insights is a case study illuminating Stable Diffusion's role in metamorphosing the virtual realm. Collectively, this exploration illuminates the symbiotic relationship between Generative AI and the Metaverse, foreshadowing a future where immersive, interactive, and personalized experiences blackefine human engagement with digital landscapes.", "isOpenAccess": false, "url": ""}
{"paperId": "3b345b17431ce1a6132abab3fc1da0cbc134bf06", "year": 2024, "title": "Good Models Borrow, Great Models Steal: Intellectual Property Rights and Generative AI", "authors": "Simon Chesterman", "venue": "Social Science Research Network", "citationCount": 63, "abstract": "\n Two critical policy questions will determine the impact of generative artificial intelligence (AI) on the knowledge economy and the creative sector. The first concerns how we think about the training of such models\u2014in particular, whether the creators or owners of the data that are \u201cscraped\u201d (lawfully or unlawfully, with or without permission) should be compensated for that use. The second question revolves around the ownership of the output generated by AI, which is continually improving in quality and scale. These topics fall in the realm of intellectual property, a legal framework designed to incentivize and reward only human creativity and innovation. For some years, however, Britain has maintained a distinct category for \u201ccomputer-generated\u201d outputs; on the input issue, the EU and Singapore have recently introduced exceptions allowing for text and data mining or computational data analysis of existing works. This article explores the broader implications of these policy choices, weighing the advantages of reducing the cost of content creation and the value of expertise against the potential risk to various careers and sectors of the economy, which might be rendered unsustainable. Lessons may be found in the music industry, which also went through a period of unrestrained piracy in the early digital era, epitomized by the rise and fall of the file-sharing service Napster. Similar litigation and legislation may help navigate the present uncertainty, along with an emerging market for \u201clegitimate\u201d models that respect the copyright of humans and are clear about the provenance of their own creations.", "isOpenAccess": false, "url": ""}
{"paperId": "2a350127799a82ce7280b1e95f9ab23c73cfe8f8", "year": 2023, "title": "Exploring User Perspectives on ChatGPT: Applications, Perceptions, and Implications for AI-Integrated Education", "authors": "Reza Hadi Mogavi, Chaohua Deng, Justin Juho Kim, Pengyuan Zhou, Young D. Kwon, A. H. Metwally, A. Tlili, Simone Bassanelli, A. Bucchiarone, Sujit Gujar, Lennart E. Nacke, Pan Hui", "venue": "arXiv.org", "citationCount": 63, "abstract": "To foster the development of pedagogically potent and ethically sound AI-integrated learning landscapes, it is pivotal to critically explore the perceptions and experiences of the users immersed in these contexts. In this study, we perform a thorough qualitative content analysis across four key social media platforms. Our goal is to understand the user experience (UX) and views of early adopters of ChatGPT across different educational sectors. The results of our research show that ChatGPT is most commonly used in the domains of higher education, K-12 education, and practical skills training. In social media dialogues, the topics most frequently associated with ChatGPT are productivity, efficiency, and ethics. Early adopters' attitudes towards ChatGPT are multifaceted. On one hand, some users view it as a transformative tool capable of amplifying student self-efficacy and learning motivation. On the other hand, there is a degree of apprehension among concerned users. They worry about a potential overdependence on the AI system, which they fear might encourage superficial learning habits and erode students' social and critical thinking skills. This dichotomy of opinions underscores the complexity of Human-AI Interaction in educational contexts. Our investigation adds depth to this ongoing discourse, providing crowd-sourced insights for educators and learners who are considering incorporating ChatGPT or similar generative AI tools into their pedagogical strategies.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.13114"}
{"paperId": "191e116815a951e3a917d515eb9aa9e892373c88", "year": 2023, "title": "Generative AI in Medical Imaging: Applications, Challenges, and Ethics", "authors": "M. Koohi-Moghadam, K. Bae", "venue": "Journal of medical systems", "citationCount": 63, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "0f6439b95aed189908c628f1103dbcef8541cc2e", "year": 2024, "title": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning", "authors": "Alireza Ghafarollahi, Markus J. Buehler", "venue": "arXiv.org", "citationCount": 63, "abstract": "A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations. Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a `swarm of intelligence' similar to biological systems. This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature's design principles.", "isOpenAccess": false, "url": ""}
{"paperId": "f60bd7510e6433c34e511f3a6032d670a393e049", "year": 2023, "title": "Prompt Aloud!: Incorporating image-generative AI into STEAM class with learning analytics using prompt data", "authors": "Unggi Lee, Ariel Han, Jeongjin Lee, Eunseo Lee, Jiwon Kim, Hyeoncheol Kim, Cheolil Lim", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 62, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "c9c9b930cbbbb0c3bc8b778ce6709846b2661f6a", "year": 2024, "title": "AI and ethics: Investigating the first policy responses of higher education institutions to the challenge of generative AI", "authors": "Attila Dabis, C. Cs\u00e1ki", "venue": "Humanities and Social Sciences Communications", "citationCount": 62, "abstract": "This article addresses the ethical challenges posed by generative artificial intelligence (AI) tools in higher education and explores the first responses of universities to these challenges globally. Drawing on five key international documents from the UN, EU, and OECD, the study used content analysis to identify key ethical dimensions related to the use of generative AI in academia, such as accountability, human oversight, transparency, or inclusiveness. Empirical evidence was compiled from 30 leading universities ranked among the top 500 in the Shanghai Ranking list from May to July 2023, covering those institutions that already had publicly available responses to these dimensions in the form of policy documents or guidelines. The paper identifies the central ethical imperative that student assignments must reflect individual knowledge acquired during their education, with human individuals retaining moral and legal responsibility for AI-related wrongdoings. This top-down requirement aligns with a bottom-up approach, allowing instructors flexibility in determining how they utilize generative AI especially large language models in their own courses. Regarding human oversight, the typical response identified by the study involves a blend of preventive measures (e.g., course assessment modifications) and soft, dialogue-based sanctioning procedures. The challenge of transparency induced the good practice of clear communication of AI use in course syllabi in the first university responses examined by this study.", "isOpenAccess": true, "url": "https://doi.org/10.1057/s41599-024-03526-z"}
{"paperId": "c2b6f0cf3c76d314a8c1f46cd8c831e67f2e16bb", "year": 2023, "title": "ChatGPT and the Generation of Digitally Born \u201cKnowledge\u201d: How Does a Generative AI Language Model Interpret Cultural Heritage Values?", "authors": "D. Spennemann", "venue": "Knowledge", "citationCount": 62, "abstract": "The public release of ChatGPT, a generative artificial intelligence language model, caused wide-spread public interest in its abilities but also concern about the implications of the application on academia, depending on whether it was deemed benevolent (e.g., supporting analysis and simplification of tasks) or malevolent (e.g., assignment writing and academic misconduct). While ChatGPT has been shown to provide answers of sufficient quality to pass some university exams, its capacity to write essays that require an exploration of value concepts is unknown. This paper presents the results of a study where ChatGPT-4 (released May 2023) was tasked with writing a 1500-word essay to discuss the nature of values used in the assessment of cultural heritage significance. Based on an analysis of 36 iterations, ChatGPT wrote essays of limited length with about 50% of the stipulated word count being primarily descriptive and without any depth or complexity. The concepts, which are often flawed and suffer from inverted logic, are presented in an arbitrary sequence with limited coherence and without any defined line of argument. Given that it is a generative language model, ChatGPT often splits concepts and uses one or more words to develop tangential arguments. While ChatGPT provides references as tasked, many are fictitious, albeit with plausible authors and titles. At present, ChatGPT has the ability to critique its own work but seems unable to incorporate that critique in a meaningful way to improve a previous draft. Setting aside conceptual flaws such as inverted logic, several of the essays could possibly pass as a junior high school assignment but fall short of what would be expected in senior school, let alone at a college or university level.", "isOpenAccess": true, "url": "https://www.mdpi.com/2673-9585/3/3/32/pdf?version=1695111050"}
{"paperId": "86c10e08b8f1e848ddb6b5f59f7dae061e7e8bd9", "year": 2024, "title": "Ethical considerations in implementing generative AI for healthcare supply chain optimization: A cross-country analysis across India, the United Kingdom, and the United States of America", "authors": "Amina Catherine Ijiga, Ehi Peace, Idoko Peter Idoko, Daniel Obekpa Agbo, Kimberly D. Harry, Chijioke Ifakandu Ezebuka, Esther Ene Umama", "venue": "International Journal of Biological and Pharmaceutical Sciences Archive", "citationCount": 62, "abstract": "This review paper critically examines the ethical considerations involved in implementing generative Artificial Intelligence (AI) in healthcare supply chain optimization across three distinct regions: India, the United Kingdom, and the United States of America. The study synthesizes findings from various case studies and academic research to highlight both common and unique ethical challenges faced in these countries. Key themes such as data privacy, algorithmic transparency, and equitable access to AI-driven healthcare solutions are explored, alongside the unique socio-cultural, legal, and regulatory challenges specific to each region. The paper proposes a set of best practices for incorporating ethical considerations into the deployment of generative AI in healthcare. These include the development of inclusive ethical frameworks, regular ethical audits, comprehensive training and education programs, public engagement initiatives, and interdisciplinary collaboration. The paper also delves into future research directions and policy development, emphasizing the need to address healthcare disparities, adapt legal and regulatory frameworks, enhance generative AI explainability, and evaluate long-term outcomes.The study concludes by underscoring the importance of ethical design and deployment of generative AI systems in healthcare, advocating for a balanced approach that aligns technological advancements with ethical standards and global healthcare needs. This comprehensive review aims to contribute to the discourse on ethical generative AI implementation, offering insights and recommendations for policymakers, healthcare professionals, and generative AI developers to foster responsible and beneficial use of generative AI in healthcare globally.", "isOpenAccess": true, "url": "https://ijbpsa.com/sites/default/files/IJBPSA-2024-0015.pdf"}
{"paperId": "808dcba89421d7f926f50ad88f41c42788ac4875", "year": 2023, "title": "How will generative AI disrupt data science in drug discovery?", "authors": "Jean-Philippe Vert", "venue": "Nature Biotechnology", "citationCount": 62, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "73c40ffada02d20cf7b37be9bea4b08d1647acc2", "year": 2024, "title": "Generative AI for Cyber Security: Analyzing the Potential of ChatGPT, DALL-E, and Other Models for Enhancing the Security Space", "authors": "Siva Sai, Utkarsh Yashvardhan, V. Chamola, Biplab Sikdar", "venue": "IEEE Access", "citationCount": 62, "abstract": "This research paper intends to provide real-life applications of Generative AI (GAI) in the cybersecurity domain. The frequency, sophistication and impact of cyber threats have continued to rise in today\u2019s world. This ever-evolving threat landscape poses challenges for organizations and security professionals who continue looking for better solutions to tackle these threats. GAI technology provides an effective way for them to address these issues in an automated manner with increasing efficiency. It enables them to work on more critical security aspects which require human intervention, while GAI systems deal with general threat situations. Further, GAI systems can better detect novel malware and threatening situations than humans. This feature of GAI, when leveraged, can lead to higher robustness of the security system. Many tech giants like Google, Microsoft etc., are motivated by this idea and are incorporating elements of GAI in their cybersecurity systems to make them more efficient in dealing with ever-evolving threats. Many cybersecurity tools like Google Cloud Security AI Workbench, Microsoft Security Copilot, SentinelOne Purple AI etc., have come into the picture, which leverage GAI to develop more straightforward and robust ways to deal with emerging cybersecurity perils. With the advent of GAI in the cybersecurity domain, one also needs to take into account the limitations and drawbacks that such systems have. This paper also provides some of the limitations of GAI, like periodically giving wrong results, costly training, the potential of GAI being used by malicious actors for illicit activities etc.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10491270.pdf"}
{"paperId": "e5d0cd12ec81eacd7861c8147b55048555cc7573", "year": 2023, "title": "Can ChatGPT be used to generate scientific hypotheses?", "authors": "Yang Jeong Park, Daniel Kaplan, Zhichu Ren, Chia-Wei Hsu, Changhao Li, Haowei Xu, Sipei Li, Ju Li", "venue": "Journal of Materiomics", "citationCount": 61, "abstract": "We investigate whether large language models can perform the creative hypothesis generation that human researchers regularly do. While the error rate is high, generative AI seems to be able to effectively structure vast amounts of scientific knowledge and provide interesting and testable hypotheses. The future scientific enterprise may include synergistic efforts with a swarm of\"hypothesis machines\", challenged by automated experimentation and adversarial peer reviews.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.12208"}
{"paperId": "df409cc1387abe0ffa7e65c6b90e283b1e37dd6f", "year": 2024, "title": "Generative AI and deepfakes: a human rights approach to tackling harmful content", "authors": "Felipe Romero Moreno", "venue": "International Review of Law, Computers &amp; Technology", "citationCount": 61, "abstract": "ABSTRACT The EU's Artificial Intelligence Act (AIA) introduces necessary deepfake regulations. However, these could infringe on the rights of AI providers and deployers or users, potentially conflicting with privacy and free expression under Articles 8 and 10 of the European Convention on Human Rights, and the General Data Protection Regulation (EU) 2016/679 (GDPR). This paper critically examines how an unmodified AIA could enable voter manipulation, blackmail, and the generation of sexual abusive content, facilitating misinformation and potentially harming millions, both emotionally and financially. Through analysis of the AIA's provisions, GDPR's regulations, relevant case law, and academic literature, the paper identifies risks for both AI providers and users. While the AIA's yearly review cycle is important, the immediacy of these threats demands swifter action. This paper proposes two key amendments: 1) mandate structured synthetic data for deepfake detection, and 2) classify AI intended for malicious deepfakes as \u2018high-risk\u2019. These amendments, alongside clear definitions and robust safeguards would ensure effective deepfake regulation while protecting fundamental rights. The paper urges policymakers to adopt these amendments during the next review cycle to protect democracy, individual safety, and children. Only then will the AIA fully achieve its aims while safeguarding the freedoms it seeks to uphold.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/13600869.2024.2324540?needAccess=true"}
{"paperId": "a71efa2b6c288799c2274cb9f642959ebf3aa05f", "year": 2024, "title": "Personalizing guest experience with generative AI in the hotel industry: there's more to it than meets a Kiwi\u2019s eye", "authors": "Pola Q. Wang", "venue": "Current Issues in Tourism", "citationCount": 61, "abstract": "ABSTRACT Since its launch in November 2022, ChatGPT has pioneered a new era in AI, globally acclaimed for its content creation and language understanding. This advancement is reshaping industries like hospitality, offering innovative applications but also raising ethical and efficiency challenges. In the context of New Zealand\u2019s hotel industry, renowned for its vibrant and inclusive \u2018Kiwi\u2019 hospitality culture, the idea of incorporating generative AI offers a novel perspective. While its application could potentially enhance service efficiency and help to alleviate staff shortages, integration with the country\u2019s deeply rooted cultural values demands a carefully considered approach. This study adopted a qualitative methodology using semi-structured interviews with hotel managers and AI experts in New Zealand. The findings revealed that generative AI holds promises for cost savings, work efficiency and meeting specific social group demands. Concerns have been raised, however, relating to the ability of AI to handle complex interactions, incorporate a sense of Kiwi culture, respond appropriately to service contingency events, maintain data privacy and meet the generational service preferences of guests. The absence of clear AI legislation has led to cautious interest among hotel managers, restrained by concerns around legality, privacy and service quality.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/13683500.2023.2300030?needAccess=true"}
{"paperId": "965d941897de90c4ad4c6cde77cb2b3333edcaeb", "year": 2023, "title": "\u2018ChatGPT et al.\u2019: The ethics of using (generative) artificial intelligence in research and science", "authors": "D. Schlagwein, L. Willcocks", "venue": "Journal of Information and Technology", "citationCount": 61, "abstract": "Artificial intelligence (AI) seeks to make computers do what human minds can do. By \u2018AI\u2019, we refer to the use of machine learning, algorithms, large datasets, neural networks and traditional statistical reasoning by computing. The term \u2018AI\u2019 is misleading: Despite suggestions to the contrary (Bubeck et al., 2023) \u2013 and some surely impressive achievements in specific areas \u2013we are still far from reaching the benchmark of \u2018general human intelligence\u2019. AI has undergone several generations, from \u2018good old-fashioned AI\u2019 (Haugeland, 1989), the defined algorithms of which failed at the common sense problem, to the current and more successful generation of neural network and deep learning AI. One specific form of current AI is \u2018generative AI\u2019 (e.g. ChatGPT, DALL-E, Midjourney) \u2013 and without a doubt, it\u2019s the \u2018technology hype\u2019 of 2023 and the focus of this editorial comment. Generative AI, specifically ChatGPT, became a \u2018cultural sensation\u2019 (Thorp, 2023) rather rapidly in early 2023. When Daniel brought up generative AI as a future ethical issue at a panel for journal editors on publishing ethics in December 2022 (Burton-Jones et al., 2022), many audience members seemed unfamiliar withMidjourney orChatGPT.However, within just a few weeks, the landscape shifted dramatically. Publicly launched on 30 November 2022, ChatGPT \u2013 a chatbot built on top of a text-generating AI \u2013 had an impressive debut, reaching onemillion users within 5 days and surpassing 100million users in January 2023 (Dwivedi et al., 2023). Since then, ChatGPT has become widely used and is believed to impact many areas, including research and science (Hill-Yardin et al., 2023; Liebrenz et al., 2023; Lund and Wang, 2023). While detailed explanations of the underlying technology can be found in other sources (Goodfellow et al., 2016), generative AI is a subset of deep learning AI that specialises in producing human-like outputs. OpenAI\u2019s ChatGPToperates on a neural network AI architecture, GPT (Generative Pretrained Transformer). Although ChatGPT might have seemed like a natural progression of the AI domain, especially since Midjourney and DALL-E had been introduced earlier, it astonished global audiences and led companies like Alphabet (Google) to hastily release comparable tools (Teubner et al., 2023). Simplified, deep learning AI systems \u2018hallucinate\u2019 \u2018plausible looking\u2019 (though not necessarily accurate) responses to user prompts. They base these responses on patterns of \u2018likeness\u2019 (associations between words and concepts), stored in a digital neural network (multiple layers of interconnected nodes) and learnt from massive training datasets. Such systems can quickly generate high-quality images and texts, outperforming traditional algorithms. However, this advanced capability is accompanied by the challenge of the \u2018black box\u2019 problem:wemay understand the model\u2019s general principles, but the reasons behind specific decisions remain opaque. The neural network provides a flexible, changing structure, inspired by the human brain, that encodes patterns, but not in an intelligible, auditable manner \u2013 there is no clear formula to scrutinise. (This is akin to how the reader might instantly and reliably distinguish between their mother and their cat but would be unable to write down a precise formula for this recognition process). As journal editors, the emergence of ChatGPT prompted us \u2013 and others (e.g. Hill-Yardin et al., 2023; Liebrenz et al., 2023; Lund and Wang, 2023; Teubner et al., 2023; Van Dis et al., 2023) \u2013 to ask foundational questions about using generative AI in research and science. Specifically: Is it \u2018ethical\u2019 to use generative or other AIs in conducting research or for writing academic research papers? In this editorial, we go back to first principles to reflect on the fundamental ethics to apply to using ChatGPT and AI in research and science. Next, we caution that (generative) AI is also at the \u2018peak of inflated (hype) expectations\u2019 and discuss eight in-principle issues that AI struggles with, both ethically and practically. We conclude with what this all means for the ethics of using generative AI in research and science.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/02683962231200411"}
{"paperId": "8854d9df65a35670b0b34db371442aa5353c42a5", "year": 2023, "title": "Waiting, Banning, and Embracing: An Empirical Analysis of Adapting Policies for Generative AI in Higher Education", "authors": "Ping Xiao, Yuanyuan Chen, Weining Bao", "venue": "Social Science Research Network", "citationCount": 61, "abstract": "Generative AI tools such as ChatGPT have recently gained significant attention in higher education. This study aims to understand how universities establish policies regarding the use of AI tools and explore the factors that influence their decisions. Our study examines ChatGPT policies implemented at universities around the world, including their existence, content, and issuance dates. Specifically, we analyzed the top 500 universities according to the 2022 QS World University Rankings. Our findings indicate that there is significant variation in university policies. Less than one-third of the universities included in the study had implemented ChatGPT policies. Of the universities with ChatGPT policies, approximately 67 percent embraced ChatGPT in teaching and learning, more than twice the number of universities that banned it. The majority of the universities that ban the use of ChatGPT in assessments allow individual instructors to deviate from this restrictive policy. Our empirical analysis identifies several factors that are significantly and positively correlated with a university's likelihood of having a ChatGPT policy, including the university's academic reputation score, being in an English-speaking country, and the general public attitudes toward ChatGPT. In addition, we found that a university's likelihood of having a ban policy is positively associated with faculty student ratio, citations, and the English-speaking country dummy, while negatively associated with the number of peer universities within the same country that have banned ChatGPT. We discuss the challenges faced by universities based our empirical findings.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.18617"}
{"paperId": "872ea68fa5ddb070c671c44b321d63415d153742", "year": 2023, "title": "Living guidelines for generative AI \u2014 why scientists must oversee its use", "authors": "C. Bockting, Eva A. M. van Dis, Robert van Rooij, Willem Zuidema, Johan Bollen", "venue": "Nature", "citationCount": 61, "abstract": null, "isOpenAccess": true, "url": "https://www.nature.com/articles/d41586-023-03266-1.pdf"}
{"paperId": "62fd03cbb2ae7123be2901c843c1ce96cf4005ba", "year": 2023, "title": "Generative AI and Firm Values", "authors": "Andrea L. Eisfeldt, G. Schubert, Miao Zhang", "venue": "Social Science Research Network", "citationCount": 61, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.3386/w31222"}
{"paperId": "44b225dc3a7fa8e06c6b7c78b5973219fc6c6ecb", "year": 2023, "title": "How do we respond to generative AI in education? Open educational practices give us a framework for an ongoing process", "authors": "", "venue": "1", "citationCount": 61, "abstract": null, "isOpenAccess": true, "url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/843/597"}
{"paperId": "ccee96b6148d84350115ce595fe193c1d95731f2", "year": 2024, "title": "The synergy of generative AI and inquiry-based learning: transforming the landscape of English teaching and learning", "authors": "Hui-Chin Yeh", "venue": "Interactive Learning Environments", "citationCount": 60, "abstract": "ABSTRACT This study investigates the integration of artificial intelligence (AI) tools, such as ChatGPT, into English as a Foreign Language (EFL) teacher learning, aiming to transcend the traditional, test-centric constraints of language education through inquiry-based learning (IBL). Conducted over a semester, the research involved thirteen in-service teachers who engaged in crafting lesson plans, executing microteaching sessions, and documenting their reflections. These qualitative data sources provided insights into how AI can enhance language teaching by personalizing content and supporting the development of communicative skills. The analysis through thematic analysis revealed that AI technologies empowered teachers to design interactive and adaptive learning materials, including picture books and karaoke exercises, thereby fostering a more dynamic and student-centered learning environment. In-service teachers noted that the adaptability of AI tools not only facilitated the creation of compelling lessons but also significantly improved students\u2019 listening and speaking skills. The findings advocate for the strategic incorporation of AI in EFL teaching, suggesting that such technologies can lead to innovative pedagogical approaches that are attuned to the diverse needs of learners. This study underscores the potential of AI to revolutionize language education.", "isOpenAccess": false, "url": ""}
{"paperId": "c1cb6a46915155cfeecc098607730f0ffc914db3", "year": 2023, "title": "Integrating Generative AI in Education: How ChatGPT Brings Challenges for Future Learning and Teaching", "authors": "Yi Wu", "venue": "Journal of Advanced Research in Education", "citationCount": 60, "abstract": "ChatGPT, a chatbot based on the Open-AI\u2019s generative pre-trained (GPT) language models, has been hailed as a \u201c24/7 tutor\u201d that has transformed the way people view education in just under six months since its debut. (Jason Pohl, 2023; Kara Manke, 2023) The impact of AI on future learning and teaching has sparked discussions that draw parallels to the debates held over 2,000 years ago by renowned Greek philosophers such as Socrates (469-399 B.C.), Plato (427-347 B.C.), and Aristotle (384-322 B.C.). These ancient thinkers delved into theories pertaining to the acquisition and dissemination of new knowledge. By drawing these historical comparisons, we gain valuable insights into the ongoing discourse surrounding the influence of AI in education. Does Socrates\u2019 dialectic method, in which truth is discovered through discussions with peers, still have a role in the learning process? Could the peer involved in this case be considered a chatbot?", "isOpenAccess": true, "url": "https://www.pioneerpublisher.com/jare/article/download/324/286"}
{"paperId": "7b7933281b31d31615218b8a81cdde570a39f395", "year": 2023, "title": "LDM3D: Latent Diffusion Model for 3D", "authors": "Gabriela Ben Melech Stan, Diana Wofk, Scottie Fox, Alex Redden, Will Saxton, Jean Yu, Estelle Aflalo, Shao-Yen Tseng, Fabio Nonato, Matthias M\u00fcller, Vasudev Lal", "venue": "arXiv.org", "citationCount": 60, "abstract": "This research paper proposes a Latent Diffusion Model for 3D (LDM3D) that generates both image and depth map data from a given text prompt, allowing users to generate RGBD images from text prompts. The LDM3D model is fine-tuned on a dataset of tuples containing an RGB image, depth map and caption, and validated through extensive experiments. We also develop an application called DepthFusion, which uses the generated RGB images and depth maps to create immersive and interactive 360-degree-view experiences using TouchDesigner. This technology has the potential to transform a wide range of industries, from entertainment and gaming to architecture and design. Overall, this paper presents a significant contribution to the field of generative AI and computer vision, and showcases the potential of LDM3D and DepthFusion to revolutionize content creation and digital experiences. A short video summarizing the approach can be found at https://t.ly/tdi2.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.10853"}
{"paperId": "51b0fb65133deedef2693382c20f098de9463e52", "year": 2024, "title": "Bias in Generative AI", "authors": "Mi Zhou, Vibhanshu Abhishek, Timothy P. Derdenger, Jaymo Kim, Kannan Srinivasan", "venue": "arXiv.org", "citationCount": 60, "abstract": "This study analyzed images generated by three popular generative artificial intelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 - representing various occupations to investigate potential bias in AI generators. Our analysis revealed two overarching areas of concern in these AI generators, including (1) systematic gender and racial biases, and (2) subtle biases in facial expressions and appearances. Firstly, we found that all three AI generators exhibited bias against women and African Americans. Moreover, we found that the evident gender and racial biases uncovered in our analysis were even more pronounced than the status quo when compared to labor force statistics or Google images, intensifying the harmful biases we are actively striving to rectify in our society. Secondly, our study uncovered more nuanced prejudices in the portrayal of emotions and appearances. For example, women were depicted as younger with more smiles and happiness, while men were depicted as older with more neutral expressions and anger, posing a risk that generative AI models may unintentionally depict women as more submissive and less competent than men. Such nuanced biases, by their less overt nature, might be more problematic as they can permeate perceptions unconsciously and may be more difficult to rectify. Although the extent of bias varied depending on the model, the direction of bias remained consistent in both commercial and open-source AI generators. As these tools become commonplace, our study highlights the urgency to identify and mitigate various biases in generative AI, reinforcing the commitment to ensuring that AI technologies benefit all of humanity for a more inclusive future.", "isOpenAccess": false, "url": ""}
{"paperId": "4a806670b0aeb2b55c1efce5ae294e34ac9c676b", "year": 2023, "title": "On the application of Large Language Models for language teaching and assessment technology", "authors": "Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher Bryant, Marek Rei, H. Yannakoudakis, Andrew Mullooly, D. Nicholls, P. Buttery", "venue": "LLM@AIED", "citationCount": 60, "abstract": "The recent release of very large language models such as PaLM and GPT-4 has made an unprecedented impact in the popular media and public consciousness, giving rise to a mixture of excitement and fear as to their capabilities and potential uses, and shining a light on natural language processing research which had not previously received so much attention. The developments offer great promise for education technology, and in this paper we look specifically at the potential for incorporating large language models in AI-driven language teaching and assessment systems. We consider several research areas and also discuss the risks and ethical considerations surrounding generative AI in education technology for language learners. Overall we find that larger language models offer improvements over previous models in text generation, opening up routes toward content generation which had not previously been plausible. For text generation they must be prompted carefully and their outputs may need to be reshaped before they are ready for use. For automated grading and grammatical error correction, tasks whose progress is checked on well-known benchmarks, early investigations indicate that large language models on their own do not improve on state-of-the-art results according to standard evaluation metrics. For grading it appears that linguistic features established in the literature should still be used for best performance, and for error correction it may be that the models can offer alternative feedback styles which are not measured sensitively with existing methods. In all cases, there is work to be done to experiment with the inclusion of large language models in education technology for language learners, in order to properly understand and report on their capacities and limitations, and to ensure that foreseeable risks such as misinformation and harmful bias are mitigated.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.08393"}
{"paperId": "355a39acb3f5fe8ab0523d610fdfa01659de9ad4", "year": 2024, "title": "Rethinking open source generative AI: open-washing and the EU AI Act", "authors": "Andreas Liesenfeld, Mark Dingemanse", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 60, "abstract": "The past year has seen a steep rise in generative AI systems that claim to be open. But how open are they really? The question of what counts as open source in generative AI is poised to take on particular importance in light of the upcoming EU AI Act that regulates open source systems differently, creating an urgent need for practical openness assessment. Here we use an evidence-based framework that distinguishes 14 dimensions of openness, from training datasets to scientific and technical documentation and from licensing to access methods. Surveying over 45 generative AI systems (both text and text-to-image), we find that while the term open source is widely used, many models are \u2018open weight\u2019 at best and many providers seek to evade scientific, legal and regulatory scrutiny by withholding information on training and fine-tuning data. We argue that openness in generative AI is necessarily composite (consisting of multiple elements) and gradient (coming in degrees), and point out the risk of relying on single features like access or licensing to declare models open or not. Evidence-based openness assessment can help foster a generative AI landscape in which models can be effectively regulated, model providers can be held accountable, scientists can scrutinise generative AI, and end users can make informed decisions.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3659005"}
{"paperId": "2d2752a7500e41bdf3f34ff77b443e31b47617c3", "year": 2024, "title": "Audio Deepfake Detection with Self-Supervised XLS-R and SLS Classifier", "authors": "Qishan Zhang, Shuangbing Wen, Tao Hu", "venue": "ACM Multimedia", "citationCount": 60, "abstract": "Generative AI technologies, including text-to-speech (TTS) and voice conversion (VC), frequently become indistinguishable from genuine samples, posing challenges for individuals in discerning between real and synthetic content. This indistinguishability undermines trust in media, and the arbitrary cloning of personal voice signals presents significant challenges to privacy and security. In the field of deepfake audio detection, the majority of models achieving higher detection accuracy currently employ self-supervised pre-trained models. However, with the ongoing development of deepfake audio generation algorithms, maintaining high discrimination accuracy against new algorithms grows more challenging. To enhance the sensitivity of deepfake audio features, we propose a deepfake audio detection model that incorporates an SLS (Sensitive Layer Selection) module. Specifically, utilizing the pre-trained XLS-R enables our model to extract diverse audio features from its various layers, each providing distinct discriminative information. Utilizing the SLS classifier, our model captures sensitive contextual information across different layer levels of audio features, effectively employing this information for fake audio detection. Experimental results show that our method achieves state-of-the-art (SOTA) performance on both the ASVspoof 2021 DF and In-the-Wild datasets, with a specific Equal Error Rate (EER) of 1.92% on the ASVspoof 2021 DF dataset and 7.46% on the In-the-Wild dataset. Codes and data can be found at https://github.com/QiShanZhang/SLSforADD.", "isOpenAccess": false, "url": ""}
{"paperId": "21f8977648e25ce8b95020e6f01988af99209c82", "year": 2024, "title": "A Safe Harbor for AI Evaluation and Red Teaming", "authors": "Shayne Longpre, Sayash Kapoor, Kevin Klyman, Ashwin Ramaswami, Rishi Bommasani, Borhane Blili-Hamelin, Yangsibo Huang, Aviya Skowron, Zheng-Xin Yong, Suhas Kotha, Yi Zeng, Weiyan Shi, Xianjun Yang, Reid Southen, Alexander Robey, Patrick Chao, Diyi Yang, Ruoxi Jia, Daniel Kang, Sandy Pentland, Arvind Narayanan, Percy Liang, Peter Henderson", "venue": "International Conference on Machine Learning", "citationCount": 60, "abstract": "Independent evaluation and red teaming are critical for identifying the risks posed by generative AI systems. However, the terms of service and enforcement strategies used by prominent AI companies to deter model misuse have disincentives on good faith safety evaluations. This causes some researchers to fear that conducting such research or releasing their findings will result in account suspensions or legal reprisal. Although some companies offer researcher access programs, they are an inadequate substitute for independent research access, as they have limited community representation, receive inadequate funding, and lack independence from corporate incentives. We propose that major AI developers commit to providing a legal and technical safe harbor, indemnifying public interest safety research and protecting it from the threat of account suspensions or legal reprisal. These proposals emerged from our collective experience conducting safety, privacy, and trustworthiness research on generative AI systems, where norms and incentives could be better aligned with public interests, without exacerbating model misuse. We believe these commitments are a necessary step towards more inclusive and unimpeded community efforts to tackle the risks of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "f1f35272fc6c8b00cfcd8baa7f901f3f0d708a1e", "year": 2024, "title": "Simple techniques to bypass GenAI text detectors: implications for inclusive education", "authors": "Mike Perkins, Jasper Roe, Binh H. Vu, Darius Postma, Don Hickerson, James McGaughran, Huy Q. Khuat British University Vietnam, James Cook University Singapore", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 59, "abstract": "This study investigates the efficacy of six major Generative AI (GenAI) text detectors when confronted with machine-generated content modified to evade detection (n\u2009=\u2009805). We compare these detectors to assess their reliability in identifying AI-generated text in educational settings, where they are increasingly used to address academic integrity concerns. Results show significant reductions in detector accuracy (17.4%) when faced with simple techniques to manipulate the AI generated content. The varying performances of GenAI tools and detectors indicate they cannot currently be recommended for determining academic integrity violations due to accuracy limitations and the potential for false accusation which undermines inclusive and fair assessment practices. However, these tools may support learning and academic integrity when used non-punitively. This study aims to guide educators and institutions in the critical implementation of AI text detectors in higher education, highlighting the importance of exploring alternatives to maintain inclusivity in the face of emerging technologies.", "isOpenAccess": true, "url": "https://doi.org/10.1186/s41239-024-00487-w"}
{"paperId": "e27ed40a8850a74ab478bfae81fa202558557493", "year": 2023, "title": "How AI Threatens Democracy", "authors": "Sarah E. Kreps, Doug Kriner", "venue": "Journal of Democracy", "citationCount": 59, "abstract": "Abstract:The explosive rise of generative AI is already transforming journalism, finance, and medicine, but it could also have a disruptive influence on politics. For example, asking a chatbot how to navigate a complicated bureaucracy or to help draft a letter to an elected official could bolster civic engagement. However, that same technology\u2014with its potential to produce disinformation and misinformation at scale\u2014threatens to interfere with democratic representation, undermine democratic accountability, and corrode social and political trust. This essay analyzes the scope of the threat in each of these spheres and discusses potential guardrails for these misuses, including neural networks used to identify generated content, self-regulation by generative-AI platforms, and greater digital literacy on the part of the public and elites alike.", "isOpenAccess": false, "url": ""}
{"paperId": "cb6d5e3fec71e5dd4437a9b336a01bf66c36e145", "year": 2023, "title": "Generative artificial intelligence and engineering education", "authors": "A. Johri, Andrew Katz, Junaid Qadir, Ashish Hingle", "venue": "Journal of Engineering Education", "citationCount": 59, "abstract": "The recent popularity of generative AI (GAI) applications such as ChatGPT portend a new era of research, teaching, and learning across domains, including in engineering (Bubeck et al., 2023; Kasneci et al., 2023; Lo, 2023; Qadir, 2023). In this guest editorial, we discuss the potential impact of GAI for engineering education as researchers and teachers. We see this editorial as the start of a serious dialogue within the community around how GAI can and will change our practices, and what we can do to respond to these shifts. GAI is built on foundational models (FMs) that can be adapted to various other tasks, such as large language models (LLMs), and they operate by learning from many examples and becoming very good at predicting the subsequent probable output or output sequence. Given the abundance of digitized data, they can quickly learn a wide range of topics and respond to user queries almost instantly. Whether engineering a new software application, writing a code snippet to analyze data, designing a product, or composing a cover letter for a job application, GAI users can leverage the power of LLMs to generate outputs that meet their specific needs (UNESCO, 2023). The ability to learn a skill and adapt it to new contexts is a capability that humans have excelled at for a long time. Some would even argue that the competence to learn original things in new environments to tackle novel problems, and teach it to others, is one of the most unique characteristics of our species (Tomasello, 2009). To assist us in this process, we also have the capability to continually create tools and techniques, another distinct trait of humans and central to the engineering profession (Johri, 2022). What, though, is the potential and limit of developing tools and technologies that can mimic and even go beyond what we have conceived of as human intelligence? What potential consequences do technology that can generate novel outputs have for society, especially education in terms of both benefits and harms (Bommasani et al., 2021; Farrokhnia et al., 2023)? What implications does this have for engineering educators (Johri, 2020)? While we discuss how GAI shapes research and teaching practices within engineering education, we recognize that there are additional implications for the use of GAI for self-motivated and sustained learning initiated by learners on their own. That topic is beyond the scope of this editorial and discussed in some detail in the Menekse et al.0s guest editorial in this issue.", "isOpenAccess": true, "url": "https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1002/jee.20537"}
{"paperId": "c8691974e7459989d0b9c8da027599b582910c0c", "year": 2025, "title": "Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails", "authors": "Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, J. Varghese, Christopher Parisien", "venue": "North American Chapter of the Association for Computational Linguistics", "citationCount": 59, "abstract": "As Large Language Models (LLMs) and generative AI become increasingly widespread, concerns about content safety have grown in parallel. Currently, there is a clear lack of high-quality, human-annotated datasets that address the full spectrum of LLM-related safety risks and are usable for commercial applications. To bridge this gap, we propose a comprehensive and adaptable taxonomy for categorizing safety risks, structured into 12 top-level hazard categories with an extension to 9 fine-grained subcategories. This taxonomy is designed to meet the diverse requirements of downstream users, offering more granular and flexible tools for managing various risk types. Using a hybrid data generation pipeline that combines human annotations with a multi-LLM\"jury\"system to assess the safety of responses, we obtain Aegis 2.0, a carefully curated collection of 34,248 samples of human-LLM interactions, annotated according to our proposed taxonomy. To validate its effectiveness, we demonstrate that several lightweight models, trained using parameter-efficient techniques on Aegis 2.0, achieve performance competitive with leading safety models fully fine-tuned on much larger, non-commercial datasets. In addition, we introduce a novel training blend that combines safety with topic following data.This approach enhances the adaptability of guard models, enabling them to generalize to new risk categories defined during inference. We plan to open-source Aegis 2.0 data and models to the research community to aid in the safety guardrailing of LLMs.", "isOpenAccess": false, "url": ""}
{"paperId": "99fc800f20fbdc7bbb70cc5dbd456959338ce7b8", "year": 2023, "title": "A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material", "authors": "Mengchun Zhang, Maryam Qamar, Taegoo Kang, Yuna Jung, Chenshuang Zhang, S. Bae, Chaoning Zhang", "venue": "arXiv.org", "citationCount": 59, "abstract": "Diffusion models have become a new SOTA generative modeling method in various fields, for which there are multiple survey works that provide an overall survey. With the number of articles on diffusion models increasing exponentially in the past few years, there is an increasing need for surveys of diffusion models on specific fields. In this work, we are committed to conducting a survey on the graph diffusion models. Even though our focus is to cover the progress of diffusion models in graphs, we first briefly summarize how other generative modeling methods are used for graphs. After that, we introduce the mechanism of diffusion models in various forms, which facilitates the discussion on the graph diffusion models. The applications of graph diffusion models mainly fall into the category of AI-generated content (AIGC) in science, for which we mainly focus on how graph diffusion models are utilized for generating molecules and proteins but also cover other cases, including materials design. Moreover, we discuss the issue of evaluating diffusion models in the graph domain and the existing challenges.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.01565"}
{"paperId": "38c5f3332f54d6876b74427482508bbf39b8fa33", "year": 2024, "title": "Generative AI in education and research: A\u00a0systematic mapping review", "authors": "Abdullahi Yusuf, Nasrin Pervin, Marcos Rom\u00e1n\u2010Gonz\u00e1lez, Norah Md Noor", "venue": "Revista de educaci\u00f3n", "citationCount": 59, "abstract": "Given the potential applications of generative AI (GenAI) in education and its rising interest in research, this systematic review mapped the thematic landscape of 407 publications indexed in the Web of Science, ScienceDirect and Scopus. Using EPPI Reviewer, publication type, educational level, disciplines, research areas and applications of GenAI were extracted. Eight discursive themes were identified, predominantly focused on \u2018application, impact and potential\u2019, \u2018ethical implication and risks\u2019, \u2018perspectives and experiences\u2019, \u2018institutional and individual adoption\u2019, and \u2018performance and intelligence\u2019. GenAI was conceptualised as a tool for \u2018pedagogical enhancement\u2019, \u2018specialised training and practices\u2019, \u2018writing assistance\u00a0and productivity\u2019, \u2018professional skills and development\u2019, and as an \u2018interdisciplinary learning tool\u2019. Key gaps highlighted include a paucity of research and discussions on GenAI in K\u201012 education; a limited exploration of GenAI's impact using experimental procedures; and a limited exploration of the potential and ethical concerns of GenAI from the lens of cultural dimensions. Promising opportunities for future research are highlighted.", "isOpenAccess": false, "url": ""}
{"paperId": "09b213eb39f031e8588b0ac940c3443c073ca40e", "year": 2025, "title": "Artificial Intelligence in Natural Product Drug Discovery: Current Applications and Future Perspectives", "authors": "Amit Gangwal, Antonio Lavecchia", "venue": "Journal of Medicinal Chemistry", "citationCount": 59, "abstract": "Drug discovery, a multifaceted process from compound identification to regulatory approval, historically plagued by inefficiencies and time lags due to limited data utilization, now faces urgent demands for accelerated lead compound identification. Innovations in biological data and computational chemistry have spurred a shift from trial-and-error methods to holistic approaches to medicinal chemistry. Computational techniques, particularly artificial intelligence (AI), notably machine learning (ML) and deep learning (DL), have revolutionized drug development, enhancing data analysis and predictive modeling. Natural products (NPs) have long served as rich sources of biologically active compounds, with many successful drugs originating from them. Advances in information science expanded NP-related databases, enabling deeper exploration with AI. Integrating AI into NP drug discovery promises accelerated discoveries, leveraging AI\u2019s analytical prowess, including generative AI for data synthesis. This perspective illuminates AI\u2019s current landscape in NP drug discovery, addressing strengths, limitations, and future trajectories to advance this vital research domain.", "isOpenAccess": true, "url": "https://doi.org/10.1021/acs.jmedchem.4c01257"}
{"paperId": "eaa13b6982ce5b7acee0b11bf3763fc25a4547ae", "year": 2023, "title": "ChatGPT: The transformative influence of generative AI on science and healthcare.", "authors": "J. Varghese, J. Chapiro", "venue": "Journal of Hepatology", "citationCount": 58, "abstract": null, "isOpenAccess": true, "url": "http://www.journal-of-hepatology.eu/article/S0168827823050390/pdf"}
{"paperId": "e65b98ecdfc61f7429b9df03d9ac431289b29f54", "year": 2024, "title": "Higher education crisis: Academic misconduct with generative AI", "authors": "NaYoung Song", "venue": "Journal of Contingencies and Crisis Management", "citationCount": 58, "abstract": "Higher educational institutions (HEIs) are facing a significant challenge in maintaining academic integrity due to the technological integration of generative artificial intelligence (AI). The widespread use of AI tools by college students has resulted in an increase in plagiarism and cheating, highlighting the need for effective implementation of this technology. However, there is a lack of research on the best practices for using AI in academic settings. HEIs must take responsibility for addressing these issues, as the majority of institutions do not have formal guidelines for AI use, leading to confusion among students and instructors. To combat academic misconduct, HEIs should establish clear objectives and policies for the equitable, inclusive, and ethical use of AI. Improving AI literacy among students and faculty is crucial, as it ensures that everyone has equal access to technology, preventing a digital divide. Moreover, proactive education on the ethical use of AI is vital for HEIs to prepare students for the AI\u2010driven future of education and maintain academic integrity.", "isOpenAccess": false, "url": ""}
{"paperId": "db329fd9eada8b2f6533272b6e210c212dcbeab4", "year": 2023, "title": "Augmenting Greybox Fuzzing with Generative AI", "authors": "Jie Hu, Qian Zhang, Heng Yin", "venue": "arXiv.org", "citationCount": 58, "abstract": "Real-world programs expecting structured inputs often has a format-parsing stage gating the deeper program space. Neither a mutation-based approach nor a generative approach can provide a solution that is effective and scalable. Large language models (LLM) pre-trained with an enormous amount of natural language corpus have proved to be effective for understanding the implicit format syntax and generating format-conforming inputs. In this paper, propose ChatFuzz, a greybox fuzzer augmented by generative AI. More specifically, we pick a seed in the fuzzer's seed pool and prompt ChatGPT generative models to variations, which are more likely to be format-conforming and thus of high quality. We conduct extensive experiments to explore the best practice for harvesting the power of generative LLM models. The experiment results show that our approach improves the edge coverage by 12.77\\% over the SOTA greybox fuzzer (AFL++) on 12 target programs from three well-tested benchmarks. As for vulnerability detection, \\sys is able to perform similar to or better than AFL++ for programs with explicit syntax rules but not for programs with non-trivial syntax.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.06782"}
{"paperId": "cad3f70ea44442cee36cf1e97408455b70267526", "year": 2023, "title": "Brain-Diffuser: Natural scene reconstruction from fMRI signals using generative latent diffusion", "authors": "Furkan Ozcelik, R. V. Rullen", "venue": "arXiv.org", "citationCount": 58, "abstract": null, "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.05334"}
{"paperId": "79c6278423c07915ae5ec409b0110d15c45bef8c", "year": 2024, "title": "The Illusion of Artificial Inclusion", "authors": "William Agnew, A. S. Bergman, Usa Google DeepMind, Jennifer Chien, Mark D\u00edaz, Usa Google Research, Seliem El-Sayed, Shakir Mohamed, Kevin McKee, Jaylen Pittman", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 58, "abstract": "Human participants play a central role in the development of modern artificial intelligence (AI) technology, in psychological science, and in user research. Recent advances in generative AI have attracted growing interest to the possibility of replacing human participants in these domains with AI surrogates. We survey several such \u201csubstitution proposals\u201d to better understand the arguments for and against substituting human participants with modern generative AI. Our scoping review indicates that the recent wave of these proposals is motivated by goals such as reducing the costs of research and development work and increasing the diversity of collected data. However, these proposals ignore and ultimately conflict with foundational values of work with human participants: representation, inclusion, and understanding. This paper critically examines the principles and goals underlying human participation to help chart out paths for future work that truly centers and empowers participants.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642703"}
{"paperId": "6cdb155ba2f5cbeea398237f28529a95405cd5c7", "year": 2024, "title": "Generative AI chatbots in higher education: a review of an emerging research area", "authors": "C. McGrath, Alexandra Farazouli, Teresa Cerratto-Pargman", "venue": "Higher Education", "citationCount": 58, "abstract": "Artificial intelligence (AI) chatbots trained on large language models are an example of generative AI which brings promises and threats to the higher education sector. In this study, we examine the emerging research area of AI chatbots in higher education (HE), focusing specifically on empirical studies conducted since the release of ChatGPT. Our review includes 23 research articles published between December 2022 and December 2023 exploring the use of AI chatbots in HE settings. We take a three-pronged approach to the empirical data. We first examine the state of the emerging field of AI chatbots in HE. Second, we identify the theories of learning used in the empirical studies on AI chatbots in HE. Third, we scrutinise the discourses of AI in HE framing the latest empirical work on AI chatbots. Our findings contribute to a better understanding of the eclectic state of the nascent research area of AI chatbots in HE, the lack of common conceptual groundings about human learning, and the presence of both dystopian and utopian discourses about the future role of AI chatbots in HE.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10734-024-01288-w.pdf"}
{"paperId": "5caf2471bf747b773e52c6aaba46be752386d2ac", "year": 2024, "title": "Generative AI\u2019s Impact on Critical Thinking: Revisiting Bloom\u2019s Taxonomy", "authors": "Chahna Gonsalves", "venue": "Journal of Marketing Education", "citationCount": 58, "abstract": "The integration of generative artificial intelligence (AI) tools like ChatGPT in education has raised concerns that students may become dependent on AI-generated solutions, potentially stifling the development of critical thinking skills. Compounding this issue is the fact that Bloom\u2019s Taxonomy\u2014the widely used framework for designing educational goals\u2014fails to address the cognitive demands of AI-assisted learning. This exploratory study presents a revised framework that incorporates AI-specific competencies, offering a more relevant model for nurturing critical thinking in an AI-driven environment. Using a conceptual approach supported by empirical evidence from MSc Marketing students\u2019 interactions with AI tools over 4 weeks, the study found that AI can both enhance and challenge critical thinking across cognitive, affective, and metacognitive domains. Key elements such as melioration, ethical reasoning, collaboration, and reflective thinking were identified as critical for developing deeper engagement with AI-generated content. The framework proposes 12 propositions that inform future research and pedagogical strategies. This study outlines a research agenda for examining AI\u2019s impact on cognitive development, serving as a resource for educators, policymakers, and researchers seeking to adapt teaching methods for AI-assisted education.", "isOpenAccess": false, "url": ""}
{"paperId": "51aaaff4f12e4c6b0a6b2826f4e3a1fd9e1ce8c6", "year": 2023, "title": "From Generative AI to Generative Internet of Things: Fundamentals, Framework, and Outlooks", "authors": "Jinbo Wen, Jiangtian Nie, Jiawen Kang, D. Niyato, Hongyang Du, Yang Zhang, Mohsen Guizani", "venue": "IEEE Internet of Things Magazine", "citationCount": 58, "abstract": "Generative Artificial Intelligence (GAI) possesses the capabilities of generating realistic data and facilitating advanced decision-making. By integrating GAI into modern Internet of Things (IoT), Generative Internet of Things (GIoT) is emerging and holds immense potential to revolutionize various aspects of society, enabling more efficient and intelligent IoT applications, such as smart surveillance and voice assistants. In this article, we present the concept of GIoT and conduct an exploration of its potential prospects. Specifically, we first overview four GAI techniques and investigate promising GIoT applications. Then, we elaborate on the main challenges in enabling GIoT and propose a general GAI-based secure incentive mechanism framework to address them, in which we adopt Generative Diffusion Models (GDMs) for incentive mechanism designs and apply blockchain technologies for secure GIoT management. Moreover, we conduct a case study on modern Internet of Vehicle traffic monitoring, which utilizes GDMs to generate effective contracts for incentivizing users to contribute sensing data with high quality. Numerical results demonstrate the superiority of the proposed scheme. Finally, we suggest several open directions worth investigating for the future popularity of GIoT.", "isOpenAccess": false, "url": ""}
{"paperId": "4b0759e89d9562305a104090b20cfda6f1e3d05e", "year": 2024, "title": "Can Generative AI and ChatGPT Outperform Humans on Cognitive-Demanding Problem-Solving Tasks in Science?", "authors": "Xiaoming Zhai, Matthew Nyaaba, Wenchao Ma", "venue": "Science Education", "citationCount": 58, "abstract": "This study aimed to examine an assumption regarding whether generative artificial intelligence (GAI) tools can overcome the cognitive intensity that humans suffer when solving problems. We examine the performance of ChatGPT and GPT-4 on NAEP science assessments and compare their performance to students by cognitive demands of the items. Fifty-four 2019 NAEP science assessment tasks were coded by content experts using a two-dimensional cognitive load framework, including task cognitive complexity and dimensionality. ChatGPT and GPT-4 answered the questions individually and were scored using the scoring keys provided by NAEP. The analysis of the available data for this study was based on the average student ability scores for students who answered each item correctly and the percentage of students who responded to individual items. The results showed that both ChatGPT and GPT-4 consistently outperformed most students who answered each individual item in the NAEP science assessments. As the cognitive demand for NAEP science assessments increases, statistically higher average student ability scores are required to correctly address the questions. This pattern was observed for Grades 4, 8, and 12 students respectively. However, ChatGPT and GPT-4 were not statistically sensitive to the increase of cognitive demands of the tasks, except for Grade 4. As the first study focusing on comparing cutting-edge GAI and K-12 students in problem-solving in science, this finding implies the need for changes to educational objectives to prepare students with competence to work with GAI tools such as ChatGPT and GPT-4 in the future. Education ought to emphasize the cultivation of advanced cognitive skills rather than depending solely on tasks that demand cognitive intensity. This approach would foster critical thinking, analytical skills, and the application of knowledge in novel contexts among students. Furthermore, the findings suggest that researchers should innovate assessment practices by moving away from cognitive intensity tasks toward creativity and analytical skills to more efficiently avoid the negative effects of GAI on testing.", "isOpenAccess": false, "url": ""}
{"paperId": "10dbda610567255cd3ef10ba5b5365e080c9859b", "year": 2023, "title": "When is a Tool a Tool? User Perceptions of System Agency in Human\u2013AI Co-Creative Drawing", "authors": "Tomas Lawton, Kazjon Grace, F. Ibarrola", "venue": "Conference on Designing Interactive Systems", "citationCount": 58, "abstract": "This paper presents an analysis of the user experience of Reframer, a novel human-AI drawing interface designed with the iterative and reflective nature of creativity in mind. Collaboration with Reframer occurs in real time, with the user and the system drawing together concurrently. This approach is inspired by theories of creativity as being more problem-framing than problem-solving, and contrasts with the automated one-shot end-to-end workflows of most generative AI models. A 12-participant qualitative exploratory study of the capabilities of our prototype is detailed, as well as a thematic analysis of user attitudes towards drawing with it. The paper then describes two modified prototypes and a second 32-participant comparative study revealing how interface variations evoke differences in user attitudes and experiences. It concludes by proposing a model that characterises the conditions under which users experience co-creative AI as a collaborator, rather than a non-agentive tool.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3563657.3595977"}
{"paperId": "ff090c3fc5eb00daf059331f61a1ea70d11b5ace", "year": 2024, "title": "Generative AI models for different steps in architectural design: A literature review", "authors": "Chengyuan Li, Tianyu Zhang, Xu Du, Ye Zhang, Haoran Xie", "venue": "Frontiers of Architectural Research", "citationCount": 57, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.foar.2024.10.001"}
{"paperId": "e09979f9f72cd4dbc8634f54e612430a382ab65f", "year": 2023, "title": "Leveraging Generative AI Models for Synthetic Data Generation in Healthcare: Balancing Research and Privacy", "authors": "Aryan Jadon, Shashank Kumar", "venue": "International Conference on Smart Communications and Networking", "citationCount": 57, "abstract": "The widespread adoption of electronic health records and digital healthcare data has created a demand for data-driven insights to enhance patient outcomes, diagnostics, and treatments. However, using real patient data presents privacy and regulatory challenges, including compliance with HIPAA [1] and GDPR [2]. Synthetic data generation, using generative AI models like GANs [3] and VAEs [4], offers a promising solution to balance valuable data access and patient privacy protection. In this paper, we examine generative AI models for creating realistic, anonymized patient data for research and training [5], explore synthetic data applications in healthcare, and discuss its benefits, challenges, and future research directions. Synthetic data has the potential to revolutionize healthcare by providing anonymized patient data while preserving privacy and enabling versatile applications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.05247"}
{"paperId": "d9ef609651f285abe37d4b80daa9f0e1183acbac", "year": 2023, "title": "Towards Anatomy Education with Generative AI-based Virtual Assistants in Immersive Virtual Reality Environments", "authors": "Vuthea Chheang, Rommy Marquez-Hernandez, Megha Patel, D. Rajasekaran, Shayla Sharmin, Gavin Caulfield, Behdokht Kiafar, Jicheng Li, R. Barmaki", "venue": "2024 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)", "citationCount": 57, "abstract": "Virtual reality (VR) and interactive 3D visualization systems have enhanced educational experiences and environments, particularly in complicated subjects such as anatomy education. VR-based systems surpass the potential limitations of traditional training approaches in facilitating interactive engagement among students. However, research on embodied virtual assistants that leverage generative artificial intelligence (AI) and verbal communication in the anatomy education context is underrepresented. In this work, we introduce a VR environment with a generative AI-embodied virtual assistant to support participants in responding to varying cognitive complexity anatomy questions and enable verbal communication. We assessed the technical efficacy and usability of the proposed environment in a pilot user study with 16 participants. We conducted a within-subject design for virtual assistant configuration (avatar- and screen-based), with two levels of cognitive complexity (knowledge- and analysis-based). The results reveal a significant difference in the scores obtained from knowledge- and analysis-based questions in relation to avatar configuration. Moreover, results provide insights into usability, cognitive task load, and the sense of presence in the proposed virtual assistant configurations. Our environment and results of the pilot study offer potential benefits and future research directions beyond medical education, using generative AI and embodied virtual agents as customized virtual conversational assistants.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2306.17278"}
{"paperId": "d5f229bda2af3f4415decec1d0298d38c1e51a6c", "year": 2024, "title": "Generative AI usage and sustainable supply chain performance: A practice-based view", "authors": "Lixu Li, Wenwen Zhu, Lujie Chen, Yaoqi Liu", "venue": "Transportation Research Part E: Logistics and Transportation Review", "citationCount": 57, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "98d83e27a1f322879aa2585d5ca0eff6f987d342", "year": 2024, "title": "Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools", "authors": "James Prather, Juho Leinonen, Natalie Kiesler, Jamie Gorson Benario, Sam Lau, Stephen Macneil, Narges Norouzi, Simone Opel, Vee Pettit, Leo Porter, Brent N. Reeves, Jaromir Savelka, IV DavidH.Smith, Sven Strickroth, Daniel Zingaro", "venue": "ITiCSE-WGR", "citationCount": 57, "abstract": "Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2412.14732"}
{"paperId": "84f4ebde52a8d543367ca063df6866a5f6a67c86", "year": 2024, "title": "Generative AI for Secure Physical Layer Communications: A Survey", "authors": "Changyuan Zhao, Hongyang Du, D. Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, Xuemin Shen, K. B. Letaief", "venue": "IEEE Transactions on Cognitive Communications and Networking", "citationCount": 57, "abstract": "Generative Artificial Intelligence (GAI) stands at the forefront of AI innovation, demonstrating rapid advancement and unparalleled proficiency in generating diverse content. Beyond content creation, GAI has significant analytical abilities to learn complex data distribution, offering numerous opportunities to resolve security issues. In the realm of security from physical layer perspectives, traditional AI approaches frequently struggle, primarily due to their limited capacity to dynamically adjust to the evolving physical attributes of transmission channels and the complexity of contemporary cyber threats. This adaptability and analytical depth are precisely where GAI excels. Therefore, in this paper, we offer an extensive survey on the various applications of GAI in enhancing security within the physical layer of communication networks. We first emphasize the importance of advanced GAI models in this area, including Generative Adversarial Networks (GANs), Autoencoders (AEs), Variational Autoencoders (VAEs), and Diffusion Models (DMs). We delve into the roles of GAI in addressing challenges of physical layer security, focusing on communication confidentiality, authentication, availability, resilience, and integrity. Furthermore, we also present future research directions focusing model improvements, multi-scenario deployment, resource-efficient optimization, and secure semantic communication, highlighting the multifaceted potential of GAI to address emerging challenges in secure physical layer communications and sensing.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2402.13553"}
{"paperId": "5a90a8f4ec612cef6b1bb9cf4eae897385d33c2d", "year": 2023, "title": "An Overview on Generative AI at Scale With Edge\u2013Cloud Computing", "authors": "Yun Cheng Wang, Jintang Xue, Chengwei Wei, C.-C. Jay Kuo", "venue": "IEEE Open Journal of the Communications Society", "citationCount": 57, "abstract": "As a specific category of artificial intelligence (AI), generative artificial intelligence (GenAI) generates new content that resembles what humans create. The rapid development of GenAI systems has created a huge amount of new data on the Internet, posing new challenges to current computing and communication frameworks. Currently, GenAI services rely on the traditional cloud computing framework due to the need for large computation resources. However, such services will encounter high latency because of data transmission and a high volume of user requests. On the other hand, edge-cloud computing can provide adequate computation power and low latency at the same time through the collaboration between edges and the cloud. Thus, it is attractive to build GenAI systems at scale by leveraging the edge-cloud computing paradigm. In this overview paper, we review recent developments in GenAI and edge-cloud computing, respectively. Then, we use two exemplary GenAI applications to discuss technical challenges in scaling up their solutions using edge-cloud collaborative systems. Finally, we list design considerations for training and deploying GenAI systems at scale and point out future research directions.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/8782661/8901158/10268594.pdf"}
{"paperId": "2b1d9d09a56cfc820e76df99b60c0b793bb86621", "year": 2024, "title": "A fine-tuned tourism-specific generative AI concept", "authors": "Cathy H. C. Hsu, Guoxiong Tan, Bela Stantic", "venue": "Annals of Tourism Research", "citationCount": 57, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "ee4c1921d60daceec5c02e1e15a157060aa33422", "year": 2024, "title": "AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas", "authors": "Jessica He, Stephanie Houde, G. E. Gonzalez, Dar\u00edo Andr\u00e9s Silva Moran, Steven I. Ross, Michael J. Muller, Justin D. Weisz", "venue": "Symposium on Human-Computer Interaction for Work", "citationCount": 56, "abstract": "The introduction of generative AI into multi-user applications raises novel considerations for the future of collaborative work. How might collaborative work practices change? How might we incorporate generative AI into shared tools with users\u2019 needs at the forefront? We examine these questions in the context of a remote team conducting ideation tasks \u2013 an example of collaborative work enabled by a shared digital workspace. We conducted a user study with 17 professionals experienced with virtual group ideation workshops. Our study examined their use of the Collaborative Canvas, a virtual canvas tool with integrated generative AI capabilities that we created as a probe. Participants saw value in using generative AI to assist with group facilitation and to augment perspectives and ideas. However, they worried about losing human perspectives and critical thinking, as well as reputational harms resulting from harmful AI outputs. Participants shared suggestions for appropriate ways to incorporate generative AI capabilities within multi-user applications and identified needs for transparency of content ownership, private digital spaces, and specialized AI capabilities. Based on participants\u2019 insights, we share implications and opportunities for the incorporation of generative AI into collaborative work in ways that place user needs at the forefront.", "isOpenAccess": false, "url": ""}
{"paperId": "d8922dc57e9cbe9e2ee9c9edeef0758fb69db00b", "year": 2023, "title": "Friend or foe? Exploring the implications of large language models on the science system", "authors": "Benedikt Fecher, Marcel Hebing, Melissa Laufer, J\u00f6rg Pohle, Fabian Sofsky", "venue": "Ai & Society", "citationCount": 56, "abstract": "The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 researchers specializing in AI and digitization. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and helps identify areas for future action.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s00146-023-01791-1.pdf"}
{"paperId": "d14dd743aa45e2ae365243b71fada5c0799fafee", "year": 2024, "title": "The ChatGPT effect and transforming nursing education with generative AI: Discussion paper.", "authors": "Lucija Gosak, Lisiane Pruinelli, Maxim Topaz, Gregor Stiglic", "venue": "Nurse Education in Practice", "citationCount": 56, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "ce4f78d38e5ae6b3b8361016b2fbb173deb64b8e", "year": 2023, "title": "Letter to editor: NLP systems such as ChatGPT cannot be listed as an author because these cannot fulfill widely adopted authorship criteria", "authors": "N. S. Yeo-Teh, B. Tang", "venue": "Accountability in Research", "citationCount": 56, "abstract": "ABSTRACT This letter to the editor suggests adding a technical point to the new editorial policy expounded by Hosseini et al. on the mandatory disclosure of any use of natural language processing (NLP) systems, or generative AI, in writing scholarly publications. Such AI systems should naturally also be forbidden from being named as authors, because they would not have fulfilled prevailing authorship guidelines (such as the widely adopted ICMJE authorship criteria).", "isOpenAccess": false, "url": ""}
{"paperId": "c6b8f70704cb066d4d731cc2426ad2ab4fbb8bc0", "year": 2023, "title": "Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models", "authors": "Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff", "venue": "JMIR Medical Education", "citationCount": 56, "abstract": "Background Patients with rare and complex diseases often experience delayed diagnoses and misdiagnoses because comprehensive knowledge about these diseases is limited to only a few medical experts. In this context, large language models (LLMs) have emerged as powerful knowledge aggregation tools with applications in clinical decision support and education domains. Objective This study aims to explore the potential of 3 popular LLMs, namely Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical education to enhance the diagnosis of rare and complex diseases while investigating the impact of prompt engineering on their performance. Methods We conducted experiments on publicly available complex and rare cases to achieve these objectives. We implemented various prompt strategies to evaluate the performance of these models using both open-ended and multiple-choice prompts. In addition, we used a majority voting strategy to leverage diverse reasoning paths within language models, aiming to enhance their reliability. Furthermore, we compared their performance with the performance of human respondents and MedAlpaca, a generative LLM specifically designed for medical tasks. Results Notably, all LLMs outperformed the average human consensus and MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 cases from the diagnostic case challenge collection. On the frequently misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca and the human respondents on the moderately often misdiagnosed cases category with minimum accuracy scores of 28% and 11%, respectively. The majority voting strategy, particularly with GPT-4, demonstrated the highest overall score across all cases from the diagnostic complex case collection, surpassing that of other LLMs. On the Medical Information Mart for Intensive Care-III data sets, Bard and GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, respectively. Furthermore, our results demonstrate that there is no one-size-fits-all prompting approach for improving the performance of LLMs and that a single strategy does not universally apply to all LLMs. Conclusions Our findings shed light on the diagnostic capabilities of LLMs and the challenges associated with identifying an optimal prompting strategy that aligns with each language model\u2019s characteristics and specific task requirements. The significance of prompt engineering is highlighted, providing valuable insights for researchers and practitioners who use these language models for medical training. Furthermore, this study represents a crucial step toward understanding how LLMs can enhance diagnostic reasoning in rare and complex medical cases, paving the way for developing effective educational tools and accurate diagnostic aids to improve patient care and outcomes.", "isOpenAccess": true, "url": "https://mededu.jmir.org/2024/1/e51391/PDF"}
{"paperId": "aab02122501817286a02d85ff06d2081da8a937c", "year": 2024, "title": "MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding", "authors": "Xu Cao, Tongxi Zhou, Yunsheng Ma, Wenqian Ye, Can Cui, Kun Tang, Zhipeng Cao, Kaizhao Liang, Ziran Wang, J. Rehg, Chao Zheng", "venue": "Computer Vision and Pattern Recognition", "citationCount": 56, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "9ccdbbcb9aa033589fe4c0367c5295cd1c30befc", "year": 2024, "title": "Generative AI and higher education: a review of claims from the first months of ChatGPT", "authors": "Lasse X. Jensen, Alexandra Buhl, Anjali Sharma, M. Bearman", "venue": "Higher Education", "citationCount": 56, "abstract": "The release of the Artificial Intelligence (AI) chatbot ChatGPT renewed discussions about how AI would upend higher education. This paper presents a critical analysis of \u201cgrey literature\u201d claims made in the first months after ChatGPT was made public, exploring what these discussions might mobilise in practice. We identified articles for inclusion through a systematic search of five prominent higher education sector outlets. The included articles were thematically coded for claims about generative AI and higher education. We identified ten claims: Three about the nature of ChatGPT, four about changing practices of institutions and teachers, and three about new independent practices of students. Overall, the claims present a positive perspective on AI in higher education. While being perceived as a disruption of the status quo, the authors generally frame AI as a catalyst for existing agendas, e.g. assessment reform, personalisation, or inclusion. This suggests a focus on embracing the affordances offered by AI and primarily addressing risks by including AI in curricula. Furthermore, the claims mainly portray students as either plagiarists or victims of a failing educational system. The paper proposes that a more critical interrogation of generative AI, and the involvement of students in the conversation, may be beneficial.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10734-024-01265-3.pdf"}
{"paperId": "876ab228f4b1026a3e9ef9d1f99f28f96b77b3e4", "year": 2024, "title": "Why and how is the power of Big Tech increasing in the policy process? The case of generative AI", "authors": "Shaleen Khanal, Hongzhou Zhang, Araz Taeihagh", "venue": "Policy & Society", "citationCount": 56, "abstract": "\n The growing digitalization of our society has led to a meteoric rise of large technology companies (Big Tech), which have amassed tremendous wealth and influence through their ownership of digital infrastructure and platforms. The recent launch of ChatGPT and the rapid popularization of generative artificial intelligence (GenAI) act as a focusing event to further accelerate the concentration of power in the hands of the Big Tech. By using Kingdon\u2019s multiple streams framework, this article investigates how Big Tech utilize their technological monopoly and political influence to reshape the policy landscape and establish themselves as key actors in the policy process. It explores the implications of the rise of Big Tech for policy theory in two ways. First, it develops the Big Tech-centric technology stream, highlighting the differing motivations and activities from the traditional innovation-centric technology stream. Second, it underscores the universality of Big Tech exerting ubiquitous influence within and across streams, to primarily serve their self-interests rather than promote innovation. Our findings emphasize the need for a more critical exploration of policy role of Big Tech to ensure balanced and effective policy outcomes in the age of AI.", "isOpenAccess": true, "url": "https://academic.oup.com/policyandsociety/advance-article-pdf/doi/10.1093/polsoc/puae012/57102619/puae012.pdf"}
{"paperId": "84b8624b41eb594abbd8d256cc5bc8a43c942a75", "year": 2023, "title": "Supporting self-directed learning and self-assessment using TeacherGAIA, a generative AI chatbot application: Learning approaches and prompt engineering", "authors": "Farhan Ali, Doris Choy, Shanti Divaharan, Hui Yong Tay, Wenli Chen", "venue": "Learning: Research and Practice", "citationCount": 56, "abstract": "ABSTRACT Self-directed learning and self-assessment require student responsibility over learning needs, goals, processes, and outcomes. However, this student-led learning can be challenging to achieve in a classroom limited by a one-to-many teacher-led instruction. We, thus, have designed and prototyped a generative artificial intelligence chatbot application (GAIA), named TeacherGAIA, that can be used to asynchronously support students in their self-directed learning and self-assessment outside the classroom. We first identified diverse constructivist learning approaches that align with, and promote, student-led learning. These included knowledge construction, inquiry-based learning, self-assessment, and peer teaching. The in-context learning abilities of large language model (LLM) from OpenAI were then leveraged via prompt engineering to steer interactions supporting these different learning approaches. These interactions contrasted with ChatGPT, OpenAI\u2019s chatbot which by default engaged in the traditional transmissionist mode of learning reminiscent of teacher-led instruction. Preliminary design, prompt engineering and prototyping suggested fidelity to the learning approaches, cognitive guidance, and social-emotional support, all of which were implemented in a generative AI manner without pre-specified rules or \u201chard-coding\u201d. Other affordances of TeacherGAIA are discussed and future development outlined. We anticipate TeacherGAIA to be a useful application for teachers in facilitating self-directed learning and self-assessment among K-12 students.", "isOpenAccess": false, "url": ""}
{"paperId": "625c727243a075ea71cbe51d5ef3aa86ba1bac7e", "year": 2024, "title": "Generative AI for synthetic data across multiple medical modalities: A systematic review of recent developments and challenges", "authors": "Mahmoud K. Ibrahim, Yasmina Alkhalil, S. Amirrajab, Chang Sun, M. Breeuwer, J. Pluim, Bart Elen, G\u00f6khan Ertaylan, Michel Dumontier", "venue": "Comput. Biol. Medicine", "citationCount": 56, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "27176bbf705e9e0519ce366ab712404e75d9c31c", "year": 2024, "title": "Examining the moderating effect of motivation on technology acceptance of generative AI for English as a foreign language learning", "authors": "Yi Zheng, Yabing Wang, Kelly Shu-xia Liu, M. Jiang", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 56, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "1d61410f21de30eec4193b06383897e883608a84", "year": 2023, "title": "Generative AI for Business Decision-Making: A Case of ChatGPT", "authors": "E. Chuma, Gabriel Gomes de Oliveira", "venue": "Management Science and Business Decisions", "citationCount": 56, "abstract": "ChatGPT (Generative Pretrained Transformer) is a chatbot using artificial intelligence (AI) launched by OpenAI, which is an AI research and deployment company. The ChatGPT has taken the technology world by storm. The ChatGPT is a trained AI model that can chat almost like a human. The dialog format allows the ChatGPT to answer follow-up questions, admit mistakes, challenge incorrect premises, and reject inappropriate requests. The ChatGPT can be utilized for compiling research, drafting marketing content, brainstorming ideas, delivering aftercare services, increasing customer engagement, and many others. The ChatGPT can provide enormous opportunities for companies leveraging this breakthrough technology strategically. Thus, we evaluate ChatGPT as a tool in common business decision-making cases in the current study. For example, the ChatGPT was asked about the impacts of a hypothetical merging of two supermarket chains in Sweden. In another example, the ChatGPT was asked about recommendations for investment in a Brazilian oil company. Finally, it was asked about the factors that influence online shopping behavior. The results are significant and demonstrate the tremendous potential of the ChatGPT in revolutionizing the corporate world.\n\u00a0", "isOpenAccess": true, "url": "http://publish.thescienceinsight.com/index.php/msbd/article/download/63/44"}
{"paperId": "1adb97650f0d9122ad28116897731ccb08e6f422", "year": 2023, "title": "A Prompt Log Analysis of Text-to-Image Generation Systems", "authors": "Yutong Xie, Zhaoying Pan, Jing Ma, Jie Luo, Qiaozhu Mei", "venue": "The Web Conference", "citationCount": 56, "abstract": "Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \u201cprompt\u201d. These systems have immediately received lots of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale. We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs. Users make more edits within creation sessions, which present remarkable exploratory patterns. There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2303.04587"}
{"paperId": "1554d7e72a8b5bcad108ff1d0c9014ddfaaebd0f", "year": 2023, "title": "Safety of Large Language Models in Addressing Depression", "authors": "T. F. Heston", "venue": "Cureus", "citationCount": 56, "abstract": "Background Generative artificial intelligence (AI) models, exemplified by systems such as ChatGPT, Bard, and Anthropic, are currently under intense investigation for their potential to address existing gaps in mental health support. One implementation of these large language models involves the development of mental health-focused conversational agents, which utilize pre-structured prompts to facilitate user interaction without requiring specialized knowledge in prompt engineering. However, uncertainties persist regarding the safety and efficacy of these agents in recognizing severe depression and suicidal tendencies. Given the well-established correlation between the severity of depression and the risk of suicide, improperly calibrated conversational agents may inadequately identify and respond to crises. Consequently, it is crucial to investigate whether publicly accessible repositories of mental health-focused conversational agents can consistently and safely address crisis scenarios before considering their adoption in clinical settings. This study assesses the safety of publicly available ChatGPT-3.5 conversational agents by evaluating their responses to a patient simulation indicating worsening depression and suicidality. Methodology This study evaluated ChatGPT-3.5 conversational agents on a publicly available repository specifically designed for mental health counseling. Each conversational agent was evaluated twice by a highly structured patient simulation. First, the simulation indicated escalating suicide risk based on the Patient Health Questionnaire (PHQ-9). For the second patient simulation, the escalating risk was presented in a more generalized manner not associated with an existing risk scale to assess the more generalized ability of the conversational agent to recognize suicidality. Each simulation recorded the exact point at which the conversational agent recommended human support. Then, the simulation continued until the conversational agent stopped entirely and shut down completely, insisting on human intervention. Results All 25 agents available on the public repository FlowGPT.com were evaluated. The point at which the conversational agents referred to a human occurred around the mid-point of the simulation, and definitive shutdown predominantly only happened at the highest risk levels. For the PHQ-9 simulation, the average initial referral and shutdown aligned with PHQ-9 scores of 12 (moderate depression) and 25 (severe depression). Few agents included crisis resources - only two referenced suicide hotlines. Despite the conversational agents insisting on human intervention, 22 out of 25 agents would eventually resume the dialogue if the simulation reverted to a lower risk level. Conclusions Current generative AI-based conversational agents are slow to escalate mental health risk scenarios, postponing referral to a human to potentially dangerous levels. More rigorous testing and oversight of conversational agents are needed before deployment in mental healthcare settings. Additionally, further investigation should explore if sustained engagement worsens outcomes and whether enhanced accessibility outweighs the risks of improper escalation. Advancing AI safety in mental health remains imperative as these technologies continue rapidly advancing.", "isOpenAccess": true, "url": "https://assets.cureus.com/uploads/original_article/pdf/213293/20231218-16883-1yezre0.pdf"}
{"paperId": "14e470401a6a463d204ed3274dd28c381d4e854a", "year": 2024, "title": "Determinants of Students\u2019 Satisfaction with AI Tools in Education: A PLS-SEM-ANN Approach", "authors": "Ahmad Almufarreh", "venue": "Sustainability", "citationCount": 56, "abstract": "The emergence of Artificial Intelligence (AI) technology has significantly disrupted the educational landscape. The latest development in AI, generative AI that can generate new and tailored to specific content, has significantly impacted education. Given the value of AI technology in general and generative AI specific to users in education, such as students, the adaptability of these technologies has significantly increased. However, continuing and productive usage of AI tools depends upon students\u2019 satisfaction with these tools. Drawing from the existing research, the present research has developed factors that affect students\u2019 general satisfaction with AI tools. The research collected the data using a survey questionnaire from a Saudi Arabian university. The two-stage method of partial least squares structural equation modeling (PLS-SEM) and artificial neural network (ANN) have been employed. The two-stage method is applied in a way that PLS-SEM is used for testing the hypothesis and significance of the factor\u2019s influence on satisfaction, and ANN is used to determine the relevant importance of the factor. The PLS-SEM results have shown that factors such as content quality, emotional wellbeing and perceived utility determine student satisfaction with AI tools. The ANN results show that emotional wellbeing is the most critical factor in satisfaction, followed equally by content quality and perceived utility.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/16/13/5354/pdf?version=1719216464"}
{"paperId": "13760c6569d81813f1ebe3385feb47972be2b658", "year": 2024, "title": "A phase transition in diffusion models reveals the hierarchical nature of data", "authors": "Antonio Sclocchi, Alessandro Favero, M. Wyart", "venue": "Proceedings of the National Academy of Sciences of the United States of America", "citationCount": 56, "abstract": "Significance The success of deep learning is often attributed to its ability to harness the hierarchical and compositional structure of data. However, formalizing and testing this notion remained a challenge. This work shows how diffusion models\u2014generative AI techniques producing high-resolution images\u2014operate at different hierarchical levels of features over different time scales of the diffusion process. This phenomenon allows for the generation of images of various classes by recombining low-level features. We study a hierarchical model of data that reproduces this phenomenology and provides a theoretical explanation for this compositional behavior. Overall, the present framework provides a description of how generative models operate, and put forward diffusion models as powerful lenses to probe data structure.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2402.16991"}
{"paperId": "112349fbc11d52a6530b5b780763af4f6ca8d34d", "year": 2025, "title": "Opportunities, challenges and school strategies for integrating generative AI in education", "authors": "D. Ng, Eagle Kai Chi Chan, Chung Kwan Lo", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 56, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2025.100373"}
{"paperId": "bf384d54184076dbcd640baf9b2c549a1bbbf5f2", "year": 2023, "title": "Transforming boundaries: how does ChatGPT change knowledge work?", "authors": "P. Ritala, Mika Ruokonen, Laavanya Ramaul", "venue": "Journal of Business Strategy", "citationCount": 55, "abstract": "\nPurpose\nThis paper aims to demonstrate how the new generative artificial intelligence (AI) tool ChatGPT changes knowledge work for individuals and what are the implications of this change for companies.\n\n\nDesign/methodology/approach\nBased on 22 interviews from informants across different industries, the authors conducted an inductive analysis on the use and utility of ChatGPT in knowledge work. Based on this initial analysis, they discovered different ways in which ChatGPT either augments human agency, makes it redundant or lacks capability in that regard.\n\n\nFindings\nThe authors develop a 2 \u00d7 2 framework of algorithmic assistance, which demonstrates four ways in which ChatGPT (and generative AI in general) interacts with knowledge workers, depending on the usefulness of ChatGPT in particular tasks and the type of the task (routine vs creative).\n\n\nPractical implications\nBased on the insights from the interviews, the authors propose a set of actionable questions for individual knowledge workers and companies from four viewpoints: skills and capabilities; team structure and workflow coordination; culture and mindset; and business model innovation.\n\n\nOriginality/value\nTo the best of the authors\u2019 knowledge, this study is among the first to identify and analyze the use of ChatGPT by knowledge workers across different industries.\n", "isOpenAccess": true, "url": "https://www.emerald.com/insight/content/doi/10.1108/JBS-05-2023-0094/full/pdf?title=transforming-boundaries-how-does-chatgpt-change-knowledge-work"}
{"paperId": "88959660d2a9e14ba6beb248f5a1e03af579116e", "year": 2024, "title": "Patient-centered radiology reports with generative artificial intelligence: adding value to radiology reporting", "authors": "Jiwoo Park, Kangrok Oh, Kyunghwa Han, Young Han Lee", "venue": "Scientific Reports", "citationCount": 55, "abstract": "The purposes were to assess the efficacy of AI-generated radiology reports in terms of report summary, patient-friendliness, and recommendations and to evaluate the consistent performance of report quality and accuracy, contributing to the advancement of radiology workflow. Total 685 spine MRI reports were retrieved from our hospital database. AI-generated radiology reports were generated in three formats: (1) summary reports, (2) patient-friendly reports, and (3) recommendations. The occurrence of artificial hallucinations was evaluated in the AI-generated reports. Two radiologists conducted qualitative and quantitative assessments considering the original report as a standard reference. Two non-physician raters assessed their understanding of the content of original and patient-friendly reports using a 5-point Likert scale. The scoring of the AI-generated radiology reports were overall high average scores across all three formats. The average comprehension score for the original report was 2.71\u2009\u00b1\u20090.73, while the score for the patient-friendly reports significantly increased to 4.69\u2009\u00b1\u20090.48 (p\u2009<\u20090.001). There were 1.12% artificial hallucinations and 7.40% potentially harmful translations. In conclusion, the potential benefits of using generative AI assistants to generate these reports include improved report quality, greater efficiency in radiology workflow for producing summaries, patient-centered reports, and recommendations, and a move toward patient-centered radiology.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-024-63824-z.pdf"}
{"paperId": "836c652834b0f6ffe10e53ede1c0b9433cfad9ea", "year": 2024, "title": "Copyright Protection in Generative AI: A Technical Perspective", "authors": "Jie Ren, Han Xu, Pengfei He, Yingqian Cui, Shenglai Zeng, Jiankun Zhang, Hongzhi Wen, Jiayuan Ding, Hui Liu, Yi Chang, Jiliang Tang", "venue": "arXiv.org", "citationCount": 55, "abstract": "Generative AI has witnessed rapid advancement in recent years, expanding their capabilities to create synthesized content such as text, images, audio, and code. The high fidelity and authenticity of contents generated by these Deep Generative Models (DGMs) have sparked significant copyright concerns. There have been various legal debates on how to effectively safeguard copyrights in DGMs. This work delves into this issue by providing a comprehensive overview of copyright protection from a technical perspective. We examine from two distinct viewpoints: the copyrights pertaining to the source data held by the data owners and those of the generative models maintained by the model builders. For data copyright, we delve into methods data owners can protect their content and DGMs can be utilized without infringing upon these rights. For model copyright, our discussion extends to strategies for preventing model theft and identifying outputs generated by specific models. Finally, we highlight the limitations of existing techniques and identify areas that remain unexplored. Furthermore, we discuss prospective directions for the future of copyright protection, underscoring its importance for the sustainable and ethical development of Generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "508e5ecf73cb865afa079705193c6883db1ecfd7", "year": 2024, "title": "The Impact of ChatGPT on English for Academic Purposes (EAP) Students\u2019 Language Learning Experience: A Self-Determination Theory Perspective", "authors": "Jinming Du, Antonie Alm", "venue": "Education sciences", "citationCount": 55, "abstract": "This qualitative study explores the perceptions of English language students regarding the use of the generative AI tool, ChatGPT, as a supportive tool for English for Academic Purposes (EAP) students in a New Zealand university context. Using self-determination theory (SDT) as an explanatory framework, this study explores how ChatGPT impacts students\u2019 basic psychological needs for autonomy, competence, and relatedness in their language-learning experience. Semi-structured interviews are conducted with 24 postgraduate EAP students and the data are analysed using thematic analysis. The findings suggest that ChatGPT has the potential to support students\u2019 needs for autonomy and competence by providing flexibility, personalised feedback and a safe space for practice. However, the impact on relatedness needs is mixed, with some students experiencing a sense of companionship and others expressing concerns about reduced human interaction. While students acknowledge the benefits of ChatGPT, they also emphasise the importance of human-teacher interactivity and empathy. The findings provide theoretical insights and practical recommendations for educators seeking to integrate generative AI tools effectively into language education.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/14/7/726/pdf?version=1720000353"}
{"paperId": "4576ea8c2c49051df527fe0679ee141ba1ec0d5a", "year": 2024, "title": "Is It AI or Is It Me? Understanding Users\u2019 Prompt Journey with Text-to-Image Generative AI Tools", "authors": "Atefeh Mahdavi Goloujeh, Anne Sullivan, Brian Magerko", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 55, "abstract": "Generative Artificial Intelligence (AI) has witnessed unprecedented growth in text-to-image AI tools. Yet, much remains unknown about users\u2019 prompt journey with such tools in the wild. In this paper, we posit that designing human-centered text-to-image AI tools requires a clear understanding of how individuals intuitively approach crafting prompts, and what challenges they may encounter. To address this, we conducted semi-structured interviews with 19 existing users of a text-to-image AI tool. Our findings (1) offer insights into users\u2019 prompt journey including structures and processes for writing, evaluating, and refining prompts in text-to-image AI tools and (2) indicate that users must overcome barriers to aligning AI to their intents, and mastering prompt crafting knowledge. From the findings, we discuss the prompt journey as an individual yet a social experience and highlight opportunities for aligning text-to-image AI tools and users\u2019 intents.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642861"}
{"paperId": "30fce83297f693ec2f97a0c05ec28d910c6c6b9d", "year": 2024, "title": "Generative AI for Synthetic Data Generation: Methods, Challenges and the Future", "authors": "Xu Guo, Yiqiang Chen", "venue": "arXiv.org", "citationCount": 55, "abstract": "The recent surge in research focused on generating synthetic data from large language models (LLMs), especially for scenarios with limited data availability, marks a notable shift in Generative Artificial Intelligence (AI). Their ability to perform comparably to real-world data positions this approach as a compelling solution to low-resource challenges. This paper delves into advanced technologies that leverage these gigantic LLMs for the generation of task-specific training data. We outline methodologies, evaluation techniques, and practical applications, discuss the current limitations, and suggest potential pathways for future research.", "isOpenAccess": false, "url": ""}
{"paperId": "182921694e351be521fa895e6741287a1a1cbc78", "year": 2024, "title": "Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations", "authors": "Hasan Abu-Rasheed, Christian Weber, M. Fathi", "venue": "IEEE Global Engineering Education Conference", "citationCount": 55, "abstract": "In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.", "isOpenAccess": true, "url": "https://osf.io/rvnx3/download"}
{"paperId": "07ec54f8afcc28b5b6c957e4ead9371ab0299230", "year": 2024, "title": "\u2018No, Alexa, no!\u2019: designing child-safe AI and protecting children from the risks of the \u2018empathy gap\u2019 in large language models", "authors": "Nomisha Kurian", "venue": "Journal of Educational Media", "citationCount": 55, "abstract": "ABSTRACT Rapid advancements in large language models makes child-safe design for their youngest users crucial. This article therefore offers child-centred AI design and policy recommendations to help make large language models (LLMs) utilised in conversational and generative AI systems safer for children. Conceptualising the risk of LLMs as \u2018an empathy gap\u2019, this research-based conceptual article focuses on the need to design LLMs that prevent or mitigate against the risks of responding inappropriately to children's personal disclosures or accidentally promoting harm. The article synthesises selected cases of human chatbot interaction and research findings across education, computer science and human-computer interaction studies. It concludes with practical recommendations for child-safe AI across eight dimensions of design and policy: content and communication; human intervention; transparency; accountability; justifiability; regulation; school-family engagement; and child-centred design methodologies. These eight dimensions are tailored to a variety of stakeholders, from policymakers and AI developers to educators and caregivers.", "isOpenAccess": false, "url": ""}
{"paperId": "fce13ffb817216ad53efc2864a8f02404f18358e", "year": 2023, "title": "It\u2019s not like a calculator, so what is the relationship between learners and generative artificial intelligence?", "authors": "J. Lodge, Suijing Yang, Leon Furze, P. Dawson", "venue": "Learning: Research and Practice", "citationCount": 54, "abstract": "ABSTRACT It is becoming apparent that generative AI has significant implications for education. However, previous technologies that have had a large impact, such as calculators, do not provide a suitable model for understanding how generative AI can and will be used in learning. Drawing on research on human-computer interactions, we map out a typology of possible student-to-generative AI relationships to afford a more nuanced discussion about what these new technologies can and should be used for in learning. Our contribution in this article is to offer a typology for considering the range of possible interactions across two dimensions of relationships. In doing so, we argue that there is not a single metaphor for the relationship between humans and AI in learning, but many.", "isOpenAccess": false, "url": ""}
{"paperId": "b91bcadc6227f7d61e406bb6957850231733442e", "year": 2023, "title": "Factuality Challenges in the Era of Large Language Models", "authors": "Isabelle Augenstein, Timothy Baldwin, Meeyoung Cha, Tanmoy Chakraborty, Giovanni Luca Ciampaglia, David Corney, Renee DiResta, Emilio Ferrara, Scott Hale, A. Halevy, Eduard H. Hovy, Heng Ji, Filippo Menczer, Rub\u00e9n M\u00edguez, Preslav Nakov, Dietram A. Scheufele, Shivam Sharma, Giovanni Zagni", "venue": "arXiv.org", "citationCount": 54, "abstract": "The emergence of tools based on Large Language Models (LLMs), such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered immense public attention. These incredibly useful, natural-sounding tools mark significant advances in natural language generation, yet they exhibit a propensity to generate false, erroneous, or misleading content -- commonly referred to as\"hallucinations.\"Moreover, LLMs can be exploited for malicious applications, such as generating false but credible-sounding content and profiles at scale. This poses a significant challenge to society in terms of the potential deception of users and the increasing dissemination of inaccurate information. In light of these risks, we explore the kinds of technological innovations, regulatory reforms, and AI literacy initiatives needed from fact-checkers, news organizations, and the broader research and policy communities. By identifying the risks, the imminent threats, and some viable solutions, we seek to shed light on navigating various aspects of veracity in the era of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "b1a8abadb6fd2a6b86cbbdc3e86b71e1b8808273", "year": 2024, "title": "Supporting Teachers\u2019 Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy", "authors": "Jijian Lu, Ruxin Zheng, Zikun Gong, Huifen Xu", "venue": "IEEE Transactions on Learning Technologies", "citationCount": 54, "abstract": "Generative artificial intelligence (AI) has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted preservice teaching skills training on preservice teachers\u2019 self-efficacy and higher order thinking. The participants of this study were 215 preservice mathematics, science, and computer teachers from a university in China. First, a pretest\u2013post-test quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Finally, a semistructured interview comprising open-ended questions was administered to 25 preservice teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of preservice teachers in the experimental group, who used generative AI for teachers\u2019 professional development, were considerably higher than those of the control group, both in teacher self-efficacy (F = 8.589, p = 0.0084 < 0.05) and higher order thinking (F = 7.217, p = 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers\u2019 professional development. This study produced a practical teachers\u2019 professional development method for preservice teachers with generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "b190697d8106a555f525acec33c6a91c67b88483", "year": 2024, "title": "The Clever Hans Mirage: A Comprehensive Survey on Spurious Correlations in Machine Learning", "authors": "Wenqian Ye, Guangtao Zheng, Xu Cao, Yunsheng Ma, Xia Hu, Aidong Zhang", "venue": "", "citationCount": 54, "abstract": "Back in the early 20th century, a horse named Hans appeared to perform arithmetic and other intellectual tasks during exhibitions in Germany, while it actually relied solely on involuntary cues in the body language from the human trainer. Modern machine learning models are no different. These models are known to be sensitive to spurious correlations between non-essential features of the inputs (e.g., background, texture, and secondary objects) and the corresponding labels. Such features and their correlations with the labels are known as\"spurious\"because they tend to change with shifts in real-world data distributions, which can negatively impact the model's generalization and robustness. In this paper, we provide a comprehensive survey of this emerging issue, along with a fine-grained taxonomy of existing state-of-the-art methods for addressing spurious correlations in machine learning models. Additionally, we summarize existing datasets, benchmarks, and metrics to facilitate future research. The paper concludes with a discussion of the broader impacts, the recent advancements, and future challenges in the era of generative AI, aiming to provide valuable insights for researchers in the related domains of the machine learning community.", "isOpenAccess": false, "url": ""}
{"paperId": "a2d5e56af68c5b61bb6d69fbfb5a0546bb97a106", "year": 2024, "title": "Generative AI in User Experience Design and Research: How Do UX Practitioners, Teams, and Companies Use GenAI in Industry?", "authors": "Macy Takaffoli, Sijia Li, Ville M\u00e4kel\u00e4", "venue": "Conference on Designing Interactive Systems", "citationCount": 54, "abstract": "User Experience (UX) practitioners, like UX designers and researchers, have begun to adopt Generative Artificial Intelligence (GenAI) tools into their work practices. However, we lack an understanding of how UX practitioners, UX teams, and companies actually utilize GenAI and what challenges they face. We conducted interviews with 24 UX practitioners from multiple companies and countries, with varying roles and seniority. Our findings include: 1) There is a significant lack of GenAI company policies, with companies informally advising caution or leaving the responsibility to individual employees; 2) UX teams lack team-wide GenAI practices. UX practitioners typically use GenAI individually, favoring writing-based tasks, but note limitations for design-focused activities, like wireframing and prototyping; 3) UX practitioners call for better training on GenAI to enhance their abilities to generate effective prompts and evaluate output quality. Based on our findings, we provide recommendations for GenAI integration in the UX sector.", "isOpenAccess": false, "url": ""}
{"paperId": "77725db1efcd2812f653aa18620d69669bcd945d", "year": 2024, "title": "Benchmarking operations and supply chain management practices using Generative AI: Towards a theoretical framework", "authors": "Rameshwar Dubey, A. Gunasekaran, T. Papadopoulos", "venue": "Transportation Research Part E: Logistics and Transportation Review", "citationCount": 54, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "57c2fbcf8a32fffacf79bdf9c1df12b8cd26980e", "year": 2023, "title": "Text Summarization Using Large Language Models: A Comparative Study of MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models", "authors": "Lochan Basyal, Mihir Sanghvi", "venue": "arXiv.org", "citationCount": 54, "abstract": "Text summarization is a critical Natural Language Processing (NLP) task with applications ranging from information retrieval to content generation. Leveraging Large Language Models (LLMs) has shown remarkable promise in enhancing summarization techniques. This paper embarks on an exploration of text summarization with a diverse set of LLMs, including MPT-7b-instruct, falcon-7b-instruct, and OpenAI ChatGPT text-davinci-003 models. The experiment was performed with different hyperparameters and evaluated the generated summaries using widely accepted metrics such as the Bilingual Evaluation Understudy (BLEU) Score, Recall-Oriented Understudy for Gisting Evaluation (ROUGE) Score, and Bidirectional Encoder Representations from Transformers (BERT) Score. According to the experiment, text-davinci-003 outperformed the others. This investigation involved two distinct datasets: CNN Daily Mail and XSum. Its primary objective was to provide a comprehensive understanding of the performance of Large Language Models (LLMs) when applied to different datasets. The assessment of these models' effectiveness contributes valuable insights to researchers and practitioners within the NLP domain. This work serves as a resource for those interested in harnessing the potential of LLMs for text summarization and lays the foundation for the development of advanced Generative AI applications aimed at addressing a wide spectrum of business challenges.", "isOpenAccess": false, "url": ""}
{"paperId": "4e1d56e3f612c3598ca55d731993fe9cfc90bac3", "year": 2024, "title": "How do students use ChatGPT as a writing support?", "authors": "Sarah Levine, Sarah W. Beck, Chris Mah, Lena Phalen, Jaylen Pittman", "venue": "Journal of Adolescent &amp; Adult Literacy", "citationCount": 54, "abstract": "Educators and researchers are interested in ways that ChatGPT and other generative AI tools might move beyond the role of \u201ccheatbot\u201d and become part of the network of resources students use for writing. We studied how high school students used ChatGPT as a writing support while writing arguments about topics like school mascots. We asked: What did students prompt ChatGPT to do? And how did students take up ChatGPT's responses to those prompts? We used Flower and Hayes' writing model to analyze screencasts of students interacting with ChatGPT and one another as they planned, drafted, and reviewed their arguments. Our data show that while planning and drafting, students primarily asked ChatGPT for ideas and then built upon those ideas to develop their own arguments. While reviewing, they generally used ChatGPT as they might use Grammarly or other editing tools. Students also compared their writing with that of ChatGPT, which allowed them to identify their unique writing voices and build meta\u2010level understandings of rhetorical choices and effects. Our study indicates that ChatGPT can become a part of a social, distributed model of writing, and that students can use ChatGPT as a resource for writing without sidestepping the processes of planning, drafting, and reviewing.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jaal.1373"}
{"paperId": "4de98f426c682717b752452d07132ddd6e2a032e", "year": 2023, "title": "Speed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations", "authors": "Yu-Hui Chen, Raman Sarokin, Juhyun Lee, Jiuqiang Tang, Chuo-Ling Chang, Andrei Kulik, Matthias Grundmann", "venue": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citationCount": 54, "abstract": "The rapid development and application of foundation models have revolutionized the field of artificial intelligence. Large diffusion models have gained significant attention for their ability to generate photorealistic images and support various tasks. On-device deployment of these models provides benefits such as lower server costs, offline functionality, and improved user privacy. However, common large diffusion models have over 1 billion parameters and pose challenges due to restricted computational and memory resources on devices. We present a series of implementation optimizations for large diffusion models that achieve the fastest reported inference latency to-date(under 12 seconds for Stable Diffusion 1.4 without INT8 quantization for a 512 \u00d7 512 image with 20 iterations) on GPU-equipped mobile devices. These enhancements broaden the applicability of generative AI and improve the overall user experience across a wide range of devices.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.11267"}
{"paperId": "432bdeb7fa7afcfebcf9afbbbc938ac547956c68", "year": 2024, "title": "AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business", "authors": "Declan Humphreys, Abigail Koay, Dennis Desmond, Erica Mealy", "venue": "AI and Ethics", "citationCount": 54, "abstract": "This paper examines the ethical obligations companies have when implementing generative Artificial Intelligence (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt generative AI solutions or buying into \u201cAI hype\u201d. While the benefits of implementing generative AI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate generative AI is not being accompanied by adequate safety measures. The rush to buy into the hype of generative AI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats generative AI models pose, including potential \u2018backdoors\u2019 in AI models that could compromise user data or the risk of \u2018poisoned\u2019 AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing generative AI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, overreliance and over-trust in generative AI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of generative AI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s43681-024-00443-4.pdf"}
{"paperId": "2820c7c85fd93f0661c282a36e1a68a185c7b0c1", "year": 2024, "title": "Distributed agency in second language learning and teaching through generative AI", "authors": "Robert Godwin-Jones", "venue": "Language Learning &amp; Technology", "citationCount": 54, "abstract": "Generative AI offers significant opportunities for language learning. Tools like ChatGPT provide second language practice through chats in written or voice formats, with the learner specifying through prompts conversational parameters. AI can be instructed to give corrective feedback and create practice exercises. Using AI, instructors can build learning and assessment materials in a variety of media. Generative AI provides affordances for both autonomous and instructed learning. In addition, AI is poised to enhance dramatically the usefulness of immersive technologies. For both learners and teachers, it is important to understand the limitations of AI systems that arise from their statistical model of human language, which constrains their capacity for dealing with sociocultural aspects of language use. Additionally, there are ethical concerns over how AI systems are created and deployed, as well as practical constraints in their use, especially for less privileged populations. Nevertheless, the power and versatility of AI tools are likely to turn them into constant companions in many people\u2019s lives, creating a close connection that goes beyond simple tool use. Ecological theories such as sociomaterialism are helpful in examining the shared agency that develops through close user-AI interactions, as are the perspectives on human-tool relationships from Indigenous cultures.", "isOpenAccess": false, "url": ""}
{"paperId": "21b302436c50d25f936828092b266c1fdcad8914", "year": 2024, "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap", "authors": "Jialong Li, Mingyue Zhang, Nianyu Li, Danny Weyns, Zhi Jin, Kenji Tei", "venue": "ACM Transactions on Autonomous and Adaptive Systems", "citationCount": 54, "abstract": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI\u2019s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.\u2020", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3686803"}
{"paperId": "1b43632036f7e1f45a4759849f2924478eccc81e", "year": 2024, "title": "Generative Artificial Intelligence and Evaluating Strategic Decisions", "authors": "Anil R. Doshi, J. J. Bell, Emil Mirzayev, Bart S. Vanneste", "venue": "Social Science Research Network", "citationCount": 54, "abstract": "Strategic decisions are uncertain and often irreversible. Hence, predicting the value of alternatives is important for strategic decision making. We investigate the use of generative artificial intelligence (AI) in evaluating strategic alternatives using business models generated by AI (study 1) or submitted to a competition (study 2). Each study uses a sample of 60 business models and examines agreement in business model rankings made by large language models (LLMs) and those by human experts. We consider multiple LLMs, assumed LLM roles, and prompts. We find that generative AI often produces evaluations that are inconsistent and biased. However, when aggregating evaluations, AI rankings tend to resemble those of human experts. This study highlights the value of generative AI in strategic decision making by providing predictions.Managers are seeking to create value by integrating generative AI into their organizations. We show how managers can use generative AI to help evaluate strategic decisions. Generative AI's single evaluations are often inconsistent or biased. However, if managers aggregate many evaluations across LLMs, prompts, or roles, the results show that the resulting evaluations tend to resemble those of human experts. This approach allows managers to obtain insight on strategic decisions across a variety of domains with relatively low investments in time or resources, which can be combined with human inputs.", "isOpenAccess": false, "url": ""}
{"paperId": "d63fb6f1fdc536a3d59320651b78ffcaca5031d2", "year": 2023, "title": "How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering", "authors": "Rudrajit Choudhuri, Dylan Liu, Igor Steinmacher, M. Gerosa, Anita Sarma", "venue": "International Conference on Software Engineering", "citationCount": 53, "abstract": "Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3597503.3639201"}
{"paperId": "ae7274735fb999b4a6eaf264252351c90c082583", "year": 2024, "title": "Diversity in the digital age: how consumers respond to diverse virtual influencers", "authors": "Carla Ferraro, S. Sands, Nives Zubcevic-Basic, Colin Campbell", "venue": "International Journal of Advertising", "citationCount": 53, "abstract": "Abstract In recent years the popularity of social media influencers has grown exponentially, in part because influencers tend to not be seen as advertising and they enable brands to reach engaged audiences. As such, influencer marketing is perceived as an effective and cost-effective marketing tool. However, like all areas of marketing there are broad-based shifts that are having significant effects on the domain of influencer marketing. First, there are calls for greater levels of diversity and broader representation of diverse communities. Second, digital innovation is having a profound effect on the field of influencer marketing, leading to the advent of virtual influencers that are artificially created, often through generative AI. These shifts raise questions about the effect of diversity in influencer marketing \u2013 with implications for brands that engage virtual influencers. In this paper, we present two experiments that investigate the effect of diversity representation in the context of virtual influencers. Results show that when brands engage virtual influencers to represent diverse subgroups, novelty and likeability act to mediate positive effects for the influencer (word-of-mouth and follow intentions) and the brand (purchase intentions). Theoretical and practical implications are discussed.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/02650487.2023.2300927?needAccess=true"}
{"paperId": "9fad4e9cb933071ca3c045418a5d67feb1d6b504", "year": 2024, "title": "How to build a competitive advantage for your brand using generative AI", "authors": "Y. Cui, Patrick van Esch, Steven Phelan", "venue": "Business Horizons", "citationCount": 53, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "8287358ed0aa68d3062b5cf2d6b8d9a6bcabff38", "year": 2024, "title": "Opportunities and Challenges of Integrating Generative Artificial Intelligence in Education", "authors": "Rommel Alali, Y. Wardat", "venue": "International Journal of Religion", "citationCount": 53, "abstract": "This paper thoroughly examines both the opportunities and obstacles associated with integrating Generative Artificial Intelligence (AI) into educational settings. It explores how Generative AI has the potential to enrich learning experiences, customize education for individuals, and foster creativity. However, it also confronts several challenges including ethical dilemmas, safeguarding data privacy, mitigating algorithmic biases, and reshaping the role of educators. Through a synthesis of theoretical frameworks and empirical research, the paper offers valuable insights into effective strategies for navigating these challenges. It emphasizes the importance of establishing ethical guidelines, ensuring transparency in algorithms, and adopting inclusive design principles during AI integration. Furthermore, the paper underscores the importance of providing educators with adequate training and professional development opportunities to effectively utilize AI tools. Additionally, it advocates for ongoing dialogue among stakeholders\u2014such as educators, policymakers, technologists, and students\u2014to steer responsible AI integration in education. Ultimately, the paper advocates for a collaborative approach that prioritizes human-centric values, equity, and diversity. While Generative AI holds promise for revolutionizing educational practices, its integration requires thoughtful consideration of ethical, social, and pedagogical implications. Through proactive collaboration and partnership, educators can leverage AI's potential to create more immersive, tailored, and equitable learning environments.\u00a0", "isOpenAccess": true, "url": "https://ijor.co.uk/ijor/article/download/4397/2263"}
{"paperId": "7a9559ac8b1185832487de45b13b8a3e3ffcc2fc", "year": 2024, "title": "Unveiling the evolution of generative AI (GAI): a comprehensive and investigative analysis toward LLM models (2021\u20132024) and beyond", "authors": "Zarif Bin Akhtar", "venue": "Journal of Electrical Systems and Information Technology", "citationCount": 53, "abstract": "This comprehensive exploration of recent breakthroughs in artificial intelligence (AI) traversed the realms of language models, computer vision, and generative models, unraveling the intricacies of cutting-edge technologies such as GPT-3.5, GPT-4, Pix2Seq, and multimodal models in terms of generative AI. In this multifaceted journey, the focus extended beyond technological prowess to ethical considerations, emphasizing responsible AI practices guided by Google's AI Principles. The nuanced discussions encapsulated the transformative impact of AI on user experiences across various Google products and toolsets, paving the way for a future where natural language interaction, creative content generation, and multimodal understanding redefine human\u2013computer interactions. The research investigation showcased not only the advancements themselves but also the critical lens through which these innovations are approached, underscoring the importance of ethical and responsible AI in shaping the technological landscape.", "isOpenAccess": true, "url": "https://jesit.springeropen.com/counter/pdf/10.1186/s43067-024-00145-1"}
{"paperId": "55c7c2249274e8a34ee25b91fcc6abf779e2cff9", "year": 2024, "title": "Generative AI tools as educators' assistants: Designing and implementing inquiry-based lesson plans", "authors": "Maria Moundridou, Nikolaos Matzakos, Spyridon Doukakis", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 53, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100277"}
{"paperId": "5326f0b6882ee8c1043e718b007c3595858f48fe", "year": 2024, "title": "The ChatGPT Effect: Nursing Education and Generative Artificial Intelligence.", "authors": "Maxim Topaz, Laura-Maria Peltonen, Martin Michalowski, Gregor Stiglic, C. Ronquillo, Lisiane Pruinelli, Jiyoun Song, Siobh\u00e1n O\u2019Connor, Shoko Miyagawa, Hiroki Fukahori", "venue": "The Journal of Nursery Education", "citationCount": 53, "abstract": null, "isOpenAccess": true, "url": "https://kclpure.kcl.ac.uk/portal/en/publications/43f64efa-b638-4aa6-8e6d-234037526ef3"}
{"paperId": "35e91bdfc74076b7b09c1071c7acd0f26a343106", "year": 2024, "title": "DesignPrompt: Using Multimodal Interaction for Design Exploration with Generative AI", "authors": "Xiaohan Peng, Janin Koch, Wendy E. Mackay", "venue": "Conference on Designing Interactive Systems", "citationCount": 53, "abstract": "Visually oriented designers often struggle to create effective generative AI (GenAI) prompts. A preliminary study identified specific issues in composing and fine-tuning prompts, as well as needs in accurately translating intentions into rich input. We developed DesignPrompt, a moodboard tool that lets designers combine multiple modalities \u2014 images, color, text \u2014 into a single GenAI prompt and tweak the results. We ran a comparative structured observation study with 12 professional designers to better understand their intent expression, expectation alignment and transparency perception using DesignPrompt and text input GenAI. We found that multimodal prompt input encouraged designers to explore and express themselves more effectively. Designer\u2019s interaction preferences change according to their overall sense of control over the GenAI and whether they are seeking inspiration or a specific image. Designers developed innovative uses of DesignPrompt, including developing elaborate multimodal prompts and creating a multimodal prompt pattern to maximize novelty while ensuring consistency.", "isOpenAccess": false, "url": ""}
{"paperId": "32f90d91e6dd03da6dc098c421adfe699bc52f9e", "year": 2024, "title": "Critical Thinking in the Age of Generative AI", "authors": "Barbara Z. Larson, Christine Moser, A. Caza, K. Muehlfeld, Laura A. Colombo", "venue": "Academy of Management Learning &amp; Education", "citationCount": 53, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "2f328f1c2c7ef798cc9f8540c56bfa940d97ceed", "year": 2024, "title": "Diffusion models in protein structure and docking", "authors": "Jason Yim, Hannes St\u00e4rk, Gabriele Corso, Bowen Jing, R. Barzilay, T. Jaakkola", "venue": "WIREs Computational Molecular Science", "citationCount": 53, "abstract": "Generative AI is rapidly transforming the frontier of research in computational structural biology. Indeed, recent successes have substantially advanced protein design and drug discovery. One of the key methodologies underlying these advances is diffusion models (DM). Diffusion models originated in computer vision, rapidly taking over image generation and offering superior quality and performance. These models were subsequently extended and modified for uses in other areas including computational structural biology. DMs are well equipped to model high dimensional, geometric data while exploiting key strengths of deep learning. In structural biology, for example, they have achieved state\u2010of\u2010the\u2010art results on protein 3D structure generation and small molecule docking. This review covers the basics of diffusion models, associated modeling choices regarding molecular representations, generation capabilities, prevailing heuristics, as well as key limitations and forthcoming refinements. We also provide best practices around evaluation procedures to help establish rigorous benchmarking and evaluation. The review is intended to provide a fresh view into the state\u2010of\u2010the\u2010art as well as highlight its potentials and current challenges of recent generative techniques in computational structural biology.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wcms.1711"}
{"paperId": "05bb0af2720ebdcd5fa7509f51e8d1d6601569af", "year": 2023, "title": "Race with the machines: Assessing the capability of generative AI in solving authentic assessments", "authors": "Binh Nguyen Thanh, Diem Thi-Ngoc Vo, Minh Nguyen Nhat, Thi Thu Tra Pham, Hieu Thai Trung, Son Ha Xuan", "venue": "Australasian Journal of Educational Technology", "citationCount": 53, "abstract": "In this study, we introduce a framework designed to help educators assess the effectiveness of popular generative artificial intelligence (AI) tools in solving authentic assessments. We employed Bloom\u2019s taxonomy as a guiding principle to create authentic assessments that evaluate the capabilities of generative AI tools. We applied this framework to assess the abilities of ChatGPT-4, ChatGPT-3.5, Google Bard and Microsoft Bing in solving authentic assessments in economics. We found that generative AI tools perform very well at the lower levels of Bloom's taxonomy while still maintaining a decent level of performance at the higher levels, with \u201ccreate\u201d being the weakest level of performance. Interestingly, these tools are better able to address numeric-based questions than text-based ones. Moreover, all the generative AI tools exhibit weaknesses in building arguments based on theoretical frameworks, maintaining the coherence of different arguments and providing appropriate references. Our study provides educators with a framework to assess the capabilities of generative AI tools, enabling them to make more informed decisions regarding assessments and learning activities. Our findings demand a strategic reimagining of educational goals and assessments, emphasising higher cognitive skills and calling for a concerted effort to enhance the capabilities of educators in preparing students for a rapidly transforming professional environment.\nImplications for practice or policy\n\nOur proposed framework enables educators to systematically evaluate the capabilities of widely used generative AI tools in assessments and assist them in the assessment design process.\nTertiary institutions should re-evaluate and redesign programmes and course learning outcomes. The new focus on learning outcomes should address the higher levels of educational goals of Bloom\u2019s taxonomy, specifically the \u201ccreate\u201d level.\n", "isOpenAccess": true, "url": "https://ajet.org.au/index.php/AJET/article/download/8902/2051"}
{"paperId": "e540f6de825dd74b64157845ba23b4355965b54b", "year": 2024, "title": "ChatGPT and the digitisation of writing", "authors": "Xin Zhao, Andrew Cox, Liang Cai", "venue": "Humanities and Social Sciences Communications", "citationCount": 52, "abstract": "The aim of this study is to uncover how students\u2019 practices of writing in higher education are being impacted by ChatGPT. The use of ChatGPT and other generative AI needs to be set in the context of a longer-term process of the digitisation of writing, where many tools are being employed by students to support writing because it is a complex iterative process. Generative AI appears to have had a large impact on how students write, and we propose a model of generative AI literacy to assess their capabilities in doing so. Semi-structured interviews and observation data were collected at a British University with 23 students from diverse backgrounds, including the UK, USA, China, Japan, and Saudi Arabia. The data was analysed thematically. It was found that students used ChatGPT alongside many other tools, and in rather individualistic ways often to address specific challenges they felt they had with writing. Their main concerns were around plagiarism, information inaccuracy and technology dependence. There was a relatively weak understanding or interest in the ethical issues around the exploitative and environmental impacts of generative AI. The social controversy around ChatGPT can be seen as a useful opportunity to engage students in a discussion about the digitisation of writing and promote AI literacy in this context.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41599-024-02904-x.pdf"}
{"paperId": "b260a0263589324aa02adf4adecc211e44931536", "year": 2024, "title": "Enhancing Autonomous System Security and Resilience With Generative AI: A Comprehensive Survey", "authors": "Martin Andreoni, W. Lunardi, George Lawton, S. Thakkar", "venue": "IEEE Access", "citationCount": 52, "abstract": "This survey explores the transformative role of Generative Artificial Intelligence (GenAI) in enhancing the trustworthiness, reliability, and security of autonomous systems such as Unmanned Aerial Vehicles (UAVs), self-driving cars, and robotic arms. As edge robots become increasingly integrated into daily life and critical infrastructure, the complexity and connectivity of these systems introduce formidable challenges in ensuring security, resilience, and safety. GenAI advances from mere data interpretation to autonomously generating new data, proving critical in complex, context-aware environments like edge robotics. Our survey delves into the impact of GenAI technologies\u2014including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Transformer-based models, and Large Language Models (LLMs)\u2014on cybersecurity, decision-making, and the development of resilient architectures. We categorize existing research to highlight how these technologies address operational challenges and innovate predictive maintenance, anomaly detection, and adaptive threat response. Our comprehensive analysis distinguishes this work from existing reviews by mapping out the applications, challenges, and technological advancements of GenAI and their impact on creating secure frameworks for autonomous systems. We discuss significant challenges and future directions for integrating these technologies within security frameworks to address the evolving landscape of cyber-physical threats, underscoring the potential of GenAI to make autonomous systems more adaptive, secure, and efficient.", "isOpenAccess": true, "url": "https://doi.org/10.1109/access.2024.3439363"}
{"paperId": "b11ce8ec43b1fffa5606a253e2b4fca3912bb880", "year": 2024, "title": "Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors", "authors": "Aashish Ghimire, James Prather, John Edwards", "venue": "Frontiers in Education Conference", "citationCount": 52, "abstract": "This research full paper delves into university in-structors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. The objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly aware of and generally positive towards these tools. We find no correlation between teaching style and attitude toward generative AI. Finally, while CS educators show far more confidence in their technical understanding of generative AI tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect AI-generated work.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2403.15586"}
{"paperId": "ad200cf8c1e4659e42510aa339d71299a1abc9d9", "year": 2024, "title": "SoK: Watermarking for AI-Generated Content", "authors": "Xuandong Zhao, Sam Gunn, Miranda Christ, Jaiden Fairoze, Andres Fabrega, Nicholas Carlini, Sanjam Garg, Sanghyun Hong, Milad Nasr, Florian Tram\u00e8r, Somesh Jha, Lei Li, Yu-Xiang Wang, D. Song", "venue": "IEEE Symposium on Security and Privacy", "citationCount": 52, "abstract": "As the outputs of generative AI (GenAl) techniques improve in quality, it becomes increasingly challenging to distinguish them from human-created content. Watermarking schemes are a promising approach to address the problem of distinguishing between AI and human-generated content. These schemes embed hidden signals within AI -generated content to enable reliable detection. While watermarking is not a silver bullet for addressing all risks associated with GenAl, it can play a crucial role in enhancing AI safety and trustworthiness by combating misinformation and deception. This paper presents a comprehensive overview of water-marking techniques for GenAl, beginning with the need for watermarking from historical and regulatory perspectives. We formalize the definitions and desired properties of watermarking schemes and examine the key objectives and threat models for existing approaches. Practical evaluation strategies are also explored, providing insights into the development of robust watermarking techniques capable of resisting various attacks. Additionally, we review recent representative works, highlight open challenges, and discuss potential directions for this emerging field. By offering a thorough understanding of watermarking in GenAl, this work aims to guide researchers in advancing watermarking methods and applications, and support policymakers in addressing the broader implications of GenAl.", "isOpenAccess": false, "url": ""}
{"paperId": "a33b11069721c8912e03f8555cb4aee71f0461b4", "year": 2023, "title": "Exploring generative AI assisted feedback writing for students\u2019 written responses to a physics conceptual question with prompt engineering and few-shot learning", "authors": "Tong Wan, Zhongzhou Chen", "venue": "Physical Review Physics Education Research", "citationCount": 52, "abstract": "Instructor\u2019s feedback plays a critical role in students\u2019 development of conceptual understanding and reasoning skills. However, grading student written responses and providing personalized feedback can take a substantial amount of time, especially in large enrollment courses. In this study, we explore using GPT-3.5 to write feedback on students\u2019 written responses to conceptual questions with prompt engineering and few-shot learning techniques. In stage I, we used a small portion (n=20) of the student responses on one conceptual question to iteratively train GPT to generate feedback. Four of the responses paired with human-written feedback were included in the prompt as examples for GPT. We tasked GPT to generate feedback for another 16 responses and refined the prompt through several iterations. In stage II, we gave four student researchers (one graduate and three undergraduate researchers) the 16 responses as well as two versions of feedback, one written by the authors and the other by GPT. Students were asked to rate the correctness and usefulness of each feedback and to indicate which one was generated by GPT. The results showed that students tended to rate the feedback by human and GPT equally on correctness, but they all rated the feedback by GPT as more useful. Additionally, the success rates of identifying GPT\u2019s feedback were low, ranging from 0.1 to 0.6. In stage III, we tasked GPT to generate feedback for the rest of the students\u2019 responses (n=65). The feedback messages were rated by four instructors based on the extent of modification needed if they were to give the feedback to students. All four instructors rated approximately 70% (ranging from 68% to 78%) of the feedback statements needing only minor or no modification. This study demonstrated the feasibility of using generative artificial intelligence (AI) as an assistant to generate feedback for student written responses with only a relatively small number of examples in the prompt. An AI assistant can be one of the solutions to substantially reduce time spent on grading student written responses.\n \n \n \n \n Published by the American Physical Society\n 2024\n \n \n", "isOpenAccess": true, "url": "http://link.aps.org/pdf/10.1103/PhysRevPhysEducRes.20.010152"}
{"paperId": "6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0", "year": 2023, "title": "Understanding Telecom Language Through Large Language Models", "authors": "Lina Bariah, Han Zou, Qiyang Zhao, B. Mouhouche, F. Bader, M. Debbah", "venue": "Global Communications Conference", "citationCount": 52, "abstract": "The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.07933"}
{"paperId": "5df984d6eb8b4e1ac2328ec1e7ff5610556f7db8", "year": 2024, "title": "The power of generative marketing: Can generative AI create superhuman visual marketing content?", "authors": "Jochen Hartmann, Yannick Exner, Samuel Domdey", "venue": "International Journal of Research in Marketing", "citationCount": 52, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.ijresmar.2024.09.002"}
{"paperId": "456a73d00425e48b35dc39ac85dd637794f9284f", "year": 2023, "title": "Cyberethics in nursing education: Ethical implications of artificial intelligence", "authors": "J. C. De Gagne, Hyeyoung Hwang, Dukyoo Jung", "venue": "Nursing Ethics", "citationCount": 52, "abstract": "As the use of artificial intelligence (AI) technologies, particularly generative AI (Gen AI), becomes increasingly prevalent in nursing education, it is paramount to address the ethical implications of their implementation. This article explores the realm of cyberethics (a field of applied ethics that focuses on the ethical, legal, and social implications of cybertechnology), highlighting the ethical principles of autonomy, nonmaleficence, beneficence, justice, and explicability as a roadmap for facilitating AI integration into nursing education. Research findings suggest that ethical dilemmas that challenge these five principles can emerge within the context of nursing education; however, adherence to these very principles, which is essential to improving patient care, can offer solutions to these dilemmas. To ensure the ethical and responsible use of Gen AI in nursing education, these principles must be woven into the fabric of curricula, and appropriate guidelines must be developed. Nurse educators have a pivotal role in strategizing comprehensive approaches for ethical AI integration, establishing clear guidelines, and instilling critical thinking among students. Fostering lifelong learning and adaptability is key to ensuring that future nurses can successfully navigate the constantly evolving landscape of health care technology. Future research should investigate the long-term impacts of AI utilization on learning outcomes and ethical decision-making.", "isOpenAccess": false, "url": ""}
{"paperId": "1071902c5444d32970620e47321b5d5c3ec9d819", "year": 2025, "title": "Seedream 4.0: Toward Next-generation Multimodal Image Generation", "authors": "Yunpeng Chen, Yu Gao, Lixue Gong, Meng Guo, Qiushan Guo, Zhiyao Guo, Xiaoxia Hou, Weilin Huang, Yixuan Huang, Xiaowen Jian, Huafeng Kuang, Zhichao Lai, Fanshi Li, Liang Li, Xiaochen Lian, Chao Liao, Liyang Liu, Wei Liu, Yanzuo Lu, Zhengxiong Luo, Tongtong Ou, Guangchao Shi, Yichun Shi, Shiqi Sun, Yu-Chen Tian, Zhi Tian, Peng Wang, Rui Wang, Xun Wang, Ye Wang, Guofeng Wu, Jie Wu, Wenxu Wu, Yonghui Wu, Xin Xia, Xuefeng Xiao, Shuang Xu, Xin Yan, Ceyuan Yang, Jianchao Yang, Zhonghua Zhai, Chenlin Zhang, Heng Zhang, Qi Zhang, Xinyu Zhang, Yuwei Zhang, Shijia Zhao, Wenliang Zhao, W. Zhu", "venue": "arXiv.org", "citationCount": 52, "abstract": "We introduce Seedream 4.0, an efficient and high-performance multimodal image generation system that unifies text-to-image (T2I) synthesis, image editing, and multi-image composition within a single framework. We develop a highly efficient diffusion transformer with a powerful VAE which also can reduce the number of image tokens considerably. This allows for efficient training of our model, and enables it to fast generate native high-resolution images (e.g., 1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning diverse taxonomies and knowledge-centric concepts. Comprehensive data collection across hundreds of vertical scenarios, coupled with optimized strategies, ensures stable and large-scale training, with strong generalization. By incorporating a carefully fine-tuned VLM model, we perform multi-modal post-training for training both T2I and image editing tasks jointly. For inference acceleration, we integrate adversarial distillation, distribution matching, and quantization, as well as speculative decoding. It achieves an inference time of up to 1.8 seconds for generating a 2K image (without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream 4.0 can achieve state-of-the-art results on both T2I and multimodal image editing. In particular, it demonstrates exceptional multimodal capabilities in complex tasks, including precise image editing and in-context reasoning, and also allows for multi-image reference, and can generate multiple output images. This extends traditional T2I systems into an more interactive and multidimensional creative tool, pushing the boundary of generative AI for both creativity and professional applications. We further scale our model and data as Seedream 4.5. Seedream 4.0 and Seedream 4.5 are accessible on Volcano Engine https://www.volcengine.com/experience/ark?launch=seedream.", "isOpenAccess": false, "url": ""}
{"paperId": "ecdb6ebe9ccb6cebd40bac577a2071c2c3197ea1", "year": 2024, "title": "Transforming Assessment: The Impacts and Implications of Large Language Models and Generative AI", "authors": "Jiangang Hao, Alina A. von Davier, Victoria Yaneva, Susan M. Lottridge, Matthias von Davier, Deborah J. Harris", "venue": "Educational Measurement: Issues and Practice", "citationCount": 51, "abstract": "The remarkable strides in artificial intelligence (AI), exemplified by ChatGPT, have unveiled a wealth of opportunities and challenges in assessment. Applying cutting\u2010edge large language models (LLMs) and generative AI to assessment holds great promise in boosting efficiency, mitigating bias, and facilitating customized evaluations. Conversely, these innovations raise significant concerns regarding validity, reliability, transparency, fairness, equity, and test security, necessitating careful thinking when applying them in assessments. In this article, we discuss the impacts and implications of LLMs and generative AI on critical dimensions of assessment with example use cases and call for a community effort to equip assessment professionals with the needed AI literacy to harness the potential effectively.", "isOpenAccess": false, "url": ""}
{"paperId": "e69fa42408ce1050abb0e47174e1bddeabb23a98", "year": 2023, "title": "The Age of Generative AI and AI-Generated Everything", "authors": "Hongyang Du, Dusist Niyato, Jiawen Kang, Zehui Xiong, Ping Zhang, Shuguang Cui, Xuemin Shen, Shiwen Mao, Zhu Han, Abbas Jamalipour, H. V. Poor, Dong In Kim", "venue": "IEEE Network", "citationCount": 51, "abstract": "Generative AI (GAI) has emerged as a significant advancement in artificial intelligence, renowned for its language and image generation capabilities. This paper presents \u201cAI-Generated Everything\u201d (AIGX), a concept that extends GAI beyond mere content creation to real-time adaptation and control across diverse technological domains. In networking, AIGX collaborates closely with physical, data link, network, and application layers to enhance real-time network management that responds to various system and service settings as well as application and user requirements. Networks, in return, serve as crucial components in further AIGX capability optimization through the AIGX lifecycle, i.e., data collection, distributed pre-training, and rapid decision-making, thereby establishing a mutually enhancing interplay. Moreover, we offer an in-depth case study focused on power allocation to illustrate the interdependence between AIGX and networking systems. Through this exploration, the article analyzes the significant role of GAI for networking, clarifies the ways networks augment AIGX functionalities, and underscores the virtuous interactive cycle they form. It is hoped that this article will pave the way for subsequent future research aimed at fully unlocking the potential of GAI and networks.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2311.00947"}
{"paperId": "aaa971c619766f9445c223a22783dab303b7d526", "year": 2024, "title": "A Comparative Analysis of Generative Artificial Intelligence Tools for Natural Language Processing", "authors": "A. Iorliam, Joseph Abunimye Ingio", "venue": "Journal of Computing Theories and Applications", "citationCount": 51, "abstract": "Generative artificial intelligence tools have recently attracted a great deal of attention. This is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. This paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (AI) tools, namely ChatGPT, Perplexity AI, YouChat, ChatSonic, Google's Bard, Microsoft Bing Assistant, HuggingChat, Jasper AI, and Quora's Poe, paying attention to the Pros and Cons each of the AI tools presents. This comparative analysis shows that the generative AI tools have several Pros that outweigh the Cons. Further, we explore the transformative impact of generative AI in Natural Language Processing (NLP), focusing on its integration with search engines, privacy concerns, and ethical implications. A comparative analysis categorizes generative AI tools based on popularity and evaluates challenges in development, including data limitations and computational costs. The study highlights ethical considerations such as technology misuse and regulatory challenges. Additionally, we delved into AI Planning techniques in NLP, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. These planning approaches are vital in achieving specific goals in NLP tasks. In conclusion, we provide a concise overview of the current state of generative AI, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction. \u00a0", "isOpenAccess": true, "url": "https://publikasi.dinus.ac.id/index.php/jcta/article/download/9447/4379"}
{"paperId": "9d459dcae14f80dc1f2ec0495435191430c0c654", "year": 2023, "title": "Digital transformation in engineering education: Exploring the potential of AI-assisted learning", "authors": "Thanh Pham, Thanh Binh Nguyen, Son Ha, Ngoc Thanh Nguyen Ngoc", "venue": "Australasian Journal of Educational Technology", "citationCount": 51, "abstract": "This research explored the potential of artificial intelligence (AI)-assisted learning using ChatGPT in an engineering course at a university in South-east Asia. The study investigated the benefits and challenges that students may encounter when utilising ChatGPT-3.5 as a learning tool. This research developed an AI-assisted learning flow that empowers learners and lecturers to integrate ChatGPT into their teaching and learning processes. The flow was subsequently used to validate and assess a variety of exercises, tutorial tasks and assessment-like questions for the course under study. Introducing a self-rating system allowed the study to facilitate users in assessing the generative responses. The findings indicate that ChatGPT has significant potential to assist students; however, there is a necessity for training and offering guidance to students on effective interactions with ChatGPT. The study contributes to the evidence of the potential of AI-assisted learning and identifies areas for future research in refining the use of AI tools to better support students' educational journey.\nImplications for practice or policy\n\nEducators and administrators could review the usage of ChatGPT in an engineering technology course and study the implications of generative AI tools in higher education.\nAcademics could adapt and modify the proposed AI-assisted learning flow in this paper to suit their classroom.\nStudents can review and adopt the proposed AI-assisted learning flow in this paper for their studies.\nResearchers could follow up on the application of ChatGPT in teaching and learning: teaching quality and student experience, academic integrity and assessment design.\n", "isOpenAccess": true, "url": "https://ajet.org.au/index.php/AJET/article/download/8825/2048"}
{"paperId": "91cb499142b609bedb327c41b4b5738a0aa5b4bb", "year": 2024, "title": "Generative AI and large language models in health care: pathways to implementation", "authors": "Marium M. Raza, Kaushik P. Venkatesh, J. Kvedar", "venue": "npj Digital Medicine", "citationCount": 51, "abstract": "Generative AI is designed to create new content from trained parameters. Learning from large amounts of data, many of these models aim to simulate human conversation. Generative AI is being applied to many different sectors. Within healthcare there has been innovation specifically towards generative AI models trained on electronic medical record data. A recent review characterizes these models, their strengths, and weaknesses. Inspired by that work, we present our evaluation checklist for generative AI models applied to electronic medical records.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-023-00988-4.pdf"}
{"paperId": "8e088f789919d17f608fb009a35926535d77dfed", "year": 2024, "title": "The use of Generative AI in qualitative analysis: Inductive thematic analysis with ChatGPT", "authors": "", "venue": "1", "citationCount": 51, "abstract": null, "isOpenAccess": true, "url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/1585/753"}
{"paperId": "72e0e40e49f00f5dd8a4996ce7173ac553b9b351", "year": 2024, "title": "Uses and limitations of artificial intelligence for oncology", "authors": "Likhitha Kolla, Ravi B. Parikh", "venue": "Cancer", "citationCount": 51, "abstract": "Modern artificial intelligence (AI) tools built on high\u2010dimensional patient data are reshaping oncology care, helping to improve goal\u2010concordant care, decrease cancer mortality rates, and increase workflow efficiency and scope of care. However, data\u2010related concerns and human biases that seep into algorithms during development and post\u2010deployment phases affect performance in real\u2010world settings, limiting the utility and safety of AI technology in oncology clinics. To this end, the authors review the current potential and limitations of predictive AI for cancer diagnosis and prognostication as well as of generative AI, specifically modern chatbots, which interfaces with patients and clinicians. They conclude the review with a discussion on ongoing challenges and regulatory opportunities in the field.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cncr.35307"}
{"paperId": "60f653b14da8cc6866e5062a9700bb5f85a387ca", "year": 2024, "title": "Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes", "authors": "Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho", "venue": "Neural Information Processing Systems", "citationCount": 51, "abstract": "Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can significantly improve the LLM's rejection capability for malicious jailbreak queries, while maintaining the model's performance for benign user queries by adjusting the detection threshold.", "isOpenAccess": false, "url": ""}
{"paperId": "574c225b7082c45b4ce358ec665c7dfb12ae0194", "year": 2024, "title": "The health risks of generative AI-based wellness apps", "authors": "Julian De Freitas, I. G. Cohen", "venue": "Nature Medicine", "citationCount": 51, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "49af4da134c1aec388d7612a0743709d79292e22", "year": 2024, "title": "The Paradox of Artificial Creativity: Challenges and Opportunities of Generative AI Artistry", "authors": "Manuel B. Garcia", "venue": "Creativity Research Journal", "citationCount": 51, "abstract": "ABSTRACT Creativity has long been viewed as the bastion of human expression. With the advent of generative artificial intelligence (AI), there is an emerging notion of artificial creativity that contests traditional perspectives of artistic exploration. This paper explores the complex dynamics of this evolution by examining how generative AI intertwines with and transforms the art world. It presents a comprehensive analysis of the challenges posed by generative AI in art, from questions of authenticity and intellectual property to ethical dilemmas and impacts on conventional art practices. Simultaneously, it investigates the revolutionary opportunities generative AI offers, including the democratization of art creation, the expansion of creative boundaries, and the development of new collaborative and economic models. The paper posits that the integration of generative AI in art is not just a technological advancement but a significant cultural shift, which necessitates a reevaluation of our understanding of art and the artist. It concludes with a forward-looking perspective, advocating for a collaborative approach to harness the potential of this technology in enriching human creativity and ensuring the vibrant evolution of the art world in the era of AI-driven generation.", "isOpenAccess": false, "url": ""}
{"paperId": "0bcce897df773e5c16e37adeda7d7a0a789d31f8", "year": 2023, "title": "Public perception of generative AI on Twitter: an empirical study based on occupation and usage", "authors": "K. Miyazaki, Taichi Murayama, T. Uchiba, Jisun An, Haewoon Kwak", "venue": "EPJ Data Science", "citationCount": 51, "abstract": "The emergence of generative AI has sparked substantial discussions, with the potential to have profound impacts on society in all aspects. As emerging technologies continue to advance, it is imperative to facilitate their proper integration into society, managing expectations and fear. This paper investigates users\u2019 perceptions of generative AI using 3M posts on Twitter from January 2019 to March 2023, especially focusing on their occupation and usage. We find that people across various occupations, not just IT-related ones, show a strong interest in generative AI. The sentiment toward generative AI is generally positive, and remarkably, their sentiments are positively correlated with their exposure to AI. Among occupations, illustrators show exceptionally negative sentiment mainly due to concerns about the unethical usage of artworks in constructing AI. People use ChatGPT in diverse ways, and notably the casual usage in which they \u201cplay with\u201d ChatGPT tends to be associated with positive sentiments. These findings would offer valuable lessons for policymaking on the emergence of new technology and also empirical insights for the considerations of future human-AI symbiosis.", "isOpenAccess": true, "url": "https://epjdatascience.springeropen.com/counter/pdf/10.1140/epjds/s13688-023-00445-y"}
{"paperId": "f4554e57aa1688cd819988d735b6e2930b524b34", "year": 2025, "title": "Generative AI Empowered Network Digital Twins: Architecture, Technologies, and Applications", "authors": "Tong Li, Qingyue Long, Haoye Chai, Shiyuan Zhang, Fenyu Jiang, Haoqiang Liu, Wenzhen Huang, Depeng Jin, Yong Li", "venue": "ACM Computing Surveys", "citationCount": 50, "abstract": "The rapid advancement of mobile networks highlights the limitations of traditional network planning and optimization methods, particularly in modeling, evaluation, and application. Network Digital Twins, which simulate networks in the digital domain for evaluation, offer a solution to these challenges. This concept is further enhanced by generative AI technology, which promises more efficient and accurate AI-driven data generation for network simulation and optimization. This survey provides insights into generative AI-empowered network digital twins. We begin by outlining the architecture of a network digital twin, which encompasses both digital and physical domains. This architecture involves four key steps: data processing and network monitoring, digital replication and network simulation, designing and training network optimizers, Sim2Real, and network control. Next, we systematically discuss the related studies in each step and make a detailed taxonomy of the problem studied, the methods used, and the key designs leveraged. Each step is examined with a focus on the role of generative AI, from estimating missing data and simulating network behaviors to designing control strategies and bridging the gap between digital and physical domains. Finally, we discuss the open issues and challenges of generative AI-based network digital twins.", "isOpenAccess": false, "url": ""}
{"paperId": "eb97f189867a26e5dc2b54723df6c4f47cdc88f4", "year": 2023, "title": "Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks", "authors": "M. Ferrag, M. Debbah, Muna Al-Hawawreh", "venue": "2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW)", "citationCount": 50, "abstract": "The next generation of cellular technology, 6G, is being developed to enable a wide range of new applications and services for the Internet of Things (IoT). One of 6G\u2019s main advantages for IoT applications is its ability to support much higher data rates and bandwidth as well as to support ultralow latency. However, with this increased connectivity will come to an increased risk of cyber threats, as attackers will be able to exploit the large network of connected devices. Generative Artificial Intelligence (AI) can be used to detect and prevent cyber attacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we discuss the use of generative AI for cyber threat-hunting (CTH) in 6G-enabled IoT networks. Then, we propose a new generative adversarial network (GAN) and Transformer-based model for CTH in 6Genabled IoT Networks. The experimental analysis results with a new cyber security dataset demonstrate that the Transformer-based security model for CTH can detect IoT attacks with a high overall accuracy of 95%. We examine the challenges and opportunities and conclude by highlighting the potential of generative AI in enhancing the security of 6G-enabled IoT networks and call for further research to be conducted in this area.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2303.11751"}
{"paperId": "a13bbde142ea866156a8ae8b1801fb6179c9ffd2", "year": 2024, "title": "Factors affecting generative artificial intelligence, such as ChatGPT, use in higher education: An application of technology acceptance model", "authors": "Muhammad Farrukh Shahzad, Shuo Xu, Muhammad Asif", "venue": "British Educational Research Journal", "citationCount": 50, "abstract": "The adoption of generative artificial intelligence (GAI) tools, such as ChatGPT, in higher education presents numerous opportunities and challenges. The use of GAI technologies in various fields, including education, has accelerated as technology develops. The widely used language model ChatGPT, developed by OpenAI, has become progressively more important, especially in the field of education. This study employs the technology acceptance model to investigate the factors influencing the employment of ChatGPT within the higher education sector of Pakistan. This study employed the PLS\u2010SEM method for probing data collected from 368 Pakistani university students. The findings indicate that ChatGPT trust positively mediates the affiliation between ChatGPT self\u2010efficacy, ChatGPT actual use, ChatGPT use for information and ChatGPT use for interaction. Further, ChatGPT usefulness and ChatGPT ease of use significantly moderate the association between ChatGPT self\u2010efficacy and ChatGPT trust. Educators must encourage students to use ChatGPT safely to preserve their critical thinking, problem\u2010solving abilities and creativity during assessments. This study contributes to understanding generative AI tools such as ChatGPT that are used in educational settings and provides insights for administrators and policymakers aiming to implement these technologies effectively.", "isOpenAccess": false, "url": ""}
{"paperId": "8c44c3fa1d3cbc9cbde4cb028f598f1999d539d7", "year": 2024, "title": "Generative Retrieval-Augmented Ontologic Graph and Multiagent Strategies for Interpretive Large Language Model-Based Materials Design", "authors": "Markus J. Buehler", "venue": "ACS Engineering Au", "citationCount": 50, "abstract": "Transformer neural networks show promising capabilities, in particular for uses in materials analysis, design, and manufacturing, including their capacity to work effectively with human language, symbols, code, and numerical data. Here, we explore the use of large language models (LLMs) as a tool that can support engineering analysis of materials, applied to retrieving key information about subject areas, developing research hypotheses, discovery of mechanistic relationships across disparate areas of knowledge, and writing and executing simulation codes for active knowledge generation based on physical ground truths. Moreover, when used as sets of AI agents with specific features, capabilities, and instructions, LLMs can provide powerful problem-solution strategies for applications in analysis and design problems. Our experiments focus on using a fine-tuned model, MechGPT, developed based on training data in the mechanics of materials domain. We first affirm how fine-tuning endows LLMs with a reasonable understanding of subject area knowledge. However, when queried outside the context of learned matter, LLMs can have difficulty recalling correct information and may hallucinate. We show how this can be addressed using retrieval-augmented Ontological Knowledge Graph strategies. The graph-based strategy helps us not only to discern how the model understands what concepts are important but also how they are related, which significantly improves generative performance and also naturally allows for injection of new and augmented data sources into generative AI algorithms. We find that the additional feature of relatedness provides advantages over regular retrieval augmentation approaches and not only improves LLM performance but also provides mechanistic insights for exploration of a material design process. Illustrated for a use case of relating distinct areas of knowledge, here, music and proteins, such strategies can also provide an interpretable graph structure with rich information at the node, edge, and subgraph level that provides specific insights into mechanisms and relationships. We discuss other approaches to improve generative qualities, including nonlinear sampling strategies and agent-based modeling that offer enhancements over single-shot generations, whereby LLMs are used to both generate content and assess content against an objective target. Examples provided include complex question answering, code generation, and execution in the context of automated force-field development from actively learned density functional theory (DFT) modeling and data analysis.", "isOpenAccess": true, "url": "https://pubs.acs.org/doi/pdf/10.1021/acsengineeringau.3c00058"}
{"paperId": "8a47797163543d65ca3d726d6ffa6f96a7191626", "year": 2024, "title": "Integrating Generative AI and IoT for Sustainable Smart Tourism Destinations", "authors": "Pannee Suanpang, Pattanaphong Pothipassa", "venue": "Sustainability", "citationCount": 50, "abstract": "This paper aims to develop a groundbreaking approach to fostering inclusive smart tourism destinations by integrating generative artificial intelligence (Gen AI) with natural language processing (NLP) and the Internet of Things (IoT) into an intelligent platform that supports tourism decision making and travel planning in smart tourism destinations. The acquisition of this new technology was conducted using Agile methodology through requirements analysis, system architecture analysis and design, implementation, and user evaluation. The results revealed that the synergistic combination of these technologies was organized into three tiers. The system provides information, including place names, images, descriptive text, and an audio option for users to listen to the information, supporting tourists with disabilities. Employing advanced AI algorithms alongside NLP, developed systems capable of generating predictive analytics, personalized recommendations, and conducting real-time, multilingual communication with tourists. This system was implemented and evaluated in Suphan Buri and Ayutthaya, UNESCO World Heritage sites in Thailand, with 416 users participating. The results showed that system satisfaction was influenced by (1) the tourism experience, (2) tourism planning and during-trip factors (attention, interest, and usage), and (3) emotion. The relative Chi-square (\u03c72/df) of 1.154 indicated that the model was suitable. The Comparative Fit Index (CFI) was 0.990, the Goodness-of-Fit Index (GFI) was 0.965, and the model based on the research hypothesis was consistent with the empirical data. This paper contributions significant advancements in the field of smart tourism by demonstrating the integration of Gen AI, NLP, and the IoT and offering practical solutions and theoretical insights that enhance accessibility, personalization, and environmental sustainability in tourism.", "isOpenAccess": true, "url": "https://doi.org/10.3390/su16177435"}
{"paperId": "8235075ecdfb41045a7824f71c2985617dc4016f", "year": 2024, "title": "The impact of large language models on higher education: exploring the connection between AI and Education 4.0", "authors": "Iris Cristina Pelaez-Sanchez, Davis Velarde-Camaqui, L. Glasserman-Morales", "venue": "Frontiers in Education", "citationCount": 50, "abstract": "The digital transformation has profoundly affected every facet of human life, with technological advancements potentially reshaping the economy, society, and our daily living and working modalities. Artificial Intelligence (AI), particularly Generative AI (GAI), has emerged as a pivotal disruption in education, showcasing the capability to produce diverse and context-relevant content. Generative Artificial Intelligence (GAI) has revolutionized natural language processing, computer vision, and creative arts. Large language models (LLMs) like GPT-4 and Open Assistant and tools like DALL-E and Midjourney for the visual and creative domain are increasingly used for various tasks by students and others with critical information needs. AI presents novel avenues for crafting effective learning activities and developing enhanced technology-driven learning applications in the educational sector. However, integrating AI with a pedagogical focus pose challenge. Education 4.0, which integrates emerging technologies and innovative strategies, aims to prepare new generations for a technologically fluid world. This systematic literature review aims to analyze the use of LLMs in higher education within the context of Education 4.0\u2019s pedagogical approaches, identifying trends and challenges from a selection of 83 relevant articles out of an initial set of 841 papers. The findings underscore the significant potential of LLMs to enrich higher education, aligning with Education 4.0 by fostering more autonomous, collaborative, and interactive learning. It highlights the necessity for human oversight to ensure the quality and accuracy of AI-generated content. It addresses ethical and legal challenges to ensure equitable implementation, suggesting an exploration of LLM integration that complements human interaction while maintaining academic integrity and pedagogical foundation.", "isOpenAccess": true, "url": "https://doi.org/10.3389/feduc.2024.1392091"}
{"paperId": "7b74c355abb0ec1d9800223ed3bfd7ccb6c943bc", "year": 2023, "title": "A Preliminary Checklist (METRICS) to Standardize the Design and Reporting of Studies on Generative Artificial Intelligence\u2013Based Models in Health Care Education and Practice: Development Study Involving a Literature Review", "authors": "Malik Sallam, M. Barakat, Mohammed Sallam", "venue": "Interactive Journal of Medical Research", "citationCount": 50, "abstract": "Background Adherence to evidence-based practice is indispensable in health care. Recently, the utility of generative artificial intelligence (AI) models in health care has been evaluated extensively. However, the lack of consensus guidelines on the design and reporting of findings of these studies poses a challenge for the interpretation and synthesis of evidence. Objective This study aimed to develop a preliminary checklist to standardize the reporting of generative AI-based studies in health care education and practice. Methods A literature review was conducted in Scopus, PubMed, and Google Scholar. Published records with \u201cChatGPT,\u201d \u201cBing,\u201d or \u201cBard\u201d in the title were retrieved. Careful examination of the methodologies employed in the included records was conducted to identify the common pertinent themes and the possible gaps in reporting. A panel discussion was held to establish a unified and thorough checklist for the reporting of AI studies in health care. The finalized checklist was used to evaluate the included records by 2 independent raters. Cohen \u03ba was used as the method to evaluate the interrater reliability. Results The final data set that formed the basis for pertinent theme identification and analysis comprised a total of 34 records. The finalized checklist included 9 pertinent themes collectively referred to as METRICS (Model, Evaluation, Timing, Range/Randomization, Individual factors, Count, and Specificity of prompts and language). Their details are as follows: (1) Model used and its exact settings; (2) Evaluation approach for the generated content; (3) Timing of testing the model; (4) Transparency of the data source; (5) Range of tested topics; (6) Randomization of selecting the queries; (7) Individual factors in selecting the queries and interrater reliability; (8) Count of queries executed to test the model; and (9) Specificity of the prompts and language used. The overall mean METRICS score was 3.0 (SD 0.58). The tested METRICS score was acceptable, with the range of Cohen \u03ba of 0.558 to 0.962 (P<.001 for the 9 tested items). With classification per item, the highest average METRICS score was recorded for the \u201cModel\u201d item, followed by the \u201cSpecificity\u201d item, while the lowest scores were recorded for the \u201cRandomization\u201d item (classified as suboptimal) and \u201cIndividual factors\u201d item (classified as satisfactory). Conclusions The METRICS checklist can facilitate the design of studies guiding researchers toward best practices in reporting results. The findings highlight the need for standardized reporting algorithms for generative AI-based studies in health care, considering the variability observed in methodologies and reporting. The proposed METRICS checklist could be a preliminary helpful base to establish a universally accepted approach to standardize the design and reporting of generative AI-based studies in health care, which is a swiftly evolving research topic.", "isOpenAccess": true, "url": "https://www.i-jmr.org/2024/1/e54704/PDF"}
{"paperId": "76f894bd6da252eae4a48cad300d0279061ea087", "year": 2023, "title": "ChatGPT in the Classroom. Exploring Its Potential and Limitations in a Functional Programming Course", "authors": "Dan-Matei Popovici", "venue": "International journal of human computer interactions", "citationCount": 50, "abstract": "Abstract In November 2022, OpenAI has introduced ChatGPT \u2013 a chatbot based on supervised and reinforcement learning. Not only can it answer questions emulating human-like responses, but it can also generate code from scratch or complete coding templates provided by the user. ChatGPT can generate unique responses which render any traditional anti-plagiarism tool useless. Its release has ignited a heated debate about its usage in academia, especially by students. We have found, to our surprise, that our students at POLITEHNICA University of Bucharest (UPB) have been using generative AI tools (ChatGPT and its predecessors) for solving homework, for at least 6\u2009months. We therefore set out to explore the capabilities of ChatGPT and assess its value for educational purposes. We used ChatGPT to solve all our coding assignments for the semester from our UPB Functional Programming course. We discovered that, although ChatGPT provides correct answers in 68% of the cases, only around half of those are legible solutions which can benefit students in some form. On the other hand, ChatGPT has a very good ability to perform code review on student programming homework. Based on these findings, we discuss the pros and cons of ChatGPT in a teaching environment, as well as means for integrating GPT models for generating code reviews, in order to improve the code-writing skills of students.", "isOpenAccess": false, "url": ""}
{"paperId": "701ef60330ecb4c3a82afe0f735ad92b1c683f1f", "year": 2024, "title": "Dr. Google to Dr. ChatGPT: assessing the content and quality of artificial intelligence-generated medical information on appendicitis", "authors": "Yazid K. Ghanem, Armaun D. Rouhi, Ammr Al-Houssan, Zena Saleh, M. C. Moccia, Hansa Joshi, K. Dumon, Y. Hong, Francis R. Spitz, Amit R T Joshi, Michael E. Kwiatt", "venue": "Surgical Endoscopy", "citationCount": 50, "abstract": "Generative artificial intelligence (AI) chatbots have recently been posited as potential sources of online medical information for patients making medical decisions. Existing online patient-oriented medical information has repeatedly been shown to be of variable quality and difficult readability. Therefore, we sought to evaluate the content and quality of AI-generated medical information on acute appendicitis. A modified DISCERN assessment tool, comprising 16 distinct criteria each scored on a 5-point Likert scale (score range 16\u201380), was used to assess AI-generated content. Readability was determined using the Flesch Reading Ease (FRE) and Flesch-Kincaid Grade Level (FKGL) scores. Four popular chatbots, ChatGPT-3.5 and ChatGPT-4, Bard, and Claude-2, were prompted to generate medical information about appendicitis. Three investigators independently scored the generated texts blinded to the identity of the AI platforms. ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 had overall mean (SD) quality scores of 60.7 (1.2), 62.0 (1.0), 62.3 (1.2), and 51.3 (2.3), respectively, on a scale of 16\u201380. Inter-rater reliability was 0.81, 0.75, 0.81, and 0.72, respectively, indicating substantial agreement. Claude-2 demonstrated a significantly lower mean quality score compared to ChatGPT-4 (p\u2009=\u20090.001), ChatGPT-3.5 (p\u2009=\u20090.005), and Bard (p\u2009=\u20090.001). Bard was the only AI platform that listed verifiable sources, while Claude-2 provided fabricated sources. All chatbots except for Claude-2 advised readers to consult a physician if experiencing symptoms. Regarding readability, FKGL and FRE scores of ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 were 14.6 and 23.8, 11.9 and 33.9, 8.6 and 52.8, 11.0 and 36.6, respectively, indicating difficulty readability at a college reading skill level. AI-generated medical information on appendicitis scored favorably upon quality assessment, but most either fabricated sources or did not provide any altogether. Additionally, overall readability far exceeded recommended levels for the public. Generative AI platforms demonstrate measured potential for patient education and engagement about appendicitis.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s00464-024-10739-5.pdf"}
{"paperId": "66711d1cc873ac608977674cd9020a4a5695bd9f", "year": 2023, "title": "Unit Test Generation using Generative AI : A Comparative Performance Analysis of Autogeneration Tools", "authors": "Shreya Bhatia, Tarushi Gandhi, Dhruv Kumar, Pankaj Jalote", "venue": "2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)", "citationCount": 50, "abstract": "Generating unit tests is a crucial task in software development, demanding substantial time and effort from programmers. The advent of Large Language Models (LLMs) introduces a novel avenue for unit test script generation. This research aims to experimentally investigate the effectiveness of LLMs, specifically exemplified by ChatGPT, for generating unit test scripts for Python programs, and how the generated test cases compare with those generated by an existing unit test generator (Pynguin). For experiments, we consider three types of code units: 1) Procedural scripts, 2) Function-based modular code, and 3) Class-based code. The generated test cases are evaluated based on criteria such as coverage, correctness, and readability. Our results show that ChatGPT's performance is comparable with Pynguin in terms of coverage, though for some cases its performance is superior to Pynguin. We also find that about a third of assertions generated by ChatGPT for some categories were incorrect. Our results also show that there is minimal overlap in missed statements between ChatGPT and Pynguin, thus, suggesting that a combination of both tools may enhance unit test generation performance. Finally, in our experiments, prompt engineering improved ChatGPT's performance, achieving a much higher coverage.CCS Concepts\u2022 Software and its engineering \u2192 Software testing and debugging; \u2022 Computing methodologies \u2192 Artificial intelligence.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2312.10622"}
{"paperId": "5dea6cc412aa821ffdb34eca304a7f0e1d44fb13", "year": 2024, "title": "Advancing Students\u2019 Academic Excellence in Distance Education: Exploring the Potential of Generative AI Integration to Improve Academic Writing Skills", "authors": "K. Maphoto, Kershnee Sevnarayan, Ntshimane Elphas Mohale, Zuleika Suliman, Tumelo Jacquiline Ntsopi, Douglas Mokoena", "venue": "Open Praxis", "citationCount": 50, "abstract": "This qualitative study explores the potential of generative artificial intelligence (AI) to improve the academic writing skills of a large student cohort within the context of a distance learning institution. Utilising qualitative methods, the research explores diverse approaches and applications of generative AI to elevate teaching and learning experiences. Grounded in socio-cultural theory and a human-AI collaboration framework, the study highlights the synergistic interplay between human intelligence and generative AI capabilities. Email interviews with lecturers, focus group discussions with students, and informal discussions with markers on a WhatsApp group helped researchers to (1) understand lecturers\u2019 perceptions of generative AI integration in the Academic Writing module, (2) explore students\u2019 perspectives on the potential of generative AI as a guide in the Academic Writing module, and (3) examine the potential of generative AI on students\u2019 motivation to enhance their academic writing skills. Findings from the study reveal that the potential of generative AI has a positive impact on teaching and learning experiences, providing innovative opportunities for academics. This research contributes to the discourse on the intersection of generative AI and education, reiterating the innovative potential of generative AI in redefining pedagogical strategies and shaping the future of distance learning", "isOpenAccess": true, "url": "https://storage.googleapis.com/jnl-up-j-op-files/journals/1/articles/649/660d524ba7e22.pdf"}
{"paperId": "57c61a12a9a152ca3641785234dc1477844e39b8", "year": 2023, "title": "Brain tumor segmentation using synthetic MR images - A comparison of GANs and diffusion models", "authors": "Muhammad Usman Akbar, M\u00e5ns Larsson, Ida Blystad, Anders Eklund", "venue": "Scientific Data", "citationCount": 50, "abstract": "Large annotated datasets are required for training deep learning models, but in medical imaging data sharing is often complicated due to ethics, anonymization and data protection legislation. Generative AI models, such as generative adversarial networks (GANs) and diffusion models, can today produce very realistic synthetic images, and can potentially facilitate data sharing. However, in order to share synthetic medical images it must first be demonstrated that they can be used for training different networks with acceptable performance. Here, we therefore comprehensively evaluate four GANs (progressive GAN, StyleGAN 1\u20133) and a diffusion model for the task of brain tumor segmentation (using two segmentation networks, U-Net and a Swin transformer). Our results show that segmentation networks trained on synthetic images reach Dice scores that are 80%\u201390% of Dice scores when training with real images, but that memorization of the training images can be a problem for diffusion models if the original dataset is too small. Our conclusion is that sharing synthetic medical images is a viable option to sharing real images, but that further work is required. The trained generative models and the generated synthetic images are shared on AIDA data hub.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41597-024-03073-x.pdf"}
{"paperId": "3f632cf3fcdd36c58432dee1bd364e70b7d2d84a", "year": 2023, "title": "Generative Artificial Intelligence and the Emergence of Creative Displacement Anxiety", "authors": "Nicholas Caporusso", "venue": "Research Directs in Psychology and Behavior", "citationCount": 50, "abstract": "Generative Artificial Intelligence (AI), a subset of AI that can generate novel content such as images, text, and music, has the unique transformative potential of augmenting human creativity, offering tools that can enhance creative expression and open unprecedented avenues for innovation. However, alongside its remarkable capabilities, the inevitable pervasive integration of this technology in every aspect of human life, including creative fields, involves the risk of giving rise to unforeseen psychological challenges for our society. This article discusses the potential emergence of a novel psychological phenomenon consisting in the multifaceted response to the perceived overshadowing of human creativity by AI-driven tools. Specifically, the article introduces the term \u201cCreative Displacement Anxiety\u201d (CDA), describe its foundation, and discuss its relationships with established psychological and psychosocial models, theories, constructs, and diagnoses such as technostress, impostor syndrome, cognitive dissonance, and economic anxiety. The article conceptualizes and elucidates the potential root causes, symptoms, and implications of CDA. Additionally, it discusses how some of the possible negative mental health outcomes could potentially be mitigated. Our work emphasizes the need for interventions that raise awareness on generative AI, support individuals in accepting and incorporating AI as a creative tool and companion and helps them navigate this new landscape. Finally, by offering a view of the interplay between AI advancements and the human creative psyche, our research aims at fostering the discussion around embracing the positive contribution of generative AI to our society.", "isOpenAccess": true, "url": "https://www.researchdirects.com/index.php/psychology/article/download/95/75"}
{"paperId": "0e2edab18dc00cfda593b2426a344f40cacd3654", "year": 2023, "title": "Generative AI for Semantic Communication: Architecture, Challenges, and Outlook", "authors": "Le Xia, Yao Sun, Cheng Liang, Lei Zhang, M. Imran, D. Niyato", "venue": "IEEE wireless communications", "citationCount": 50, "abstract": "Semantic communication (SemCom) is expected to be a core paradigm in future communication networks, yielding significant benefits in terms of spectrum resource saving and information interaction efficiency. However, the existing SemCom structure is limited by the lack of context-reasoning ability and background knowledge provisioning, which, therefore, motivates us to seek the potential of incorporating generative artificial intelligence (GAI) technologies with SemCom. Recognizing GAI's powerful capability in automating and creating valuable, diverse, and personalized multimodal content, this article first highlights the principal characteristics of the combination of GAI and SemCom along with their pertinent benefits and challenges. To tackle these challenges, we further propose a novel GAI-integrated SemCom network (GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing global and local GAI models, our GAI-SCN enables multimodal semantic content provisioning, semantic-level joint-source-channel coding, and AIGC acquisition to maximize the efficiency and reliability of semantic reasoning and resource utilization. Afterward, we present a detailed implementation workflow of GAI-SCN, followed by corresponding initial simulations for performance evaluation in comparison with two benchmarks. Finally, we discuss several open issues and offer feasible solutions to unlock the full potential of GAI-SCN.", "isOpenAccess": false, "url": ""}
{"paperId": "036fcafe93e692b245cc1752be671166ed21d3f7", "year": 2024, "title": "Protecting scientific integrity in an age of generative AI", "authors": "Wolfgang Blau, Vinton G. Cerf, Juan Enriquez, Joseph S. Francisco, Urs Gasser, Mary L Gray, Mark Greaves, Barbara J Grosz, K. Jamieson, G. Haug, John L Hennessy, Eric Horvitz, David Kaiser, A. London, Robin Lovell-Badge, Marcia K McNutt, Martha Minow, Tom M. Mitchell, Susan Ness, Shobita Parthasarathy, Saul Perlmutter, William H. Press, Jeannette M Wing, M. Witherell", "venue": "Proceedings of the National Academy of Sciences of the United States of America", "citationCount": 50, "abstract": "Revolutionary advances in AI have brought us to a transforma - tive moment for science. AI is accelerating scientific discoveries and analyses. At the same time, its tools and processes chal -", "isOpenAccess": true, "url": "https://www.pnas.org/doi/pdf/10.1073/pnas.2407886121"}
{"paperId": "e09501b14db36e10a35f2c5e53cd75245d555691", "year": 2024, "title": "Griefbots, Deadbots, Postmortem Avatars: on Responsible Applications of Generative AI in the Digital Afterlife Industry", "authors": "Tomasz Hollanek, Katarzyna Nowaczyk-Basi\u0144ska", "venue": "Philosophy & Technology", "citationCount": 49, "abstract": "To analyze potential negative consequences of adopting generative AI solutions in the digital afterlife industry (DAI), in this paper we present three speculative design scenarios for AI-enabled simulation of the deceased. We highlight the perspectives of the data donor, data recipient, and service interactant \u2013 terms we employ to denote those whose data is used to create \u2018deadbots,\u2019 those in possession of the donor\u2019s data after their death, and those who are meant to interact with the end product. We draw on the scenarios to map out several key ethical concerns posed by \u2018re-creation services\u2019 and to put forward recommendations on the ethical development of AI systems in this specific area of application. The recommendations, targeted at providers of AI-enabled re-creation services, include suggestions for developing sensitive procedures for retiring deadbots, ensuring meaningful transparency, restricting access to such services to adult users only, and adhering to the principle of mutual consent of both data donors and service interactants. While we suggest practical solutions to the socio-ethical challenges posed by the emergence of re-creation services, we also emphasize the importance of ongoing interdisciplinary research at the intersection of the ethics of AI and the ethics of the DAI.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s13347-024-00744-w.pdf"}
{"paperId": "d4e52f63a52f7b3ee61e1fbafa4e40e60490dbb3", "year": 2024, "title": "Machine Learning for Healthcare-IoT Security: A Review and Risk Mitigation", "authors": "Mirza Akhi Khatun, S. Memon, Ciar\u00e1n Eising, L. L. Dhirani", "venue": "IEEE Access", "citationCount": 49, "abstract": "The Healthcare Internet-of-Things (H-IoT), commonly known as Digital Healthcare, is a data-driven infrastructure that highly relies on smart sensing devices (i.e., blood pressure monitors, temperature sensors, etc.) for faster response time, treatments, and diagnosis. However, with the evolving cyber threat landscape, IoT devices have become more vulnerable to the broader risk surface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if exploited, may lead to data breaches, unauthorized access, and lack of command and control and potential harm. This paper reviews the fundamentals of healthcare IoT, its privacy, and data security challenges associated with machine learning and H-IoT devices. The paper further emphasizes the importance of monitoring healthcare IoT layers such as perception, network, cloud, and application. Detecting and responding to anomalies involves various cyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things (NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust authentication mechanism based on machine learning and deep learning techniques is required to protect and mitigate H-IoT devices from increasing cybersecurity vulnerabilities. Hence, in this review paper, security and privacy challenges and risk mitigation strategies for building resilience in H-IoT are explored and reported.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10371310.pdf"}
{"paperId": "d23b6eb7a9b0552446a0464f1a895b40a9c039b1", "year": 2023, "title": "ChatGPT and its impact on research supervision: Insights from Australian postgraduate research students", "authors": "Yun Dai, Sichen Lai, C. Lim, Angpeng Liu", "venue": "Australasian Journal of Educational Technology", "citationCount": 49, "abstract": "As artificial intelligence (AI) continues to evolve, its impact on academic environments, especially in postgraduate research supervision, becomes increasingly significant. This study explored the impact of ChatGPT, an advanced AI conversational model, on five dimensions of research supervision: functional, enculturation, critical thinking, emancipation and relationship development. Using a qualitative approach, we examined the practices and perspectives of 20 postgraduate research students with at least 4 months\u2019 experience of using ChatGPT in research activities in Australia. The study revealed several areas of impact, including accelerated research progress, enhanced research quality, improved scholarly development and professional skills, enhanced critical thinking, increased student confidence and autonomy, and a deeper supervisory relationship. The findings suggest a shift in the roles and responsibilities of supervisors and students: the former provides strategic direction and high-level guidance, while the latter transits from apprentices to autonomous researchers due to the independence fostered by ChatGPT. This shift suggests an evolving model of postgraduate research supervision, with educational technology acting as epistemic tools to enhance the supervisory process. The study also considers the ethical implications of AI-enabled support.\nImplications for practice or policy: \n\nPostgraduate students can be facilitated by ChatGPT in self-directed research for enhanced independence and autonomy.\nSupervisors can deploy supervisory meetings for high-level guidance and personalized feedback in an AI-enhanced supervision model.\nPostgraduate programmes can leverage generative AI tools for an AI-enhanced research supervision model.\nUniversities need to develop AI literacy curricula and protocols to guide students towards responsible use of generative AI tools while addressing potential challenges.\n", "isOpenAccess": true, "url": "https://ajet.org.au/index.php/AJET/article/download/8843/2026"}
{"paperId": "c37fc281ad01a0c4f401b6758cf10a705564078b", "year": 2024, "title": "Software Engineering Education Must Adapt and Evolve for an LLM Environment", "authors": "V. Kirova, Cyril S. Ku, Joseph R. Laracy, Thomas J. Marlowe", "venue": "Technical Symposium on Computer Science Education", "citationCount": 49, "abstract": "In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3626252.3630927"}
{"paperId": "af16b6f8146432e9437c1dd9b8320ee24ac63455", "year": 2023, "title": "Bloated Disclosures: Can ChatGPT Help Investors Process Information?", "authors": "Alex G. Kim, Maximilian Muhn, Valeri V. Nikolaev", "venue": "Social Science Research Network", "citationCount": 49, "abstract": "Generative AI tools such as ChatGPT can fundamentally change the way investors process information. We probe the economic usefulness of these tools in summarizing complex corporate disclosures using the stock market as a laboratory. The unconstrained summaries are remarkably shorter compared to the originals, whereas their information content is amplified. When a document has a positive (negative) sentiment, its summary becomes more positive (negative). Importantly, the summaries are more effective at explaining stock market reactions to the disclosed information. Motivated by these findings, we propose a measure of information ``bloat.\"We show that bloated disclosure is associated with adverse capital market consequences, such as lower price efficiency and higher information asymmetry. Finally, we show that the model is effective at constructing targeted summaries that identify firms'(non-)financial performance. Collectively, our results indicate that generative AI adds considerable value for investors with information processing constraints.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.10224"}
{"paperId": "a82d3924f488d74af91ba31ff1cf80a6c07ee206", "year": 2023, "title": "Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?", "authors": "Gonzalo Mart\u00ednez Ruiz de Arcaute, Lauren Watson, P. Reviriego, Jos\u00e9 Alberto Hern\u00e1ndez, Marc Ju\u00e1rez, Rik Sarkar", "venue": "arXiv.org", "citationCount": 49, "abstract": "In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.01255"}
{"paperId": "a40dca801310badf6516bc97138d1ea4dba7f9ad", "year": 2023, "title": "Co-creating digital art with generative AI in K-9 education: Socio-material insights", "authors": "Henriikka Vartiainen, M. Tedre, I. Jormanainen", "venue": "International Journal of Education Through Art", "citationCount": 49, "abstract": "The rise of image-generating artificial intelligence (AI) tools has triggered changes in digital art and graphic design, provoking debates in the creative industry. However, scant research exists about children\u2019s and youths\u2019 insights into and encounters with generative AI. Building on sociocultural and new materialist perspectives, this exploratory study proposed to address this gap by exploring middle schoolers\u2019 (N = 10) creative interaction with generative AI, particularly with text-to-image generative models. Qualitative content analyses of emerging learning activities evidenced how generative AI-formed relations were externalized through novel digital artefacts and collaborative discussions. Ideas evolved through peer collaboration organized around creative making with AI. Teachers facilitated relations between people and technology using dialogic teaching, providing room for unpredictability and critical reflection on the impacts of generative AI, especially authorship and copyright. The study concludes with a discussion of the potential uses of generative AI in future art education research and practice.", "isOpenAccess": true, "url": "https://doi.org/10.1386/eta_00143_1"}
{"paperId": "986945a1c5a32ce049a5ed08e19536f98f8b036b", "year": 2023, "title": "Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion", "authors": "Yuanxun Lu, Jingyang Zhang, Shiwei Li, Tian Fang, David McKinnon, Yanghai Tsin, Long Quan, Xun Cao, Yao Yao", "venue": "Computer Vision and Pattern Recognition", "citationCount": 49, "abstract": "Recent advances in generative AI have unveiled significant potential for the creation of 3D content. However, current methods either apply a pre-trained 2D diffusion model with the time-consuming score distillation sampling (SDS), or a direct 3D diffusion model trained on limited 3D data losing generation diversity. In this work, we approach the problem by employing a multi-view 2.5D diffusion fine-tuned from a pre-trained 2D diffusion model. The multi-view 2.5D diffusion directly models the structural distribution of 3D data, while still maintaining the strong generalization ability of the original 2D diffusion model, filling the gap between 2D diffusion-based and direct 3D diffusion-based methods for 3D content generation. During inference, multi-view normal maps are generated using the 2.5D diffusion, and a novel differentiable rasterization scheme is introduced to fuse the almost consistent multi-view normal maps into a consistent 3D model. We further design a normal-conditioned multi-view image generation module for fast appearance generation given the 3D geometry. Our method is a one-pass diffusion process and does not require any SDS optimization as post-processing. We demonstrate through extensive experiments that, our direct 2.5D generation with the specially-designed fusion scheme can achieve diverse, mode-seeking-free, and high-fidelity 3D content generation in only 10 seconds. Project page: https://nju-3dv.github.io/projects/direct25.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2311.15980"}
{"paperId": "8549d32e2ef2102eb9076fc5d40c4fa928436c44", "year": 2024, "title": "Can artificial intelligence support creativity in early design processes?", "authors": "T. Chandrasekera, Zahrasadat Hosseini, Ubhaya Perera", "venue": "International Journal of Architectural Computing", "citationCount": 49, "abstract": "This study focuses on Generative Artificial Intelligence (AI) and its transformative impact on design ideation. Generative AI, recognized for its ability to produce a wide array of design alternatives, has become an important tool in design, reshaping traditional methodologies. It facilitates the generation of novel and diverse design forms, acting as a co-creator in the design process. This technology, through machine learning and pattern recognition, analyzes extensive design datasets, enabling the production of innovative solutions. The utilization of generative AI extends beyond replicating AI-provided solutions; it aids in developing and influencing novel concepts, thus fostering original design solutions. This aligns with the concept of \u2018reflective practice\u2019 in design, where designers iteratively refine concepts through a dialogue between thought and action. The study employed a quasi-experimental design with 40 design students, randomly assigned to two groups of 20 each. Conducted in two phases, each phase involved a distinct urban furniture design task. In Phase 1, Group A was provided with a text-to-image generating AI tool, while Group B was not. In Phase 2, both groups undertook a similar task without AI assistance. This design exercise allowed for examining the influence of AI on creativity and cognitive load. Design outcomes from both tasks were anonymized and evaluated by experienced professionals using the Creative Product Semantic Scale (CPSS), which measures Novelty, Resolution, and Elaboration and Synthesis. Additionally, the NASA Task Load Index (NASA TLX) questionnaire assessed cognitive load aspects such as mental demand and effort. Findings suggest that generative AI significantly influences the creative design process, enhancing the quality of design outcomes and reducing cognitive load. The AI group demonstrated better performance in both tasks, indicating the impact of AI tools on design skills. This study underscores the potential of AI tools in design education, balancing cognitive load management with creativity enhancement.", "isOpenAccess": false, "url": ""}
{"paperId": "8175551c3a234832c095059c2688f393514e86c9", "year": 2023, "title": "Copyright Protection and Accountability of Generative AI: Attack, Watermarking and Attribution", "authors": "Haonan Zhong, Jiamin Chang, Ziyue Yang, Tingmin Wu, Pathum Chamikara Mahawaga Arachchige, Chehara Pathmabandu, Minhui Xue", "venue": "The Web Conference", "citationCount": 49, "abstract": "Generative AI (e.g., Generative Adversarial Networks \u2013 GANs) has become increasingly popular in recent years. However, Generative AI introduces significant concerns regarding the protection of Intellectual Property Rights (IPR) (resp. model accountability) pertaining to images (resp. toxic images) and models (resp. poisoned models) generated. In this paper, we propose an evaluation framework to provide a comprehensive overview of the current state of the copyright protection measures for GANs, evaluate their performance across a diverse range of GAN architectures, and identify the factors that affect their performance and future research directions. Our findings indicate that the current IPR protection methods for input images, model watermarking, and attribution networks are largely satisfactory for a wide range of GANs. We highlight that further attention must be directed towards protecting training sets, as the current approaches fail to provide robust IPR protection and provenance tracing on training sets.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2303.09272"}
{"paperId": "7fd5f9f8028e4e007e8d3d11199c4acb203ca18c", "year": 2024, "title": "Machine Learning for Healthcare Radars: Recent Progresses in Human Vital Sign Measurement and Activity Recognition", "authors": "Shahzad Ahmed, Sung Ho Cho", "venue": "IEEE Communications Surveys and Tutorials", "citationCount": 49, "abstract": "The unprecedented non-contact, non-invasive, and privacy-preserving nature of radar sensors has enabled various healthcare applications, including vital sign monitoring, fall detection, gait analysis, activity recognition, fitness evaluation, and sleep monitoring. Machine learning (ML) is revolutionizing every domain, with radar-based healthcare being no exception. Progress in the field of healthcare radars and ML is complementing the existing radar-based healthcare industry. This article provides an overview of ML usage for two major healthcare applications: vital sign monitoring and activity recognition. Vital sign monitoring is the most promising healthcare application of radar, as it can predict several chronic cardiac and respiratory diseases. Activity recognition is also a prominent application since the inability to perform activities may result in critical suffering. The article presents an overview of commercial radars, radar hardware, and historical progress of healthcare radars, followed by the usage of ML for healthcare radars. Subsequently, the paper discusses how ML can overcome the limitations of conventional radar data processing chains for healthcare radars. The article also touches upon recent generative ML concepts used in healthcare radars. Among several interesting findings, it was discovered that ML does not completely replace existing vital sign monitoring algorithms; rather, ML is deployed to overcome the limitations of traditional algorithms. On the other hand, activity recognition always relies on ML approaches. The most widely used algorithms for both applications are Convolutional Neural Network (CNN) followed by Support Vector Machine (SVM). Generative AI has the capability to augment data and is expected to have a significant impact soon. Recent trends, lessons learned from these trends, and future directions for both healthcare applications are presented in detail. Finally, the future work section discusses a wide range of healthcare topics for humans, ranging from neonates to elderly individuals.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/9739/5451756/10322785.pdf"}
{"paperId": "722d47ddb374c1196a02fe2f3b44575136e5dd6b", "year": 2023, "title": "Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI", "authors": "Yuqian Sun, Zhouyi Li, Ke Fang, Chang Hee Lee, A. Asadipour", "venue": "Artificial Intelligence and Interactive Digital Entertainment Conference", "citationCount": 49, "abstract": "Generative AI (GenAI), encompassing image generation and large language models (LLMs), has opened new avenues for gameplay experiences. This paper introduces \"1001 Nights\", a narrative game centered on GenAI. Drawing inspiration from Wittgenstein's note, \"The limits of my language mean the limits of my world\", the game exemplifies the concept of language as reality. The protagonist, Shahrzad, possesses a unique power: specific keywords, such as \"sword\" or \"shield\", when spoken by others in tales, materialize as tangible weapons, serving as battle equipment against the King. Players guide the LLM-driven King in co-creating narratives, with GPT-4 employing LLM reasoning methods to ensure story consistency. As these narratives progress, the depicted world is dynamically generated and visualized through Stable Diffusion, blurring the boundaries between narrative and in-game reality. This fusion of interactive storytelling combines gameplay paradigms and story together with dynamic content generation. Players not only aim to alter Shahrzad's fate from the original folklore, but also leverage the power of natural language to shape the game's world. With this example, we propose the term \"AI-Native games\" to categorize innovative games where GenAI is fundamental to the game's novel mechanics and very existence.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.12915"}
{"paperId": "665dfa21cfd4a7a01ad7ac6689b84fb78cee6ce1", "year": 2023, "title": "Designs and practices using generative AI for sustainable student discourse and knowledge creation", "authors": "Alwyn Vwen Yen Lee, S. Tan, C. Teo", "venue": "Smart Learning Environments", "citationCount": 49, "abstract": "Utilizing generative artificial intelligence, especially the more popularly used Generative Pre-trained Transformer (GPT) architecture, has made it possible to employ AI in ways that were previously not possible with conventional assessment and evaluation technologies for learning. As educational use cases and academic studies become increasingly prevalent, it is critical for education stakeholders to discuss design considerations and ideals that are key in supporting and augmenting learning via quality classroom discourse that sets the climate for student learning and thinking, and teachers\u2019 transmission of expectations. In this paper, we seek to address how emergent technological advancements such as GPT, can be considered and utilized in designs that are consistent with the ideals of sustainable student discourse and knowledge creation. We showcase contemporary exemplars of possible designs and practices that are based on the pedagogy of knowledge building, with recent illustrations of how GPT may be utilized to sustain students\u2019 knowledge building discourse. We also examine the potential effects and repercussions of technological utilization and misuse, along with insights into GPT\u2019s role in supporting and enhancing knowledge building practices. We anticipate that the findings, through our exploration of designs and practices for knowledge creation, will be able to resonate with a broader audience and instigate meaningful change on issues of teaching and learning within smart learning environments.", "isOpenAccess": true, "url": "https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00279-1"}
{"paperId": "2ea12f6beb2d504b985503e945526a85251ed3af", "year": 2024, "title": "Generative artificial intelligence in\u00a0manufacturing: opportunities for actualizing Industry 5.0 sustainability goals", "authors": "Morteza Ghobakhloo, Masood Fathi, Mohammad Iranmanesh, Mantas Vilkas, Andrius Grybauskas, A. Amran", "venue": "Journal of Manufacturing Technology Management", "citationCount": 49, "abstract": "PurposeThis study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach.Design/methodology/approachThe study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0.FindingsGenerative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations.Practical implicationsWhile each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits.Originality/valueThis study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.", "isOpenAccess": true, "url": "https://www.emerald.com/insight/content/doi/10.1108/JMTM-12-2023-0530/full/pdf?title=generative-artificial-intelligence-in-manufacturing-opportunities-for-actualizing-industry-50-sustainability-goals"}
{"paperId": "275682a77c83df824cf4c0c386a80c1b54047cd4", "year": 2024, "title": "Addressing 6 challenges in generative AI for digital health: A scoping review", "authors": "Tara Templin, Monika W Perez, Sean Sylvia, Jeff Leek, Nasa Sinnott-Armstrong", "venue": "PLOS Digital Health", "citationCount": 49, "abstract": "Generative artificial intelligence (AI) can exhibit biases, compromise data privacy, misinterpret prompts that are adversarial attacks, and produce hallucinations. Despite the potential of generative AI for many applications in digital health, practitioners must understand these tools and their limitations. This scoping review pays particular attention to the challenges with generative AI technologies in medical settings and surveys potential solutions. Using PubMed, we identified a total of 120 articles published by March 2024, which reference and evaluate generative AI in medicine, from which we synthesized themes and suggestions for future work. After first discussing general background on generative AI, we focus on collecting and presenting 6 challenges key for digital health practitioners and specific measures that can be taken to mitigate these challenges. Overall, bias, privacy, hallucination, and regulatory compliance were frequently considered, while other concerns around generative AI, such as overreliance on text models, adversarial misprompting, and jailbreaking, are not commonly evaluated in the current literature.", "isOpenAccess": true, "url": "https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000503&type=printable"}
{"paperId": "113ddfcf87a6cf7bfe70c36a80fe793c7e962878", "year": 2024, "title": "Process Modeling With Large Language Models", "authors": "Humam Kourani, Alessandro Berti, Daniel Schuster, W. M. Aalst", "venue": "BPMDS/EMMSAD@CAiSE", "citationCount": 49, "abstract": "In the realm of Business Process Management (BPM), process modeling plays a crucial role in translating complex process dynamics into comprehensible visual representations, facilitating the understanding, analysis, improvement, and automation of organizational processes. Traditional process modeling methods often require extensive expertise and can be time-consuming. This paper explores the integration of Large Language Models (LLMs) into process modeling to enhance the accessibility of process modeling, offering a more intuitive entry point for non-experts while augmenting the efficiency of experts. We propose a framework that leverages LLMs for the automated generation and iterative refinement of process models starting from textual descriptions. Our framework involves innovative prompting strategies for effective LLM utilization, along with a secure model generation protocol and an error-handling mechanism. Moreover, we instantiate a concrete system extending our framework. This system provides robust quality guarantees on the models generated and supports exporting them in standard modeling notations, such as the Business Process Modeling Notation (BPMN) and Petri nets. Preliminary results demonstrate the framework's ability to streamline process modeling tasks, underscoring the transformative potential of generative AI in the BPM field.", "isOpenAccess": false, "url": ""}
{"paperId": "f8e63df903d95f08839016db3d59d07af7f1275f", "year": 2023, "title": "CVPR 2023 Text Guided Video Editing Competition", "authors": "Jay Zhangjie Wu, Xiuyu Li, Difei Gao, Zhen Dong, Jinbin Bai, Aishani Singh, Xiaoyu Xiang, Youzeng Li, Zuwei Huang, Yuanxi Sun, Rui He, Feng Hu, Junhua Hu, Hai Huang, Hanyu Zhu, Xu Cheng, Jie Tang, Mike Zheng Shou, Kurt Keutzer, Forrest Iandola", "venue": "arXiv.org", "citationCount": 48, "abstract": "Humans watch more than a billion hours of video per day. Most of this video was edited manually, which is a tedious process. However, AI-enabled video-generation and video-editing is on the rise. Building on text-to-image models like Stable Diffusion and Imagen, generative AI has improved dramatically on video tasks. But it's hard to evaluate progress in these video tasks because there is no standard benchmark. So, we propose a new dataset for text-guided video editing (TGVE), and we run a competition at CVPR to evaluate models on our TGVE dataset. In this paper we present a retrospective on the competition and describe the winning method. The competition dataset is available at https://sites.google.com/view/loveucvpr23/track4.", "isOpenAccess": false, "url": ""}
{"paperId": "f25c6a7b1a63e0cad0a8e56cced4e905f9c241ef", "year": 2024, "title": "Generative AI as a transformative force for innovation: a review of\u00a0opportunities, applications and challenges", "authors": "Soraya Sedkaoui, Rafika Benaichouba", "venue": "European Journal of Innovation Management", "citationCount": 48, "abstract": "PurposeThis study examines the existing literature on generative artificial intelligence (Gen AI) and its impact across many sectors. This analysis explores the potential, applications, and challenges of Gen AI in driving innovation and creativity and generating ideas.Design/methodology/approachThe study adopts a comprehensive literature review approach, carefully assessing current scientific articles on Gen AI published from 2022 to 2024. The analysis examines trends and insights derived from research.FindingsThe review indicates that Gen AI has significant potential to augment human creativity and innovation processes as a collaborative partner. However, it is imperative to prioritize responsible development and ethical frameworks in order to effectively tackle biases, privacy concerns, and other challenges. Gen AI is significantly transforming business models, processes, and value propositions in several industries, but with varying degrees of effect. Findings indicate also that despite the theory-driven approach to investigating Gen AI's creative and innovative potential, cutting-edge applications research prioritizes examining the possibilities of Gen AI models.Research limitations/implicationsAlthough this review offers a picture of great possibilities, it concurrently underlines the necessity for a deep knowledge of Gen AI nuances to fully harness its capabilities. The findings indicate that continuous research and exploration efforts are required to address the challenges of Gen AI and assure its responsible and ethical implementation. Therefore, more study is needed on enhancing human-AI collaboration and defining ethical norms for varied circumstances.Originality/valueThis study presents a relevant analysis of Gen AI's transformational potential as an innovation catalyst. It emphasizes major potential, applications across industries, and ethical issues for responsible integration.", "isOpenAccess": false, "url": ""}
{"paperId": "edd3a430ca0f04f55e37fa9998d1b0155ca6925d", "year": 2024, "title": "UnUnlearning: Unlearning is not sufficient for content regulation in advanced generative AI", "authors": "Ilia Shumailov, Jamie Hayes, Eleni Triantafillou, Guillermo Ortiz-Jim\u00e9nez, Nicolas Papernot, Matthew Jagielski, Itay Yona, Heidi Howard, Eugene Bagdasaryan", "venue": "arXiv.org", "citationCount": 48, "abstract": "Exact unlearning was first introduced as a privacy mechanism that allowed a user to retract their data from machine learning models on request. Shortly after, inexact schemes were proposed to mitigate the impractical costs associated with exact unlearning. More recently unlearning is often discussed as an approach for removal of impermissible knowledge i.e. knowledge that the model should not possess such as unlicensed copyrighted, inaccurate, or malicious information. The promise is that if the model does not have a certain malicious capability, then it cannot be used for the associated malicious purpose. In this paper we revisit the paradigm in which unlearning is used for in Large Language Models (LLMs) and highlight an underlying inconsistency arising from in-context learning. Unlearning can be an effective control mechanism for the training phase, yet it does not prevent the model from performing an impermissible act during inference. We introduce a concept of ununlearning, where unlearned knowledge gets reintroduced in-context, effectively rendering the model capable of behaving as if it knows the forgotten knowledge. As a result, we argue that content filtering for impermissible knowledge will be required and even exact unlearning schemes are not enough for effective content regulation. We discuss feasibility of ununlearning for modern LLMs and examine broader implications.", "isOpenAccess": false, "url": ""}
{"paperId": "e9ba0c90b199ed83c5cce46a6548e174f8599b97", "year": 2023, "title": "Revolutionizing Cyber Threat Detection with Large Language Models", "authors": "M. Ferrag, Mthandazo Ndhlovu, Norbert Tihanyi, Lucas C. Cordeiro, M. Debbah, T. Lestable", "venue": "arXiv.org", "citationCount": 48, "abstract": null, "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.14263"}
{"paperId": "d301a1f242a39e395e2756cd33b2e7ce0e4afe15", "year": 2023, "title": "Decoding the Threat Landscape : ChatGPT, FraudGPT, and WormGPT in Social Engineering Attacks", "authors": "Polra Victor Falade", "venue": "International Journal of Scientific Research in Computer Science Engineering and Information Technology", "citationCount": 48, "abstract": "In the ever-evolving realm of cybersecurity, the rise of generative AI models like ChatGPT, FraudGPT, and WormGPT has introduced both innovative solutions and unprecedented challenges. This research delves into the multifaceted applications of generative AI in social engineering attacks, offering insights into the evolving threat landscape using blog mining technique. Generative AI models have revolutionized the field of cyberattacks, empowering malicious actors to craft convincing and personalized phishing lures, manipulate public opinion through deepfakes, and exploit human cognitive biases. These models, ChatGPT, FraudGPT, and WormGPT, have augmented existing threats and ushered in new dimensions of risk. From phishing campaigns that mimic trusted organizations to deepfake technology impersonating authoritative figures, we explore how generative AI amplifies the arsenal of cybercriminals. Furthermore, we shed light on the vulnerabilities that AI-driven social engineering exploits, including psychological manipulation, targeted phishing, and the crisis of authenticity. To counter these threats, we outline a range of strategies, including traditional security measures, AI-powered security solutions, and collaborative approaches in cybersecurity. We emphasize the importance of staying vigilant, fostering awareness, and strengthening regulations in the battle against AI-enhanced social engineering attacks. In an environment characterized by the rapid evolution of AI models and a lack of training data, defending against generative AI threats requires constant adaptation and the collective efforts of individuals, organizations, and governments. This research seeks to provide a comprehensive understanding of the dynamic interplay between generative AI and social engineering attacks, equipping stakeholders with the knowledge to navigate this intricate cybersecurity landscape.", "isOpenAccess": true, "url": "https://doi.org/10.32628/cseit2390533"}
{"paperId": "d2622d8b6017c4f61d0d2c272db0413740d20875", "year": 2024, "title": "Establishing the importance of co-creation and self-efficacy in creative collaboration with artificial intelligence", "authors": "Jack McGuire, David de Cremer, Tim Van de Cruys", "venue": "Scientific Reports", "citationCount": 48, "abstract": "The emergence of generative AI technologies has led to an increasing number of people collaborating with AI to produce creative works. Across two experimental studies, in which we carefully designed and programmed state-of-the-art human\u2013AI interfaces, we examine how the design of generative AI systems influences human creativity (poetry writing). First, we find that people were most creative when writing a poem on their own, compared to first receiving a poem generated by an AI system and using sophisticated tools to edit it (Study 1). Following this, we demonstrate that this creativity deficit dissipates when people co-create with\u2014not edit\u2014AI and establish creative self-efficacy as an important mechanism in this process (Study 2). Thus, our findings indicate that people must occupy the role of a co-creator, not an editor, to reap the benefits of generative AI in the production of creative works.", "isOpenAccess": false, "url": ""}
{"paperId": "c436cfbcc98908062c01eb80c3ed5e037f68ba07", "year": 2024, "title": "A Critical Analysis of the Largest Source for Generative AI Training Data: Common Crawl", "authors": "Stefan Baack", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 48, "abstract": "Common Crawl is the largest freely available collection of web crawl data and one of the most important sources of pre-training data for large language models (LLMs). It is used so frequently and makes up such large proportions of the overall pre-training data in many cases that it arguably has become a foundational building block for LLM development, and subsequently generative AI products built on top of LLMs. Despite its pivotal role, Common Crawl itself is not widely understood, nor is there much reflection evident among LLM builders about the implications of using Common Crawl's data. This paper discusses what Common Crawl's popularity for LLM development means for fairness, accountability, and transparency in generative AI by highlighting the organization's values and practices, as well as how it views its own role within the AI ecosystem. Our qualitative analysis is based on in-depth interviews with Common Crawl staffers and relevant online documents. After discussing Common Crawl's role in generative AI and how LLM builders have typically used its data for pre-training LLMs, we review Common Crawl's self-defined values and priorities and highlight the limitations and biases of its crawling process. We find that Common Crawl's popularity has contributed to making generative AI more transparent to scrutiny in many ways, and that it has enabled more LLM research and development to take place beyond well-resourced leading AI companies. At the same time, many LLM builders have used Common Crawl as a source for training data in ways that are problematic: for instance, with lack of care and transparency for how Common Crawl's massive crawl data was filtered for harmful content before the pre-training, often by relying on rudimentary automated filtering techniques. We offer recommendations for Common Crawl and LLM builders on how to improve fairness, accountability, and transparency in LLM research and development.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3659033"}
{"paperId": "b93c3f0763e3e1768b4448aea9f0bb80492eeda9", "year": 2025, "title": "A systematic review and meta-analysis of diagnostic performance comparison between generative AI and physicians", "authors": "H. Takita, D. Kabata, Shannon L. Walston, Hiroyuki Tatekawa, Kenichi Saito, Yasushi Tsujimoto, Yukio Miki, Daiju Ueda", "venue": "npj Digital Medicine", "citationCount": 48, "abstract": "While generative artificial intelligence (AI) has shown potential in medical diagnostics, comprehensive evaluation of its diagnostic performance and comparison with physicians has not been extensively explored. We conducted a systematic review and meta-analysis of studies validating generative AI models for diagnostic tasks published between June 2018 and June 2024. Analysis of 83 studies revealed an overall diagnostic accuracy of 52.1%. No significant performance difference was found between AI models and physicians overall (p\u2009=\u20090.10) or non-expert physicians (p\u2009=\u20090.93). However, AI models performed significantly worse than expert physicians (p\u2009=\u20090.007). Several models demonstrated slightly higher performance compared to non-experts, although the differences were not significant. Generative AI demonstrates promising diagnostic capabilities with accuracy varying by model. Although it has not yet achieved expert-level reliability, these findings suggest potential for enhancing healthcare delivery and medical education when implemented with appropriate understanding of its limitations.", "isOpenAccess": true, "url": "https://doi.org/10.1038/s41746-025-01543-z"}
{"paperId": "a582d0637a9f1862c1494c3656768a886466aa28", "year": 2023, "title": "Editorial: Written by ChatGPT, illustrated by Midjourney: generative AI for content marketing", "authors": "Risqo M. Wahid, J. Mero, P. Ritala", "venue": "Asia Pacific Journal of Marketing and Logistics", "citationCount": 48, "abstract": null, "isOpenAccess": true, "url": "https://www.emerald.com/insight/content/doi/10.1108/APJML-10-2023-994/full/pdf?title=editorial-written-by-chatgpt-illustrated-by-midjourney-generative-ai-for-content-marketing"}
{"paperId": "a54f683be1c48d43c9b18e3b782f667cac910921", "year": 2024, "title": "Gemini-the most powerful LLM: Myth or Truth", "authors": "Raisa Islam, Imtiaz Ahmed", "venue": "Information and Communication Technology Convergence", "citationCount": 48, "abstract": "Gemini models excel in various tasks including image generation and interpretation, video understanding, and solving mathematical problems, among others. The Vertex AI Gemini API and Google AI Gemini API both enable developers to integrate Gemini model functionalities into their applications. This paper offers a concise summary of the Gemini Framework, focusing on its distinctive modalities that distinguish it from current systems. In our research, we explored the details of its architecture, pointing out the innovative strategies employed to improve generative AI capabilities. Furthermore, we conduct a comparative study, assessing Gemini\u2019s performance against other top generative AI models.", "isOpenAccess": false, "url": ""}
{"paperId": "7dc5c440c7018d04e9331abc37784b764412190f", "year": 2023, "title": "CHATGPT and the Global South: how are journalists in sub-Saharan Africa engaging with generative AI?", "authors": "Gregory Gondwe", "venue": "Online Media and Global Communication", "citationCount": 48, "abstract": "Abstract Study purpose This study explores the usage of generative AI tools by journalists in sub-Saharan Africa, with a focus on issues of misinformation, plagiarism, stereotypes, and the unrepresentative nature of online databases. The research places this inquiry within broader debates of whether the Global South can effectively and fairly use AI tools. Design/methodology/approach This study involved conducting interviews with journalists from five sub-Saharan African countries, namely Congo, DRC, Kenya, Tanzania, Uganda, and Zambia. The objective of the study was to ascertain how journalists in sub-Saharan Africa are utilizing ChatGPT. It is worth noting that this study is a component of an ongoing project on AI that commenced on September 19, 2022, shortly after receiving IRB approval. The ChatGPT project was initiated in January 2023 after discovering that our participants were already employing the Chatbot. Findings The study highlights that generative AI like ChatGPT operates on a limited and non-representative African corpus, making it selective on what is considered civil and uncivil language, thus limiting its effectiveness in the region. However, the study also suggests that in the absence of representative corpora, generative AI tools like ChatGPT present an opportunity for effective journalism practice in that journalists cannot completely rely on the tools. Practical implications The study emphasizes the need for human agencies to provide relevant information to the tool, thus contributing to a global database, and to consider diverse data sources when designing AI tools to minimize biases and stereotypes. Social implications The social implications of the study suggest that AI tools have both positive and negative effects on journalism in developing countries, and there is a need to promote the responsible and ethical use of AI tools in journalism and beyond. Originality/value The original value of the study lies in shedding light on the challenges and opportunities associated with AI in journalism, promoting postcolonial thinking, and emphasizing the importance of diverse data sources and human agency in the development and use of AI tools.", "isOpenAccess": true, "url": "https://www.degruyter.com/document/doi/10.1515/omgc-2023-0023/pdf"}
{"paperId": "65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e", "year": 2024, "title": "Accelerating Software Development Using Generative AI: ChatGPT Case Study", "authors": "Asha Rajbhoj, Akanksha Somase, Piyush Kulkarni, Vinay Kulkarni", "venue": "International Symposium on Electronic Commerce", "citationCount": 48, "abstract": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.", "isOpenAccess": false, "url": ""}
{"paperId": "60e5dba224d901be67c49e150cacbe5109b245f4", "year": 2023, "title": "ChatGPT\u2014A promising generative AI tool and its implications for cancer care", "authors": "D. Uprety, Dongxiao Zhu, H. West", "venue": "Cancer", "citationCount": 48, "abstract": "Since its launch, ChatGPT has taken the internet by storm and has the potential to be used broadly in the health care system, particularly in a setting such as medical oncology. ChatGPT is well suited to review and extract key content from records of patients with cancer, interpret next\u2010generation sequencing reports, and offer a list of potential clinical trial options.", "isOpenAccess": false, "url": ""}
{"paperId": "5dbb0776662824df97bf31db96abfea0c230068b", "year": 2025, "title": "Generative AI in AI-Based Digital Twins for Fault Diagnosis for Predictive Maintenance in Industry 4.0/5.0", "authors": "Emilia Miko\u0142ajewska, Dariusz Miko\u0142ajewski, Tadeusz Miko\u0142ajczyk, T. P\u0105czkowski", "venue": "Applied Sciences", "citationCount": 48, "abstract": "Generative AI (GenAI) is revolutionizing digital twins (DTs) for fault diagnosis and predictive maintenance in Industry 4.0 and 5.0 by enabling real-time simulation, data augmentation, and improved anomaly detection. DTs, virtual replicas of physical systems, already use generative models to simulate various failure scenarios and rare events, improving system resilience and failure prediction accuracy. They create synthetic datasets that improve training quality while addressing data scarcity and data imbalance. The aim of this paper was to present the current state of the art and perspectives for using AI-based generative DTs for fault diagnosis for predictive maintenance in Industry 4.0/5.0. With GenAI, DTs enable proactive maintenance and minimize downtime, and their latest implementations combine multimodal sensor data to generate more realistic and actionable insights into system performance. This provides realistic operational profiles, identifying potential failure scenarios that traditional methods may miss. New perspectives in this area include the incorporation of Explainable AI (XAI) to increase transparency in decision-making and improve reliability in key industries such as manufacturing, energy, and healthcare. As Industry 5.0 emphasizes a human-centric approach, AI-based generative DT can seamlessly integrate with human operators to support collaboration and decision-making. The implementation of edge computing increases the scalability and real-time capabilities of DTs in smart factories and industrial Internet of Things (IoT) systems. Future advances may include federated learning to ensure data privacy while enabling data exchange between enterprises for fault diagnostics, and the evolution of GenAI alongside industrial systems, ensuring their long-term validity. However, challenges remain in managing computational complexity, ensuring data security, and addressing ethical issues during implementation.", "isOpenAccess": false, "url": ""}
{"paperId": "507b1ee00e67f085ef8563b786176258ec12d638", "year": 2024, "title": "Accelerating histopathology workflows with generative AI-based virtually multiplexed tumour profiling", "authors": "Pushpak Pati, S. Karkampouna, F. Bonollo, Eva Comp\u00e9rat, Martina Radi\u0107, M. Spahn, A. Martinelli, Martin Wartenberg, Marianna Kruithof-de Julio, Marianna Rapsomaniki", "venue": "Nature Machine Intelligence", "citationCount": 48, "abstract": "Understanding the spatial heterogeneity of tumours and its links to disease initiation and progression is a cornerstone of cancer biology. Presently, histopathology workflows heavily rely on hematoxylin and eosin and serial immunohistochemistry staining, a cumbersome, tissue-exhaustive process that results in non-aligned tissue images. We propose the VirtualMultiplexer, a generative artificial intelligence toolkit that effectively synthesizes multiplexed immunohistochemistry images for several antibody markers (namely AR, NKX3.1, CD44, CD146, p53 and ERG) from only an input hematoxylin and eosin image. The VirtualMultiplexer captures biologically relevant staining patterns across tissue scales without requiring consecutive tissue sections, image registration or extensive expert annotations. Thorough qualitative and quantitative assessment indicates that the VirtualMultiplexer achieves rapid, robust and precise generation of virtually multiplexed imaging datasets of high staining quality that are indistinguishable from the real ones. The VirtualMultiplexer is successfully transferred across tissue scales and patient cohorts with no need for model fine-tuning. Crucially, the virtually multiplexed images enabled training a graph transformer that simultaneously learns from the joint spatial distribution of several proteins to predict clinically relevant endpoints. We observe that this multiplexed learning scheme was able to greatly improve clinical prediction, as corroborated across several downstream tasks, independent patient cohorts and cancer types. Our results showcase the clinical relevance of artificial intelligence-assisted multiplexed tumour imaging, accelerating histopathology workflows and cancer biology. VirtualMultiplexer is a generative AI tool that produces realistic multiplexed immunohistochemistry images from tissue biopsies. The generated images could be used to improve clinical predictions, enhancing histopathology workflows and accelerating cancer research.", "isOpenAccess": true, "url": "https://doi.org/10.1038/s42256-024-00889-5"}
{"paperId": "42bd4028361ff9d7189df212d8978e9c06b6fd5a", "year": 2024, "title": "Enhancing Active Learning through Collaboration Between Human Teachers and Generative AI", "authors": "Kritish Pahi, Shiplu Hawlader, Eric Hicks, Alina Zaman, Vinhthuy T. Phan", "venue": "Computers and Education Open", "citationCount": 48, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeo.2024.100183"}
{"paperId": "292097a93d1cd97c317bbe0bd663d3c9669042d5", "year": 2023, "title": "Initial policy considerations for generative artificial intelligence", "authors": "Philippe Lorenz, Karine Perset, J. Berryhill", "venue": "OECD Artificial Intelligence Papers", "citationCount": 48, "abstract": "Generative artificial intelligence (AI) creates new content in response to prompts, offering transformative potential across multiple sectors such as education, entertainment, healthcare and scientific research. However, these technologies also pose critical societal and policy challenges that policy makers must confront: potential shifts in labour markets, copyright uncertainties, and risk associated with the perpetuation of societal biases and the potential for misuse in the creation of disinformation and manipulated content. Consequences could extend to the spreading of mis-and disinformation, perpetuation of discrimination, distortion of public discourse and markets, and the incitement of violence. Governments recognise the transformative impact of generative AI and are actively working to address these challenges. This paper aims to inform these policy considerations and support decision makers in addressing them.", "isOpenAccess": true, "url": "https://www.oecd-ilibrary.org/deliver/fae2d1e6-en.pdf?itemId=%2Fcontent%2Fpaper%2Ffae2d1e6-en&mimeType=pdf"}
{"paperId": "1b82aac44197a67d8665ddfae9bf815377681fa0", "year": 2024, "title": "The Uneven Impact of Generative AI on Entrepreneurial Performance", "authors": "Nicholas Otis, Rowan P. Clarke, Sol\u00e8ne Delecourt, David Holtz, Rembrand Koning", "venue": "Social Science Research Network", "citationCount": 48, "abstract": null, "isOpenAccess": true, "url": "https://escholarship.org/content/qt40s41244/qt40s41244.pdf"}
{"paperId": "11f01361e1f7ed7487a10d7abd176f30fd8a0435", "year": 2024, "title": "Raidar: geneRative AI Detection viA Rewriting", "authors": "Chengzhi Mao, Carl Vondrick, Hao Wang, Junfeng Yang", "venue": "International Conference on Learning Representations", "citationCount": 48, "abstract": "We find that large language models (LLMs) are more likely to modify human-written text than AI-generated text when tasked with rewriting. This tendency arises because LLMs often perceive AI-generated text as high-quality, leading to fewer modifications. We introduce a method to detect AI-generated content by prompting LLMs to rewrite text and calculating the editing distance of the output. We dubbed our geneRative AI Detection viA Rewriting method Raidar. Raidar significantly improves the F1 detection scores of existing AI content detection models -- both academic and commercial -- across various domains, including News, creative writing, student essays, code, Yelp reviews, and arXiv papers, with gains of up to 29 points. Operating solely on word symbols without high-dimensional features, our method is compatible with black box LLMs, and is inherently robust on new content. Our results illustrate the unique imprint of machine-generated text through the lens of the machines themselves.", "isOpenAccess": false, "url": ""}
{"paperId": "eae34c019fd08d5b2df25dd3d21149eaf67c6183", "year": 2023, "title": "ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3)", "authors": "Edisa Lozi\u0107, Benjamin \u0160tular", "venue": "Future Internet", "citationCount": 47, "abstract": "Historically, mastery of writing was deemed essential to human progress. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI-generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness in a manner similar to grading students, while qualitative precision gauged the scientific contribution similar to reviewing a scientific article. In the quantitative test, ChatGPT-4 scored near the passing grade (\u22125) whereas ChatGPT-3.5 (\u221218), Bing (\u221221) and Bard (\u221231) were not far behind. Claude 2 (\u221275) and Aria (\u221280) scored much lower. In the qualitative test, all AI chatbots, but especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, but all failed to generate original scientific content. As a side note, our results suggest that with ChatGPT-4, the size of large language models has reached a plateau. Furthermore, this paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, highlighting the challenges AI chatbots face in emulating human originality in scientific writing. Our results apply to the state of affairs in the third quarter of 2023. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect this to change in the near future as current large language model-based AI chatbots evolve into large language model-powered software.", "isOpenAccess": true, "url": "https://www.mdpi.com/1999-5903/15/10/336/pdf?version=1697183299"}
{"paperId": "a25a6a7dabe6621e5e74cccdc3963aea947d2d20", "year": 2024, "title": "Can Large Language Models beat wall street? Evaluating GPT-4\u2019s impact on financial decision-making with MarketSenseAI", "authors": "George Fatouros, Kostas C. Metaxas, John Soldatos, D. Kyriazis", "venue": "Neural computing & applications (Print)", "citationCount": 47, "abstract": "This paper introduces MarketSenseAI, an innovative framework leveraging GPT-4\u2019s advanced reasoning for selecting stocks in financial markets. By integrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes diverse data sources, including market trends, news, fundamentals, and macroeconomic factors, to emulate expert investment decision-making. The development, implementation, and validation of the framework are elaborately discussed, underscoring its capability to generate actionable and interpretable investment signals. A notable feature of this work is employing GPT-4 both as a predictive mechanism and signal evaluator, revealing the significant impact of the AI-generated explanations on signal accuracy, reliability, and acceptance. Through empirical testing on the competitive S&P 100 stocks over a 15-month period, MarketSenseAI demonstrated exceptional performance, delivering excess alpha of 10\u201330% and achieving a cumulative return of up to 72% over the period, while maintaining a risk profile comparable to the broader market. Our findings highlight the transformative potential of Large Language Models in financial decision-making, marking a significant leap in integrating generative AI into financial analytics and investment strategies.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s00521-024-10613-4.pdf"}
{"paperId": "9c70d1cc3e56c1479775873e6c22840d0449313f", "year": 2025, "title": "Fanar: An Arabic-Centric Multimodal Generative AI Platform", "authors": "Fanar Team Ummar Abbas, M. S. Ahmad, Firoj Alam, Enes Altinisik, Ehsannedin Asgari, Yazan Boshmaf, Sabri Boughorbel, Sanjay Chawla, Shammur A. Chowdhury, Fahim Dalvi, Kareem Darwish, Nadir Durrani, M. Elfeky, A. Elmagarmid, M. Eltabakh, Masoomali Fatehkia, Anastasios Fragkopoulos, Maram Hasanain, Majd Hawasly, Mus'ab Husaini, Soon-Gyo Jung, J. Lucas, Walid Magdy, Safa Messaoud, Abubakr Mohamed, Tasnim Mohiuddin, Basel Mousi, Hamdy Mubarak, Ahmad Musleh, Z. Naeem, M. Ouzzani, Dorde Popovic, Amin Sadeghi, H. Sencar, Mohammed Shinoy, Omar Sinan, Yifan Zhang, Ahmed Ali, Yassine El Kheir, Xiaosong Ma, Chaoyi Ruan", "venue": "arXiv.org", "citationCount": 47, "abstract": "We present Fanar, a platform for Arabic-centric multimodal generative AI systems, that supports language, speech and image generation tasks. At the heart of Fanar are Fanar Star and Fanar Prime, two highly capable Arabic Large Language Models (LLMs) that are best in the class on well established benchmarks for similar sized models. Fanar Star is a 7B (billion) parameter model that was trained from scratch on nearly 1 trillion clean and deduplicated Arabic, English and Code tokens. Fanar Prime is a 9B parameter model continually trained on the Gemma-2 9B base model on the same 1 trillion token set. Both models are concurrently deployed and designed to address different types of prompts transparently routed through a custom-built orchestrator. The Fanar platform provides many other capabilities including a customized Islamic Retrieval Augmented Generation (RAG) system for handling religious prompts, a Recency RAG for summarizing information about current or recent events that have occurred after the pre-training data cut-off date. The platform provides additional cognitive capabilities including in-house bilingual speech recognition that supports multiple Arabic dialects, voice and image generation that is fine-tuned to better reflect regional characteristics. Finally, Fanar provides an attribution service that can be used to verify the authenticity of fact based generated content. The design, development, and implementation of Fanar was entirely undertaken at Hamad Bin Khalifa University's Qatar Computing Research Institute (QCRI) and was sponsored by Qatar's Ministry of Communications and Information Technology to enable sovereign AI technology development.", "isOpenAccess": false, "url": ""}
{"paperId": "9c603d6b75c0c1406098bba9b08c9e5b0521cb5a", "year": 2023, "title": "Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study", "authors": "Yinqiu Liu, Hongyang Du, D. Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, A. Jamalipour", "venue": "IEEE wireless communications", "citationCount": 47, "abstract": "With the phenomenal success of diffusion models and ChatGPT, deep generation models (DGMs) have been experiencing explosive growth. Not limited to content generation, DGMs are also widely adopted in Internet of Things, Metaverse, and digital twin, due to their outstanding ability to represent complex patterns and generate realistic samples. In this article, we explore the applications of DGMs in a crucial task, that is, improving the efficiency of wireless network management. Specifically, we first overview the generative AI, as well as three representative DGMs. Then, we propose a DGM-empowered framework for wireless network management, in which we elaborate on the issues of the conventional network management approaches, why DGMs can address them efficiently, and the step-by-step workflow for applying DGMs in managing wireless networks. Moreover, we conduct a case study on network economics, using the state-of-the-art DGM model, that is, diffusion model, to generate effective contracts for incentivizing the mobile AI-generated content (AIGC) services. Last but not least, we discuss important open directions for further research.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.17114"}
{"paperId": "7a0f7237219c1e5727307d87a0ad341cda7ac83f", "year": 2024, "title": "Generative AI, Research Ethics, and Higher Education Research: Insights from a Scientometric Analysis", "authors": "S. Qadhi, Ahmed Alduais, Youmen Chaaban, M. Khraisheh", "venue": "Inf.", "citationCount": 47, "abstract": "In the digital age, the intersection of artificial intelligence (AI) and higher education (HE) poses novel ethical considerations, necessitating a comprehensive exploration of this multifaceted relationship. This study aims to quantify and characterize the current research trends and critically assess the discourse on ethical AI applications within HE. Employing a mixed-methods design, we integrated quantitative data from the Web of Science, Scopus, and the Lens databases with qualitative insights from selected studies to perform scientometric and content analyses, yielding a nuanced landscape of AI utilization in HE. Our results identified vital research areas through citation bursts, keyword co-occurrence, and thematic clusters. We provided a conceptual model for ethical AI integration in HE, encapsulating dichotomous perspectives on AI\u2019s role in education. Three thematic clusters were identified: ethical frameworks and policy development, academic integrity and content creation, and student interaction with AI. The study concludes that, while AI offers substantial benefits for educational advancement, it also brings challenges that necessitate vigilant governance to uphold academic integrity and ethical standards. The implications extend to policymakers, educators, and AI developers, highlighting the need for ethical guidelines, AI literacy, and human-centered AI tools.", "isOpenAccess": true, "url": "https://www.mdpi.com/2078-2489/15/6/325/pdf?version=1717319273"}
{"paperId": "6b3dcfc0887b2682904e33667a868ffd529fec47", "year": 2024, "title": "Generative AI and Process Systems Engineering: The Next Frontier", "authors": "Benjamin Decardi-Nelson, Abdulelah S. Alshehri, Akshay Ajagekar, Fengqi You", "venue": "Computers and Chemical Engineering", "citationCount": 47, "abstract": null, "isOpenAccess": true, "url": "https://arxiv.org/pdf/2402.10977"}
{"paperId": "1fd59bbd99a7b6121e7403b6ef68e98bf7a520ef", "year": 2024, "title": "AI-based avatars are changing the way we learn and teach: benefits and challenges", "authors": "Maximilian C. Fink, Seth A. Robinson, Bernhard Ertl", "venue": "Frontiers in Education", "citationCount": 47, "abstract": "Advancements in the generative AI field have enabled the development of powerful educational avatars. These avatars embody a human and can, for instance, listen to users\u2019 spoken input, generate an answer utilizing a large-language model, and reply by speaking with a synthetic voice. A theoretical introduction summarizes essential steps in developing AI-based educational avatars and explains how they differ from previously available educational technologies. Moreover, we introduce GPTAvatar, an open-source, state-of-the-art AI-based avatar. We then discuss the benefits of using AI-based educational avatars, which include, among other things, individualized and contextualized instruction. Afterward, we highlight the challenges of using AI-based educational avatars. Major problems concern incorrect and inaccurate information provided, as well as insufficient data protection. In the discussion, we provide an outlook by addressing advances in educational content and educational technology and identifying three crucial open questions for research and practice.", "isOpenAccess": true, "url": "https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1416307/pdf"}
{"paperId": "01713a5f38c0164151caa9b6cc740a8c864420cc", "year": 2023, "title": "Scientists' Perspectives on the Potential for Generative AI in their Fields", "authors": "M. Morris", "venue": "arXiv.org", "citationCount": 47, "abstract": "Generative AI models, including large language models and multimodal models that include text and other media, are on the cusp of transforming many aspects of modern life, including entertainment, education, civic life, the arts, and a range of professions. There is potential for Generative AI to have a substantive impact on the methods and pace of discovery for a range of scientific disciplines. We interviewed twenty scientists from a range of fields (including the physical, life, and social sciences) to gain insight into whether or how Generative AI technologies might add value to the practice of their respective disciplines, including not only ways in which AI might accelerate scientific discovery (i.e., research), but also other aspects of their profession, including the education of future scholars and the communication of scientific findings. In addition to identifying opportunities for Generative AI to augment scientists' current practices, we also asked participants to reflect on concerns about AI. These findings can help guide the responsible development of models and interfaces for scientific education, inquiry, and communication.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.01420"}
{"paperId": "00cabeea72919d7d018db19e0d73cace816d7d99", "year": 2024, "title": "Human and AI collaboration in the higher education environment: opportunities and concerns", "authors": "Paul Atchley, Hannah Pannell, Kaelyn Wofford, Michael Hopkins, R. Atchley", "venue": "Cognitive Research", "citationCount": 47, "abstract": "In service of the goal of examining how cognitive science can facilitate human\u2013computer interactions in complex systems, we explore how cognitive psychology research might help educators better utilize artificial intelligence and AI supported tools as facilitatory to learning, rather than see these emerging technologies as a threat. We also aim to provide historical perspective, both on how automation and technology has generated unnecessary apprehension over time, and how generative AI technologies such as ChatGPT are a product of the discipline of cognitive science. We introduce a model for how higher education instruction can adapt to the age of AI by fully capitalizing on the role that metacognition knowledge and skills play in determining learning effectiveness. Finally, we urge educators to consider how AI can be seen as a critical collaborator to be utilized in our efforts to educate around the critical workforce skills of effective communication and collaboration.", "isOpenAccess": true, "url": "https://cognitiveresearchjournal.springeropen.com/counter/pdf/10.1186/s41235-024-00547-9"}
{"paperId": "ebae6e48eedf456de10b7e4cf70eab467731fd73", "year": 2023, "title": "Generative AI: Implications and Applications for Education", "authors": "A. Tzirides, A. Saini, Gabriela C. Zapata, Duane Searsmith, B. Cope, M. Kalantzis, Vania Castro, Theodora Kourkoulou, John W. Jones, Rodrigo Abrantes da Silva, Jennifer K. Whiting, Nikoleta Polyxeni Kastania", "venue": "arXiv.org", "citationCount": 46, "abstract": "The launch of ChatGPT in November 2022 precipitated a panic among some educators while prompting qualified enthusiasm from others. Under the umbrella term Generative AI, ChatGPT is an example of a range of technologies for the delivery of computer-generated text, image, and other digitized media. This paper examines the implications for education of one generative AI technology, chatbots responding from large language models, or C-LLM. It reports on an application of a C-LLM to AI review and assessment of complex student work. In a concluding discussion, the paper explores the intrinsic limits of generative AI, bound as it is to language corpora and their textual representation through binary notation. Within these limits, we suggest the range of emerging and potential applications of Generative AI in education.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.07605"}
{"paperId": "db599a0ffcaf891bda55b62dafe348c3cc88ec6e", "year": 2023, "title": "Experimental narratives: A comparison of human crowdsourced storytelling and AI storytelling", "authors": "Nina Begu\u0161", "venue": "Humanities and Social Sciences Communications", "citationCount": 46, "abstract": "The paper proposes a framework that combines behavioral and computational experiments employing fictional prompts as a novel tool for investigating cultural artifacts and social biases in storytelling both by humans and generative AI. The study analyzes 250 stories authored by crowdworkers in June 2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging methods from narratology and inferential statistics. Both crowdworkers and large language models responded to identical prompts about creating and falling in love with an artificial human. The proposed experimental paradigm allows a direct and controlled comparison between human and LLM-generated storytelling. Responses to the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth in the collective imaginary of both humans and large language models. All solicited narratives present a scientific or technological pursuit. The analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more progressive in terms of gender roles and sexuality than those written by humans. While AI narratives with default settings and no additional prompting can occasionally provide innovative plot twists, they offer less imaginative scenarios and rhetoric than human-authored texts. The proposed framework argues that fiction can be used as a window into human and AI-based collective imaginary and social dimensions.", "isOpenAccess": true, "url": "https://doi.org/10.1057/s41599-024-03868-8"}
{"paperId": "be4d586ca8add316c14f24397f57f8c77e36cb9d", "year": 2024, "title": "A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming", "authors": "Pengyuan Zhou, Lin Wang, Zhi Liu, Yanbin Hao, Pan Hui, Sasu Tarkoma, J. Kangasharju", "venue": "arXiv.org", "citationCount": 46, "abstract": "This paper offers an insightful examination of how currently top-trending AI technologies, i.e., generative artificial intelligence (Generative AI) and large language models (LLMs), are reshaping the field of video technology, including video generation, understanding, and streaming. It highlights the innovative use of these technologies in producing highly realistic videos, a significant leap in bridging the gap between real-world dynamics and digital creation. The study also delves into the advanced capabilities of LLMs in video understanding, demonstrating their effectiveness in extracting meaningful information from visual content, thereby enhancing our interaction with videos. In the realm of video streaming, the paper discusses how LLMs contribute to more efficient and user-centric streaming experiences, adapting content delivery to individual viewer preferences. This comprehensive review navigates through the current achievements, ongoing challenges, and future possibilities of applying Generative AI and LLMs to video-related tasks, underscoring the immense potential these technologies hold for advancing the field of video technology related to multimedia, networking, and AI communities.", "isOpenAccess": false, "url": ""}
{"paperId": "6d367738e5ae6056b069ea512f79ff8bacb00d26", "year": 2023, "title": "Diffusion-based generative AI for exploring transition states from 2D molecular graphs", "authors": "Seonghwan Kim, Jeheon Woo, Woo Youn Kim", "venue": "Nature Communications", "citationCount": 46, "abstract": "The exploration of transition state (TS) geometries is crucial for elucidating chemical reaction mechanisms and modeling their kinetics. Recently, machine learning (ML) models have shown remarkable performance for prediction of TS geometries. However, they require 3D conformations of reactants and products often with their appropriate orientations as input, which demands substantial efforts and computational cost. Here, we propose a generative approach based on the stochastic diffusion method, namely TSDiff, for prediction of TS geometries just from 2D molecular graphs. TSDiff outperforms the existing ML models with 3D geometries in terms of both accuracy and efficiency. Moreover, it enables to sample various TS conformations, because it learns the distribution of TS geometries for diverse reactions in training. Thus, TSDiff finds more favorable reaction pathways with lower barrier heights than those in the reference database. These results demonstrate that TSDiff shows promising potential for an efficient and reliable TS exploration. The exploration of transition state (TS) geometries is crucial for elucidating chemical reaction mechanisms and modelling their kinetics. Here, authors propose a generative AI approach to predict TS geometries just from 2D molecular graphs of a reaction.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41467-023-44629-6.pdf"}
{"paperId": "6079ddcda2fc1b15729041376726ffed29464a70", "year": 2023, "title": "A Proposed Meta-Reality Immersive Development Pipeline: Generative AI Models and Extended Reality (XR) Content for the Metaverse", "authors": "J. Ratican, James Hutson, Andrew Wright", "venue": "Journal of Intelligent Learning Systems and Applications", "citationCount": 46, "abstract": "The realization of an interoperable and scalable virtual platform, currently known as the \u201cmetaverse,\u201d is inevitable, but many technological challenges need to be overcome first. With the metaverse still in a nascent phase, research currently indicates that building a new 3D social environment capable of interoperable avatars and digital transactions will represent most of the initial investment in time and capital. The return on investment, however, is worth the financial risk for firms like Meta, Google, and Apple. While the current virtual space of the metaverse is worth $6.30 billion, that is expected to grow to $84.09 billion by the end of 2028. But the creation of an entire alternate virtual universe of 3D avatars, objects, and otherworldly cityscapes calls for a new development pipeline and workflow. Existing 3D modeling and digital twin processes, already well-established in industry and gaming, will be ported to support the need to architect and furnish this new digital world. The current development pipeline, however, is cumbersome, expensive and limited in output capacity. This paper proposes a new and innovative immersive development pipeline leveraging the recent advances in artificial intelligence (AI) for 3D model creation and optimization. The previous reliance on 3D modeling software to create assets and then import into a game engine can be replaced with nearly instantaneous", "isOpenAccess": true, "url": "http://www.scirp.org/journal/PaperDownload.aspx?paperID=122878"}
{"paperId": "547324fa11f2e4c6be4dc85479b1b433dc5e9439", "year": 2023, "title": "AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis", "authors": "Zhiyuan Yu, Shixuan Zhai, Ning Zhang", "venue": "Conference on Computer and Communications Security", "citationCount": 46, "abstract": "The rapid development of deep neural networks and generative AI has catalyzed growth in realistic speech synthesis. While this technology has great potential to improve lives, it also leads to the emergence of ''DeepFake'' where synthesized speech can be misused to deceive humans and machines for nefarious purposes. In response to this evolving threat, there has been a significant amount of interest in mitigating this threat by DeepFake detection. Complementary to the existing work, we propose to take the preventative approach and introduce AntiFake, a defense mechanism that relies on adversarial examples to prevent unauthorized speech synthesis. To ensure the transferability to attackers' unknown synthesis models, an ensemble learning approach is adopted to improve the generalizability of the optimization process. To validate the efficacy of the proposed system, we evaluated AntiFake against five state-of-the-art synthesizers using real-world DeepFake speech samples. The experiments indicated that AntiFake achieved over 95% protection rate even to unknown black-box models. We have also conducted usability tests involving 24 human participants to ensure the solution is accessible to diverse populations.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3576915.3623209"}
{"paperId": "47ba104012d9228ef5b9a1147728f64750560a13", "year": 2024, "title": "Understanding University Students\u2019 Acceptance of ChatGPT: Insights from the UTAUT2 Model", "authors": "Simone Grassini, Maren Linnea Aasen, Anja M\u00f8gelvang", "venue": "Applied Artificial Intelligence", "citationCount": 46, "abstract": "ABSTRACT The current study explores the determinants of ChatGPT adoption and utilization among a sample of Norwegian university students. The theoretical perspective of the study is anchored in the Unified Theory of Acceptance and Use of Technology (UTAUT2) and based on a previously tested model. The proposed model integrates six constructs to explain the Behavioral intentions and actual usage patterns of ChatGPT in a higher education context. The study analyzed responses from 104 students attending Universities in West and Central Norway using the partial-least squares approach to structural equation modeling. The data showed that performance expectancy emerged as the construct with the biggest impact on Behavioral intention, followed by Habit. This study contributes to the research on the factors influencing university students\u2019 engagement with generative AI technologies. Furthermore, it contributes to a more comprehensive understanding of how tools like ChatGPT can be integrated effectively in educational contexts in both students learning and instructors teaching.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/08839514.2024.2371168?needAccess=true"}
{"paperId": "32d03cdea23f8445bc2b91888bcfa48a23bad1b6", "year": 2024, "title": "From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency", "authors": "Yunying Yang, Jinwen Luo, Miaoyan Yang, Runde Yang, Jiayin Chen", "venue": "Studies in Higher Education", "citationCount": 46, "abstract": "ABSTRACT Recent emergence of generative artificial intelligence (GenAI) technology has stimulated interests as well as concerns in their potential in teaching and learning. Situated in the new and transforming context, this study provides an avenue for students to introspectively explore their use of GenAI in a postgraduate course. Seventy-four students from three Chinese universities participated in this study. By analyzing student interviews conducted pre- and post-course, alongside their chat logs with GenAI and reflective journal entries detailing their learning approaches, the research uncovers a spectrum of student perspectives on GenAI\u2019s impact, ranging from beneficial optimism, to cautious skepticism and adaptable pragmatism. Notably, student agency is identified as a crucial element in relation to these themes. This was articulated in four types of learning activities: receptive, resistive, resourceful, and reflective. The research underscores the importance of supporting and empowering student agency in the learning approaches aided by GenAI in education, highlighting its role in optimizing its use and enhancing autonomous, lifelong learning skills amidst the evolving technologically advanced learning landscape.", "isOpenAccess": false, "url": ""}
{"paperId": "219add0ef5c6e6a7073e17df3b210e9c6d594f44", "year": 2024, "title": "Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis", "authors": "Nauman Khan, Zahid Khan, Anis Koubaa, Muhammad Khurram Khan, Rosli bin Salleh", "venue": "Connection science", "citationCount": 46, "abstract": "ABSTRACT In 2022, OpenAI's unveiling of generative AI Large Language Models (LLMs)- ChatGPT, heralded a significant leap forward in human-machine interaction through cutting-edge AI technologies. With its surging popularity, scholars across various fields have begun to delve into the myriad applications of ChatGPT. While existing literature reviews on LLMs like ChatGPT are available, there is a notable absence of systematic literature reviews (SLRs) and bibliometric analyses assessing the research's multidisciplinary and geographical breadth. This study aims to bridge this gap by synthesising and evaluating how ChatGPT has been integrated into diverse research areas, focussing on its scope and the geographical distribution of studies. Through a systematic review of scholarly articles, we chart the global utilisation of ChatGPT across various scientific domains, exploring its contribution to advancing research paradigms and its adoption trends among different disciplines. Our findings reveal a widespread endorsement of ChatGPT across multiple fields, with significant implementations in healthcare (38.6%), computer science/IT (18.6%), and education/research (17.3%). Moreover, our demographic analysis underscores ChatGPT's global reach and accessibility, indicating participation from 80 unique countries in ChatGPT-related research, with the most frequent countries keyword occurrence, USA (719), China (181), and India (157) leading in contributions. Additionally, our study highlights the leading roles of institutions such as King Saud University, the All India Institute of Medical Sciences, and Taipei Medical University in pioneering ChatGPT research in our dataset. This research not only sheds light on the vast opportunities and challenges posed by ChatGPT in scholarly pursuits but also acts as a pivotal resource for future inquiries. It emphasises that the generative AI (LLM) role is revolutionising every field. The insights provided in this paper are particularly valuable for academics, researchers, and practitioners across various disciplines, as well as policymakers looking to grasp the extensive reach and impact of generative AI technologies like ChatGPT in the global research community.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/09540091.2024.2353630?needAccess=true"}
{"paperId": "ff5b8bf0500f45cc8e2c160c89c5a25479e7f45c", "year": 2024, "title": "Advances in AI for Protein Structure Prediction: Implications for Cancer Drug Discovery and Development", "authors": "Xinru Qiu, Han Li, Greg Ver Steeg, Adam Godzik", "venue": "Biomolecules", "citationCount": 45, "abstract": "Recent advancements in AI-driven technologies, particularly in protein structure prediction, are significantly reshaping the landscape of drug discovery and development. This review focuses on the question of how these technological breakthroughs, exemplified by AlphaFold2, are revolutionizing our understanding of protein structure and function changes underlying cancer and improve our approaches to counter them. By enhancing the precision and speed at which drug targets are identified and drug candidates can be designed and optimized, these technologies are streamlining the entire drug development process. We explore the use of AlphaFold2 in cancer drug development, scrutinizing its efficacy, limitations, and potential challenges. We also compare AlphaFold2 with other algorithms like ESMFold, explaining the diverse methodologies employed in this field and the practical effects of these differences for the application of specific algorithms. Additionally, we discuss the broader applications of these technologies, including the prediction of protein complex structures and the generative AI-driven design of novel proteins.", "isOpenAccess": true, "url": "https://www.mdpi.com/2218-273X/14/3/339/pdf?version=1710244599"}
{"paperId": "f22f1c02bab0719056c3ad399a336f3c32883249", "year": 2024, "title": "Design2Code: Benchmarking Multimodal Code Generation for Automated Front-End Engineering", "authors": "Chenglei Si, Yanzhe Zhang, Ryan Li, Zhengyuan Yang, Ruibo Liu, Diyi Yang", "venue": "North American Chapter of the Association for Computational Linguistics", "citationCount": 45, "abstract": "Generative AI has made rapid advancements in recent years, achieving unprecedented capabilities in multimodal understanding and code generation. This can enable a new paradigm of front-end development in which multimodal large language models (MLLMs) directly convert visual designs into code implementations. In this work, we construct Design2Code - the first real-world benchmark for this task. Specifically, we manually curate 484 diverse real-world webpages as test cases and develop a set of automatic evaluation metrics to assess how well current multimodal LLMs can generate the code implementations that directly render into the given reference webpages, given the screenshots as input. We also complement automatic metrics with comprehensive human evaluations to validate the performance ranking. To rigorously benchmark MLLMs, we test various multimodal prompting methods on frontier models such as GPT-4o, GPT-4V, Gemini, and Claude. Our fine-grained break-down metrics indicate that models mostly lag in recalling visual elements from the input webpages and generating correct layout designs.", "isOpenAccess": false, "url": ""}
{"paperId": "ac48e5a6322539677f221a28383f07f5b0bf700f", "year": 2023, "title": "Embracing the Disrupted Language Teaching and Learning Field: Analyzing YouTube Content Creation Related to ChatGPT", "authors": "Belle Li, Xiaojing Kou, Curtis J. Bonk", "venue": "Languages", "citationCount": 45, "abstract": "Since late 2022, dozens of YouTube channels focusing on a diverse array of topics related to language learning with generative AI tools such as ChatGPT have rapidly emerged. This study explores the implementations and perspectives of YouTube content creators who now constitute an increasingly important segment of the ecosystem of language teaching and learning. A mixed methods netnographic approach was employed, combining qualitative and quantitative techniques. A total of 140 videos were identified and analyzed, and an in-depth content analysis was conducted to uncover underlying themes. Four main categories of creators were identified: educators, learners, technology professionals, and e-learning providers. Educators, especially English and Japanese teachers, were the majority, followed by learners and technology field professionals. This study highlights the benefits, drawbacks, and concerns associated with the integration of AI tools in language learning. By examining this rapidly evolving phenomenon, the study contributes towards an understanding of the role and impact of generative AI tools in language education.", "isOpenAccess": true, "url": "https://www.mdpi.com/2226-471X/8/3/197/pdf?version=1692698236"}
{"paperId": "a467d2c79ff319aaa5361e8b1fc1e4ddb6305048", "year": 2024, "title": "Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning", "authors": "Markus J. Buehler", "venue": "Machine Learning: Science and Technology", "citationCount": 45, "abstract": "Leveraging generative Artificial Intelligence (AI), we have transformed a dataset comprising 1000 scientific papers focused on biological materials into a comprehensive ontological knowledge graph. Through an in-depth structural analysis of this graph, we have calculated node degrees, identified communities along with their connectivities, and evaluated clustering coefficients and betweenness centrality of pivotal nodes, uncovering fascinating knowledge architectures. We find that the graph has an inherently scale-free nature, shows a high level of connectedness, and can be used as a rich source for downstream graph reasoning by taking advantage of transitive and isomorphic properties to reveal insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, propose never-before-seen material designs, and predict material behaviors. Using a large language embedding model we compute deep node representations and use combinatorial node similarity ranking to develop a path sampling strategy that allows us to link dissimilar concepts that have previously not been related. One comparison revealed detailed structural parallels between biological materials and Beethoven\u2019s 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. In another example, the algorithm proposed an innovative hierarchical mycelium-based composite based on integrating path sampling with principles extracted from Kandinsky\u2019s \u2018Composition VII\u2019 painting. The resulting material integrates an innovative set of concepts that include a balance of chaos and order, adjustable porosity, mechanical strength, and complex patterned chemical functionalization. We uncover other isomorphisms across science, technology and art, revealing a nuanced ontology of immanence that reveal a context-dependent heterarchical interplay of constituents. Because our method transcends established disciplinary boundaries through diverse data modalities (graphs, images, text, numerical data, etc), graph-based generative AI achieves a far higher degree of novelty, explorative capacity, and technical detail, than conventional approaches and establishes a widely useful framework for innovation by revealing hidden connections.", "isOpenAccess": true, "url": "https://doi.org/10.1088/2632-2153/ad7228"}
{"paperId": "9931717b0054d14185009c407145463793f7bed5", "year": 2024, "title": "GenAI Arena: An Open Evaluation Platform for Generative Models", "authors": "Dongfu Jiang, Max W.F. Ku, Tianle Li, Yuansheng Ni, Shizhuo Sun, Rongqi \"Richard\" Fan, Wenhu Chen", "venue": "Neural Information Processing Systems", "citationCount": 45, "abstract": "Generative AI has made remarkable strides to revolutionize fields such as image and video generation. These advancements are driven by innovative algorithms, architecture, and data. However, the rapid proliferation of generative models has highlighted a critical gap: the absence of trustworthy evaluation metrics. Current automatic assessments such as FID, CLIP, FVD, etc often fail to capture the nuanced quality and user satisfaction associated with generative outputs. This paper proposes an open platform GenAI-Arena to evaluate different image and video generative models, where users can actively participate in evaluating these models. By leveraging collective user feedback and votes, GenAI-Arena aims to provide a more democratic and accurate measure of model performance. It covers three tasks of text-to-image generation, text-to-video generation, and image editing respectively. Currently, we cover a total of 35 open-source generative models. GenAI-Arena has been operating for seven months, amassing over 9000 votes from the community. We describe our platform, analyze the data, and explain the statistical methods for ranking the models. To further promote the research in building model-based evaluation metrics, we release a cleaned version of our preference data for the three tasks, namely GenAI-Bench. We prompt the existing multi-modal models like Gemini, and GPT-4o to mimic human voting. We compute the accuracy by comparing the model voting with the human voting to understand their judging abilities. Our results show existing multimodal models are still lagging in assessing the generated visual content, even the best model GPT-4o only achieves an average accuracy of 49.19 across the three generative tasks. Open-source MLLMs perform even worse due to the lack of instruction-following and reasoning ability in complex vision scenarios.", "isOpenAccess": false, "url": ""}
{"paperId": "840e16757dd39b61cfcc0ed24f94a2a3dacccb87", "year": 2024, "title": "Using Generative AI Midjourney to enhance divergent and convergent thinking in an architect\u2019s creative design process", "authors": "Linus Tan, Max Luhrs", "venue": "The Design Journal", "citationCount": 45, "abstract": "Abstract Architects use a range of tools, from the traditional pencil to Virtual Reality technologies to prototype and articulate their creative designs. In recent years, Generative Artificial Intelligence (GenAI) software has reached the mainstream and there is an exponential appearance of GenAI images that portray architectural designs. This article documents an architectural design methodology that uses Midjourney, a text-to-image GenAI software, as a design tool that enhances architects\u2019 creativity. Prompted by a design brief, we used Midjourney to accelerate (1) the identification and refinement process of developing a prospective user and (2) the ideation process of creating different desirable spaces for the designed user.", "isOpenAccess": true, "url": "https://doi.org/10.1080/14606925.2024.2353479"}
{"paperId": "6a16decd8298638d40e3266b57e2efc3b969e9d1", "year": 2023, "title": "Techniques for supercharging academic writing with generative AI", "authors": "Zhicheng Lin", "venue": "Nature Biomedical Engineering", "citationCount": 45, "abstract": "Generalist large language models can elevate the quality and efficiency of academic writing.", "isOpenAccess": false, "url": ""}
{"paperId": "5483b66f0e941be3e3382a97961773551d5ae563", "year": 2024, "title": "Secret Collusion among AI Agents: Multi-Agent Deception via Steganography", "authors": "S. Motwani, Mikhail Baranchuk, Martin Strohmeier, Vijay Bolina, Philip Torr, Lewis Hammond, Christian Schr\u00f6der de Witt", "venue": "Neural Information Processing Systems", "citationCount": 45, "abstract": "Recent capability increases in large language models (LLMs) open up applications in which groups of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of generative AI agents by drawing on relevant concepts from both AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary LLMs. While the steganographic capabilities of current models remain limited, GPT-4 displays a capability jump suggesting the need for continuous monitoring of steganographic frontier model capabilities. We conclude by laying out a comprehensive research program to mitigate future risks of collusion between generative AI models.", "isOpenAccess": false, "url": ""}
{"paperId": "535dc052b6d65746d09ee866f826250e1042dc99", "year": 2024, "title": "Advancements and Applications of Generative Artificial Intelligence and Large Language Models on Business Management: A Comprehensive Review", "authors": "Ahmed Ali Linkon, Mujiba \u2709, Md Shohail Uddin Sarker, Norun Nabi, Md Nasir Uddin Rana, Sandip Kumar Ghosh, Mohammad Anisur Rahman, Hammed Esa, Faiaz Rahat Chowdhury", "venue": "Journal of Computer Science and Technology Studies", "citationCount": 45, "abstract": "This comprehensive review delves into the landscape and recent advancements of Generative Artificial Intelligence (AI) and Large Language Models (LLMs), shedding light on their transformative potential and applications across various sectors. Generative AI, exemplified by models like ChatGPT, DALL-E, and Midjourney, has rapidly evolved and is driven by breakthroughs in deep learning architectures and the availability of vast datasets. Concurrently, LLMs have revolutionized natural language processing tasks, utilizing vast text corpora to generate human-like text. The study explores recent developments, including the introduction of advanced models like GPT-4 and PaLM2 and the emergence of specialized LLMs like small LLMs (sLLMs), aimed at overcoming hardware limitations and cost constraints. Additionally, the expanding applications of generative AI, from healthcare to finance, underscore its transformative potential in addressing real-world challenges. Through a comprehensive analysis, this research contributes to the ongoing discourse on AI ethics, governance, and regulation, emphasizing the importance of responsible innovation for the benefit of humanity.", "isOpenAccess": true, "url": "https://al-kindipublisher.com/index.php/jcsts/article/download/6947/5843"}
{"paperId": "4de92a0dfe0a57276daaea6145f74ad7404e3d89", "year": 2024, "title": "Writing with generative AI and human-machine teaming: Insights and recommendations from faculty and students", "authors": "Andelyn Bedington, Emma F. Halcomb, Heidi A. McKee, Thomas Sargent, Adler Smith", "venue": "Computers and Composition", "citationCount": 45, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.compcom.2024.102833"}
{"paperId": "4229e27cbed3e9625a3487299dc2d1e5cc3208f1", "year": 2023, "title": "GAIA: Zero-shot Talking Avatar Generation", "authors": "Tianyu He, Junliang Guo, Runyi Yu, Yuchi Wang, Jialiang Zhu, Kaikai An, Leyi Li, Xu Tan, Chunyu Wang, Han Hu, HsiangTao Wu, Sheng Zhao, Jiang Bian", "venue": "International Conference on Learning Representations", "citationCount": 45, "abstract": "Zero-shot talking avatar generation aims at synthesizing natural talking videos from speech and a single portrait image. Previous methods have relied on domain-specific heuristics such as warping-based motion representation and 3D Morphable Models, which limit the naturalness and diversity of the generated avatars. In this work, we introduce GAIA (Generative AI for Avatar), which eliminates the domain priors in talking avatar generation. In light of the observation that the speech only drives the motion of the avatar while the appearance of the avatar and the background typically remain the same throughout the entire video, we divide our approach into two stages: 1) disentangling each frame into motion and appearance representations; 2) generating motion sequences conditioned on the speech and reference portrait image. We collect a large-scale high-quality talking avatar dataset and train the model on it with different scales (up to 2B parameters). Experimental results verify the superiority, scalability, and flexibility of GAIA as 1) the resulting model beats previous baseline models in terms of naturalness, diversity, lip-sync quality, and visual quality; 2) the framework is scalable since larger models yield better results; 3) it is general and enables different applications like controllable talking avatar generation and text-instructed avatar generation.", "isOpenAccess": false, "url": ""}
{"paperId": "4200eb63f23671dbfebf6ea50bfb8417a4b34001", "year": 2023, "title": "Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT", "authors": "Niall Curry, Paul Baker, Gavin Brookes", "venue": "Applied Corpus Linguistics", "citationCount": 45, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.acorp.2023.100082"}
{"paperId": "3f4ce5d3066ab47b3c68f261ee68177648b53228", "year": 2024, "title": "Ironies of Generative AI: Understanding and Mitigating Productivity Loss in Human-AI Interaction", "authors": "Auste Simkute, Lev Tankelevitch, Viktor Kewenig, A. E. Scott, Abigail Sellen, Sean Rintel", "venue": "International Journal of Human-Computer Interaction", "citationCount": 45, "abstract": "Abstract Generative AI (GenAI) systems offer opportunities to increase user productivity in many tasks, such as programming and writing. However, while they boost productivity in some studies, many others show that users are working ineffectively with GenAI systems and losing productivity. Despite the apparent novelty of these usability challenges, these \u2018ironies of automation\u2019 have been observed for over three decades in Human Factors research on the introduction of automation in domains such as aviation, automated driving, and intelligence. We draw on this extensive research alongside recent GenAI user studies to outline four key reasons for productivity loss with GenAI systems: a shift in users\u2019 roles from production to evaluation, unhelpful restructuring of workflows, interruptions, and a tendency for automation to make easy tasks easier and hard tasks harder. We then suggest how Human Factors research can also inform GenAI system design to mitigate productivity loss by using approaches such as continuous feedback, system personalization, ecological interface design, task stabilization, and clear task allocation. Thus, we ground developments in GenAI system usability in decades of Human Factors research, ensuring that the design of human-AI interactions in this rapidly moving field learns from history instead of repeating it.", "isOpenAccess": false, "url": ""}
{"paperId": "12f79af20695a82029db34299445932cbafdf1c9", "year": 2024, "title": "Unlocking Potential: Key Factors Shaping Undergraduate Self-Directed Learning in AI-Enhanced Educational Environments", "authors": "Di Wu, Shuling Zhang, Zhiyuan Ma, Xiao-Guang Yue, Rebecca Kechen Dong", "venue": "Syst.", "citationCount": 45, "abstract": "This study investigates the factors influencing undergraduate students\u2019 self-directed learning (SDL) abilities in generative Artificial Intelligence (AI)-driven interactive learning environments. The advent of generative AI has revolutionized interactive learning environments, offering unprecedented opportunities for personalized and adaptive education. Generative AI supports teachers in delivering smart education, enhancing students\u2019 acceptance of technology, and providing personalized, adaptive learning experiences. Nevertheless, the application of generative AI in higher education is underexplored. This study explores how these AI-driven platforms impact undergraduate students\u2019 self-directed learning (SDL) abilities, focusing on the key factors of teacher support, learning strategies, and technology acceptance. Through a quantitative approach involving surveys of 306 undergraduates, we identified the key factors of motivation, technological familiarity, and the quality of AI interaction. The findings reveal the mediating roles of self-efficacy and learning motivation. Also, the findings confirmed that improvements in teacher support and learning strategies within generative AI-enhanced learning environments contribute to increasing students\u2019 self-efficacy, technology acceptance, and learning motivation. This study contributes to uncovering the influencing factors that can inform the design of more effective educational technologies and strategies to enhance student autonomy and learning outcomes. Our theoretical model and research findings deepen the understanding of applying generative AI in higher education while offering important research contributions and managerial implications.", "isOpenAccess": true, "url": "https://doi.org/10.3390/systems12090332"}
{"paperId": "ff5ab2f1ebe460ca1a04abb8c04344a9d1cc55b2", "year": 2024, "title": "Generative AI Applications in Architecture, Engineering, and Construction: Trends, Implications for Practice, Education & Imperatives for Upskilling\u2014A Review", "authors": "D. Onatayo, A. Onososen, A. Oyediran, Hafiz Oyediran, V. Arowoiya, Eniola Onatayo", "venue": "Architecture", "citationCount": 44, "abstract": "This study investigates the current landscape of generative AI and LLM applications in architecture, engineering, and construction (AEC), focusing on trends, practical implications, educational strategies, and imperatives for upskilling. Employing a six-stage systematic review sourced from Google Scholar, Scopus and Web of Science, 120 papers were analyzed to provide a comprehensive understanding of the role of these technologies in shaping the future of the AEC industry. By addressing these objectives, the research contributes to enhancing knowledge about the potential impacts of generative AI and LLMs on the AEC industry and provides insights into strategies for leveraging these technologies effectively. This study underscores the transformative impact of AI and advanced technologies on the AEC sector and education. By enhancing learning experiences and optimizing construction processes, AI fosters personalized education and efficient project management. The study\u2019s significance lies in its identification of necessary skills and competencies for professionals, ensuring effective AI integration. Implications include the need for continuous professional development, formal education, and practical training to leverage AI\u2019s potential fully. This paves the way for sustainable, intelligent infrastructure and accessible, adaptive learning environments, driving innovation and efficiency in both fields.", "isOpenAccess": true, "url": "https://doi.org/10.3390/architecture4040046"}
{"paperId": "f5bcbf5738c42530e2d36f61b4aaa612af391639", "year": 2023, "title": "Next Steps for Human-Centered Generative AI: A Technical Perspective", "authors": "Xiang 'Anthony' Chen, Jeff Burke, Ruofei Du, Matthew K. Hong, Jennifer Jacobs, Philippe Laban, Dingzeyu Li, Nanyun Peng, Karl D. D. Willis, Chien-Sheng Wu, Bolei Zhou", "venue": "arXiv.org", "citationCount": 44, "abstract": "Through iterative, cross-disciplinary discussions, we define and propose next-steps for Human-centered Generative AI (HGAI). We contribute a comprehensive research agenda that lays out future directions of Generative AI spanning three levels: aligning with human values; assimilating human intents; and augmenting human abilities. By identifying these next-steps, we intend to draw interdisciplinary research teams to pursue a coherent set of emergent ideas in HGAI, focusing on their interested topics while maintaining a coherent big picture of the future work landscape.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.15774"}
{"paperId": "f3697b153e2f067b348ef49f8e9bf4d6a0e75069", "year": 2024, "title": "Putting Things into Context: Generative AI-Enabled Context Personalization for Vocabulary Learning Improves Learning Motivation", "authors": "Joanne Leong, Pat Pataranutaporn, Valdemar Danry, Florian Perteneder, Yaoli Mao, Pattie Maes", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 44, "abstract": "Fostering students\u2019 interests in learning is considered to have many positive downstream effects. Large language models have opened up new horizons for generating content tuned to one\u2019s interests, yet it is unclear in what ways and to what extent this customization could have positive effects on learning. To explore this novel dimension, we conducted a between-subjects online study (n=272) featuring different variations of a generative AI vocabulary learning app that enables users to personalize their learning examples. Participants were randomly assigned to control (sentence sourced from pre-existing text) or experimental conditions (generated sentence or short story based on users\u2019 text input). While we did not observe a difference in learning performance between the conditions, the analysis revealed that generative AI-driven context personalization positively affected learning motivation. We discuss how these results relate to previous findings and underscore their significance for the emerging field of using generative AI for personalized learning.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642393"}
{"paperId": "f1057758c7ca7fe2babeea4908c281be9d1075c4", "year": 2024, "title": "IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition", "authors": "Zikang Leng, Amitrajit Bhattacharjee, Hrudhai Rajasekhar, Lizhe Zhang, Elizabeth Bruda, Hyeokhyen Kwon, Thomas Pl\u00f6tz", "venue": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies", "citationCount": 44, "abstract": "One of the primary challenges in the field of human activity recognition (HAR) is the lack of large labeled datasets. This hinders the development of robust and generalizable models. Recently, cross modality transfer approaches have been explored that can alleviate the problem of data scarcity. These approaches convert existing datasets from a source modality, such as video, to a target modality, such as inertial measurement units (IMUs). With the emergence of generative AI models such as large language models (LLMs) and text-driven motion synthesis models, language has become a promising source data modality as well - as shown in proof of concepts such as IMUGPT. In this work, we conduct a large-scale evaluation of language-based cross modality transfer to determine their effectiveness for HAR. Based on this study, we introduce two new extensions for IMUGPT that enhance its use for practical HAR application scenarios: a motion filter capable of filtering out irrelevant motion sequences to ensure the relevance of the generated virtual IMU data, and a set of metrics that measure the diversity of the generated data facilitating the determination of when to stop generating virtual IMU data for both effective and efficient processing. We demonstrate that our diversity metrics can reduce the effort needed for the generation of virtual IMU data by at least 50%, which opens up IMUGPT for practical use cases beyond a mere proof of concept.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2402.01049"}
{"paperId": "eb4f7fccffc3d8400182468be1eb2531b049f190", "year": 2023, "title": "Filling the Missing: Exploring Generative AI for Enhanced Federated Learning Over Heterogeneous Mobile Edge Devices", "authors": "Peichun Li, Hanwen Zhang, Yuan Wu, Liping Qian, Rong Yu, Dusist Niyato, Xuemin Shen", "venue": "IEEE Transactions on Mobile Computing", "citationCount": 44, "abstract": "Distributed Artificial Intelligence (AI) model training over mobile edge networks encounters significant challenges due to the data and resource heterogeneity of edge devices. The former hampers the convergence rate of the global model, while the latter diminishes the devices\u2019 resource utilization efficiency. In this paper, we propose a generative AI-empowered federated learning to address these challenges by leveraging the idea of FIlling the MIssing (FIMI) portion of local data. Specifically, FIMI can be considered as a resource-aware data augmentation method that effectively mitigates the data heterogeneity while ensuring efficient FL training. We first quantify the relationship between the training data amount and the learning performance. We then study the FIMI optimization problem with the objective of minimizing the device-side overall energy consumption subject to required learning performance constraints. The decomposition-based analysis and the cross-entropy searching method are leveraged to derive the solution, where each device is assigned suitable AI-synthetic data and resource utilization policy. Experiment results demonstrate that FIMI can save up to 50% of the device-side energy to achieve the target global test accuracy in comparison with the existing methods. Meanwhile, FIMI can significantly enhance the converged global accuracy under the non-independently-and-identically distribution (non-IID) data.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.13981"}
{"paperId": "d489fb2556de1e7d178182a14a2c7af19bd034eb", "year": 2024, "title": "Artificial Intelligence-Based Applications for Bone Fracture Detection Using Medical Images: A Systematic Review", "authors": "Mohammed Kutbi", "venue": "Diagnostics", "citationCount": 44, "abstract": "Artificial intelligence (AI) is making notable advancements in the medical field, particularly in bone fracture detection. This systematic review compiles and assesses existing research on AI applications aimed at identifying bone fractures through medical imaging, encompassing studies from 2010 to 2023. It evaluates the performance of various AI models, such as convolutional neural networks (CNNs), in diagnosing bone fractures, highlighting their superior accuracy, sensitivity, and specificity compared to traditional diagnostic methods. Furthermore, the review explores the integration of advanced imaging techniques like 3D CT and MRI with AI algorithms, which has led to enhanced diagnostic accuracy and improved patient outcomes. The potential of Generative AI and Large Language Models (LLMs), such as OpenAI\u2019s GPT, to enhance diagnostic processes through synthetic data generation, comprehensive report creation, and clinical scenario simulation is also discussed. The review underscores the transformative impact of AI on diagnostic workflows and patient care, while also identifying research gaps and suggesting future research directions to enhance data quality, model robustness, and ethical considerations.", "isOpenAccess": true, "url": "https://doi.org/10.3390/diagnostics14171879"}
{"paperId": "c83d2b254c14f5dcf7de844552b06044bed55b92", "year": 2023, "title": "Diversity representation in advertising", "authors": "Colin Campbell, S. Sands, Brent McFerran, Alexis Mavrommatis", "venue": "Journal of the Academy of Marketing Science", "citationCount": 44, "abstract": "In this article we develop a comprehensive understanding of diverse representation in advertising. While numerous studies highlight increasing demand for diversity among some consumers, such enthusiasm is not universal. This is creating challenges for brands, some of which have faced backlash, either due to a perceived lack of authenticity in their diversity efforts or because not all consumer groups value diversity equally. Amidst these challenges, technological advancements, such as data-driven decision-making and generative AI, present both new opportunities and risks. The current literature on diverse representation in advertising, although expansive, is relatively siloed. Through a detailed eight-step process, we assess and synthesize the body of literature on diversity representation, reviewing 337 articles spanning research on age, beauty, body size, gender, LGBTQIA+\u2009, physical and mental ability, and race and ethnicity. Our investigation offers two major contributions: a summarization of insights from the broader literature on these seven key areas of diverse representation and development of an integrated conceptual framework. Our conceptual framework details mechanisms, moderators, and outcomes that are either prevalent across the literature or can be reasonably expected to generalize across other forms of diversity. This framework not only offers a holistic perspective for academics and industry professionals but also exposes potential future research avenues.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11747-023-00994-8.pdf"}
{"paperId": "bc486871e6f392c40ae823d6dbaa51a1e3461426", "year": 2024, "title": "Generative AI Professional Development Needs for Teacher Educators", "authors": "Matthew Nyaaba, Xiaoming Zhai", "venue": "Journal of AI", "citationCount": 44, "abstract": "This study presents findings from a professional development (PD) webinar aimed at sensitizing and gathering teacher educators\u2019 knowledge of Generative Artificial Intelligence (GAI). The primary objective of the webinar was to deepen teacher educators\u2019 understanding and applications of GAI within the context of teacher education in Ghana and to identify areas requiring additional development. Three hundred and seven participants from a diverse group, including teacher educators, administrators, and in-service teachers participated in the PD session. The session was conducted online via Zoom. The video and audio recordings were transcribed and analyzed thematically using MAXQDA version 2022.4. Findings indicate a diverse range of familiarity with GAI among participants. While some expressed knowledge of GAI tools, others were learning about GAI for the first time. Further, the findings showed an increasing curiosity among participants for the inspiring functions of GAI in education, such as automatic scoring, academic writing, assisting teachers with image generation for their classroom practices, etc. The participants demonstrated a willingness to include GAI in their classroom practices and support their students. However, they also identified infrastructural gaps, such as the expense of premium GAI tools, training on GAI promptings, and ethical issues such as transparency, as potential barriers to the successful implementation of GAI in teacher education. Therefore, the study suggests that institutional support should be provided to teacher educators. This support would expand their access to various GAI tools and features. The study further recommends integrating GAI, including explainable GAI and prompt engineering, as a core component of teacher education and continuous professional development programs. Additionally, it emphasizes the importance of strengthening educators' skills in innovative assessment practices.", "isOpenAccess": true, "url": "https://dergipark.org.tr/en/download/article-file/3516191"}
{"paperId": "b7b4c787477688b29304925c8df6e8baa84e3d73", "year": 2023, "title": "An Introduction to Generative Artificial Intelligence in Mental Health Care: Considerations and Guidance", "authors": "Darlene R. King, Guransh Nanda, Joel Stoddard, Allison Dempsey, Sarah Hergert, Jay H. Shore, J. Torous", "venue": "Current Psychiatry Reports", "citationCount": 44, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "9d24424dcddf836870b74293ac1222cb6a371bd9", "year": 2023, "title": "Reward-Directed Conditional Diffusion: Provable Distribution Estimation and Reward Improvement", "authors": "Hui Yuan, Kaixuan Huang, Chengzhuo Ni, Minshuo Chen, Mengdi Wang", "venue": "Neural Information Processing Systems", "citationCount": 44, "abstract": "We explore the methodology and theory of reward-directed generation via conditional diffusion models. Directed generation aims to generate samples with desired properties as measured by a reward function, which has broad applications in generative AI, reinforcement learning, and computational biology. We consider the common learning scenario where the data set consists of unlabeled data along with a smaller set of data with noisy reward labels. Our approach leverages a learned reward function on the smaller data set as a pseudolabeler. From a theoretical standpoint, we show that this directed generator can effectively learn and sample from the reward-conditioned data distribution. Additionally, our model is capable of recovering the latent subspace representation of data. Moreover, we establish that the model generates a new population that moves closer to a user-specified target reward value, where the optimality gap aligns with the off-policy bandit regret in the feature subspace. The improvement in rewards obtained is influenced by the interplay between the strength of the reward signal, the distribution shift, and the cost of off-support extrapolation. We provide empirical results to validate our theory and highlight the relationship between the strength of extrapolation and the quality of generated samples.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.07055"}
{"paperId": "808edee64e73b2547610d53d8f7fcd20f24f9dea", "year": 2025, "title": "Implementing Generative AI (GenAI) in Higher Education: A Systematic Review of Case Studies", "authors": "M. Belkina, Scott Daniel, Sasha Nikolic, R. Haque, Sarah Lyden, Peter Neal, Sarah Grundy, G. M. Hassan", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 44, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "7e4dfefcbacb639faa8a6fc8224ab7e0d7acf827", "year": 2025, "title": "Investigating the higher education institutions\u2019 guidelines and policies regarding the use of generative AI in teaching, learning, research, and administration", "authors": "Yunjo An, Ji Hyun Yu, Shadarra James", "venue": "International Journal of Educational Technology in Higher Education", "citationCount": 44, "abstract": "This study examined the guidelines issued by the top 50 U.S. universities regarding the use of Generative AI (GenAI) in academic and administrative activities. Employing a mixed methods approach, the research combined topic modeling, sentiment analysis, and qualitative thematic analysis to provide a comprehensive understanding of institutional responses to GenAI. Topic modeling identified four core topics: Integration of GenAI in Learning and Assessment, GenAI in Visual and Multimodal Media, Security and Ethical Considerations in GenAI, and GenAI in Academic Integrity. These themes were further explored through sentiment analysis, which revealed highly positive attitudes towards GenAI across all institution types, with significant differences between faculty and student-targeted guidelines. Qualitative thematic analysis corroborated these findings and provided deeper insights, revealing that 94% of universities had faculty guidelines emphasizing the importance of establishing and communicating course-specific GenAI policies. This analysis also highlighted recurring themes such as academic integrity and privacy concerns, which aligned with the security and ethical considerations identified in the topic modeling. The study highlights the rapid evolution of GenAI guidelines in higher education and the need for flexible, stakeholder-specific policies that address both the opportunities and challenges presented by this technology.", "isOpenAccess": true, "url": "https://doi.org/10.1186/s41239-025-00507-3"}
{"paperId": "484ed5ea8b8590a54d70dbf541ec50bf840e1c95", "year": 2023, "title": "Addressing the harms of AI-generated inauthentic content", "authors": "F. Menczer, D. Crandall, Yong-Yeol Ahn, Apu Kapadia", "venue": "Nature Machine Intelligence", "citationCount": 44, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "46a0f48475ac7e8a89088c9a4f5f771702ebad49", "year": 2025, "title": "Governance of Generative AI", "authors": "Araz Taeihagh", "venue": "Policy & Society", "citationCount": 44, "abstract": "\n The rapid and widespread diffusion of generative artificial intelligence (AI) has unlocked new capabilities and changed how content and services are created, shared, and consumed. This special issue builds on the 2021 Policy and Society special issue on the governance of AI by focusing on the legal, organizational, political, regulatory, and social challenges of governing generative AI. This introductory article lays the foundation for understanding generative AI and underscores its key risks, including hallucination, jailbreaking, data training and validation issues, sensitive information leakage, opacity, control challenges, and design and implementation risks. It then examines the governance challenges of generative AI, such as data governance, intellectual property concerns, bias amplification, privacy violations, misinformation, fraud, societal impacts, power imbalances, limited public engagement, public sector challenges, and the need for international cooperation. The article then highlights a comprehensive framework to govern generative AI, emphasizing the need for adaptive, participatory, and proactive approaches. The articles in this special issue stress the urgency of developing innovative and inclusive approaches to ensure that generative AI development is aligned with societal values. They explore the need for adaptation of data governance and intellectual property laws, propose a complexity-based approach for responsible governance, analyze how the dominance of Big Tech is exacerbated by generative AI developments and how this affects policy processes, highlight the shortcomings of technocratic governance and the need for broader stakeholder participation, propose new regulatory frameworks informed by AI safety research and learning from other industries, and highlight the societal impacts of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "39fb9d75d218f831bec3d7c5d7898e94daf3e5ce", "year": 2024, "title": "Role of AI in Blended Learning: A Systematic Literature Review", "authors": "Ye-Ji Park, M. Doo", "venue": "International Review of Research in Open and Distance Learning", "citationCount": 44, "abstract": "As blended learning moved toward a new phase during the COVID-19 pandemic, advancements in artificial intelligence (AI) technology provided opportunities to develop more diverse and dynamic blended learning. This systematic review focused on publications related to the use of AI applications in blended learning. The original studies from January 2007 to October 2023 were extracted from the Google Scholar, ERIC, and Web of Science databases. Finally, 30 empirical studies under the inclusion criteria were reviewed based on two conceptual frameworks: four key challenges of blended learning and three roles of AI. We found that AI applications have been used mainly for the online asynchronous individual learning component in blended learning; little work has been conducted on AI applications that help connect online activities with classroom-based offline activities. Many studies have identified the role of AI as a direct mediator to help control flexibility and autonomy of students in blended learning. However, abundant studies have also identified AI as a supplementary assistant using advanced learning analytics technologies that promote effective interactions with students and facilitate the learning process. Finally, the fewest number of studies have explored the role of AI as a new subject such as use as pedagogical agents or robots. Considering the advancements of generative AI technologies, we expect more research on AI in blended learning. The findings of this study suggested that future studies should guide teachers and their smart AI partner to implement blended learning more effectively.", "isOpenAccess": true, "url": "https://www.irrodl.org/index.php/irrodl/article/download/7566/6036"}
{"paperId": "3197aafcd874b31ecfdc94fedcec1969b216d994", "year": 2024, "title": "Examining generative AI user addiction from a C-A-C perspective", "authors": "Tao Zhou, Chunlei Zhang", "venue": "Technology and Society", "citationCount": 44, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "259dcef0a56585cc9713c0496bc40f79f4492bf2", "year": 2024, "title": "Large Language Models Meet Next-Generation Networking Technologies: A Review", "authors": "Ching Nam Hang, Pei-Duo Yu, Roberto Morabito, Chee-Wei Tan", "venue": "Future Internet", "citationCount": 44, "abstract": "The evolution of network technologies has significantly transformed global communication, information sharing, and connectivity. Traditional networks, relying on static configurations and manual interventions, face substantial challenges such as complex management, inefficiency, and susceptibility to human error. The rise of artificial intelligence (AI) has begun to address these issues by automating tasks like network configuration, traffic optimization, and security enhancements. Despite their potential, integrating AI models in network engineering encounters practical obstacles including complex configurations, heterogeneous infrastructure, unstructured data, and dynamic environments. Generative AI, particularly large language models (LLMs), represents a promising advancement in AI, with capabilities extending to natural language processing tasks like translation, summarization, and sentiment analysis. This paper aims to provide a comprehensive review exploring the transformative role of LLMs in modern network engineering. In particular, it addresses gaps in the existing literature by focusing on LLM applications in network design and planning, implementation, analytics, and management. It also discusses current research efforts, challenges, and future opportunities, aiming to provide a comprehensive guide for networking professionals and researchers. The main goal is to facilitate the adoption and advancement of AI and LLMs in networking, promoting more efficient, resilient, and intelligent network systems.", "isOpenAccess": true, "url": "https://www.mdpi.com/1999-5903/16/10/365/pdf?version=1728299460"}
{"paperId": "05b45fcd739d471ae6946b872ca276e772c31fef", "year": 2024, "title": "How generative AI is (will) change consumer behaviour: Postulating the potential impact and implications for research, practice, and policy", "authors": "E. Mogaji, Varsha Jain", "venue": "Journal of Consumer Behaviour", "citationCount": 44, "abstract": "This article sheds light on the profound impact of technology on consumer behavior, specifically focusing on the rise of generative AI tools. It highlights how these advancements have revolutionized consumer engagement, purchase decision\u2010making, and technology interaction. The article underscores the transformative potential of generative AI in shaping consumer behavior through personalized recommendations and interactive shopping experiences. It emphasizes the need for continued research and exploration to comprehend and effectively navigate the ever\u2010evolving landscape of consumer behavior influenced by generative AI. Additionally, the article identifies implications for research and practice, offers valuable strategies for brands, and presents a comprehensive research agenda to delve deeper into this field. Ultimately, it provides valuable insights into the challenges and opportunities presented by generative AI in consumer behavior, serving as a guiding resource for advancing theory, practice, and policy in this domain.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cb.2345"}
{"paperId": "ff63d04bbe56ce52123a44149783fa840bf03936", "year": 2024, "title": "Generative AI in first-year writing: An early analysis of affordances, limitations, and a framework for the future", "authors": "Robert E. Cummings, Stephen M. Monroe, Marc Watkins", "venue": "Computers and Composition", "citationCount": 43, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.compcom.2024.102827"}
{"paperId": "f63239d949f265fe45fe17feab51d4e80021e734", "year": 2023, "title": "The Notorious GPT: science communication in the age of artificial intelligence", "authors": "Mike S. Sch\u00e4fer", "venue": "Journal of Science Communication", "citationCount": 43, "abstract": "\nChatGPT provides original, human-like responses to user prompts based on supervised and reinforcement machine learning techniques. It has become the poster child of generative AI, which is widely diagnosed to disrupt many realms of life \u2014 including science communication. This essay reflects on this development. It discusses opportunities for the practice of science communication, such as generative AI\u2019s translational and multimodal capacities and its capacity to provide dialogical science communication at scale, but also challenges in terms of accuracy, \u2018wrongness at scale\u2019 or job market implications. It also ponders implications for research on science communication, which has largely neglected (generative) AI so far. It argues that scholars should analyze public communication \u201cabout\u201d AI as well as communication \u201cwith\u201d AI, given its \u2018increased agency\u2019. Furthermore, scholars should analyze the impact of AI on science communication itself and the larger science communication ecosystem.", "isOpenAccess": true, "url": "https://jcom.sissa.it/article/pubid/JCOM_2202_2023_Y02/download/pdf/"}
{"paperId": "ef81f542bf56eed64d3acb1068322066f4258d93", "year": 2024, "title": "Using Artificial Intelligence in TESOL: Some Ethical and Pedagogical Considerations", "authors": "Austin Pack, Jeffrey Maloney", "venue": "TESOL Quarterly (Print)", "citationCount": 43, "abstract": "While recent and significant progress made in natural language processing and artificial intelligence (AI) has the potential to drastically influence the field of language education, many language educators and administrators remain unfamiliar with these recent technological advances and their pedagogical implications. The primary purpose of this paper is to raise the awareness of language educators regarding ethical and pedagogical issues stemming from student, teacher, and administrator use of generative AI tools such as large language models (LLMs) and AI chatbots. These issues include ethical ways of teaching with AI, questions of ownership, writing skills development, the accuracy and reliability of generated output, the potential to widen the educational divide, and AI bias. We conclude by offering suggestions for language educators and calling for further discussion.", "isOpenAccess": false, "url": ""}
{"paperId": "ec919a74d9e9a66090de765f88d0936931edcb35", "year": 2024, "title": "Harnessing the Power of Generative AI for Clinical Summaries: Perspectives From Emergency Physicians.", "authors": "Yuval Barak-Corren, Rebecca Wolf, R. Rozenblum, Jessica K. Creedon, Susan C. Lipsett, Todd W. Lyons, Kenneth A. Michelson, Kelsey A. Miller, Daniel Shapiro, Ben Y. Reis, Andrew M. Fine", "venue": "Annals of Emergency Medicine", "citationCount": 43, "abstract": null, "isOpenAccess": true, "url": "http://www.annemergmed.com/article/S0196064424000787/pdf"}
{"paperId": "ec13feaf61fd812d4192cf367c78e0a573bd9629", "year": 2023, "title": "The Effects of Generative AI Platforms on Undergraduates\u2019 Narrative Intelligence and Writing Self-Efficacy", "authors": "Nikolaos Pellas", "venue": "Education sciences", "citationCount": 43, "abstract": "Digital storytelling and generative artificial intelligence (AI) platforms have emerged as transformative tools that empower individuals to write with confidence and share their stories effectively. However, a research gap exists in understanding the effects of using such web-based platforms on narrative intelligence and writing self-efficacy. This study aims to investigate whether digital story creation tasks on web-based platforms can influence the narrative intelligence and writing self-efficacy of undergraduate students. A pretest\u2013posttest comparison study between two groups was conducted with sixty-four undergraduate students (n = 64), majoring in Primary Education. More specifically, it compares the effects of the most well-known conventional platforms, such as Storybird, Storyjumper, and ZooBurst (control condition), and generative AI platforms, such as Sudowrite, Jasper, and Shortly AI (experimental condition) on undergraduate students, with an equal distribution in each group. The findings indicate that the utilization of generative AI platforms in the context of story creation tasks can substantially enhance both narrative intelligence scores and writing self-efficacy when compared to conventional platforms. Nonetheless, there was no significant difference in the creative identity factor. Generative AI platforms have promising implications for supporting undergraduates\u2019 narrative intelligence and writing self-efficacy in fostering their story creation design and development.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-7102/13/11/1155/pdf?version=1700288501"}
{"paperId": "e64df7e9448f7a9a4cb5d22c21c460134c8646ac", "year": 2023, "title": "Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions", "authors": "W. Tann, Yuancheng Liu, Jun Heng Sim, C. Seah, E. Chang", "venue": "arXiv.org", "citationCount": 43, "abstract": "The assessment of cybersecurity Capture-The-Flag (CTF) exercises involves participants finding text strings or ``flags'' by exploiting system vulnerabilities. Large Language Models (LLMs) are natural-language models trained on vast amounts of words to understand and generate text; they can perform well on many CTF challenges. Such LLMs are freely available to students. In the context of CTF exercises in the classroom, this raises concerns about academic integrity. Educators must understand LLMs' capabilities to modify their teaching to accommodate generative AI assistance. This research investigates the effectiveness of LLMs, particularly in the realm of CTF challenges and questions. Here we evaluate three popular LLMs, OpenAI ChatGPT, Google Bard, and Microsoft Bing. First, we assess the LLMs' question-answering performance on five Cisco certifications with varying difficulty levels. Next, we qualitatively study the LLMs' abilities in solving CTF challenges to understand their limitations. We report on the experience of using the LLMs for seven test cases in all five types of CTF challenges. In addition, we demonstrate how jailbreak prompts can bypass and break LLMs' ethical safeguards. The paper concludes by discussing LLM's impact on CTF exercises and its implications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.10443"}
{"paperId": "e60b3232e57a1a184addd6e710c46cd4cd4d36f4", "year": 2024, "title": "Utilizing generative conversational artificial intelligence to create simulated patient encounters: a pilot study for anaesthesia training.", "authors": "Neil Sardesai, Paolo Russo, Jonathan Martin, Anand Sardesai", "venue": "Postgraduate medical journal", "citationCount": 43, "abstract": "PURPOSE OF THE STUDY\nGenerative conversational artificial intelligence (AI) has huge potential to improve medical education. This pilot study evaluated the possibility of using a 'no-code' generative AI solution to create 2D and 3D virtual avatars, that trainee doctors can interact with to simulate patient encounters.\n\n\nMETHODS\nThe platform 'Convai' was used to create a virtual patient avatar, with a custom backstory, to test the feasibility of this technique. The virtual patient model was set up to allow trainee anaesthetists to practice answering questions that patients' may have about interscalene nerve blocks for open reduction and internal fixation surgery. This tool was provided to anaesthetists to receive their feedback and evaluate the feasibility of this approach.\n\n\nRESULTS\nFifteen anaesthetists were surveyed after using the tool. The tool had a median score [interquartile range (IQR)] of 9 [7-10] in terms of how intuitive and user-friendly it was, and 8 [7-10] in terms of accuracy in simulating patient responses and behaviour. Eighty-seven percent of respondents felt comfortable using the model.\n\n\nCONCLUSIONS\nBy providing trainees with realistic scenarios, this technology allows trainees to practice answering patient questions regardless of actor availability, and indeed from home. Furthermore, the use of a 'no-code' platform allows clinicians to create customized training tools tailored to their medical specialties. While overall successful, this pilot study highlighted some of the current drawbacks and limitations of generative conversational AI, including the risk of outputting false information. Additional research and fine-tuning are required before generative conversational AI tools can act as a substitute for actors and peers.", "isOpenAccess": true, "url": "https://academic.oup.com/pmj/advance-article-pdf/doi/10.1093/postmj/qgad137/56206984/qgad137.pdf"}
{"paperId": "d56325ee30fc3ec2c91df2a6cbd2b26b6e9cec11", "year": 2024, "title": "Machine Unlearning in Generative AI: A Survey", "authors": "Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang", "venue": "arXiv.org", "citationCount": 43, "abstract": "Generative AI technologies have been deployed in many places, such as (multimodal) large language models and vision generative models. Their remarkable performance should be attributed to massive training data and emergent reasoning abilities. However, the models would memorize and generate sensitive, biased, or dangerous information originated from the training data especially those from web crawl. New machine unlearning (MU) techniques are being developed to reduce or eliminate undesirable knowledge and its effects from the models, because those that were designed for traditional classification tasks could not be applied for Generative AI. We offer a comprehensive survey on many things about MU in Generative AI, such as a new problem formulation, evaluation methods, and a structured discussion on the advantages and limitations of different kinds of MU techniques. It also presents several critical challenges and promising directions in MU research. A curated list of readings can be found: https://github.com/franciscoliu/GenAI-MU-Reading.", "isOpenAccess": false, "url": ""}
{"paperId": "cb018fb7fb6e04a13e3b73577c3def0d80587ec8", "year": 2024, "title": "Students\u2019 perceptions of \u2018AI-giarism\u2019: investigating changes in understandings of academic misconduct", "authors": "C. K. Chan", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 43, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "c3d4dcfcf30c40365e784491bb930339472fc74b", "year": 2023, "title": "University Students\u2019 Acceptance and Usage of Generative AI (ChatGPT) from a Psycho-Technical Perspective", "authors": "Lawal Ibrahim Dutsinma Faruk, Rohani Rohan, Unhawa Ninrutsirikun, Debajyoti Pal", "venue": "International Conference on Advances in Information Technology", "citationCount": 43, "abstract": "The emergence of ChatGPT as a generative AI tool has revolutionized the educational scenario by bringing in unprecedented changes. In this respect exploring the factors that affect the adoption and acceptance of ChatGPT services for educational purpose is of utmost importance. Accordingly, in this work we take a hybrid psycho-technical approach by considering the technological (perceived usefulness, ease of use and facilitating conditions), contextual (perceived humanness and novelty value), and psychological (agreeableness, extraversion, openness, conscientiousness, and neuroticism) gratifications of ChatGPT use. Data is collected from a sample of university students who use ChatGPT regularly across two Asian countries. The data analysis is done using Partial Least Squares Structural Equation Modelling. Results indicate that among the technical factors only perceived usefulness successfully predicts ChatGPT usage. Both the contextual factors of humanness and novelty use significantly explain ChatGPT usage. Finally, among the psychological factors\u2019 openness, agreeableness, and neuroticism determine the usage scenario, however, the later two are found to be negatively associated with ChatGPT usage.", "isOpenAccess": false, "url": ""}
{"paperId": "bfb40571b33636bc27a81821f6a10fe90afa8291", "year": 2024, "title": "AI Risk Categorization Decoded (AIR 2024): From Government Regulations to Corporate Policies", "authors": "Yi Zeng, Kevin Klyman, Andy Zhou, Yu Yang, Minzhou Pan, Ruoxi Jia, Dawn Song, Percy Liang, Bo Li", "venue": "arXiv.org", "citationCount": 43, "abstract": "We present a comprehensive AI risk taxonomy derived from eight government policies from the European Union, United States, and China and 16 company policies worldwide, making a significant step towards establishing a unified language for generative AI safety evaluation. We identify 314 unique risk categories organized into a four-tiered taxonomy. At the highest level, this taxonomy encompasses System&Operational Risks, Content Safety Risks, Societal Risks, and Legal&Rights Risks. The taxonomy establishes connections between various descriptions and approaches to risk, highlighting the overlaps and discrepancies between public and private sector conceptions of risk. By providing this unified framework, we aim to advance AI safety through information sharing across sectors and the promotion of best practices in risk mitigation for generative AI models and systems.", "isOpenAccess": false, "url": ""}
{"paperId": "a51884aab9459cc196e362dc70271ef3a63ac242", "year": 2024, "title": "Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models", "authors": "Michelle Cohn, Mahima Pushkarna, Gbolahan O. Olanubi, Joseph M. Moran, Daniel Padgett, Zion Mengesha, Courtney Heldreth", "venue": "CHI Extended Abstracts", "citationCount": 43, "abstract": "People now regularly interface with Large Language Models (LLMs) via speech and text (e.g., Bard) interfaces. However, little is known about the relationship between how users anthropomorphize an LLM system (i.e., ascribe human-like characteristics to a system) and how they trust the information the system provides. Participants (n=2,165; ranging in age from 18-90 from the United States) completed an online experiment, where they interacted with a pseudo-LLM that varied in modality (text only, speech + text) and grammatical person (\u201cI\u201d vs. \u201cthe system\u201d) in its responses. Results showed that the \u201cspeech + text\u201d condition led to higher anthropomorphism of the system overall, as well as higher ratings of accuracy of the information the system provides. Additionally, the first-person pronoun (\u201cI\u201d) led to higher information accuracy and reduced risk ratings, but only in one context. We discuss these findings for their implications for the design of responsible, human\u2013generative AI experiences.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613905.3650818"}
{"paperId": "9d89a29b2fc4108f78dea84442b78c2104a23070", "year": 2024, "title": "Generative artificial intelligence and building design: early photorealistic render visualization of fa\u00e7ades using local identity-trained models", "authors": "Hayoung Jo, Jin-Kook Lee, Yong-Cheol Lee, Seungyeon Choo", "venue": "Journal of Computational Design and Engineering", "citationCount": 43, "abstract": "\n This paper elucidates an approach that utilizes generative AI to develop alternative architectural design options based on local identity. The advancement of AI technologies has increasingly piqued the interest of the AEC-FM (architecture, engineering, construction and facility management) industry. Notably, the topic of \u2018visualization\u2019 has gained prominence as a means for enhancing communication related to a project, especially in the early phases of design. This study aims to enhance the ease of obtaining design images during initial phases of design by drawing from multiple texts and images. It develops an additional training model to generate various design alternatives that resonate with the identity of the locale through the application of generative AI to the fa\u00e7ade design of buildings. The identity of a locality in cities and regions is the capacity for the cities and regions to be identified and recognized as a specific area. Among the various visual elements of urban and regional landscapes, the front face of buildings may play a significant role in people's aesthetic perception and overall impression of the local environment. The research proposes an approach that transcends the conventional employment of three-dimensional modeling and rendering tools by readily deriving design alternatives that consider this local identity in commercial building remodeling. This approach allows for financial and temporal efficiency in the design communication phase of the initial architectural design process. The implementation and utilization of the proposed approach's supplementary training model in this study proceeds as follows: 1) image data are collected from the target area using open-source street-view resources and preprocessed for conversion to a trainable format; 2) textual data are prepared for pairing with preprocessed image data; 3) additional training and outcome testing are performed using varied text prompts and images; 4) the ability to generate building fa\u00e7ade images that reflect the identity of the collected locale by using the additional trained model is determined, as evidenced by the findings of the proposed application method study. This enables the generation of design alternatives that integrate regional styles and diverse design requirements for buildings. The training model implemented in this study can be leveraged through weight adjustments and prompt engineering to generate a greater number of design reference images, among other diverse approaches.", "isOpenAccess": true, "url": "https://academic.oup.com/jcde/advance-article-pdf/doi/10.1093/jcde/qwae017/56695508/qwae017.pdf"}
{"paperId": "8dab631128bda282a0eed81a7ecfc816c746a68b", "year": 2024, "title": "How Generative AI Is Transforming Journalism: Development, Application and Ethics", "authors": "Yi Shi, Lin Sun", "venue": "Journalism and Media", "citationCount": 43, "abstract": "Generative artificial intelligence (GAI) is a technology based on algorithms, models, etc., that creates content such as text, audio, images, videos, and code. GAI is deeply integrated into journalism as tools, platforms and systems. However, GAI\u2019s role in journalism dilutes the power of media professionals, changes traditional news production and poses ethical questions. This study attempts to systematically answer these ethical questions in specific journalistic practices from the perspectives of journalistic professionalism and epistemology. Building on the review of GAI\u2019s development and application, this study identifies the responsibilities of news organizations, journalists and audiences, ensuring that they realize the potential of GAI while adhering to journalism professionalism and universal human values to avoid negative technological effects.", "isOpenAccess": true, "url": "https://www.mdpi.com/2673-5172/5/2/39/pdf?version=1715332603"}
{"paperId": "8c74508785111193ae5171b83cce419e539e0c42", "year": 2023, "title": "The AI writing on the wall", "authors": "", "venue": "Nature Machine Intelligence", "citationCount": 43, "abstract": null, "isOpenAccess": true, "url": "https://www.nature.com/articles/s42256-023-00613-9.pdf"}
{"paperId": "81f9b4d3b33e4f39bc0086144865a4e6984602fa", "year": 2025, "title": "The Use of Generative AI Tools in Higher Education: Ethical and Pedagogical Principles", "authors": "Khoa Viet Nguyen", "venue": "Journal of Academic Ethics", "citationCount": 43, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "7d8f8aed551401ebc17c26e0948f08835c53ac00", "year": 2023, "title": "Enhancing Physics Learning with ChatGPT, Bing Chat, and Bard as Agents-to-Think-With: A Comparative Case Study", "authors": "R. P. D. Santos", "venue": "Social Science Research Network", "citationCount": 43, "abstract": "The rise of AI has brought remarkable advancements in education, with AI models demonstrating their ability to analyse and provide instructive solutions to complex problems. This study compared and analysed the responses of four Generative AI-powered chatbots (GenAIbots) - ChatGPT-3.5, ChatGPT-4, Bing Chat, and Bard - within the constructivist theoretical framework. Using a single-case study methodology, interaction logs between the GenAIbots and a simulated student in Physics learning scenarios were analysed. The GenAIbots were presented with conceptually dense Physics problems to promote deep understanding. The qualitative analysis focused on tutor traits such as subject-matter knowledge, empathy, assessment emphasis, facilitation skills, and comprehension of the learning process. Findings showed that all GenAIbots functioned as agents-to-think-with, fostering critical thinking, problem-solving, and subject-matter knowledge. ChatGPT-4 stood out for demonstrating empathy and a deep understanding of the learning process. However, inconsistencies and shortcomings were observed, highlighting the need for human intervention in AI-assisted learning. In conclusion, while GenAIbots have limitations, their potential as agents-to-think-with in Physics education offers promising prospects for revolutionising instruction.", "isOpenAccess": false, "url": ""}
{"paperId": "7d063a2e7d2bd6755a64e9f6212e10fd673f5e23", "year": 2024, "title": "Exploring the generative AI adoption in service industry: A mixed-method analysis", "authors": "Rohit Gupta, Bhawana Rathore", "venue": "Journal of Retailing and Consumer Services", "citationCount": 43, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "7cc0d673fd564edef99f15e771feac39f48895b2", "year": 2024, "title": "\"I look at it as the king of knowledge\": How Blind People Use and Understand Generative AI Tools", "authors": "Rudaiba Adnin, Maitraye Das", "venue": "International ACM SIGACCESS Conference on Computers and Accessibility", "citationCount": 43, "abstract": "The proliferation of Generative Artificial Intelligence (GenAI) tools has brought a critical shift in how people approach information retrieval and content creation in diverse contexts. Yet, we have limited understanding of how blind people use and make sense of GenAI systems. To bridge this gap, we report findings from interviews with 19 blind individuals who incorporate mainstream GenAI tools like ChatGPT and Be My AI in their everyday practices. Our findings reveal how blind users navigate accessibility issues, inaccuracies, hallucinations, and idiosyncracies associated with GenAI and develop interesting (but often flawed) mental models of how these tools work. We discuss key considerations for rethinking access and information verification in GenAI tools, unpacking erroneous mental models among blind users, and reconciling harms and benefits of GenAI from an accessibility perspective.", "isOpenAccess": false, "url": ""}
{"paperId": "79bc4f92fce3284f7fb5eaaf580583901d2eff07", "year": 2024, "title": "The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception", "authors": "Zishan Ahmed, Shakib Sadat Shanto, Most. Humayra Khanom Rime, Md. Kishor Morol, Nafiz Fahad, Md.Jakir Hossen, Md. Abdullah-Al-Jubair", "venue": "IEEE Access", "citationCount": 43, "abstract": "Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students\u2019 experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.", "isOpenAccess": true, "url": "https://doi.org/10.1109/access.2024.3461874"}
{"paperId": "3b0ed49d97643fc38a39a3246d75198558191533", "year": 2023, "title": "The Impact of Generative Artificial Intelligence", "authors": "Kai Zhang, Ohchan Kwon, Hui Xiong", "venue": "arXiv.org", "citationCount": 43, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "199f33ec7077d30a21f865e15b8b5d3fee71a80e", "year": 2024, "title": "The paradox of self-efficacy and technological dependence: Unraveling generative AI's impact on university students' task completion", "authors": "Ling Zhang, Junzhou Xu", "venue": "Internet and Higher Education", "citationCount": 43, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "fb7bcc5754087cddf77c7e854b5f40989880c228", "year": 2023, "title": "Preparing to Revolutionize Education with the Multi-Model GenAI Tool Google Gemini? A Journey towards Effective Policy Making", "authors": "Pethigamage Perera, M. Lankathilake", "venue": "Journal of Advances in Education and Philosophy", "citationCount": 42, "abstract": "The integration of Generative AI (GenAI) in Education presents immense potential for reshaping learning experiences and empowering students and educators. However, harnessing this potential requires collective action and responsible decision- making to ensure the effective and ethical use of AI technologies. This paper presents a series of recommendations and proposals aimed at effectively integrating GenAI in the higher education sector, catering to the perspectives of government, AI developers, students, educators, universities, schools, and researchers. By exploring diverse viewpoints about ChatGPT and future Google Gemini, this research aims to create a comprehensive recommendation guiding regulatory measures that address challenges, ethical considerations, and best practices of GenAI integration. Through a holistic approach, researchers believe that policymakers can foster a transformative and ethical environment, leveraging the full potential of generative AI while safeguarding students' well-being and academic integrity.", "isOpenAccess": true, "url": "https://doi.org/10.36348/jaep.2023.v07i08.001"}
{"paperId": "f61bb7673d59de01ea5fc5e11071ab955d450cee", "year": 2023, "title": "Entrepreneurship Education at the Dawn of Generative Artificial Intelligence", "authors": "Christoph Winkler, Basel Hammoda, Erik Noyes, M. van Gelderen", "venue": "Entrepreneurship Education and Pedagogy", "citationCount": 42, "abstract": "The rapid evolution, application and ubiquity of generative artificial intelligence (AI) tools seems to be indicative that our world has entered a paradigm shift that mirrors the beginning of a new era not seen since the dawn of the internet. As entrepreneurship educators, we are pushed to the frontline of this development, mandated to embrace this transformative innovation to not only educate our students but also use its potential to reshape our classrooms. To help better understand this paradigm shift, this editorial invites the larger entrepreneurship education community to innovate, experiment, and learn in order to advance our theoretical and practical understanding of generative AI\u2019s present and future impact on our field. Furthermore, it presents a series of inquiry questions to help guide our community to advance our field through rigorous research and impactful learning innovations.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/25151274231198799"}
{"paperId": "ec77da012a0d75ac59e75977032c2a9f4fabf70a", "year": 2023, "title": "Search still matters: information retrieval in the era of generative AI", "authors": "William R. Hersh", "venue": "J. Am. Medical Informatics Assoc.", "citationCount": 42, "abstract": "OBJECTIVE\nInformation retrieval (IR, also known as search) systems are ubiquitous in modern times. How does the emergence of generative artificial intelligence (AI), based on large language models (LLMs), fit into the IR process?\n\n\nPROCESS\nThis perspective explores the use of generative AI in the context of the motivations, considerations, and outcomes of the IR process with a focus on the academic use of such systems.\n\n\nCONCLUSIONS\nThere are many information needs, from simple to complex, that motivate use of IR. Users of such systems, particularly academics, have concerns for authoritativeness, timeliness, and contextualization of search. While LLMs may provide functionality that aids the IR process, the continued need for search systems, and research into their improvement, remains essential.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2311.18550"}
{"paperId": "e96bb5316ee75f23f6c501258aeada1d85afe368", "year": 2023, "title": "TrustMark: Universal Watermarking for Arbitrary Resolution Images", "authors": "Tu Bui, S. Agarwal, J. Collomosse", "venue": "arXiv.org", "citationCount": 42, "abstract": "Imperceptible digital watermarking is important in copyright protection, misinformation prevention, and responsible generative AI. We propose TrustMark - a GAN-based watermarking method with novel design in architecture and spatio-spectra losses to balance the trade-off between watermarked image quality with the watermark recovery accuracy. Our model is trained with robustness in mind, withstanding various in- and out-place perturbations on the encoded image. Additionally, we introduce TrustMark-RM - a watermark remover method useful for re-watermarking. Our methods achieve state-of-art performance on 3 benchmarks comprising arbitrary resolution images.", "isOpenAccess": false, "url": ""}
{"paperId": "e69f4f3c558d79a9b1d2a68455393fab869b41b3", "year": 2023, "title": "Generative AI for performance-based design of engineered cementitious composite", "authors": "Jie Yu, Yiwei Weng, Jiangtao Yu, Wenguang Chen, Shuainan Lu, Kequan Yu", "venue": "Composites Part B: Engineering", "citationCount": 42, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "d7caccd6632a4cfc64371f25fe1e437c708cd572", "year": 2024, "title": "Artificial Intelligence-Enabled Metaverse for Sustainable Smart Cities: Technologies, Applications, Challenges, and Future Directions", "authors": "Zita Lifelo, Jianguo Ding, Huansheng Ning, Qurat-Ul-Ain, Sahraoui Dhelim", "venue": "Electronics", "citationCount": 42, "abstract": "Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints. This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverse\u2019s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domains\u2014environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AI\u2019s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challenges\u2019 societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.", "isOpenAccess": false, "url": ""}
{"paperId": "cfa31aca1763d29ff33df0f2266a8907e39c8f99", "year": 2024, "title": "University students\u2019 perceptions of artificial intelligence-based tools for English writing courses", "authors": "Yong-Jik Lee, Robert O. Davis, Sun Ok Lee", "venue": "Online Journal of Communication and Media Technologies", "citationCount": 42, "abstract": "This research explores the perceptions of Korean university students regarding artificial intelligence (AI)-based writing tools that include tools guided by machine learning, such as Google Translate and Naver Papago, and generative AI tools, such as Grammarly. A mixed methodology was used, including both quantitative and qualitative data. Among students who have taken English writing courses, 80 Korean university students volunteered for the online survey. After the survey, the research team recruited interview participants, and five volunteered participants joined the focus group interview. The study results indicate that these AI-based writing tools could improve English language learners (ELLs) writing skills. ELLs also noted the strengths and weaknesses of each AI-based tool, including the accessibility of translation machine learning and the error-checking capabilities of generative AI. However, interview data analysis indicates that the excessive use of AI-based writing tools could interfere with ELLs\u2019 English writing process. This study highlights the need to effectively integrate AI-based tools in English language teaching for adult ELLs worldwide.", "isOpenAccess": true, "url": "https://www.ojcmt.net/download/university-students-perceptions-of-artificial-intelligence-based-tools-for-english-writing-courses-14195.pdf"}
{"paperId": "c509c7b4cd99da5081958afc2c8ce86d6446bd09", "year": 2024, "title": "University Students' Perception and Use of ChatGPT: Generative Artificial Intelligence (AI) in Higher Education", "authors": "Brandon Nacua Obenza, Alexa Salvahan, Alexandra Nicole Rios, Althea Solo, Rea Ashlee Alburo, Rey Jose Gabila", "venue": "International Journal of Human Computing Studies", "citationCount": 42, "abstract": "This quantitative study examined how university students perceive and use generative AI technology, specifically ChatGPT, in higher education. The main objective is to explore and describe university students' perception and use of generative AI, particularly ChatGPT, in the context of higher education. A 5-point Likert scale questionnaire was adopted and used in the study. Five hundred students from various universities in Region XI were surveyed using a stratified random sampling technique. Further, the validity and reliability of the scale used in the study were assessed using Cronbach's Alpha and Factor Analysis and demonstrated acceptable construct validity and reliability indices. The findings revealed that university students demonstrated high levels of understanding, knowledge, perception of the advantages and disadvantages, positive attitude, and strong intention to use generative AI technologies in the context of higher education. Moreover, the respondents showed a moderate level of concern about generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "b0bd64273dc8075db530fd696ee7eecb179bb908", "year": 2024, "title": "Image Conductor: Precision Control for Interactive Video Synthesis", "authors": "Yaowei Li, Xintao Wang, Zhaoyang Zhang, Zhouxia Wang, Ziyang Yuan, Liangbin Xie, Yuexian Zou, Ying Shan", "venue": "arXiv.org", "citationCount": 42, "abstract": "Filmmaking and animation production often require sophisticated techniques for coordinating camera transitions and object movements, typically involving labor-intensive real-world capturing. Despite advancements in generative AI for video creation, achieving precise control over motion for interactive video asset generation remains challenging. To this end, we propose Image Conductor, a method for precise control of camera transitions and object movements to generate video assets from a single image. An well-cultivated training strategy is proposed to separate distinct camera and object motion by camera LoRA weights and object LoRA weights. To further address cinematographic variations from ill-posed trajectories, we introduce a camera-free guidance technique during inference, enhancing object movements while eliminating camera transitions. Additionally, we develop a trajectory-oriented video motion data curation pipeline for training. Quantitative and qualitative experiments demonstrate our method's precision and fine-grained control in generating motion-controllable videos from images, advancing the practical application of interactive video synthesis. Project webpage available at https://liyaowei-stu.github.io/project/ImageConductor/", "isOpenAccess": false, "url": ""}
{"paperId": "a63b0864afb934b2b5ffd032e89fbb7c0d4932a3", "year": 2024, "title": "Ensuring useful adoption of generative artificial intelligence in healthcare", "authors": "Jenelle A. Jindal, M. Lungren, Nigam H. Shah", "venue": "J. Am. Medical Informatics Assoc.", "citationCount": 42, "abstract": "OBJECTIVES\nThis article aims to examine how generative artificial intelligence (AI) can be adopted with the most value in health systems, in response to the Executive Order on AI.\n\n\nMATERIALS AND METHODS\nWe reviewed how technology has historically been deployed in healthcare, and evaluated recent examples of deployments of both traditional AI and generative AI (GenAI) with a lens on value.\n\n\nRESULTS\nTraditional AI and GenAI are different technologies in terms of their capability and modes of current deployment, which have implications on value in health systems.\n\n\nDISCUSSION\nTraditional AI when applied with a framework top-down can realize value in healthcare. GenAI in the short term when applied top-down has unclear value, but encouraging more bottom-up adoption has the potential to provide more benefit to health systems and patients.\n\n\nCONCLUSION\nGenAI in healthcare can provide the most value for patients when health systems adapt culturally to grow with this new technology and its adoption patterns.", "isOpenAccess": false, "url": ""}
{"paperId": "a610485fa634e2c4f95cec5db643289c5c1f7fed", "year": 2023, "title": "Leveraging Generative AI Tools for Enhanced Lesson Planning in Initial Teacher Education at Post Primary", "authors": "Frank Kehoe", "venue": "Irish Journal of Technology Enhanced Learning", "citationCount": 42, "abstract": "The rapid development of generative AI (artificial intelligence) tools such as ChatGPT and Google Bard has opened new possibilities for enhancing lesson planning in initial teacher education (ITE). These tools have the capability to generate tailored educational content, alleviating time constraints while concurrently enhancing the quality of teaching. By simply providing specific requirements and objectives, teachers can obtain comprehensive and well-structured lesson plans and subject plans. This paper explores the potential of generative AI tools to revolutionise lesson planning in initial teacher education. It begins by reviewing lesson planning using a generative AI tool, highlighting the challenges and opportunities that exist. A sample lesson plan and a sample scheme of work are further created. While these tools are revolutionising the way teachers work, these tools will not replace real human teachers. Teachers will always need to supplement generative AI content with their own insights and experience, allowing them to make informed pedagogical decisions.", "isOpenAccess": true, "url": "https://journal.ilta.ie/index.php/telji/article/download/124/152"}
{"paperId": "6564470d2722c273725b219f90cc9f90428eb95a", "year": 2023, "title": "Generative Artificial Intelligence Assistants in Software Development Education: A Vision for Integrating Generative Artificial Intelligence Into Educational Practice, Not Instinctively Defending Against It", "authors": "Christopher Bull, Ahmed Kharrufa", "venue": "IEEE Software", "citationCount": 42, "abstract": "The use of Generative AI in software development is gaining traction. But what are the potentials and implications on software development education? We gathered insights on the use of Generative AI from professional software developers and make some pedagogical recommendations.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2303.13936"}
{"paperId": "53c73763923a576ae6d5d31a26995479833f59f3", "year": 2023, "title": "Deconstructing Student Perceptions of Generative AI (GenAI) through an Expectancy Value Theory (EVT)-based Instrument", "authors": "C. Chan, Wenxin Zhou", "venue": "arXiv.org", "citationCount": 42, "abstract": "This study examines the relationship between student perceptions and their intention to use generative AI in higher education. Drawing on Expectancy-Value Theory (EVT), a questionnaire was developed to measure students' knowledge of generative AI, perceived value, and perceived cost. A sample of 405 students participated in the study, and confirmatory factor analysis was used to validate the constructs. The results indicate a strong positive correlation between perceived value and intention to use generative AI, and a weak negative correlation between perceived cost and intention to use. As we continue to explore the implications of generative AI in education and other domains, it is crucial to carefully consider the potential long-term consequences and the ethical dilemmas that may arise from widespread adoption.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.01186"}
{"paperId": "3c47bf88ce1f8fd05408eab1fe3fb313653c24c5", "year": 2024, "title": "Preventing harm from non-conscious bias in medical generative AI.", "authors": "Janna Hastings", "venue": "The Lancet Digital Health", "citationCount": 42, "abstract": null, "isOpenAccess": true, "url": "http://www.thelancet.com/article/S2589750023002467/pdf"}
{"paperId": "2f102127ba756dfae3755b673ff3cdba49e4981d", "year": 2023, "title": "AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education", "authors": "Samuli Laato, Benedikt Morschheuser, Juho Hamari, Jari Bj\u00f6rne", "venue": "International Conference on Advanced Learning Technologies", "citationCount": 42, "abstract": "The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.", "isOpenAccess": false, "url": ""}
{"paperId": "24d911db2c214194b1e3db1fd7726c8eb6cac2bf", "year": 2023, "title": "Using generative AI to investigate medical imagery models and datasets", "authors": "Oran Lang, Doron Yaya-Stupp, I. Traynis, Heather Cole-Lewis, Chloe R. Bennett, C. Lyles, Charles Lau, Michal Irani, Christopher Semturs, D. Webster, G. Corrado, Avinatan Hassidim, Yossi Matias, Yun Liu, N. Hammel, Boris Babenko", "venue": "EBioMedicine", "citationCount": 42, "abstract": null, "isOpenAccess": true, "url": "http://www.thelancet.com/article/S2352396424001105/pdf"}
{"paperId": "21dacec58d0a344e25d63282f5742fdcdfa239fd", "year": 2025, "title": "Multimodal generative AI for medical image interpretation", "authors": "Vishwanatha M. Rao, Michael Hla, Michael Moor, Subathra Adithan, Stephen Kwak, E. Topol, P. Rajpurkar", "venue": "Nature", "citationCount": 42, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "1b780aa88e8a56c0a95968748b58abd5bbebdb9a", "year": 2023, "title": "A Word is Worth a Thousand Pictures: Prompts as AI Design Material", "authors": "Chinmay Kulkarni, Stefania Druga, Minsuk Chang, Alexander J. Fiannaca, Carrie J. Cai, Michael Terry", "venue": "arXiv.org", "citationCount": 42, "abstract": "Recent advances in Machine-Learning have led to the development of models that generate images based on a text description.Such large prompt-based text to image models (TTIs), trained on a considerable amount of data, allow the creation of high-quality images by users with no graphics or design training. This paper examines the role such TTI models can playin collaborative, goal-oriented design. Through a within-subjects study with 14 non-professional designers, we find that such models can help participants explore a design space rapidly and allow for fluid collaboration. We also find that text inputs to such models (\"prompts\") act as reflective design material, facilitating exploration, iteration, and reflection in pair design. This work contributes to the future of collaborative design supported by generative AI by providing an account of how text-to-image models influence the design process and the social dynamics around design and suggesting implications for tool design", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.12647"}
{"paperId": "118065d943e29f9a85bc48cab81395a806bb0a89", "year": 2024, "title": "Generative AI for the Optimization of Next-Generation Wireless Networks: Basics, State-of-the-Art, and Open Challenges", "authors": "Fahime Khoramnejad, Ekram Hossain", "venue": "IEEE Communications Surveys and Tutorials", "citationCount": 42, "abstract": "Next-generation (xG) wireless networks, with their complex and dynamic nature, present significant challenges to using traditional optimization techniques. Generative Artificial Intelligence (GAI) emerges as a powerful tool due to its unique strengths. Unlike traditional optimization techniques and other machine learning methods, GAI excels at learning from real-world network data, capturing its intricacies. This enables safe, offline exploration of various configurations and generation of diverse, unseen scenarios, empowering proactive, data-driven exploration and optimization for xG networks. Additionally, GAI\u2019s scalability makes it ideal for large-scale xG networks. This paper surveys how GAI-based models unlock optimization opportunities in xG wireless networks. We begin by providing a review of GAI models and some of the major communication paradigms of xG (e.g., Sixth Generation) wireless networks. We then delve into exploring how GAI can be used to improve resource allocation and enhance overall network performance. Additionally, we briefly review the networking requirements for supporting GAI applications in xG wireless networks. The paper further discusses the key challenges and future research directions in leveraging GAI for network optimization. Finally, a case study demonstrates the application of a diffusion-based GAI model for load balancing, carrier aggregation, and backhauling optimization in non-terrestrial networks, a core technology of xG networks. This case study serves as a practical example of how the combination of reinforcement learning and GAI can be implemented to address real-world network optimization problems.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2405.17454"}
{"paperId": "071d1c64455a10ac625181d0cc998e338a83517b", "year": 2024, "title": "Overview of the \"Voight-Kampff\" Generative AI Authorship Verification Task at PAN and ELOQUENT 2024", "authors": "Janek Bevendorff, Matti Wiegmann, Jussi Karlgren, Luise D\u00fcrlich, Evangelia Gogoulou, Aarne Talman, E. Stamatatos, Martin Potthast, Benno Stein", "venue": "Conference and Labs of the Evaluation Forum", "citationCount": 42, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "0576e9ab604ba4bf20cd5947f3c4a2c609ac2705", "year": 2024, "title": "A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models", "authors": "Yujuan Ding, Wenqi Fan, Liang-bo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, Qing Li", "venue": "arXiv.org", "citationCount": 42, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "035e57c18e9b130bc297479e4b692860859d7aeb", "year": 2023, "title": "Originality and the Future of Copyright in an Age of Generative AI", "authors": "Paulius Jur\u010dys, M. Fenwick", "venue": "Computer Law and Security Review", "citationCount": 42, "abstract": "This papers explores the question of human authorship when works are created with generative AI tools.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.13055"}
{"paperId": "f73fa1e171dae071a78f7b28762e631235352cde", "year": 2023, "title": "ID.8: Co-Creating Visual Stories with Generative AI", "authors": "Victor Antony, Chien-Ming Huang", "venue": "ACM Trans. Interact. Intell. Syst.", "citationCount": 41, "abstract": "Storytelling is an integral part of human culture and significantly impacts cognitive and socio-emotional development and connection. Despite the importance of interactive visual storytelling, the process of creating such content requires specialized skills and is labor-intensive. This article introduces ID.8, an open-source system designed for the co-creation of visual stories with generative AI. We focus on enabling an inclusive storytelling experience by simplifying the content creation process and allowing for customization. Our user evaluation confirms a generally positive user experience in domains such as enjoyment and exploration while highlighting areas for improvement, particularly in immersiveness, alignment, and partnership between the user and the AI system. Overall, our findings indicate promising possibilities for empowering people to create visual stories with generative AI. This work contributes a novel content authoring system, ID.8, and insights into the challenges and potential of using generative AI for multimedia content creation.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3672277"}
{"paperId": "ef40add3a2f66266d287c40057eaaf6826f69da9", "year": 2024, "title": "Generative AI in the Wild: Prospects, Challenges, and Strategies", "authors": "Yuan Sun, Eunchae Jang, Fenglong Ma, Ting Wang", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 41, "abstract": "Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N = 18) GenAI users in creative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing) framework. Our study uncovered an intriguingly complex landscape: Prospects \u2013 GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges \u2013 Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory compliance; Strategies \u2013 In response, users actively devise various strategies to overcome many of such challenges. Our study reveals key implications for the design of future GenAI tools.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642160"}
{"paperId": "ec9af412c6c3131a6a953f910bd8bc46956f2cbe", "year": 2024, "title": "GAI-IoV: Bridging Generative AI and Vehicular Networks for Ubiquitous Edge Intelligence", "authors": "Gaochang Xie, Zehui Xiong, Xinyuan Zhang, Renchao Xie, Song Guo, Mohsen Guizani, H. Vincent Poor", "venue": "IEEE Transactions on Wireless Communications", "citationCount": 41, "abstract": "The growth of intelligent vehicular services, like augmented reality (AR) road simulation, underscores the need for rapid, multi-modal content generation. Generative artificial intelligence (GAI) models, known for their swift production of diverse artificial intelligence-generated content (AIGC), stand out as a prime solution. However, integrating cloud-centric GAI models into vehicular networks is fraught with challenges. Notably, to offer specialized generative edge intelligence (EI) and boost vehicular AIGC, GAI models need to tap into user data and utilize significant computation resources. Moreover, their deployment across vehicular networks is essential for proximity-based distributed inferences. Yet, edge devices are resource-limited, and data sharing can raise safety and privacy concerns. Addressing these challenges, this paper introduces GAI-IoV, an EI-enabled GAI framework facilitated through the cooperation between road-side units (RSUs) and vehicles. Subsequently, we propose the workflow for collaborative fine-tuning and distributed inference. On this basis, two pivotal vehicle-centric problems are then formulated: computation and communication resource allocation for federated fine-tuning (FFT) to optimize time and energy cost, and splitting strategy of shared and local inferences to optimize inference latency and content-generation capability. To solve these optimizations, we introduce a self-adaptive global best harmony search (SGHS) algorithm for resource allocation and a backward induction method for determining inference splitting strategy. Our experiments based on the Stable Diffusion v1-4 model vouch for a superior fine-tuning and inference capabilities of GAI-IoV. Furthermore, simulations underscore its resource utilization and distributed inference efficiency in dynamic vehicular scenarios.", "isOpenAccess": false, "url": ""}
{"paperId": "e692ee8e0e2023b4a335a509f290e42f632254d6", "year": 2023, "title": "Advancing Qualitative Analysis: An Exploration of the Potential of Generative AI and NLP in Thematic Coding", "authors": "Yasir Gamieldien, J. Case, Andrew Katz", "venue": "Social Science Research Network", "citationCount": 41, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "e30175b2266cc7b4b68bea4668f74d5855952c6f", "year": 2024, "title": "Program Code Generation with Generative AIs", "authors": "Baskhad Idrisov, Tim Schlippe", "venue": "Algorithms", "citationCount": 41, "abstract": "Our paper compares the correctness, efficiency, and maintainability of human-generated and AI-generated program code. For that, we analyzed the computational resources of AI- and human-generated program code using metrics such as time and space complexity as well as runtime and memory usage. Additionally, we evaluated the maintainability using metrics such as lines of code, cyclomatic complexity, Halstead complexity and maintainability index. For our experiments, we had generative AIs produce program code in Java, Python, and C++ that solves problems defined on the competition coding website leetcode.com. We selected six LeetCode problems of varying difficulty, resulting in 18 program codes generated by each generative AI. GitHub Copilot, powered by Codex (GPT-3.0), performed best, solving 9 of the 18 problems (50.0%), whereas CodeWhisperer did not solve a single problem. BingAI Chat (GPT-4.0) generated correct program code for seven problems (38.9%), ChatGPT (GPT-3.5) and Code Llama (Llama 2) for four problems (22.2%) and StarCoder and InstructCodeT5+ for only one problem (5.6%). Surprisingly, although ChatGPT generated only four correct program codes, it was the only generative AI capable of providing a correct solution to a coding problem of difficulty level hard. In summary, 26 AI-generated codes (20.6%) solve the respective problem. For 11 AI-generated incorrect codes (8.7%), only minimal modifications to the program code are necessary to solve the problem, which results in time savings between 8.9% and even 71.3% in comparison to programming the program code from scratch.", "isOpenAccess": true, "url": "https://www.mdpi.com/1999-4893/17/2/62/pdf?version=1706690455"}
{"paperId": "d7c80ec085ea10d63d94a74d8f8b726bb3665876", "year": 2024, "title": "The consequences of generative AI for online knowledge communities", "authors": "Gordon Burtch, Dokyun Lee, Zhichen Chen", "venue": "Scientific Reports", "citationCount": 41, "abstract": "Generative artificial intelligence technologies, especially large language models (LLMs) like ChatGPT, are revolutionizing information acquisition and content production across a variety of domains. These technologies have a significant potential to impact participation and content production in online knowledge communities. We provide initial evidence of this, analyzing data from Stack Overflow and Reddit developer communities between October 2021 and March 2023, documenting ChatGPT\u2019s influence on user activity in the former. We observe significant declines in both website visits and question volumes at Stack Overflow, particularly around topics where ChatGPT excels. By contrast, activity in Reddit communities shows no evidence of decline, suggesting the importance of social fabric as a buffer against the community-degrading effects of LLMs. Finally, the decline in participation on Stack Overflow is found to be concentrated among newer users, indicating that more junior, less socially embedded users are particularly likely to exit.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-024-61221-0.pdf"}
{"paperId": "d6d6b17601074b124b9cdad3e119e38467545f1a", "year": 2023, "title": "Constructing Dreams using Generative AI", "authors": "Safinah Ali, Daniella DiPaola, Randi Williams, Prerna Ravi, C. Breazeal", "venue": "AAAI Conference on Artificial Intelligence", "citationCount": 41, "abstract": "Generative AI tools introduce new and accessible forms of media creation for youth. They also raise ethical concerns about the generation of fake media, data protection, privacy and ownership of AI-generated art. Since generative AI is already being used in products used by youth, it is critical that they understand how these tools work and how they can be used or misused. In this work, we facilitated students\u2019 generative AI learning through expression of their imagined future identities. We designed a learning workshop - Dreaming with AI - where students learned about the inner workings of generative AI tools, used text-to-image generation algorithms to create their imaged future dreams, reflected on the potential benefits and harms of generative AI tools and voiced their opinions about policies for the use of these tools in classrooms. In this paper, we present the learning activities and experiences of 34 high school students who engaged in our workshops. Students reached creative learning objectives by using prompt engineering to create their future dreams, gained technical knowledge by learning the abilities, limitations, text-visual mappings and applications of generative AI, and identified most potential societal benefits and harms of generative AI.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.12013"}
{"paperId": "ccbe7486f40da6a2496d168600076abc9fd56214", "year": 2024, "title": "Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems", "authors": "Lauren E. Margulieux, J. Prather, Brent N. Reeves, Brett A. Becker, Gozde Cetin Uzun, Dastyni Loksa, Juho Leinonen, Paul Denny", "venue": "Annual Conference on Innovation and Technology in Computer Science Education", "citationCount": 41, "abstract": "We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.", "isOpenAccess": false, "url": ""}
{"paperId": "c465127678757d205b30db4c767e1c800bee04d0", "year": 2024, "title": "Generative AI-enabled supply chain management: A coordination theory perspective", "authors": "Lixu Li, Yaoqi Liu, Yong Jin, T. Cheng, Qianjun Zhang", "venue": "International Journal of Production Economics", "citationCount": 41, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "c371a48e12fc5a45be9c14d698469f30afc34d86", "year": 2024, "title": "Innovating by prompting: How to facilitate innovation in the age of generative AI", "authors": "L. Sundberg, J. Holmstr\u00f6m", "venue": "Business Horizons", "citationCount": 41, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "a8f5902cec98a90b9fbbdf1d0cc902f603a96da3", "year": 2025, "title": "Atom level enzyme active site scaffolding using RFdiffusion2", "authors": "Woody Ahern, Jason Yim, D. Tischer, Saman Salike, Seth M. Woodbury, Donghyo Kim, Indrek Kalvet, Yakov Kipnis, B. Coventry, H. Altae-Tran, Magnus Bauer, R. Barzilay, T. Jaakkola, Rohith Krishna, David Baker", "venue": "bioRxiv", "citationCount": 41, "abstract": "De novo enzyme design starts from ideal active site descriptions consisting of constellations of catalytic residue functional groups around reaction transition state(s), and seeks to generate protein structures that can accurately hold the site in place. Highly active enzymes have been designed starting from such descriptions using the generative AI method RFdiffusion [1\u20133], but there are two current methodological limitations. First, the geometry of the active site can only be specified at the residue level, so for each catalytic residue functional group placed around the reaction transition state, the possible locations of the residue backbone must be enumerated by building side chain rotamers back from the functional group. Second, the location of the catalytic residues along the sequence must be specified in advance, which considerably limits the space of solutions which can be sampled. Here we describe a new deep generative method, Rosetta Fold diffusion 2 (RFdiffusion2), that solves both problems, enabling enzymes to be designed from sequence agnostic descriptions of functional group locations without inverse rotamer generation. We first evaluate RFdiffusion2 on an in silico enzyme design benchmark of 41 diverse active sites and find that it is able to successfully build proteins scaffolding all 41 sites, compared to 16/41 with prior state-of-the-art deep learning methods. Next, we design enzymes around three diverse catalytic sites and characterize the designs experimentally; in each case we identify active catalysts in testing less than 96 sequences. RFdiffusion2 demonstrates the potential of atomic resolution generative models for the design of de novo enzymes directly from their reaction mechanisms.", "isOpenAccess": true, "url": "https://doi.org/10.1101/2025.04.09.648075"}
{"paperId": "9dea44c6364e1e7aa2eeb04ccd6c0bdbca005ffe", "year": 2023, "title": "Envisioning the future of learning and teaching engineering in the artificial intelligence era: Opportunities and challenges", "authors": "Muhsin Menekse", "venue": "Journal of Engineering Education", "citationCount": 41, "abstract": "Generative artificial intelligence (AI) technologies, such as large language models (LLMs) and diffusion model image and video generators, can transform learning and teaching experiences by providing students and instructors with access to a vast amount of information and create innovative learning and teaching materials in a very efficient way (e.g., U.S. Department of Education, 2023; Kasneci et al., 2023; Mollick & Mollick, 2023; Nikolic et al., 2023). For example, Google Bard and OpenAI ChatGPT are LLMs that can generate natural language texts for various purposes, such as summaries of research papers (e.g., OpenAI, 2023). At the same time, Midjourney and DeepBrain AI are diffusion models that can create diagrams (e.g., concept maps), images, and videos from textual or visual inputs. Engineering education, in particular, can benefit from integrating and utilizing generative AI technologies to improve instructional resources, develop new technology-enhanced learning environments, reduce instructors' workloads, and provide students with opportunities to design and develop their learning experiences. These technologies can help educators to create more personalized, effective, and engaging learning experiences for engineering students. Most engineering students struggle to acquire a deep understanding of complex engineering concepts because of the nature of the highly mathematical concepts, lack of prior knowledge, limitations of the large lectures, limited resources that prevent the use of commercially available lab equipment, and the lack of innovative teaching tools that could be utilized to enhance learning experiences (e.g., Menekse et al., 2018, 2022; Miller et al., 2011; Reeves & Crippen, 2021; Streveler & Menekse, 2017). These factors adversely affect retention and graduation rates and inhibit persistence in engineering majors (e.g., Estrada et al., 2016). Generative AI technologies and tools (e.g., CourseMIRROR) could support engineering educators to improve students' learning and engagement (e.g., Fan et al., 2015; Luo et al., 2015; Menekse, 2020).", "isOpenAccess": false, "url": ""}
{"paperId": "73e68b29bc5581180fd10bf5e16495943913ffb1", "year": 2024, "title": "Exploring the potential of generative AI in democratizing English language education", "authors": "D. Tafazoli", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 41, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100275"}
{"paperId": "28e1e7479d12d5c8f89d02f1adac0e7d56efa912", "year": 2024, "title": "AI-powered ChatGPT in the hospitality and tourism industry: benefits, challenges, theoretical framework, propositions and future research directions", "authors": "R. Rather", "venue": "Tourism Recreation Resarch", "citationCount": 41, "abstract": "ABSTRACT Generative artificial intelligence (AI) and smart/e-tourism provide imperative opportunities to service industries; however, the implementation of ChatGPT in the tourism and hospitality industry is limited, which extends different considerations/challenges that need vigilant reflection. Based on this significance and research gap, we thus develop a theoretical framework which suggests different sets of key research propositions in AI technology-powered ChatGPT. A widespread literature review and practices were conducted to investigate the conceptual advancements/developments on generative AI-powered technologies including ChatGPT, chatbot in marketing, tourism, hospitality and information management. The proposed framework suggests generative AI technology-powered ChatGPT develops customer\u2019s interaction-based conditions including experience, engagement/trust, attachment, satisfaction/service quality, attitude change and operational efficiency, which consequently affect their strategic outcomes including behaviours, subjective/psychological well-being, happiness and performance. Thus, this research note suggests theoretical/practical implications to provide an extensive future-research roadmap on AI technology-powered ChatGPT and also recommends transformative opportunities, challenges and benefits in tourism, hospitality and marketing management.", "isOpenAccess": false, "url": ""}
{"paperId": "0e598ad8c140d341230ca1bf4d0c90885b529825", "year": 2024, "title": "Generative-AI, a Learning Assistant? Factors Influencing Higher-Ed Students' Technology Acceptance", "authors": "Kraisila Kanont, Pawarit Pingmuang, Thewawuth Simasathien, Suchaya Wisnuwong, Benz Wiwatsiripong, Kanitta Poonpirome, N. Songkram, Jintavee Khlaisang", "venue": "Electronic Journal of e-Learning", "citationCount": 41, "abstract": "This study investigates the factors influencing the adoption of Generative-AI tools amongst Thai university students, employing the Technology Acceptance Model (TAM) as a theoretical framework. Data from 911 higher education students from 10 different Thai Universities Health Sciences, Sciences and Technology, Social Sciences and Humanities, and Vocational Fields were analysed via Structural Equation Modelling (SEM). The instrument used in collecting the data was a questionnaire. Results indicated that Expected Benefits, Perceived Usefulness, Attitude Toward Technology, and Behavioural Intention all significantly impacted student adoption of Generative AI. Intriguingly, Perceived Ease of Use was negatively correlated with Perceived Usefulness, challenging conventional TAM assumptions. This study underscores the need to address language barriers, foster a culture of innovation, and establish ethical guidelines to promote responsible AI use within education. Despite inherent limitations, this research contributes to our understanding of AI adoption in educational settings and helps inform strategies for equitable access and responsible innovation. The result demonstrated that the easier a tool was to use, the less value leaners seemed to see in it for their learning process. It can be implied that as Generative-AI get more intuitive, learners think they're less helpful. These finding challenges a few of those assumptions we usually make within the TAM model. It also points out the characteristic of learners which affects their learning preferences and expectation. Another finding showed the impact of language barrier on non-native English speaker that obstruct the user experience in AI services. \u00a0Moreover, the role of universities in fostering both AI integration for learning for and the ethical implementation of Generative AI. By providing a supportive environment that encourages AI experimentation, redesign learning, empowering learners and faculty instructors to investigate how Generative AI can be applied across disciplines, and developing guidelines for ethical use, universities play a critical role in shaping the effective and responsible integration of AI into the next educational landscape.", "isOpenAccess": true, "url": "https://academic-publishing.org/index.php/ejel/article/download/3196/2238"}
{"paperId": "fa7c139c7f66e7991a27fdbb0dc1f254efe6b61e", "year": 2024, "title": "The Mediating Role of Generative AI Self-Regulation on Students\u2019 Critical Thinking and Problem-Solving", "authors": "Xue Zhou, Da Teng, H. Al-Samarraie", "venue": "Education sciences", "citationCount": 40, "abstract": "Within the rapid integration of AI into educational settings, understanding its impact on essential cognitive skills is crucial for developing effective teaching strategies and improving student outcomes. This study examines the influence of generative artificial intelligence (GenAI) on students\u2019 critical thinking and problem-solving skills in higher education. Our research specifically investigates how the perceived ease of use, usefulness, and learning value of GenAI tools might influence students\u2019 critical thinking and problem-solving skills, and whether self-regulation serves as a mediator in this relationship. Utilising a quantitative approach, we surveyed 223 students and analysed their responses using a structural equation modelling method. The results reveal that the ease of use of GenAI significantly enhances self-regulation, which in turn positively impacts both the critical thinking and problem-solving abilities of students. However, the perceived usefulness and learning value of GenAI were not found to significantly influence these skills through self-regulation. These findings suggest that, while AI tools can offer an environment conducive to developing higher-order cognitive skills, this might not necessarily translate to the enhancement of students\u2019 skills. This research contributes to the ongoing literature on the role of technology in education by highlighting the importance of designing GenAI tools that support self-regulated learning. Furthermore, it calls for educators and developers to focus not just on the functionality of AI, but also on how these tools can be integrated into curricula to effectively support critical thinking and problem-solving. The practical implications of our research highlight the need for AI tools that are user-friendly and aligned with educational goals, enhancing their adoption and effectiveness in improving student outcomes. It is crucial for educators to integrate strategies that promote self-regulation within AI-enhanced learning environments to maximise their impact on student learning.", "isOpenAccess": false, "url": ""}
{"paperId": "f51489c94d71271a98512c8b214aaa599cc0c059", "year": 2024, "title": "Incorporating Generative AI into Software Development Education", "authors": "Olga Petrovska, Lee Clift, Faron Moller, Rebecca Pearsall", "venue": "Conference on Computing Education Practice", "citationCount": 40, "abstract": "This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools \u201cdoing the homework\u201d.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3633053.3633057"}
{"paperId": "d288b03efdea01d96dc1666bef13db71ea2d9deb", "year": 2024, "title": "A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model", "authors": "Daeseung Park, Gi-taek An, Chayapol Kamyod, Cheong-Ghil Kim", "venue": "Journal of Web Engineering", "citationCount": 40, "abstract": "In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.", "isOpenAccess": false, "url": ""}
{"paperId": "ccc7048c34e01650758227e42cc48d2d354e035b", "year": 2024, "title": "Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey", "authors": "Thai-Hoc Vu, S. Jagatheesaperumal, Minh-Duong Nguyen, Nguyen Van Huynh, Sunghwan Kim, Viet Quoc Pham", "venue": "IEEE Internet of Things Journal", "citationCount": 40, "abstract": "The success of artificial intelligence (AI) in multiple disciplines and vertical domains in recent years has promoted the evolution of mobile networking and the future Internet toward an AI-integrated Internet of Things (IoT) era. Nevertheless, most AI techniques rely on data generated by physical devices (e.g., mobile devices and network nodes) or specific applications (e.g., fitness trackers and mobile gaming). Therefore, generative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a powerful AI paradigm; thanks to its ability to efficiently learn complex data distributions and generate synthetic data to represent the original data in various forms. This impressive feature is projected to transform the management of mobile networking and diversify the current services and applications provided. On this basis, this work presents a concise tutorial on the role of GAIs in mobile and wireless networking. In particular, this survey first provides the fundamentals of GAI and representative GAI models, serving as an essential preliminary to the understanding of GAI\u2019s applications in mobile and wireless networking. Then, this work provides a comprehensive review of state-of-the-art studies and GAI applications in network management, wireless security, semantic communication, and lessons learned from the open literature. Finally, this work summarizes the current research on GAI for mobile and wireless networking by outlining important challenges that need to be resolved to facilitate the development and applicability of GAI in this edge-cutting area.", "isOpenAccess": false, "url": ""}
{"paperId": "c97f0ba3da9cb67d81b44638abbb4dc654ae5f2c", "year": 2023, "title": "Demo: Scalable Digital Twin System for Mobile Networks with Generative AI", "authors": "Jiahui Gong, Qiaohong Yu, Tong Li, Haoqiang Liu, Jun Zhang, Hangyu Fan, Depeng Jin, Yong Li", "venue": "ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services", "citationCount": 40, "abstract": "Digital Twin brings a new realization approach to the modeling of mobile networks. Mobile networks, as complex systems comprising multiple components, such as mobile users, base stations, and wireless environments, have intricate interactions and relationships with each other. By creating a virtual replica of each physical mobile network entity in a virtual space, we build a scalable digital twin system for mobile networks with generative AI. The system can interact with multiple optimizers to evaluate and display real-time simulation results. A companion video can be accessed using the link below. https://youtu.be/xtcBIXPzvkc", "isOpenAccess": false, "url": ""}
{"paperId": "c4c4e874b3298d6803b74727f0edf952a10b2d10", "year": 2024, "title": "Generative AI for Advanced UAV Networking", "authors": "Geng Sun, Wenwen Xie, D. Niyato, Hongyang Du, Jiawen Kang, Jing Wu, Sumei Sun, Ping Zhang", "venue": "IEEE Network", "citationCount": 40, "abstract": "With the impressive achievements of chatGPT and Sora, generative artificial intelligence (GAI) has received increasing attention. Not limited to the field of content generation, GAI is also widely used to solve the problems in wireless communication scenarios due to its powerful learning and generalization capabilities. Therefore, we discuss key applications of GAI in improving unmanned aerial vehicle (UAV) communication and networking performance in this article. Specifically, we first review the key technologies of GAI and the important roles of UAV networking. Then, we show how GAI can improve the communication, networking, and security performances of UAV systems. Subsequently, we propose a novel framework of GAI for advanced UAV networking, and then present a case study of UAV-enabled spectrum map estimation and transmission rate optimization based on the proposed framework to verify the effectiveness of GAI-enabled UAV systems. Finally, we discuss some important open directions.", "isOpenAccess": false, "url": ""}
{"paperId": "b462147a93bb5b74998b6c563b2ffeaa91ee0d47", "year": 2024, "title": "Reconceptualizing Self-Directed Learning in the Era of Generative AI: An Exploratory Analysis of Language Learning", "authors": "Belle Li, Curtis J. Bonk, Chaoran Wang, Xiaojing Kou", "venue": "IEEE Transactions on Learning Technologies", "citationCount": 40, "abstract": "This exploratory analysis investigates the integration of ChatGPT in self-directed learning (SDL). Specifically, this study examines YouTube content creators\u2019 language-learning experiences and the role of ChatGPT in their SDL, building upon Song and Hill's conceptual model of SDL in online contexts. Thematic analysis of interviews with 19 YouTubers and relevant video contents reveals distinct constructs of ChatGPT-integrated SDL, suggesting a reconceptualization and refinement of the SDL framework in the consideration of generative artificial intelligence (AI). This framework emphasizes critical aspects of utilizing ChatGPT as an SDL tool on two distinct levels: 1) the interactive relationships and interplay between learners\u2019 personal traits and their ongoing learning processes (local) and 2) the evolving nature of SDL in the rapidly advancing landscape of generative AI, with socio-political-cultural foundations of AI constantly shaping the learning environment where SDL occurs (global). The study highlights the potential of ChatGPT as a tool for promoting self-directed language learning (SDLL) and provides implications for the development of learning technologies and research on AI-facilitated SDL.", "isOpenAccess": false, "url": ""}
{"paperId": "9c70b8ca18bc38ac3ebf22129aa0ed33b2c25e89", "year": 2024, "title": "Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators", "authors": "Wiebke Hutiri, Orestis Papakyriakopoulos, Alice Xiang", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 40, "abstract": "The rapid and wide-scale adoption of AI to generate human speech poses a range of significant ethical and safety risks to society that need to be addressed. For example, a growing number of speech generation incidents are associated with swatting attacks in the United States, where anonymous perpetrators create synthetic voices that call police officers to close down schools and hospitals, or to violently gain access to innocent citizens\u2019 homes. Incidents like this demonstrate that multimodal generative AI risks and harms do not exist in isolation, but arise from the interactions of multiple stakeholders and technical AI systems. In this paper we analyse speech generation incidents to study how patterns of specific harms arise. We find that specific harms can be categorised according to the exposure of affected individuals, that is to say whether they are a subject of, interact with, suffer due to, or are excluded from speech generation systems. Similarly, specific harms are also a consequence of the motives of the creators and deployers of the systems. Based on these insights we propose a conceptual framework for modelling pathways to ethical and safety harms of AI, which we use to develop a taxonomy of harms of speech generators. Our relational approach captures the complexity of risks and harms in sociotechnical AI systems, and yields a taxonomy that can support appropriate policy interventions and decision making for the responsible development and release of speech generation models.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658911"}
{"paperId": "8d13880fb0c5d28c8250e9b2acb2b1cd070dc149", "year": 2025, "title": "How Generative AI Influences Students' Self-Regulated Learning and Critical Thinking Skills? A Systematic Review", "authors": "Juli Sardi, Darmansyah, Oriza Candra, Devita Yuliana, Habibullah, D.T.P. Yanto, Fivia Eliza", "venue": "Int. J. Eng. Pedagog.", "citationCount": 40, "abstract": "Generative artificial intelligence (AI), particularly tools such as ChatGPT, is transforming education by enhancing self-regulated learning (SRL) and critical thinking skills, two essential competencies in the digital era. This study systematically analyzes the impact of generative AI on these skills using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework to identify, evaluate, and synthesize relevant studies. Document searches were conducted in Scopus, Web of Science, and ScienceDirect, focusing on publications from 2022 to 2024, when ChatGPT was first widely adopted. Of the 3,214 documents identified, 557 met the initial screening criteria, and 38 studies were selected for detailed analysis. The findings reveal that 71.4% of studies reported AI\u2019s positive role in SRL, mainly through personalized learning, metacognitive support, and adaptive feedback. Likewise, 62.5% of studies reported its significant role in critical thinking, supporting the process of analysis, evaluation, and reflection. However, researchers cautioned against an overreliance on technology, which one said could take away some students\u2019 ability to think for themselves. Such findings indicate that educational institutions need to change their ways and include generative AI in a model that focuses on areas that foster learner independence. This approach will assist teachers and decision-makers in harnessing the distinctive kitsch of AI technology by creating new learning spaces that are creative and future-oriented.", "isOpenAccess": true, "url": "https://doi.org/10.3991/ijep.v15i1.53379"}
{"paperId": "8781e2075d624df5ba99866959b4da59c304e2c6", "year": 2023, "title": "GANCollage: A GAN-Driven Digital Mood Board to Facilitate Ideation in Creativity Support", "authors": "Qian Wan, Zhicong Lu", "venue": "Conference on Designing Interactive Systems", "citationCount": 40, "abstract": "During past decades, Artificial Intelligence (AI) has been consistently used in Creativity Support Tools (CSTs). Recently, with the development of generative AI models, particularly Generative Adversarial Nets (GAN) in Computer Vision, it became possible that AI directly generates visual ideas. However, there were rarely any work in creativity research that harnessed the design ideas generated by such models directly for design space exploration. In this paper, we propose a StyleGAN-driven digital mood board, GANCollage, that integrates AI generated visual ideas into the ideation phase for creativity support. GANCollage supports semantic explorations of StyleGAN generations in an iterative human-in-the-loop manner, using an AI-driven interactive tagging system. Our evaluation involving 10 participants manifests that GANCollage provides more creativity support without compromising the final results. It also offers a more enjoyable, explicit and effective way of exploring AI generated visual ideas for ideation.", "isOpenAccess": false, "url": ""}
{"paperId": "753eb709e52f37699e994553088857e8aa3d1d6c", "year": 2025, "title": "Who Is AI Replacing? The Impact of Generative AI on Online Freelancing Platforms", "authors": "Ozge Demirci, Jonas Hannane, Xinrong Zhu", "venue": "Management Sciences", "citationCount": 40, "abstract": "This paper studies the impact of generative artificial intelligence (AI) technologies on the demand for online freelancers using a large data set from a leading global freelancing platform. We identify the types of jobs that are more affected by generative AI and quantify the magnitude of the heterogeneous impact. Our findings indicate a 21% decrease in the number of job posts for automation-prone jobs related to writing and coding compared with jobs requiring manual-intensive skills within eight months after the introduction of ChatGPT. We show that the reduction in the number of job posts increases competition among freelancers, whereas the remaining automation-prone jobs are of greater complexity and offer higher pay. We also find that the introduction of image-generating AI technologies led to a 17% decrease in the number of job posts related to image creation. We use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT\u2019s substitutability. This paper was accepted by Duncan Simester, marketing. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mnsc.2024.05420 .", "isOpenAccess": false, "url": ""}
{"paperId": "69ee881b66e99453314b8a5445ba4a3160f4ed0a", "year": 2024, "title": "Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise", "authors": "Rose E. Wang, Ana T. Ribeiro, Carly D. Robinson, Susanna Loeb, Dora Demszky", "venue": "arXiv.org", "citationCount": 40, "abstract": "Generative AI, particularly Language Models (LMs), has the potential to transform real-world domains with societal impact, particularly where access to experts is limited. For example, in education, training novice educators with expert guidance is important for effectiveness but expensive, creating significant barriers to improving education quality at scale. This challenge disproportionately harms students from under-served communities, who stand to gain the most from high-quality education. We introduce Tutor CoPilot, a novel Human-AI approach that leverages a model of expert thinking to provide expert-like guidance to tutors as they tutor. This study is the first randomized controlled trial of a Human-AI system in live tutoring, involving 900 tutors and 1,800 K-12 students from historically under-served communities. Following a preregistered analysis plan, we find that students working with tutors that have access to Tutor CoPilot are 4 percentage points (p.p.) more likely to master topics (p<0.01). Notably, students of lower-rated tutors experienced the greatest benefit, improving mastery by 9 p.p. We find that Tutor CoPilot costs only $20 per-tutor annually. We analyze 550,000+ messages using classifiers to identify pedagogical strategies, and find that tutors with access to Tutor CoPilot are more likely to use high-quality strategies to foster student understanding (e.g., asking guiding questions) and less likely to give away the answer to the student. Tutor interviews highlight how Tutor CoPilot's guidance helps tutors to respond to student needs, though they flag issues in Tutor CoPilot, such as generating suggestions that are not grade-level appropriate. Altogether, our study of Tutor CoPilot demonstrates how Human-AI systems can scale expertise in real-world domains, bridge gaps in skills and create a future where high-quality education is accessible to all students.", "isOpenAccess": false, "url": ""}
{"paperId": "5e54d3c0f64f3ab6c670c68c74ad33e25c0fadae", "year": 2024, "title": "Comparing the Perspectives of Generative AI, Mental Health Experts, and the General Public on Schizophrenia Recovery: Case Vignette Study", "authors": "Zohar Elyoseph, I. Levkovich", "venue": "JMIR Mental Health", "citationCount": 40, "abstract": "Abstract Background The current paradigm in mental health care focuses on clinical recovery and symptom remission. This model\u2019s efficacy is influenced by therapist trust in patient recovery potential and the depth of the therapeutic relationship. Schizophrenia is a chronic illness with severe symptoms where the possibility of recovery is a matter of debate. As artificial intelligence (AI) becomes integrated into the health care field, it is important to examine its ability to assess recovery potential in major psychiatric disorders such as schizophrenia. Objective This study aimed to evaluate the ability of large language models (LLMs) in comparison to mental health professionals to assess the prognosis of schizophrenia with and without professional treatment and the long-term positive and negative outcomes. Methods Vignettes were inputted into LLMs interfaces and assessed 10 times by 4 AI platforms: ChatGPT-3.5, ChatGPT-4, Google Bard, and Claude. A total of 80 evaluations were collected and benchmarked against existing norms to analyze what mental health professionals (general practitioners, psychiatrists, clinical psychologists, and mental health nurses) and the general public think about schizophrenia prognosis with and without professional treatment and the positive and negative long-term outcomes of schizophrenia interventions. Results For the prognosis of schizophrenia with professional treatment, ChatGPT-3.5 was notably pessimistic, whereas ChatGPT-4, Claude, and Bard aligned with professional views but differed from the general public. All LLMs believed untreated schizophrenia would remain static or worsen without professional treatment. For long-term outcomes, ChatGPT-4 and Claude predicted more negative outcomes than Bard and ChatGPT-3.5. For positive outcomes, ChatGPT-3.5 and Claude were more pessimistic than Bard and ChatGPT-4. Conclusions The finding that 3 out of the 4 LLMs aligned closely with the predictions of mental health professionals when considering the \u201cwith treatment\u201d condition is a demonstration of the potential of this technology in providing professional clinical prognosis. The pessimistic assessment of ChatGPT-3.5 is a disturbing finding since it may reduce the motivation of patients to start or persist with treatment for schizophrenia. Overall, although LLMs hold promise in augmenting health care, their application necessitates rigorous validation and a harmonious blend with human expertise.", "isOpenAccess": true, "url": "https://mental.jmir.org/2024/1/e53043/PDF"}
{"paperId": "5bea7828c7a5aeaac8fc86e2012d8fa43ba64242", "year": 2023, "title": "A Survey of Generative Artificial Intelligence Techniques", "authors": "Tam Sakirin, Siddartha Kusuma", "venue": "Babylonian Journal of Artificial Intelligence", "citationCount": 40, "abstract": "Generative artificial intelligence (AI) refers to algorithms capable of creating novel, realistic digital content autonomously. Recently, generative models have attained groundbreaking results in domains like image and audio synthesis, spurring vast interest in the field. This paper surveys the landscape of modern techniques powering the rise of creative AI systems. We structurally examine predominant algorithmic approaches including generative adversarial networks (GANs), variational autoencoders (VAEs), and autoregressive models. Architectural innovations and illustrations of generated outputs are highlighted for major models under each category. We give special attention to generative techniques for constructing realistic images, tracing rapid progress from early GAN samples to modern diffusion models like Stable Diffusion. The paper further reviews generative modeling to create convincing audio, video, and 3D renderings, which introduce critical challenges around fake media detection and data bias. Additionally, we discuss common datasets that have enabled advances in generative modeling. Finally, open questions around evaluation, technique blending, controlling model behaviors, commercial deployment, and ethical considerations are outlined as active areas for future work. This survey presents both long-standing and emerging techniques molding the state and trajectory of generative AI. The key goals are to overview major algorithm families, highlight innovations through example models, synthesize capabilities for multimedia generation, and discuss open problems around data, evaluation, control, and ethics. Please let me know if you would like any clarification or modification of this proposed abstract.", "isOpenAccess": true, "url": "https://mesopotamian.press/journals/index.php/BJAI/article/download/201/192"}
{"paperId": "552c4f1d22637bbbfdf70dc5cab471e5dca9c7d6", "year": 2024, "title": "Instructors as Innovators: A future-focused approach to new AI learning opportunities, with prompts", "authors": "Ethan R. Mollick, Lilach Mollick", "venue": "Social Science Research Network", "citationCount": 40, "abstract": "This paper explores how instructors can leverage generative AI to create personalized learning experiences for students that transform teaching and learning. We present a range of AI-based exercises that enable novel forms of practice and application including simulations, mentoring, coaching, and co-creation. For each type of exercise, we provide prompts that instructors can customize, along with guidance on classroom implementation, assessment, and risks to consider. We also provide blueprints, prompts that help instructors create their own original prompts. Instructors can leverage their content and pedagogical expertise to design these experiences, putting them in the role of builders and innovators. We argue that this instructor-driven approach has the potential to democratize the development of educational technology by enabling individual instructors to create AI exercises and tools tailored to their students' needs. While the exercises in this paper are a starting point, not a definitive solutions, they demonstrate AI's potential to expand what is possible in teaching and learning.", "isOpenAccess": false, "url": ""}
{"paperId": "4bda2650cb9e5c7fe09b30a78d1974f5876f7b18", "year": 2024, "title": "On the Challenges and Opportunities in Generative AI", "authors": "Laura Manduchi, Kushagra Pandey, Robert Bamler, Ryan Cotterell, Sina Daubener, Sophie Fellenz, Asja Fischer, Thomas Gartner, Matthias Kirchler, M. Kloft, Yingzhen Li, Christoph Lippert, Gerard de Melo, Eric T. Nalisnick, Bjorn Ommer, Rajesh Ranganath, Maja Rudolph, Karen Ullrich, Guy Van den Broeck, Julia E Vogt, Yixin Wang, F. Wenzel, Frank Wood, Stephan Mandt, Vincent Fortuin", "venue": "Trans. Mach. Learn. Res.", "citationCount": 40, "abstract": "The field of deep generative modeling has grown rapidly in the last few years. With the availability of massive amounts of training data coupled with advances in scalable unsupervised learning paradigms, recent large-scale generative models show tremendous promise in synthesizing high-resolution images and text, as well as structured data such as videos and molecules. However, we argue that current large-scale generative AI models exhibit several fundamental shortcomings that hinder their widespread adoption across domains. In this work, our objective is to identify these issues and highlight key unresolved challenges in modern generative AI paradigms that should be addressed to further enhance their capabilities, versatility, and reliability. By identifying these challenges, we aim to provide researchers with insights for exploring fruitful research directions, thus fostering the development of more robust and accessible generative AI solutions.", "isOpenAccess": false, "url": ""}
{"paperId": "48dae3af16e63d96eb83df4b3af3d1133fb4571e", "year": 2023, "title": "Is artificial intelligence more creative than humans?", "authors": "David H. Cropley", "venue": "Learning Letters", "citationCount": 40, "abstract": "A fundamental premise of the future of work is that AI will replace people in many cognitive and physical tasks, leaving creativity as a core, human 21st century skill. However, the recent launch of generative AI (especially ChatGPT) has seen many claims that AI is creative. If true, then the foundation of future human work, and education, is under threat. To examine claims of AI creativity, this research applied a test of verbal divergent thinking \u2013 the Divergent Association Task \u2013 to two versions of ChatGPT (GPT3.5 and GPT4). The results are reported and compared to a large human baseline. While both forms of ChatGPT show a capacity for verbal divergent production that exceeds human means, a range of factors call into question the \u201ccreativity\u201d of generative AI.\nLIFT Learning: Could AI replicate your creativity? Engage with Professor David Cropley as he discusses the rise of ChatGPT and its ability to \u201cthink\u201d creatively at this article\u2019s companion LIFT Learning site. Professor Cropley explains the process of divergent thinking as a measure of creativity and outlines why your creative role is probably still safe for now. The LIFT Learning site is available at\u00a0https://lift.c3l.ai/courses/course-v1:LEARNINGLETTERS+0113+2023\n\u00a0", "isOpenAccess": true, "url": "https://learningletters.org/index.php/learn/article/download/13/24"}
{"paperId": "4751a4a17d1e002407753d4d7e07d0e06054c4fe", "year": 2025, "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits", "authors": "Brandon Radosevich, John Halloran", "venue": "arXiv.org", "citationCount": 40, "abstract": "To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol (MCP) (Anthropic, 2024) has recently been released and subsequently widely adopted. The MCP is an open protocol that standardizes API calls to large language models (LLMs), data sources, and agentic tools. By connecting multiple MCP servers, each defined with a set of tools, resources, and prompts, users are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries a wide range of security risks for end users. In particular, we demonstrate that industry-leading LLMs may be coerced into using MCP tools to compromise an AI developer's system through various attacks, such as malicious code execution, remote access control, and credential theft. To proactively mitigate these and related attacks, we introduce a safety auditing tool, MCPSafetyScanner, the first agentic tool to assess the security of an arbitrary MCP server. MCPScanner uses several agents to (a) automatically determine adversarial samples given an MCP server's tools and resources; (b) search for related vulnerabilities and remediations based on those samples; and (c) generate a security report detailing all findings. Our work highlights serious security issues with general-purpose agentic workflows while also providing a proactive tool to audit MCP server safety and address detected vulnerabilities before deployment. The described MCP server auditing tool, MCPSafetyScanner, is freely available at: https://github.com/johnhalloran321/mcpSafetyScanner", "isOpenAccess": false, "url": ""}
{"paperId": "422f1c0e3906c34d234f3ecd9a0ef40512a95b8a", "year": 2024, "title": "Optimizing Rare Disease Gait Classification through Data Balancing and Generative AI: Insights from Hereditary Cerebellar Ataxia", "authors": "Dante Trabassi, S. Castiglia, F. Bini, F. Marinozzi, Arash Ajoudani, M. Lorenzini, G. Chini, T. Varrecchia, A. Ranavolo, R. Icco, Carlo Casali, Mariano Serrao", "venue": "Italian National Conference on Sensors", "citationCount": 40, "abstract": "The interpretability of gait analysis studies in people with rare diseases, such as those with primary hereditary cerebellar ataxia (pwCA), is frequently limited by the small sample sizes and unbalanced datasets. The purpose of this study was to assess the effectiveness of data balancing and generative artificial intelligence (AI) algorithms in generating synthetic data reflecting the actual gait abnormalities of pwCA. Gait data of 30 pwCA (age: 51.6 \u00b1 12.2 years; 13 females, 17 males) and 100 healthy subjects (age: 57.1 \u00b1 10.4; 60 females, 40 males) were collected at the lumbar level with an inertial measurement unit. Subsampling, oversampling, synthetic minority oversampling, generative adversarial networks, and conditional tabular generative adversarial networks (ctGAN) were applied to generate datasets to be input to a random forest classifier. Consistency and explainability metrics were also calculated to assess the coherence of the generated dataset with known gait abnormalities of pwCA. ctGAN significantly improved the classification performance compared with the original dataset and traditional data augmentation methods. ctGAN are effective methods for balancing tabular datasets from populations with rare diseases, owing to their ability to improve diagnostic models with consistent explainability.", "isOpenAccess": true, "url": "https://www.mdpi.com/1424-8220/24/11/3613/pdf?version=1717417995"}
{"paperId": "278bc3b9d7e9e38e5922dbfee8c9f5546d44fd72", "year": 2024, "title": "The ethics of using generative AI for qualitative data analysis", "authors": "Robert M. Davison, Hameed Chughtai, Petter Nielsen, Marco Marabelli, F. Iannacci, Marjolein van Offenbeek, Monideepa Tarafdar, Manuel Trenz, A. Techatassanasoontorn, A. D\u00edaz-Andrade, Niki Panteli", "venue": "Information Systems Journal", "citationCount": 40, "abstract": "GAI", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/isj.12504"}
{"paperId": "1702e7a52a5367e5b5f267ff77e3e67b17d09c3f", "year": 2023, "title": "Requirements Engineering using Generative AI: Prompts and Prompting Patterns", "authors": "Krishna Ronanki, Beatriz Cabrero Daniel, Jennifer Horkoff, Christian Berger", "venue": "arXiv.org", "citationCount": 40, "abstract": "[Context]: Companies are increasingly recognizing the importance of automating Requirements Engineering (RE) tasks due to their resource-intensive nature. The advent of GenAI has made these tasks more amenable to automation, thanks to its ability to understand and interpret context effectively. [Problem]: However, in the context of GenAI, prompt engineering is a critical factor for success. Despite this, we currently lack tools and methods to systematically assess and determine the most effective prompt patterns to employ for a particular RE task. [Method]: Two tasks related to requirements, specifically requirement classification and tracing, were automated using the GPT-3.5 turbo API. The performance evaluation involved assessing various prompts created using 5 prompt patterns and implemented programmatically to perform the selected RE tasks, focusing on metrics such as precision, recall, accuracy, and F-Score. [Results]: This paper evaluates the effectiveness of the 5 prompt patterns' ability to make GPT-3.5 turbo perform the selected RE tasks and offers recommendations on which prompt pattern to use for a specific RE task. Additionally, it also provides an evaluation framework as a reference for researchers and practitioners who want to evaluate different prompt patterns for different RE tasks.", "isOpenAccess": false, "url": ""}
{"paperId": "101469e9d22a66775262c93be994249205056d31", "year": 2023, "title": "Artificial intelligence in marketing research and future research directions: Science mapping and research clustering using bibliometric analysis", "authors": "Jyoti Thakur, B. Kushwaha", "venue": "Global Business and Organizational Excellence", "citationCount": 40, "abstract": "The marketing environment has experienced significant advancements due to the transformative influence of technologies such as artificial intelligence, data analytics, decision sciences, and robotics. These innovations have entirely reshaped the fundamental marketing principles as we know them. This study uses bibliometric analysis to conduct a systematic literature review of research on Artificial Intelligence (AI) in marketing and provides future research directions. It also aims to identify the most influential and productive contributors and progression of research on AI in marketing. The bibliographic data of 317 documents on artificial intelligence in marketing research was extracted from the Scopus database. The bibliometric analysis is performed to comprehensively understand the most influential and productive articles, authors, sources, and the top contributing countries and institutions towards the discipline of AI in marketing research. The results and the publication trend show exponential growth yearly in AI in marketing research. Furthermore, it discovered four main thematic clusters: Data mining and deep learning in decision support systems, big data and generative AI in marketing, AI\u2010enabled commerce, and chatbots and marketing Tech that represent the recent research being carried out under AI in marketing. The trending topics recognized are marketing algorithms for decision\u2010making, AI\u2010enabled marketing, the Internet of Things (IoT) and marketing, natural language processing and customer service, robotic services, and chatbots. This study also emphasizes potential future research areas, building upon the established thematic clusters.", "isOpenAccess": false, "url": ""}
{"paperId": "050cdac1e7a87e66a997f128c8d831b9636b2f7c", "year": 2024, "title": "Enhancing Pre\u2010Service Teachers' Global Englishes Awareness with Technology: A\u00a0Focus on AI Chatbots in 3D Metaverse Environments", "authors": "Seongyong Lee, Jae-Bong Jeon, Hohsung Choe", "venue": "TESOL Quarterly (Print)", "citationCount": 40, "abstract": "Although Global Englishes (GE) research continues to grow in English language teaching (ELT), the role of technology in enhancing GE awareness remains underexplored. Addressing this gap, the study investigates the potential of English as a lingua franca (ELF) interactions with artificial intelligence (AI) chatbots in raising GE awareness. Using a quasi\u2010experimental design, 97 South Korean pre\u2010service English teachers were divided into a control group (CG, n\u2009=\u200932) and two experimental groups (EG1, n\u2009=\u200931; EG2, n\u2009=\u200934) for 16\u2010week teacher\u2010training courses. The CG received no GE instruction, while EG1 conducted a presentation task and EG2 interacted with AI chatbots in 3D metaverse environments. We used a mixed\u2010methods approach of pre\u2010 and post\u2010test surveys and interviews. ANCOVA results for survey data showed that both tasks had positive effects on all facets of GE awareness (e.g., acceptance of one's local English, acceptance of other Englishes, native\u2010speakerism, ELF confidence and intention, and willingness to incorporate GELT into teaching), with the AI chatbot task exerting a stronger effect on ELF confidence and intention. For practical implications, the findings outlined pedagogical strategies for integrating GELT into computer\u2010assisted (CA) language learning. Theoretically, we proposed the CA\u2010GELT approach for future research in the era of generative AI technology.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/tesq.3300"}
{"paperId": "f7c78ce85ffaf5c0ba01d0ceac4f9bbb5681ef96", "year": 2023, "title": "Digital Advertising in the Age of Generative AI", "authors": "T. Baek", "venue": "Journal of Current Issues &amp; Research in Advertising", "citationCount": 39, "abstract": "Abstract Artificial intelligence (AI) is significantly reshaping branded content delivery and consumer engagement in the advertising industry. Generative AI, exemplified by ChatGPT, is anticipated to have a substantial impact on all digital advertising domains worldwide. This special issue delves into the exploration of future trends in global digital advertising in the era of generative AI. The research articles within this special issue encompass a diverse array of topics, ranging from consumer responses to AI-generated virtual influencers in the metaverse and livestreaming e-commerce to the influence of anthropomorphic virtual agents, privacy concerns in online behavioral advertising, understanding of AI-driven ethnic affinity targeting, and the role of relational bonds within online gaming communities.", "isOpenAccess": false, "url": ""}
{"paperId": "f4f8725a534edd8c7fa4af0438f242945133012f", "year": 2023, "title": "Enhancing Kidney Transplant Care through the Integration of Chatbot", "authors": "Oscar A. Garcia Valencia, C. Thongprayoon, Caroline C. Jadlowiec, Shennen A. Mao, Jing Miao, W. Cheungpasitporn", "venue": "Healthcare", "citationCount": 39, "abstract": "Kidney transplantation is a critical treatment option for end-stage kidney disease patients, offering improved quality of life and increased survival rates. However, the complexities of kidney transplant care necessitate continuous advancements in decision making, patient communication, and operational efficiency. This article explores the potential integration of a sophisticated chatbot, an AI-powered conversational agent, to enhance kidney transplant practice and potentially improve patient outcomes. Chatbots and generative AI have shown promising applications in various domains, including healthcare, by simulating human-like interactions and generating contextually appropriate responses. Noteworthy AI models like ChatGPT by OpenAI, BingChat by Microsoft, and Bard AI by Google exhibit significant potential in supporting evidence-based research and healthcare decision making. The integration of chatbots in kidney transplant care may offer transformative possibilities. As a clinical decision support tool, it could provide healthcare professionals with real-time access to medical literature and guidelines, potentially enabling informed decision making and improved knowledge dissemination. Additionally, the chatbot has the potential to facilitate patient education by offering personalized and understandable information, addressing queries, and providing guidance on post-transplant care. Furthermore, under clinician or transplant pharmacist supervision, it has the potential to support post-transplant care and medication management by analyzing patient data, which may lead to tailored recommendations on dosages, monitoring schedules, and potential drug interactions. However, to fully ascertain its effectiveness and safety in these roles, further studies and validation are required. Its integration with existing clinical decision support systems may enhance risk stratification and treatment planning, contributing to more informed and efficient decision making in kidney transplant care. Given the importance of ethical considerations and bias mitigation in AI integration, future studies may evaluate long-term patient outcomes, cost-effectiveness, user experience, and the generalizability of chatbot recommendations. By addressing these factors and potentially leveraging AI capabilities, the integration of chatbots in kidney transplant care holds promise for potentially improving patient outcomes, enhancing decision making, and fostering the equitable and responsible use of AI in healthcare.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-9032/11/18/2518/pdf?version=1694500106"}
{"paperId": "e3a95550f68b975fbd3552fe7d7f95907cb7d6e7", "year": 2024, "title": "Opportunities and challenges of diffusion models for generative AI", "authors": "Minshuo Chen, Song Mei, Jianqing Fan, Mengdi Wang", "venue": "National Science Review", "citationCount": 39, "abstract": "ABSTRACT Diffusion models, a powerful and universal generative artificial intelligence technology, have achieved tremendous success and opened up new possibilities in diverse applications. In these applications, diffusion models provide flexible high-dimensional data modeling, and act as a sampler for generating new samples under active control towards task-desired properties. Despite the significant empirical success, theoretical underpinnings of diffusion models are very limited, potentially slowing down principled methodological innovations for further harnessing and improving diffusion models. In this paper, we review emerging applications of diffusion models to highlight their sample generation capabilities under various control goals. At the same time, we dive into the unique working flow of diffusion models through the lens of stochastic processes. We identify theoretical challenges in analyzing diffusion models, owing to their complicated training procedure and interaction with the underlying data distribution. To address these challenges, we overview several promising advances, demonstrating diffusion models as an efficient distribution learner and a sampler. Furthermore, we introduce a new avenue in high-dimensional structured optimization through diffusion models, where searching for solutions is reformulated as a conditional sampling problem and solved by diffusion models. Lastly, we discuss future directions about diffusion models. The purpose of this paper is to provide a well-rounded exposure for stimulating forward-looking theories and methods of diffusion models.", "isOpenAccess": true, "url": "https://doi.org/10.1093/nsr/nwae348"}
{"paperId": "aee0e8de10f74209c8eb20f1a924392ed67ec534", "year": 2024, "title": "An explanatory study of factors influencing engagement in AI education at the K-12 Level: an extension of the classic TAM model", "authors": "Wei Li, Xiaolin Zhang, Jing Li, Xiao Yang, Dong Li, Yantong Liu", "venue": "Scientific Reports", "citationCount": 39, "abstract": "Artificial intelligence (AI) holds immense promise for K-12 education, yet understanding the factors influencing students\u2019 engagement with AI courses remains a challenge. This study addresses this gap by extending the technology acceptance model (TAM) to incorporate cognitive factors such as AI intrinsic motivation (AIIM), AI readiness (AIRD), AI confidence (AICF), and AI anxiety (AIAX), alongside human\u2013computer interaction (HCI) elements like user interface (UI), content (C), and learner-interface interactivity (LINT) in the context of using generative AI (GenAI) tools. By including these factors, an expanded model is presented to capture the complexity of student engagement with AI education. To validate the model, 210 Chinese students spanning grades K7 to K9 participated in a 1 month artificial intelligence course. Survey data and structural equation modeling reveal significant relationships between cognitive and HCI factors and perceived usefulness (PU) and ease of use (PEOU). Specifically, AIIM, AIRD, AICF, UI, C, and LINT positively influence PU and PEOU, while AIAX negatively affects both. Furthermore, PU and PEOU significantly predict students\u2019 attitudes toward AI curriculum learning. These findings underscore the importance of considering cognitive and HCI factors in the design and implementation of AI education initiatives. By providing a theoretical foundation and practical insights, this study informs curriculum development and aids educational institutions and businesses in evaluating and optimizing AI4K12 curriculum design and implementation strategies.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41598-024-64363-3.pdf"}
{"paperId": "a3bc233050fd89bcfbdfd87f8bc7a4b935c2008e", "year": 2023, "title": "Auditing the inference processes of medical-image classifiers by leveraging generative AI and the expertise of physicians", "authors": "A. DeGrave, Z. Cai, Joseph D. Janizek, Roxana Daneshjou, Su-In Lee", "venue": "Nature Biomedical Engineering", "citationCount": 39, "abstract": null, "isOpenAccess": true, "url": "https://www.nature.com/articles/s41551-023-01160-9.pdf"}
{"paperId": "9ea6eba6a91516b854005fe64a2d7ca735a98dab", "year": 2024, "title": "Navigating the generative AI travel landscape: the influence of ChatGPT on the evolution from new users to loyal adopters", "authors": "Yu Li, Soyeun Olivia Lee", "venue": "International Journal of Contemporary Hospitality Management", "citationCount": 39, "abstract": "\nPurpose\nThis study, rooted in affordance-actualization theory and communication theory, aims to critically examine how ChatGPT influences users\u2019 transition from new adopters to loyal advocates within the context of travel decision-making. It incorporates constructs including communication quality, personalization, anthropomorphism, cognitive and emotional trust (ET), loyalty and intention to adopt into a comprehensive model.\n\n\nDesign/methodology/approach\nThis study used quantitative methods to analyze data from 477 respondents, collected online through a self-administered questionnaire by Embrain, a leading market research company in South Korea. Lavaan package within R studio was used for evaluating the measurement model through confirmatory factor analysis and using structural equation modeling to examine the proposed hypotheses.\n\n\nFindings\nThe findings reveal a pivotal need for enhancing ChatGPT\u2019s communication quality, particularly in terms of accuracy, currency and understandability. Personalization emerges as a key driver for cognitive trust, while anthropomorphism significantly impacts ET. Interestingly, the study unveils that in the context of travel recommendations, users\u2019 trust in ChatGPT predominantly operates at the cognitive level, significantly impacting loyalty and subsequent adoption intentions.\n\n\nPractical implications\nThe findings of this research provide valuable insights for improving Generative AI (GenAI) technology and management practices in travel recommendations.\n\n\nOriginality/value\nAs one of the few empirical research papers in the burgeoning field of GenAI, this study proposes a highly explanatory model for the process from affordance to actualization in the context of using ChatGPT for travel recommendations.\n", "isOpenAccess": false, "url": ""}
{"paperId": "96f94f9fdefe92be692e5461999d9a72c3a4e2b8", "year": 2024, "title": "The Challenges of Evaluating LLM Applications: An Analysis of Automated, Human, and LLM-Based Approaches", "authors": "Bhashithe Abeysinghe, Ruhan Circi", "venue": "LLM4Eval@SIGIR", "citationCount": 39, "abstract": "Chatbots have been an interesting application of natural language generation since its inception. With novel transformer based Generative AI methods, building chatbots have become trivial. Chatbots which are targeted at specific domains for example medicine and psychology are implemented rapidly. This however, should not distract from the need to evaluate the chatbot responses. Especially because the natural language generation community does not entirely agree upon how to effectively evaluate such applications. With this work we discuss the issue further with the increasingly popular LLM based evaluations and how they correlate with human evaluations. Additionally, we introduce a comprehensive factored evaluation mechanism that can be utilized in conjunction with both human and LLM-based evaluations. We present the results of an experimental evaluation conducted using this scheme in one of our chatbot implementations which consumed educational reports, and subsequently compare automated, traditional human evaluation, factored human evaluation, and factored LLM evaluation. Results show that factor based evaluation produces better insights on which aspects need to be improved in LLM applications and further strengthens the argument to use human evaluation in critical spaces where main functionality is not direct retrieval.", "isOpenAccess": false, "url": ""}
{"paperId": "9338d744bada15e5d5c66bf5eddb7d16dce9de56", "year": 2024, "title": "CaloChallenge 2022: a community challenge for fast calorimeter simulation", "authors": "Claudius Krause, M. F. Giannelli, G. Kasieczka, Benjamin Nachman, Dalila Salamani, David Shih, A. Zaborowska, O. Amram, Kerstin Borras, Matthew R. Buckley, E. Buhmann, Thorsten Buss, Renato Cardoso, Anthony L. Caterini, N. Chernyavskaya, F. A. Corchia, Jesse C. Cresswell, S. Diefenbacher, Etienne Dreyer, Vijay Ekambaram, Engin Eren, Florian Ernst, Luigi Favaro, M. Franchini, F. Gaede, Eilam Gross, Shih-Chieh Hsu, K. Jaruskova, Benno Kach, Jayant Kalagnanam, Raghav Kansal, Taewoo Kim, D. Kobylianskii, A. Korol, W. Korcari, D. Krucker, K. Kruger, M. Letizia, Shu Li, Qibin Liu, Xiulong Liu, G. Loaiza-Ganem, Thandikire Madula, Peter McKeown, I. Melzer-Pellmann, Vinicius Mikuni, Nam Nguyen, Ayodele Ore, Sofia Palacios Schweitzer, Ian Pang, Kevin Pedro, Tilman Plehn, W. Pokorski, Huilin Qu, Piyush Raikwar, J. Raine, H. Reyes-Gonz\u00e1lez, L. Rinaldi, Brendan Leigh Ross, M. Scham, S. Schnake, C. Shimmin, Eli Shlizerman, N. Soybelman, M. Srivatsa, Kalliopi Tsolaki, Sofia Vallecorsa, Kyongmin Yeo, Rui Zhang", "venue": "Reports on progress in physics. Physical Society", "citationCount": 39, "abstract": "We present the results of the \u2018Fast Calorimeter Simulation Challenge 2022\u2019\u2014the CaloChallenge. We study state-of-the-art generative models on four calorimeter shower datasets of increasing dimensionality, ranging from a few hundred voxels to a few tens of thousand voxels. The 31 individual submissions span a wide range of current popular generative architectures, including variational autoencoders (VAEs), generative adversarial networks (GANs), normalizing flows, diffusion models, and models based on conditional flow matching. We compare all submissions in terms of quality of generated calorimeter showers, as well as shower generation time and model size. To assess the quality we use a broad range of different metrics including differences in one-dimensional histograms of observables, KPD/FPD scores, AUCs of binary classifiers, and the log-posterior of a multiclass classifier. The results of the CaloChallenge provide the most complete and comprehensive survey of cutting-edge approaches to calorimeter fast simulation to date. In addition, our work provides a uniquely detailed perspective on the important problem of how to evaluate generative models. As such, the results presented here should be applicable for other domains that use generative AI and require fast and faithful generation of samples in a large phase space. Report Numbers: HEPHY-ML-24-05, FERMILAB-PUB-24-0728-CMS, TTK-24-43.", "isOpenAccess": false, "url": ""}
{"paperId": "8f92666f2008a120aaa988762623f15e2b1e2b75", "year": 2023, "title": "A Unified Framework for Guiding Generative AI With Wireless Perception in Resource Constrained Mobile Edge Networks", "authors": "Jiacheng Wang, Hongyang Du, Dusist Niyato, Jiawen Kang, Zehui Xiong, Deepu Rajan, Shiwen Mao, X. Shen", "venue": "IEEE Transactions on Mobile Computing", "citationCount": 39, "abstract": "With the significant advancements in artificial intelligence (AI) technologies and computational capabilities, generative AI (GAI) has become a pivotal digital content generation technique for offering superior digital services. However, due to the inherent instability of AI models, directing GAI towards the desired output remains a challenging task. Therefore, in this paper, we design a novel framework that utilizes wireless perception to guide GAI (WiPe-GAI) in delivering AI-generated content (AIGC) service, within resource-constrained mobile edge networks. Specifically, we first propose a new sequential multi-scale perception (SMSP) algorithm to predict user skeleton based on the channel state information (CSI) extracted from wireless signals. This prediction then guides GAI to provide users with AIGC, i.e., virtual character generation. To ensure the efficient operation of the proposed framework in resource constrained networks, we further design a pricing-based incentive mechanism and propose a diffusion model based approach to generate an optimal pricing strategy for the service provisioning. The strategy maximizes the user's utility while incentivizing the participation of the virtual service provider (VSP) in AIGC provision. The experimental results demonstrate the effectiveness of the designed framework in terms of skeleton prediction and optimal pricing strategy generation, outperforming other existing solutions.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2309.01426"}
{"paperId": "8f0a79ac0d2fb5289c51dc1e5d41f92a4d75dd60", "year": 2023, "title": "THE AUGMENTED DESIGNER: A RESEARCH AGENDA FOR GENERATIVE AI-ENABLED DESIGN", "authors": "K. Thoring, Sebastian Huettemann, Roland M. Mueller", "venue": "Proceedings of the Design Society", "citationCount": 39, "abstract": "Abstract Generative AI algorithms that are able to generate creative output are progressing at tremendous speed. This paper presents a research agenda for Generative AI-based support for designers. We present examples of existing applications and thus illustrate the possible application space of Generative AI reflecting the current state of this technology. Furthermore, we provide a theoretical foundation for AI-supported design, based on a typology of design knowledge and the concept of evolutionary creativity. Both concepts are discussed in relation to the changing roles of AI and the human designer. The outlined research agenda presents 10 research opportunities for possible AI-support to augment the designer of the future. The results presented in this paper provide researchers with an introduction to and overview of Generative AI, as well as the theoretical understanding of potential implications for the future of the design discipline.", "isOpenAccess": true, "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/1062E0AE820E79E6ACB886D08D5E247C/S2732527X23003358a.pdf/div-class-title-the-augmented-designer-a-research-agenda-for-generative-ai-enabled-design-div.pdf"}
{"paperId": "86307d23d25cefe451a53fd76ddbe5798b592c3b", "year": 2024, "title": "The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline", "authors": "Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, Kenji Kawaguchi", "venue": "International Conference on Machine Learning", "citationCount": 39, "abstract": "The commercialization of text-to-image diffusion models (DMs) brings forth potential copyright concerns. Despite numerous attempts to protect DMs from copyright issues, the vulnerabilities of these solutions are underexplored. In this study, we formalized the Copyright Infringement Attack on generative AI models and proposed a backdoor attack method, SilentBadDiffusion, to induce copyright infringement without requiring access to or control over training processes. Our method strategically embeds connections between pieces of copyrighted information and text references in poisoning data while carefully dispersing that information, making the poisoning data inconspicuous when integrated into a clean dataset. Our experiments show the stealth and efficacy of the poisoning data. When given specific text prompts, DMs trained with a poisoning ratio of 0.20% can produce copyrighted images. Additionally, the results reveal that the more sophisticated the DMs are, the easier the success of the attack becomes. These findings underline potential pitfalls in the prevailing copyright protection strategies and underscore the necessity for increased scrutiny to prevent the misuse of DMs.", "isOpenAccess": false, "url": ""}
{"paperId": "83892652ed726153203ed4e87cc03117c9f7aad0", "year": 2023, "title": "Chatbots, generative AI, and scholarly manuscripts: WAME recommendations on chatbots and generative artificial intelligence in relation to scholarly publications", "authors": "C. Zielinski, Margaret A Winker, Rakesh Aggarwal, Lorraine E Ferris, Markus Heinemann, J. F. Lape\u00f1a, Sanjay A. Pai, Edsel B. Ing, Leslie Citrome, Murad Alam, Michael Voight, F. Habibzadeh", "venue": "Colombia M\u00e9dica", "citationCount": 39, "abstract": "Abstract This statement revises our earlier \u201cWAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications\u201d (January 20, 2023). The revision reflects the proliferation of chatbots and their expanding use in scholarly publishing over the last few months, as well as emerging concerns regarding lack of authenticity of content when using chatbots. These recommendations are intended to inform editors and help them develop policies for the use of chatbots in papers published in their journals. They aim to help authors and reviewers understand how best to attribute the use of chatbots in their work and to address the need for all journal editors to have access to manuscript screening tools. In this rapidly evolving field, we will continue to modify these recommendations as the software and its applications develop.", "isOpenAccess": true, "url": "https://colombiamedica.univalle.edu.co/index.php/comedica/article/download/5868/5761"}
{"paperId": "761af20e7966e8a7d899975a332ac7eee3f92116", "year": 2023, "title": "How to Protect Copyright Data in Optimization of Large Language Models?", "authors": "T. Chu, Zhao Song, Chiwun Yang", "venue": "AAAI Conference on Artificial Intelligence", "citationCount": 39, "abstract": "Large language models (LLMs) and generative AI have played a transformative role in computer research and applications. Controversy has arisen as to whether these models output copyrighted data, which can occur if the data the models are trained on is copyrighted. LLMs are built on the transformer neural network architecture, which in turn relies on a mathematical computation called Attention that uses the softmax function.\n\nIn this paper, we observe that large language model training and optimization can be seen as a softmax regression problem. We then establish a method of efficiently performing softmax regression, in a way that prevents the regression function from generating copyright data. This establishes a theoretical method of training large language models in a way that avoids generating copyright data.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.12247"}
{"paperId": "6ff9e22615f12b031caa3ea582f1e28efa408f87", "year": 2024, "title": "Exploring generative AI literacy in higher education: student adoption, interaction, evaluation and ethical perceptions", "authors": "Kong Chen, April C. Tallant, Ian Selig", "venue": "Information and Learning Sciences", "citationCount": 39, "abstract": "Purpose\nCurrent knowledge and research on students\u2019 utilization and interaction with generative artificial intelligence (AI) tools in their academic work is limited. This study aims to investigate students\u2019 engagement with these tools.\n\nDesign/methodology/approach\nThis research used survey-based research to investigate generative AI literacy (utilization, interaction, evaluation of output and ethics) among students enrolled in a four-year public university in the southeastern USA. This article focuses on the respondents who have used generative AI (218; 47.2%).\n\nFindings\nMost respondents used generative AI to generate ideas for papers, projects or assignments, and they also used AI to assist with their original ideas. Despite their use of AI assistance, most students were critical of generative AI output, and this mindset was reflected in their reported interactions with ChatGPT. Respondents expressed a need for explicit guidance from course syllabi and university policies regarding generative AI\u2019s ethical and appropriate use.\n\nOriginality/value\nLiterature related to generative AI use in higher education specific to ChatGPT is predominantly from educators\u2019 viewpoints. This study provides empirical evidence about how university students report using generative AI in the context of generative AI literacy.\n", "isOpenAccess": false, "url": ""}
{"paperId": "6ce130e6684708e294cc09f09b23948d1f2623e9", "year": 2024, "title": "From Guidelines to Governance: A Study of AI Policies in Education", "authors": "Aashish Ghimire, John Edwards", "venue": "AIED Companion", "citationCount": 39, "abstract": "Emerging technologies like generative AI tools, including ChatGPT, are increasingly utilized in educational settings, offering innovative approaches to learning while simultaneously posing new challenges. This study employs a survey methodology to examine the policy landscape concerning these technologies, drawing insights from 102 high school principals and higher education provosts. Our results reveal a prominent policy gap: the majority of institutions lack specialized guide-lines for the ethical deployment of AI tools such as ChatGPT. Moreover,we observed that high schools are less inclined to work on policies than higher educational institutions. Where such policies do exist, they often overlook crucial issues, including student privacy and algorithmic transparency. Administrators overwhelmingly recognize the necessity of these policies, primarily to safeguard student safety and mitigate plagiarism risks. Our findings underscore the urgent need for flexible and iterative policy frameworks in educational contexts.", "isOpenAccess": false, "url": ""}
{"paperId": "5e16600a03b824911557e78f7d5521d5c3339cd9", "year": 2024, "title": "The Role of Generative AI in Software Development Productivity: A Pilot Case Study", "authors": "Mariana Coutinho, Lorena Marques, Anderson Santos, Marcio Dahia, C\u00e9sar Fran\u00e7a, Ronnie de Souza Santos", "venue": "AIware", "citationCount": 39, "abstract": "With software development increasingly reliant on innovative technologies, there is a growing interest in exploring the potential of generative AI tools to streamline processes and enhance productivity. In this scenario, this paper investigates the integration of generative AI tools within software development, focusing on understanding their uses, benefits, and challenges to software professionals, in particular, looking at aspects of productivity. Through a pilot case study involving software practitioners working in different roles, we gathered valuable experiences on the integration of generative AI tools into their daily work routines. Our findings reveal a generally positive perception of these tools in individual productivity while also highlighting the need to address identified limitations. Overall, our research sets the stage for further exploration into the evolving landscape of software development practices with the integration of generative AI tools.", "isOpenAccess": false, "url": ""}
{"paperId": "4c4af694c8242e177b5310848e8abfb5476e72d6", "year": 2023, "title": "The power of AI in marketing: enhancing efficiency and improving customer perception through AI-generated storyboards", "authors": "Atthawut Chaisatitkul, Kittikawin Luangngamkhum, Kanokthip Noulpum, C. Kerdvibulvech", "venue": "International journal of information technology", "citationCount": 39, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "31a1b96392c65a70ab944e276170c81fdffcc73b", "year": 2023, "title": "Generative Disco: Text-to-Video Generation for Music Visualization", "authors": "Vivian Liu, Tao Long, Nathan Raw, Lydia B. Chilton", "venue": "arXiv.org", "citationCount": 39, "abstract": "Visuals can enhance our experience of music, owing to the way they can amplify the emotions and messages conveyed within it. However, creating music visualization is a complex, time-consuming, and resource-intensive process. We introduce Generative Disco, a generative AI system that helps generate music visualizations with large language models and text-to-video generation. The system helps users visualize music in intervals by finding prompts to describe the images that intervals start and end on and interpolating between them to the beat of the music. We introduce design patterns for improving these generated videos: transitions, which express shifts in color, time, subject, or style, and holds, which help focus the video on subjects. A study with professionals showed that transitions and holds were a highly expressive framework that enabled them to build coherent visual narratives. We conclude on the generalizability of these patterns and the potential of generated video for creative professionals.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.08551"}
{"paperId": "2d240c3e7315348c0a6f5a2bc9d3af9cf23bae73", "year": 2024, "title": "Generative AI Prompt Engineering for Educators: Practical Strategies", "authors": "Jiyeon Park, Sam Choo", "venue": "Journal of Special Education Technology", "citationCount": 39, "abstract": "Generative AI, such as ChatGPT, produces personalized and contextually relevant content based on user prompts (inputs provided by users). These prompts act as the primary form of interaction between users and AI models, making their quality essential for generating the most relevant outputs. The process of writing, refining, and optimizing prompts, known as prompt engineering, is key to obtaining high-quality desired outputs from generative AI. For educators, proficiency in prompt engineering is crucial for effective interaction with AI as it enhances efficiency and produces the most relevant information. In this paper, we introduce practical strategies for prompt engineering for educators: (a) include essential components, including Persona, Aim, Recipients, Theme, and Structure (PARTS); (b) develop prompts using Concise, Logical, Explicit, Adaptive, and Restrictive (CLEAR) languages; (c) evaluate output and refine prompts: Rephrase key words, Experiment with context and examples, Feedback loop, Inquiry questions, Navigate by iterations, Evaluate and verify outputs (REFINE); and (d) apply with accountability. Examples for special educators and online resources are included.", "isOpenAccess": false, "url": ""}
{"paperId": "1ecd677e3d12bffec77d23db696610a7744cf33f", "year": 2023, "title": "WorldSmith: Iterative and Expressive Prompting for World Building with a Generative AI", "authors": "Hai Dang, Frederik Brudy, G. Fitzmaurice, Fraser Anderson", "venue": "ACM Symposium on User Interface Software and Technology", "citationCount": 39, "abstract": "Crafting a rich and unique environment is crucial for fictional world-building, but can be difficult to achieve since illustrating a world from scratch requires time and significant skill. We investigate the use of recent multi-modal image generation systems to enable users iteratively visualize and modify elements of their fictional world using a combination of text input, sketching, and region-based filling. WorldSmith enables novice world builders to quickly visualize a fictional world with layered edits and hierarchical compositions. Through a formative study (4 participants) and first-use study (13 participants) we demonstrate that WorldSmith offers more expressive interactions with prompt-based models. With this work, we explore how creatives can be empowered to leverage prompt-based generative AI as a tool in their creative process, beyond current \"click-once\" prompting UI paradigms.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2308.13355"}
{"paperId": "175cafff53721f65013ca00f15a7b625d31c705d", "year": 2025, "title": "Addressing bias in generative AI: Challenges and research opportunities in information management", "authors": "Xiahua Wei, Naveen Kumar, Han Zhang", "venue": "Information Manager (The)", "citationCount": 39, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "16b0d4b611d1385b5b542903dce7bb926e7b5c4e", "year": 2024, "title": "Bringing Generative AI to Adaptive Learning in Education", "authors": "Hang Li, Tianlong Xu, Chaoli Zhang, Eason Chen, Jing Liang, Xing Fan, Haoyang Li, Jiliang Tang, Qingsong Wen", "venue": "arXiv.org", "citationCount": 39, "abstract": "The recent surge in generative AI technologies, such as large language models and diffusion models, has boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next-stage learning format in education.", "isOpenAccess": false, "url": ""}
{"paperId": "0bd51f2f10fafc7aa6df56ad71a49bec68612753", "year": 2023, "title": "From principles to practices: the intertextual interaction between AI ethical and legal discourses", "authors": "Le Cheng, Xiuli Liu", "venue": "International Journal of Legal Discourse", "citationCount": 39, "abstract": "Abstract The ascendancy and ubiquity of generative AI technology, exemplified by ChatGPT, has resulted in a transformative shift in the conventional human\u2013AI interaction paradigm, leading to substantial alterations in societal modes of production. Drawing on CDA approach, this study conducts a thematic intertextuality analysis of 29 AI ethical documents, and delves into the restructuring of the human\u2013AI relations catalysed by ChatGPT, as well as the complex ethical and legal challenges it presents. The findings indicate that the thematic intertextuality between AI ethical discourse and legal discourse promotes the connection and convergence of narrative-ideological structures, which in turn primarily creates new meaningful texts and ethical frameworks that promote a holistic approach to a good AI society. This research also identifies the importance of integrating law-making efforts with substantive ethical analysis and appropriate discursive strategies to promote the responsible and ethical development of generative AI that benefits society as a whole.", "isOpenAccess": false, "url": ""}
{"paperId": "079bf0e285afd860ee47289c63c2a1fba7c3033f", "year": 2023, "title": "Generative Artificial Intelligence in Information Systems Education: Challenges, Consequences, and Responses", "authors": "C. V. Slyke, Richard D. Johnson, Jalal Sarabadani", "venue": "Communications of the Association for Information Systems", "citationCount": 39, "abstract": "ChatGPT, an interactive, generative artificial intelligence (AI) system, was introduced in late 2022, quickly becoming one of the most rapidly adopted technologies in history. The rapid emergence of ChatGPT and similar AI tools, such as Google\u2019s Bard, and GPT-enabled Bing from Microsoft have led to intense discussions about how they will affect various aspects of society, including higher education. Information systems (IS) education will not escape the impact of AI tools. Our goal for this paper is to develop a better understanding of the range of possible impacts of ChatGPT on IS education and to describe how IS educators might respond to these potential impacts. To that end, we discuss challenges for IS education brought on by generative AI tools, and discuss potential future scenarios based on the emergence of such tools, ranging from AI having little impact on IS education to AI serving as competition for IS educators. We examine the challenges and consequences of each scenario. We also discuss potential responses, ranging from doing nothing to embracing AI tools as legitimate learning aids. We then provide several specific recommendations that will allow IS educators to effectively respond to the rise of AI tools.", "isOpenAccess": false, "url": ""}
{"paperId": "fc15dd222e75743b909ea376e317e5fa2e22e6ab", "year": 2024, "title": "UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images", "authors": "Y. Qu, Xinyue Shen, Yixin Wu, Michael Backes, Savvas Zannettou, Yang Zhang", "venue": "Conference on Computer and Communications Security", "citationCount": 38, "abstract": "With the advent of text-to-image models and concerns about their misuse, developers are increasingly relying on image safety classifiers to moderate their generated unsafe images. Yet, the performance of current image safety classifiers remains unknown for both real-world and AI-generated images. In this work, we propose UnsafeBench, a benchmarking framework that evaluates the effectiveness and robustness of image safety classifiers, with a particular focus on the impact of AI-generated images on their performance. First, we curate a large dataset of 10K real-world and AI-generated images that are annotated as safe or unsafe based on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.). Then, we evaluate the effectiveness and robustness of five popular image safety classifiers, as well as three classifiers that are powered by general-purpose visual language models. Our assessment indicates that existing image safety classifiers are not comprehensive and effective enough to mitigate the multifaceted problem of unsafe images. Also, there exists a distribution shift between real-world and AI-generated images in image qualities, styles, and layouts, leading to degraded effectiveness and robustness. Motivated by these findings, we build a comprehensive image moderation tool called PerspectiveVision, which improves the effectiveness and robustness of existing classifiers, especially on AI-generated images. UnsafeBench and PerspectiveVision can aid the research community in better understanding the landscape of image safety classification in the era of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "e66b146cedfbc91e1362b6e4a6d6a994c459b14a", "year": 2024, "title": "Do Generative AI Models Output Harm while Representing Non-Western Cultures: Evidence from A Community-Centered Approach", "authors": "Sourojit Ghosh, Pranav Narayanan Venkit, Sanjana Gautam, Shomir Wilson, Aylin Caliskan", "venue": "AAAI/ACM Conference on AI, Ethics, and Society", "citationCount": 38, "abstract": "Our research investigates the impact of Generative Artificial Intelligence (GAI) models, specifically text-to-image generators (T2Is), on the representation of non-Western cultures, with a focus on Indian contexts. Despite the transformative potential of T2Is in content creation, concerns have arisen regarding biases that may lead to misrepresentations and marginalizations. Through a Non-Western community-centered approach\nand grounded theory analysis of 5 focus groups from diverse Indian subcultures, we explore how T2I outputs to English input prompts depict Indian culture and its subcultures, uncovering novel representational harms such as exoticism and cultural misappropriation. These findings highlight the urgent need for inclusive and culturally sensitive T2I systems. We propose design guidelines informed by a sociotechnical perspective, contributing to the development of more equitable and representative GAI technologies globally. Our work underscores the necessity of adopting a community-centered approach to comprehend the sociotechnical dynamics of these models, complementing existing work in this space while identifying and addressing the potential negative repercussions and harms that may arise as these models are deployed on a global scale.", "isOpenAccess": false, "url": ""}
{"paperId": "e0bdf73919ef9a9ad0322dcf248ea1ff45e7599f", "year": 2024, "title": "Frequency Masking for Universal Deepfake Detection", "authors": "Chandler Timm C. Doloriel, Ngai-Man Cheung", "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing", "citationCount": 38, "abstract": "We study universal deepfake detection. Our goal is to detect synthetic images from a range of generative AI approaches, particularly from emerging ones which are unseen during training of the deepfake detector. Universal deepfake detection requires outstanding generalization capability. Motivated by recently proposed masked image modeling which has demonstrated excellent generalization in self-supervised pre-training, we make the first attempt to explore masked image modeling for universal deepfake detection. We study spatial and frequency domain masking in training deepfake detectors. Based on empirical analysis, we propose a novel deepfake detector via frequency masking. Our focus on frequency domain is different from the majority, which primarily target spatial domain detection. Our comparative analyses reveal substantial performance gains over existing methods. Code and models are publicly available1.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2401.06506"}
{"paperId": "d8e4a1a3b8e2348d082a86bd71967660e00e136d", "year": 2024, "title": "The Use of Generative AI for Scientific Literature Searches for Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation", "authors": "Y. Gwon, Jae Heon Kim, Hyun Soo Chung, Eun Jee Jung, Joey Chun, Serin Lee, Sungryul Shim", "venue": "JMIR Medical Informatics", "citationCount": 38, "abstract": "Abstract Background A large language model is a type of artificial intelligence (AI) model that opens up great possibilities for health care practice, research, and education, although scholars have emphasized the need to proactively address the issue of unvalidated and inaccurate information regarding its use. One of the best-known large language models is ChatGPT (OpenAI). It is believed to be of great help to medical research, as it facilitates more efficient data set analysis, code generation, and literature review, allowing researchers to focus on experimental design as well as drug discovery and development. Objective This study aims to explore the potential of ChatGPT as a real-time literature search tool for systematic reviews and clinical decision support systems, to enhance their efficiency and accuracy in health care settings. Methods The search results of a published systematic review by human experts on the treatment of Peyronie disease were selected as a benchmark, and the literature search formula of the study was applied to ChatGPT and Microsoft Bing AI as a comparison to human researchers. Peyronie disease typically presents with discomfort, curvature, or deformity of the penis in association with palpable plaques and erectile dysfunction. To evaluate the quality of individual studies derived from AI answers, we created a structured rating system based on bibliographic information related to the publications. We classified its answers into 4 grades if the title existed: A, B, C, and F. No grade was given for a fake title or no answer. Results From ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant, whereas Bing AI resulted in 19 (40%) relevant studies out of 48, compared to the human benchmark of 24 studies. In the qualitative evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211 grade F studies, and Bing AI had 19 grade A and 28 grade C studies. Conclusions This is the first study to compare AI and conventional human systematic review methods as a real-time literature collection tool for evidence-based medicine. The results suggest that the use of ChatGPT as a tool for real-time evidence generation is not yet accurate and feasible. Therefore, researchers should be cautious about using such AI. The limitations of this study using the generative pre-trained transformer model are that the search for research topics was not diverse and that it did not prevent the hallucination of generative AI. However, this study will serve as a standard for future studies by providing an index to verify the reliability and consistency of generative AI from a user\u2019s point of view. If the reliability and consistency of AI literature search services are verified, then the use of these technologies will help medical research greatly.", "isOpenAccess": true, "url": "https://medinform.jmir.org/2024/1/e51187/PDF"}
{"paperId": "c9cf4dfdd07b3b93914e88d81948df4131d20607", "year": 2024, "title": "Prompt Engineering in Healthcare", "authors": "Rajvardhan Patil, T. F. Heston, Vijay Bhuse", "venue": "Electronics", "citationCount": 38, "abstract": "The rapid advancements in artificial intelligence, particularly generative AI and large language models, have unlocked new possibilities for revolutionizing healthcare delivery. However, harnessing the full potential of these technologies requires effective prompt engineering\u2014designing and optimizing input prompts to guide AI systems toward generating clinically relevant and accurate outputs. Despite the importance of prompt engineering, medical education has yet to fully incorporate comprehensive training on this critical skill, leading to a knowledge gap among medical clinicians. This article addresses this educational gap by providing an overview of generative AI prompt engineering, its potential applications in primary care medicine, and best practices for its effective implementation. The role of well-crafted prompts in eliciting accurate, relevant, and valuable responses from AI models is discussed, emphasizing the need for prompts grounded in medical knowledge and aligned with evidence-based guidelines. The article explores various applications of prompt engineering in primary care, including enhancing patient\u2013provider communication, streamlining clinical documentation, supporting medical education, and facilitating personalized care and shared decision-making. Incorporating domain-specific knowledge, engaging in iterative refinement and validation of prompts, and addressing ethical considerations and potential biases are highlighted. Embracing prompt engineering as a core competency in medical education will be crucial for successfully adopting and implementing AI technologies in primary care, ultimately leading to improved patient outcomes and enhanced healthcare delivery.", "isOpenAccess": true, "url": "https://www.mdpi.com/2079-9292/13/15/2961/pdf?version=1722009025"}
{"paperId": "c8e142c6ee5b8a044e406670e01d98f97a5d26bf", "year": 2023, "title": "Comparing the Efficacy and Efficiency of Human and Generative AI: Qualitative Thematic Analyses", "authors": "Maximo R. Prescott, S. Yeager, Lillian Ham, C. R. Rivera Saldana, Vanessa Serrano, J. Narez, D. Paltin, Jorge Delgado, David J Moore, Jessica Montoya", "venue": "JMIR AI", "citationCount": 38, "abstract": "Background Qualitative methods are incredibly beneficial to the dissemination and implementation of new digital health interventions; however, these methods can be time intensive and slow down dissemination when timely knowledge from the data sources is needed in ever-changing health systems. Recent advancements in generative artificial intelligence (GenAI) and their underlying large language models (LLMs) may provide a promising opportunity to expedite the qualitative analysis of textual data, but their efficacy and reliability remain unknown. Objective The primary objectives of our study were to evaluate the consistency in themes, reliability of coding, and time needed for inductive and deductive thematic analyses between GenAI (ie, ChatGPT and Bard) and human coders. Methods The qualitative data for this study consisted of 40 brief SMS text message reminder prompts used in a digital health intervention for promoting antiretroviral medication adherence among people with HIV who use methamphetamine. Inductive and deductive thematic analyses of these SMS text messages were conducted by 2 independent teams of human coders. An independent human analyst conducted analyses following both approaches using ChatGPT and Bard. The consistency in themes (or the extent to which the themes were the same) and reliability (or agreement in coding of themes) between methods were compared. Results The themes generated by GenAI (both ChatGPT and Bard) were consistent with 71% (5/7) of the themes identified by human analysts following inductive thematic analysis. The consistency in themes was lower between humans and GenAI following a deductive thematic analysis procedure (ChatGPT: 6/12, 50%; Bard: 7/12, 58%). The percentage agreement (or intercoder reliability) for these congruent themes between human coders and GenAI ranged from fair to moderate (ChatGPT, inductive: 31/66, 47%; ChatGPT, deductive: 22/59, 37%; Bard, inductive: 20/54, 37%; Bard, deductive: 21/58, 36%). In general, ChatGPT and Bard performed similarly to each other across both types of qualitative analyses in terms of consistency of themes (inductive: 6/6, 100%; deductive: 5/6, 83%) and reliability of coding (inductive: 23/62, 37%; deductive: 22/47, 47%). On average, GenAI required significantly less overall time than human coders when conducting qualitative analysis (20, SD 3.5 min vs 567, SD 106.5 min). Conclusions The promising consistency in the themes generated by human coders and GenAI suggests that these technologies hold promise in reducing the resource intensiveness of qualitative thematic analysis; however, the relatively lower reliability in coding between them suggests that hybrid approaches are necessary. Human coders appeared to be better than GenAI at identifying nuanced and interpretative themes. Future studies should consider how these powerful technologies can be best used in collaboration with human coders to improve the efficiency of qualitative research in hybrid approaches while also mitigating potential ethical risks that they may pose.", "isOpenAccess": true, "url": "https://doi.org/10.2196/54482"}
{"paperId": "c695768e83d4c70a3f496205e95f2f68c4ff3bdd", "year": 2024, "title": "Comparing the Ideation Quality of Humans With Generative Artificial Intelligence", "authors": "Jan Joosten, Volker Bilgram, Alexander Hahn, Dirk Totzek", "venue": "IEEE Engineering Management Review", "citationCount": 38, "abstract": "Traditionally, ideating new product innovations is primarily the responsibility of marketers, engineers, and designers. However, a rapidly growing interest lies in leveraging generative artificial intelligence (AI) to brainstorm new product and service ideas. This study conducts a comparative analysis of ideas generated by human professionals and an AI system. The results of a blind expert evaluation show that AI-generated ideas score significantly higher in novelty and customer benefit, while their feasibility scores are similar to those of human ideas. Overall, AI-generated ideas comprise the majority of the top-performing ideas, while human-generated ideas scored lower than expected. The executive's emotional and cognitive reactions were measured during the evaluation to check for potential biases and showed no differences between the idea groups. These findings suggest that, under certain circumstances, companies can benefit from integrating generative AI into their traditional idea-generation processes.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/46/8466592/10398283.pdf"}
{"paperId": "b773ad1556067b699375f3dcc6cdea67ceba4415", "year": 2023, "title": "Universal skepticism of ChatGPT: a review of early literature on chat generative pre-trained transformer", "authors": "C. Watters, Michal K. Lemanski", "venue": "Frontiers Big Data", "citationCount": 38, "abstract": "ChatGPT, a new language model developed by OpenAI, has garnered significant attention in various fields since its release. This literature review provides an overview of early ChatGPT literature across multiple disciplines, exploring its applications, limitations, and ethical considerations. The review encompasses Scopus-indexed publications from November 2022 to April 2023 and includes 156 articles related to ChatGPT. The findings reveal a predominance of negative sentiment across disciplines, though subject-specific attitudes must be considered. The review highlights the implications of ChatGPT in many fields including healthcare, raising concerns about employment opportunities and ethical considerations. While ChatGPT holds promise for improved communication, further research is needed to address its capabilities and limitations. This literature review provides insights into early research on ChatGPT, informing future investigations and practical applications of chatbot technology, as well as development and usage of generative AI.", "isOpenAccess": true, "url": "https://www.frontiersin.org/articles/10.3389/fdata.2023.1224976/pdf"}
{"paperId": "b349f3dd5b764168cba57bb4ad3fc240c2b3eddf", "year": 2023, "title": "Optimizing Mobile-Edge AI-Generated Everything (AIGX) Services by Prompt Engineering: Fundamental, Framework, and Case Study", "authors": "Yinqiu Liu, Hongyang Du, D. Niyato, Jiawen Kang, Shuguang Cui, Xuemin Shen, Ping Zhang", "venue": "IEEE Network", "citationCount": 38, "abstract": "As the next-generation paradigm for content creation, AI-Generated Content (AIGC), i.e., generating content automatically by Generative AI (GAI) based on user prompts, has gained great attention and success recently. With the ever-increasing power of GAI, especially the emergence of Pretrained Foundation Models (PFMs) that contain billions of parameters and prompt engineering methods (i.e., finding the best prompts for the given task), the application range of AIGC is rapidly expanding, covering various forms of information for human, systems, and networks, such as network designs, channel coding, and optimization solutions. In this article, we present the concept of mobile-edge AI-Generated Everything (AIGX). Specifically, we first review the building blocks of AIGX, the evolution from AIGC to AIGX, as well as practical AIGX applications. Then, we present a unified mobile-edge AIGX framework, which employs edge devices to provide PFM-empowered AIGX services and optimizes such services via prompt engineering. More importantly, we demonstrate that suboptimal prompts lead to poor generation quality, which adversely affects user satisfaction, edge network performance, and resource utilization. Accordingly, we conduct a case study, showcasing how to train an effective prompt optimizer using ChatGPT and investigating how much improvement is possible with prompt engineering in terms of user experience, quality of generation, and network performance.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.01065"}
{"paperId": "a2fe4822e7b6612b5a8bbd693492c12bbf95286a", "year": 2023, "title": "Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment", "authors": "M. Richards, Kevin Waugh, Mark Slaymaker, Marian Petre, John Woodthorpe, Daniel Gooch", "venue": "ACM Transactions on Computing Education", "citationCount": 38, "abstract": "Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate. We ran a dual-anonymous \u201cquality assurance\u201d marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (>40%), with all of the introductory module CS1 scripts receiving a distinction (>85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (>50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3633287"}
{"paperId": "90651de2fcdae42c0d00b04ebcfa0a8544d18d3b", "year": 2025, "title": "Generative AI and Academic Integrity in Higher Education: A Systematic Review and Research Agenda", "authors": "Kyle Bittle, Omar El-Gayar", "venue": "Information", "citationCount": 38, "abstract": "This systematic literature review rigorously evaluates the impact of Generative AI (GenAI) on academic integrity within higher education settings. The primary objective is to synthesize how GenAI technologies influence student behavior and academic honesty, assessing the benefits and risks associated with their integration. We defined clear inclusion and exclusion criteria, focusing on studies explicitly discussing GenAI\u2019s role in higher education from January 2021 to December 2024. Databases included ABI/INFORM, ACM Digital Library, IEEE Xplore, and JSTOR, with the last search conducted in May 2024. A total of 41 studies met our precise inclusion criteria. Our synthesis methods involved qualitative analysis to identify common themes and quantify trends where applicable. The results indicate that while GenAI can enhance educational engagement and efficiency, it also poses significant risks of academic dishonesty. We critically assessed the risk of bias in included studies and noted a limitation in the diversity of databases, which might have restricted the breadth of perspectives. Key implications suggest enhancing digital literacy and developing robust detection tools to effectively manage GenAI\u2019s dual impacts. No external funding was received for this review. Future research should expand database sources and include more diverse study designs to overcome current limitations and refine policy recommendations.", "isOpenAccess": false, "url": ""}
{"paperId": "8410c395158096bc734d0b712c8546d775995e33", "year": 2023, "title": "Developing Medical Education Curriculum Reform Strategies to Address the Impact of Generative AI: Qualitative Study", "authors": "I. Shimizu, H. Kasai, K. Shikino, Nobuyuki Araki, Zaiya Takahashi, Misaki Onodera, Yasuhiko Kimura, T. Tsukamoto, Kazuyo Yamauchi, Mayumi Asahina, Shoichi Ito, Eiryo Kawakami", "venue": "JMIR Medical Education", "citationCount": 38, "abstract": "Background Generative artificial intelligence (GAI), represented by large language models, have the potential to transform health care and medical education. In particular, GAI\u2019s impact on higher education has the potential to change students\u2019 learning experience as well as faculty\u2019s teaching. However, concerns have been raised about ethical consideration and decreased reliability of the existing examinations. Furthermore, in medical education, curriculum reform is required to adapt to the revolutionary changes brought about by the integration of GAI into medical practice and research. Objective This study analyzes the impact of GAI on medical education curricula and explores strategies for adaptation. Methods The study was conducted in the context of faculty development at a medical school in Japan. A workshop involving faculty and students was organized, and participants were divided into groups to address two research questions: (1) How does GAI affect undergraduate medical education curricula? and (2) How should medical school curricula be reformed to address the impact of GAI? The strength, weakness, opportunity, and threat (SWOT) framework was used, and cross-SWOT matrix analysis was used to devise strategies. Further, 4 researchers conducted content analysis on the data generated during the workshop discussions. Results The data were collected from 8 groups comprising 55 participants. Further, 5 themes about the impact of GAI on medical education curricula emerged: improvement of teaching and learning, improved access to information, inhibition of existing learning processes, problems in GAI, and changes in physicians\u2019 professionality. Positive impacts included enhanced teaching and learning efficiency and improved access to information, whereas negative impacts included concerns about reduced independent thinking and the adaptability of existing assessment methods. Further, GAI was perceived to change the nature of physicians\u2019 expertise. Three themes emerged from the cross-SWOT analysis for curriculum reform: (1) learning about GAI, (2) learning with GAI, and (3) learning aside from GAI. Participants recommended incorporating GAI literacy, ethical considerations, and compliance into the curriculum. Learning with GAI involved improving learning efficiency, supporting information gathering and dissemination, and facilitating patient involvement. Learning aside from GAI emphasized maintaining GAI-free learning processes, fostering higher cognitive domains of learning, and introducing more communication exercises. Conclusions This study highlights the profound impact of GAI on medical education curricula and provides insights into curriculum reform strategies. Participants recognized the need for GAI literacy, ethical education, and adaptive learning. Further, GAI was recognized as a tool that can enhance efficiency and involve patients in education. The study also suggests that medical education should focus on competencies that GAI hardly replaces, such as clinical experience and communication. Notably, involving both faculty and students in curriculum reform discussions fosters a sense of ownership and ensures broader perspectives are encompassed.", "isOpenAccess": true, "url": "https://doi.org/10.2196/53466"}
{"paperId": "70f979dc1022b94cead18236aa40077eea5500b7", "year": 2024, "title": "EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism", "authors": "Yilin Tang, Liuqing Chen, Ziyu Chen, Wenkai Chen, Yu Cai, Yao Du, Fan Yang, Lingyun Sun", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 38, "abstract": "Children with high-functioning autism (HFA) often face challenges in emotional recognition and expression, leading to emotional distress and social difficulties. Conversational agents developed for HFA children in previous studies show limitations in children's learning effectiveness due to the conversational agents\u2019 inability to dynamically generate personalized and contextual content. Recent advanced generative Artificial Intelligence techniques, with the capability to generate substantial diverse and high-quality texts and visual content, offer an opportunity for personalized assistance in emotional learning for HFA children. Based on the findings of our formative study, we integrated large language models and text-to-image models to develop a tool named EmoEden supporting children with HFA. Over a 22-day study involving six HFA children, it is observed that EmoEden effectively engaged children and improved their emotional recognition and expression abilities. Additionally, we identified the advantages and potential risks of applying generative AI to assist HFA children in emotional learning.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642899"}
{"paperId": "5f22cb4379f76d3045e22fa53bee0c52d0d392ad", "year": 2025, "title": "Artificial intelligence-assisted academic writing: recommendations for ethical use", "authors": "Adam Cheng, Aaron Calhoun, Gabriel Reedy", "venue": "Advances in Simulation", "citationCount": 38, "abstract": "Generative artificial intelligence (AI) tools have been selectively adopted across the academic community to help researchers complete tasks in a more efficient manner. The widespread release of the Chat Generative Pre-trained Transformer (ChatGPT) platform in 2022 has made these tools more accessible to scholars around the world. Despite their tremendous potential, studies have uncovered that large language model (LLM)-based generative AI tools have issues with plagiarism, AI hallucinations, and inaccurate or fabricated references. This raises legitimate concern about the utility, accuracy, and integrity of AI when used to write academic manuscripts. Currently, there is little clear guidance for healthcare simulation scholars outlining the ways that generative AI could be used to legitimately support the production of academic literature. In this paper, we discuss how widely available, LLM-powered generative AI tools (e.g. ChatGPT) can help in the academic writing process. We first explore how academic publishers are positioning the use of generative AI tools and then describe potential issues with using these tools in the academic writing process. Finally, we discuss three categories of specific ways generative AI tools can be used in an ethically sound manner and offer four key principles that can help guide researchers to produce high-quality research outputs with the highest of academic integrity.", "isOpenAccess": true, "url": "https://doi.org/10.1186/s41077-025-00350-6"}
{"paperId": "579429e5ad7e83ba55bbb7d7b37781b926332b1f", "year": 2024, "title": "Generative AI for pentesting: the good, the bad, the ugly", "authors": "Eric Hilario, S. Azam, Jawahar Sundaram, K. Mohammed, Bharanidharan Shanmugam", "venue": "International Journal of Information Security", "citationCount": 38, "abstract": "This paper examines the role of Generative AI (GenAI) and Large Language Models (LLMs) in penetration testing exploring the benefits, challenges, and risks associated with cyber security applications. Through the use of generative artificial intelligence, penetration testing becomes more creative, test environments are customised, and continuous learning and adaptation is achieved. We examined how GenAI (ChatGPT 3.5) helps penetration testers with options and suggestions during the five stages of penetration testing. The effectiveness of the GenAI tool was tested using a publicly available vulnerable machine from VulnHub. It was amazing how quickly they responded at each stage and provided better pentesting report. In this article, we discuss potential risks, unintended consequences, and uncontrolled AI development associated with pentesting.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10207-024-00835-x.pdf"}
{"paperId": "571cccb568cd47b0c8646c5b8af14e76212c5915", "year": 2025, "title": "Human-AI agency in the age of generative AI", "authors": "Sebastian Krakowski", "venue": "Information and organization", "citationCount": 38, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "4f09c369bf272a887d5da8df11f34aa3790296ec", "year": 2024, "title": "Exploring the Role of Generative AI in Enhancing Language Learning: Opportunities and Challenges", "authors": "Edwin Creely", "venue": "International Journal of Changes in Education", "citationCount": 38, "abstract": "Contemporary advances in generative AI technology have sparked considerable interest regarding its application in language education. This article explores the innovative impact that AI-powered linguistic educational tools may have, such as customised learning journeys, dynamic content, and individualised feedback mechanisms, which collectively have the potential to enhance language acquisition and literacy. At the same time, it is important to recognise the constraints associated with such technologies in the educational sphere. Concern about maintaining precision and genuineness within AI-crafted language texts is a concern in the literature. There is also caution about AI's current inclination to standardise language expression and to propagate limited cultural narratives, alongside the risks of over-reliance on technology which may diminish analytical thought and inventiveness. This article examines the ethical considerations involving generative AI, such as the authenticity of creative work and the ownership of intellectual output. Emphasising the necessity for clarity and conscientious in the application of AI, this conceptual article outlines the opportunities, limitations and ethical concerns associated with generative AI in language instruction. The core message of the article advocates for a well-rounded strategy that leverages the positive aspects of generative AI within language education, while also addressing possible drawbacks and championing an ethical and equitable approach to language learning in the emerging AI-centric digital landscape. A model for forging thinking in this new research and practice space is designed to synthesise many of the possibilities of generative AI in language education.", "isOpenAccess": true, "url": "https://ojs.bonviewpress.com/index.php/IJCE/article/download/2495/886"}
{"paperId": "449b262c50f8f504a5ff868e002589acf3864383", "year": 2024, "title": "Perceived impact of generative AI on assessments: Comparing educator and student perspectives in Australia, Cyprus, and the United States", "authors": "Ren\u00e9 F. Kizilcec, Elaine Huber, Elena C. Papanastasiou, Andrew Cram, Christos A. Makridis, Adele Smolansky, S. Zeivots, Corina Raduescu", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 38, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100269"}
{"paperId": "3cc2b0cb69454d75f65ccc3c7d3b56ceb7a1b498", "year": 2024, "title": "Towards Optimizing the Costs of LLM Usage", "authors": "Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena, Atharv Tyagi, Nishanth Kotla", "venue": "arXiv.org", "citationCount": 38, "abstract": "Generative AI and LLMs in particular are heavily used nowadays for various document processing tasks such as question answering and summarization. However, different LLMs come with different capabilities for different tasks as well as with different costs, tokenization, and latency. In fact, enterprises are already incurring huge costs of operating or using LLMs for their respective use cases. In this work, we propose optimizing the usage costs of LLMs by estimating their output quality (without actually invoking the LLMs), and then solving an optimization routine for the LLM selection to either keep costs under a budget, or minimize the costs, in a quality and latency aware manner. We propose a model to predict the output quality of LLMs on document processing tasks like summarization, followed by an LP rounding algorithm to optimize the selection of LLMs. We study optimization problems trading off the quality and costs, both theoretically and empirically. We further propose a sentence simplification model for reducing the number of tokens in a controlled manner. Additionally, we propose several deterministic heuristics for reducing tokens in a quality aware manner, and study the related optimization problem of applying the heuristics optimizing the quality and cost trade-off. We perform extensive empirical validation of our methods on not only enterprise datasets but also on open-source datasets, annotated by us, and show that we perform much better compared to closest baselines. Our methods reduce costs by 40%- 90% while improving quality by 4%-7%. We will release the annotated open source datasets to the community for further research and exploration.", "isOpenAccess": false, "url": ""}
{"paperId": "2fff285ab3d532223000809711661c07d369149b", "year": 2024, "title": "Ethics and AI-Plagiarism in an Academic Environment: Students\u2019 Understanding of Compliance with Author\u2019s Ethics and the Problem of Plagiarism in the Process of Interaction with Generative Artificial Intelligence", "authors": "P. Sysoyev", "venue": "Vysshee Obrazovanie v Rossii  = Higher Education in Russia", "citationCount": 38, "abstract": "Everyday, artificial intelligence (AI) is being increasingly integrated into the teaching and learning process at Russian universities. The high level of quality of feedback from AI tools leads to the spread of AI plagiarism \u2013 unauthorized borrowing of generative AI materials \u2013 among students. The purpose of this study is to: a) highlight aspects that determine students\u2019 understanding of the issues of compliance with author\u2019s ethics and the problem of plagiarism when interacting with generative AI; b) develop a questionnaire to determine students\u2019 understanding of the issues of compliance with author\u2019s ethics and the problem of AI plagiarism; c) conduct an online survey of university students, analyze and discuss the results obtained. The paper highlights five aspects that determine students\u2019 understanding of the issues of compliance with author\u2019s ethics and the problem of AI plagiarism when completing educational assignments and preparing research texts: a) students\u2019 general understanding of the issues of compliance with author\u2019s ethics and the problem of plagiarism in an academic environment; b) students\u2019 experience of AI tools for educational purposes; c) students\u2019 understanding of the problem of AI plagiarism and attitude towards borrowing materials from generative AI; d) teachers\u2019 actions to prevent AI plagiarism among students; e) the policy of educational organizations regarding student compliance with ethics and AI plagiarism. An online questionnaire was developed to determine the degree to which students understand the issues of compliance with copyright ethics and the problem of AI plagiarism. 1,599 students from 29 universities of the Russian Federation took part in the survey. The results showed that in general, in the Russian student community, plagiarism is a widespread social phenomenon, many types of which are perceived by young people as a norm of academic behavior. Despite the relatively high awareness of students in the field of AI technologies, the extremely rare use by teachers of specialized subject disciplines of AI tools in the educational process I\u2019d the reason for the current low level of spread of AI plagiarism in the academic environment. At the same time, it is necessary to state that students lack a systematic understanding of exactly how they can \u201clegally\u201d use generative AI materials and what exactly will be considered AI plagiarism. According to students, the importance of understanding the issues of compliance with author ethics and the problem of AI plagiarism will depend, on the one hand, on the actions of teachers to explain to students the rules for using generative AI materials, and on the other hand, the presence in universities of a regulatory framework regulating the field and the extent to which students use AI in the educational process.", "isOpenAccess": true, "url": "https://vovr.elpub.ru/jour/article/download/4804/2335"}
{"paperId": "2b304045ef9bbf899f3cd28ca3e659ff3c3df430", "year": 2023, "title": "RatGPT: Turning online LLMs into Proxies for Malware Attacks", "authors": "Mika Beckerich, L. Plein, Sergio Coronado", "venue": "arXiv.org", "citationCount": 38, "abstract": "The evolution of Generative AI and the capabilities of the newly released Large Language Models (LLMs) open new opportunities in software engineering. However, they also lead to new challenges in cybersecurity. Recently, researchers have shown the possibilities of using LLMs such as ChatGPT to generate malicious content that can directly be exploited or guide inexperienced hackers to weaponize tools and code. These studies covered scenarios that still require the attacker to be in the middle of the loop. In this study, we leverage openly available plugins and use an LLM as proxy between the attacker and the victim. We deliver a proof-of-concept where ChatGPT is used for the dissemination of malicious software while evading detection, alongside establishing the communication to a command and control (C2) server to receive commands to interact with a victim's system. Finally, we present the general approach as well as essential elements in order to stay undetected and make the attack a success. This proof-of-concept highlights significant cybersecurity issues with openly available plugins and LLMs, which require the development of security guidelines, controls, and mitigation strategies.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.09183"}
{"paperId": "1b937b3a6ce257a243bc1e1f44f4d1ef4cf79c8d", "year": 2024, "title": "Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks", "authors": "Zonghao Ying, Aishan Liu, Xianglong Liu, Dacheng Tao", "venue": "arXiv.org", "citationCount": 38, "abstract": "The recent release of GPT-4o has garnered widespread attention due to its powerful general capabilities. While its impressive performance is widely acknowledged, its safety aspects have not been sufficiently explored. Given the potential societal impact of risky content generated by advanced generative AI such as GPT-4o, it is crucial to rigorously evaluate its safety. In response to this question, this paper for the first time conducts a rigorous evaluation of GPT-4o against jailbreak attacks. Specifically, this paper adopts a series of multi-modal and uni-modal jailbreak attacks on 4 commonly used benchmarks encompassing three modalities (ie, text, speech, and image), which involves the optimization of over 4,000 initial text queries and the analysis and statistical evaluation of nearly 8,000+ response on GPT-4o. Our extensive experiments reveal several novel observations: (1) In contrast to the previous version (such as GPT-4V), GPT-4o has enhanced safety in the context of text modality jailbreak; (2) The newly introduced audio modality opens up new attack vectors for jailbreak attacks on GPT-4o; (3) Existing black-box multimodal jailbreak attack methods are largely ineffective against GPT-4o and GPT-4V. These findings provide critical insights into the safety implications of GPT-4o and underscore the need for robust alignment guardrails in large models. Our code is available at \\url{https://github.com/NY1024/Jailbreak_GPT4o}.", "isOpenAccess": false, "url": ""}
{"paperId": "18fa9fb12c4dbaccf5781fd9cab8cd616a2bdd10", "year": 2024, "title": "The Impact of Artificial Intelligence on Education", "authors": "Isa Erba\u015f, Eduina Maksuti", "venue": "International Journal of Innovative Research in Multidisciplinary Education", "citationCount": 38, "abstract": "Artificial Intelligence (AI) is an increasingly progressive field that aims to develop computer systems capable of producing inventive and creative content, including text, images, music, video, and audio, that closely resemble human-generated material. AI has significantly impacted education, with both positive and negative implications. While it has gained widespread popularity, it has also raised concerns about bias, misinformation, misuse, and risk, emphasising the need for the responsible implementation and development of generative AI in education. There have been discussions about whether it should be prohibited or whether teachers and students should receive adequate training to use it effectively and ethically. The purpose of AI in education should be to embrace the opportunities it presents while maintaining high academic standards. Renowned universities have developed guidelines and manuals for the responsible use of generative AI tools. This study examines the impact of generative AI on education, analysing its advantages and disadvantages in schools, its outcomes, and how teachers and students can use it for educational purposes. The study also emphasizes the effective use of AI in education, employing qualitative and quantitative methods to evaluate its usage. The results highlight the benefits and drawbacks of generative AI in education, concluding with recommendations and future applications of generative AI in education.", "isOpenAccess": true, "url": "https://ijirme.com/v3i4/Doc/1.pdf"}
{"paperId": "0c335e29e3c1b16491e54e70aaafe59ed1fbd253", "year": 2023, "title": "Factors Influencing the Adoption of Generative AI for Art Designing Among Chinese Generation Z: A Structural Equation Modeling Approach", "authors": "Yiyang Wang, Weining Zhang", "venue": "IEEE Access", "citationCount": 38, "abstract": "The integration of generative artificial intelligence (GenAI) technology in the realm of art and design has demonstrated significant positive effects on designers and related industries. The current study aimed to explore and evaluate the factors and personal traits that drive Generation Z to embrace GenAI-assisted design. The study model incorporated factors derived from the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2), the Technology Readiness Index, and the concept of trait curiosity. Empirical validation was conducted using data collected from 326 participants in the southeast of Chinese Mainland. The results of structural equation modeling indicated that: 1) Factors such as effort expectancy, price value, and hedonic motivation from UTAUT2 have a positive influence on the intention to use GenAI, while performance expectancy does not show a statistically significant effect. 2) Both optimism and creativity significantly contribute to performance expectancy, effort expectancy, price value, and hedonic motivation. 3) Trait curiosity has a significant positive impact on both optimism and the intention to use GenAI. The research findings suggest the need for further improvements in the construction and operational strategies of GenAI platforms and provide practical insights for enhancing Generation Z\u2019s intention to utilize such platforms.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10354296.pdf"}
{"paperId": "ed9ac39ff084fedf916380ab19b472bb683c580c", "year": 2024, "title": "Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry", "authors": "Leda Tortora", "venue": "Frontiers in Psychiatry", "citationCount": 37, "abstract": "The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.", "isOpenAccess": true, "url": "https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2024.1346059/pdf"}
{"paperId": "e6ab89d86c2f3201a0f5371b13f9c002973f2aac", "year": 2024, "title": "Artificial intelligence and medical education: application in classroom instruction and student assessment using a pharmacology & therapeutics case study", "authors": "K. Sridharan, Reginald P Sequeira", "venue": "BMC Medical Education", "citationCount": 37, "abstract": "Artificial intelligence (AI) tools are designed to create or generate content from their trained parameters using an online conversational interface. AI has opened new avenues in redefining the role boundaries of teachers and learners and has the potential to impact the teaching-learning process. In this descriptive proof-of- concept cross-sectional study we have explored the application of three generative AI tools on drug treatment of hypertension theme to generate: (1) specific learning outcomes (SLOs); (2) test items (MCQs- A type and case cluster; SAQs; OSPE); (3) test standard-setting parameters for medical students. Analysis of AI-generated output showed profound homology but divergence in quality and responsiveness to refining search queries. The SLOs identified key domains of antihypertensive pharmacology and therapeutics relevant to stages of the medical program, stated with appropriate action verbs as per Bloom\u2019s taxonomy. Test items often had clinical vignettes aligned with the key domain stated in search queries. Some test items related to A-type MCQs had construction defects, multiple correct answers, and dubious appropriateness to the learner\u2019s stage. ChatGPT generated explanations for test items, this enhancing usefulness to support self-study by learners. Integrated case-cluster items had focused clinical case description vignettes, integration across disciplines, and targeted higher levels of competencies. The response of AI tools on standard-setting varied. Individual questions for each SAQ clinical scenario were mostly open-ended. The AI-generated OSPE test items were appropriate for the learner\u2019s stage and identified relevant pharmacotherapeutic issues. The model answers supplied for both SAQs and OSPEs can aid course instructors in planning classroom lessons, identifying suitable instructional methods, establishing rubrics for grading, and for learners as a study guide. Key lessons learnt for improving AI-generated test item quality are outlined. AI tools are useful adjuncts to plan instructional methods, identify themes for test blueprinting, generate test items, and guide test standard-setting appropriate to learners\u2019 stage in the medical program. However, experts need to review the content validity of AI-generated output. We expect AIs to influence the medical education landscape to empower learners, and to align competencies with curriculum implementation. AI literacy is an essential competency for health professionals.", "isOpenAccess": true, "url": "https://bmcmededuc.biomedcentral.com/counter/pdf/10.1186/s12909-024-05365-7"}
{"paperId": "e35689c63dd63eb71991d6d2971f337de48198fc", "year": 2024, "title": "Revolutionizing Visuals: The Role of Generative AI in Modern Image Generation", "authors": "Gaurang Bansal, Aditya Nawal, V. Chamola, N. Herencsar", "venue": "ACM Trans. Multim. Comput. Commun. Appl.", "citationCount": 37, "abstract": "Traditional multimedia experiences are undergoing a transformation as generative AI integration fosters enhanced creative workflows, streamlines content creation processes, and unlocks the potential for entirely new forms of multimedia storytelling. It has potential to generate captivating visuals to accompany a documentary based solely on historical text descriptions, or creating personalized and interactive multimedia experiences tailored to individual user preferences. From the high-resolution cameras in our smartphones to the immersive experiences offered by the latest technologies, the impact of generative imaging undeniable. This study delves into the burgeoning field of generative AI, with a focus on its revolutionary impact on image generation. It explores the background of traditional imaging in consumer electronics and the motivations for integrating AI, leading to enhanced capabilities in various applications. The research critically examines current advancements in state-of-the-art technologies like DALL-E 2, Craiyon, Stable Diffusion, Imagen, Jasper, NightCafe, and Deep AI, assessing their performance on parameters such as image quality, diversity, and efficiency. It also addresses the limitations and ethical challenges posed by this integration, balancing creative autonomy with AI automation. The novelty of this work lies in its comprehensive analysis and comparison of these AI systems, providing insightful results that highlight both their strengths and areas for improvement. The conclusion underscores the transformative potential of generative AI in image generation, paving the way for future research and development to further enhance and refine these technologies. This article serves as a critical guide for understanding the current landscape and future prospects of AI-driven image creation, offering a glimpse into the evolving synergy between human creativity and artificial intelligence.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3689641"}
{"paperId": "dcb03ea50c08e7c378f22c0304c092da66525a0c", "year": 2024, "title": "Generative AI insights in tourism and hospitality: A comprehensive review and strategic research roadmap", "authors": "A. Fouad, I. Salem, E. Fathy", "venue": "Tourism and Hospitality Research", "citationCount": 37, "abstract": "This study used bibliometric analysis and a systematic literature review (SLR) to examine how the tourism and hospitality industries use generative artificial intelligence (GAI), identifying developed patterns, theoretical frameworks, strengths and limitations, and future research challenges. We conducted a systematic review using the Scopus database, adhering to PRISMA principles. We analyzed a sample of 25 articles published between 2019 and 2023 through narrative synthesis and bibliometric analysis using the VOSviewer software, a tool for visualizing network analysis. The USA, China, India, and Saudi Arabia are the major countries engaged in GAI research in tourism and hospitality. Significant research topics emphasize decision-making, chatbots, deep learning, and sentiment analysis, mainly through the Technology Acceptance Model (TAM), Stimulus-Organism-Response (S-O-R), and Human-Computer Interaction (HCI) frameworks. GAI applications demonstrate strength in improving user experience and operational efficiency, though gaps exist in scope, ethics, technology performance, and collaboration between humans and AI. This study, therefore, provides a fundamental foundation for understanding the current status of GAI research in tourism and hospitality by pointing out some trends and areas that require further investigation to ensure the responsible and effective integration of AI within the industry.", "isOpenAccess": false, "url": ""}
{"paperId": "dabe1fcf7e8c6a0ec075890347f73d06b79290d8", "year": 2024, "title": "The influence of GenAI on the effectiveness of argumentative writing in higher education: evidence from a quasi-experimental study in China", "authors": "Hanlin Li, Yu Wang, Siqi Luo, Cui Huang", "venue": "Journal of Asian Public Policy", "citationCount": 37, "abstract": "ABSTRACT The revolutionary development of generative artificial intelligence, especially large language model (LLM) chatbots like ChatGPT, has brought disruptive changes to society, especially in the field of higher education, particularly in the domain of writing. Prior studies have primarily examined the opportunities and challenges that LLM Chatbots bring to higher education writing from a theoretical perspective. However, empirical studies on how to effectively and responsibly integrate LLM Chatbots into writing learning and evaluate their effectiveness are still limited. To address this gap, the present study introduces a learning approach termed LLM-powered Chatbot-assisted argumentative writing (LCAW) to support the cultivation of university students\u2019 writing abilities. A total of 61 Chinese university students from two classes were invited to participate in a quasi-experimental study with different learning methods as intervention measures, and student perceptions were gathered through interviews. The results show that the proposed LCAW method significantly improves students\u2019 writing performance in terms of content quality and language expression, and positively impacts in providing personalized feedback and enhancing writing motivation. This study contributes by proposing an effective method for integrating generative AI into higher education writing instruction and by offering insights for curriculum design policies to enhance higher writing education through GenAI.", "isOpenAccess": false, "url": ""}
{"paperId": "d8d6f39e7d4a59ceee31d9c98a152b26a8d5c137", "year": 2023, "title": "An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions", "authors": "Jingyu Shi, Rahul Jain, Hyungjun Doh, Ryo Suzuki, Karthik Ramani", "venue": "arXiv.org", "citationCount": 37, "abstract": "Generative AI (GenAI) has shown remarkable capabilities in generating diverse and realistic content across different formats like images, videos, and text. In Generative AI, human involvement is essential, thus HCI literature has investigated how to effectively create collaborations between humans and GenAI systems. However, the current literature lacks a comprehensive framework to better understand Human-GenAI Interactions, as the holistic aspects of human-centered GenAI systems are rarely analyzed systematically. In this paper, we present a survey of 291 papers, providing a novel taxonomy and analysis of Human-GenAI Interactions from both human and Gen-AI perspectives. The dimensions of design space include 1) Purposes of Using Generative AI, 2) Feedback from Models to Users, 3) Control from Users to Models, 4) Levels of Engagement, 5) Application Domains, and 6) Evaluation Strategies. Our work is also timely at the current development stage of GenAI, where the Human-GenAI interaction design is of paramount importance. We also highlight challenges and opportunities to guide the design of Gen-AI systems and interactions towards the future design of human-centered Generative AI applications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.07127"}
{"paperId": "c613b6644f7f5bf472c8a0284aea0535880349b0", "year": 2023, "title": "Use of Generative Artificial Intelligence, Including Large Language Models Such as ChatGPT, in Scientific Publications: Policies of KJR and Prominent Authorities", "authors": "Seong Ho Park", "venue": "Korean Journal of Radiology", "citationCount": 37, "abstract": "Generative artificial intelligence (AI) refers to algorithms that can be used to create new content, such as text, code, images, videos, and audio. Particularly, with the introduction of generative adversarial networks (GAN) in medical imaging [1,2], generative AI has gained significant attention in the scientific community, leading to numerous publications in the past few years. The Korean Journal of Radiology (KJR) has published several articles on this topic [3-5]. However, the landscape of generative AI in scientific research and publication has dramatically shifted with the emergence of generative large language models (LLMs), such as ChatGPT, which are capable of generating text that closely resembles human writing and easily accessible to the public. The use of LLMs is rapidly expanding in scientific publications [6], creating ethical and legal concerns and challenges related to research integrity, plagiarism, copyright infringement, and authorship, not only for authors, but also for peer reviewers and editors [7-9]. Moreover, these concerns and challenges Use of Generative Artificial Intelligence, Including Large Language Models Such as ChatGPT, in Scientific Publications: Policies of KJR and Prominent Authorities", "isOpenAccess": true, "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10400373"}
{"paperId": "bff983a275151b8c25976dee70a1369206e01b00", "year": 2024, "title": "Generative AI for Deep Reinforcement Learning: Framework, Analysis, and Use Cases", "authors": "Geng Sun, Wenwen Xie, D. Niyato, Fang Mei, Jiawen Kang, Hongyang Du, Shiwen Mao", "venue": "IEEE wireless communications", "citationCount": 37, "abstract": "As a form of artificial intelligence (AI) technology based on interactive learning, deep reinforcement learning (DRL) has been widely applied across various fields and has achieved remarkable accomplishments. However, DRL faces certain limitations, including low sample efficiency and poor generalization. Therefore, in this article, we show how to leverage generative AI (GAI) to address these issues and enhance the performance of DRL algorithms. We first introduce several classic GAI and DRL algorithms and demonstrate the applications of GAI-enhanced DRL algorithms. Then, we discuss how to use GAI to improve DRL algorithms from the data and policy perspectives. Subsequently, we introduce a framework that demonstrates an actual and novel integration of GAI with DRL, that is, GAI-enhanced DRL. Additionally, we provide a case study of the framework for UAV-assisted integrated near-field/far-field communication to validate the performance of the proposed framework. Moreover, we present several future directions. Finally, the related code is available at: https://xiewenwen22.github.io/GAI-enhanced-DRL.", "isOpenAccess": false, "url": ""}
{"paperId": "ae4dfde9256c1fedc4cc6c9528465ec3d11aab80", "year": 2024, "title": "Learning by playing with generative AI: design and evaluation of a role-playing educational game with generative AI as scaffolding for instant feedback interaction", "authors": "C. Chien, Hung-Yu Chan, H. Hou", "venue": "Journal of Research on Technology in Education", "citationCount": 37, "abstract": "Abstract In this study, an online contextualized educational game was designed to provide interactive simulated dialogues using generative AI scaffolding (using ChatPDF) in a contextualized game as scaffolding for immediate feedback, where learners can access guides and explore knowledge. This study analyzed learners\u2019 behaviors while performing AI prompting in the interactive scaffolding, as well as learners\u2019 psychological responses. A total of 59 students participated in this study. The results of the study showed that learners had significantly high flow and low activity anxiety in the game tasks, while game feedback and scaffolding usefulness had significant effects on learning aids. The generative AI instant feedback interactive scaffolding had a certain high percentage of direct answers or indirect suggestions, which is suitable for interactive scaffolding.", "isOpenAccess": false, "url": ""}
{"paperId": "9cca0ff4ddd8ea65650da5968c800eafec2da5bb", "year": 2024, "title": "Review of Generative AI Methods in Cybersecurity", "authors": "Yagmur Yigit, William J. Buchanan, Madjid G Tehrani, Leandros A. Maglaras", "venue": "arXiv.org", "citationCount": 37, "abstract": "Over the last decade, Artificial Intelligence (AI) has become increasingly popular, especially with the use of chatbots such as ChatGPT, Gemini, and DALL-E. With this rise, large language models (LLMs) and Generative AI (GenAI) have also become more prevalent in everyday use. These advancements strengthen cybersecurity's defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of GenAI, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of GenAI in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. GenAI can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that GenAI creates and to also further encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.", "isOpenAccess": false, "url": ""}
{"paperId": "9c5fe8720cd04a7314f3f6f928310dd9737ca740", "year": 2024, "title": "Transforming Digital Marketing with Generative AI", "authors": "Tasin Islam, A. Miron, M. Nandy, Jyoti Choudrie, Xiaohui Liu, Yongmin Li", "venue": "De Computis", "citationCount": 37, "abstract": "The current marketing landscape faces challenges in content creation and innovation, relying heavily on manually created content and traditional channels like social media and search engines. While effective, these methods often lack the creativity and uniqueness needed to stand out in a competitive market. To address this, we introduce MARK-GEN, a conceptual framework that utilises generative artificial intelligence (AI) models to transform marketing content creation. MARK-GEN provides a comprehensive, structured approach for businesses to employ generative AI in producing marketing materials, representing a new method in digital marketing strategies. We present two case studies within the fashion industry, demonstrating how MARK-GEN can generate compelling marketing content using generative AI technologies. This proposition paper builds on our previous technical developments in virtual try-on models, including image-based, multi-pose, and image-to-video techniques, and is intended for a broad audience, particularly those in business management.", "isOpenAccess": true, "url": "https://www.mdpi.com/2073-431X/13/7/168/pdf?version=1720425547"}
{"paperId": "8ec3458c3bc4a0a80a2c51e01836d5bb4dd09887", "year": 2024, "title": "Ethical considerations of generative AI-enabled human resource management", "authors": "Pierre Andrieux, Richard D. Johnson, Jalal Sarabadani, Craig Van Slyke", "venue": "Organizational Dynamics", "citationCount": 37, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "78fd2d16ad2381d68b21b44f9b359c27d1697869", "year": 2024, "title": "Embracing the ChatGPT revolution: unlocking new horizons for tourism", "authors": "Ji Shi, Minwoo Lee, V. G. Girish, Guangyu Xiao, Choong-Ki Lee", "venue": "Journal of Hospitality and Tourism Technology", "citationCount": 37, "abstract": "\nPurpose\nThis study aims to investigate tourists\u2019 attitudes and intentions regarding the usage of Chat Generative Pre-trained Transformer (ChatGPT) for accessing tourism information. Furthermore, by integrating the perceived risks associated with ChatGPT and the theory of planned behavior (TPB), this research examines the impact of three types of perceived risks, such as privacy risk, accuracy risk and overreliance risk, on tourists\u2019 behavioral intention.\n\n\nDesign/methodology/approach\nData were gathered for this study by using two online survey platforms, thus resulting in a sample of 536 respondents. The online survey questionnaire assessed tourists\u2019 perceived risks, attitude, subjective norm, perceived behavioral control, behavioral intention and demographic information related to their usage of ChatGPT.\n\n\nFindings\nThe structural equation modeling analysis revealed that tourists express concerns about the associated risks of using ChatGPT to search for tourism information, specifically privacy risk, accuracy risk and overreliance risk. It was found that perceived risks significantly influence tourists\u2019 attitude and intention toward the usage of ChatGPT, which is consistent with the hypotheses proposed in previous literature regarding tourists\u2019 perceived risks of ChatGPT.\n\n\nResearch limitations/implications\nThis work is a preliminary empirical study that assesses tourists\u2019 behavioral intention toward the use of ChatGPT in the field of tourism. Previous research has remained at the hypothetical level, speculating about the impact of ChatGPT on the tourism industry. This study investigates the behavioral intention of tourists who have used ChatGPT to search for travel information. Furthermore, this study provides evidence based on the outcome of this research and offers theoretical foundations for the sustainable development of generative AI in the tourism domain. This study has limitations in that it primarily focused on exploring the risks associated with ChatGPT and did not extensively investigate its range of benefits.\n\n\nPractical implications\nFirst, to address privacy concerns that pose significant challenges for chatbots various measures, such as data encryption, secure storage and obtaining user consent, are crucial. Second, despite concerns and uncertainties, the introduction of ChatGPT holds promising prospects for the tourism industry. By offering personalized recommendations and enhancing operational efficiency, ChatGPT has the potential to revolutionize travel experiences. Finally, recognizing the potential of ChatGPT in enhancing customer service and operational efficiency is crucial for tourism enterprises.\n\n\nSocial implications\nRecognizing the potential of ChatGPT in enhancing customer service and operational efficiency is crucial for tourism enterprises. As their interest in adopting ChatGPT grows, increased investments and resources will be dedicated to developing and implementing ChatGPT solutions. This enhancement may involve creating customized ChatGPT solutions and actively engaging in training and development programs to empower employees in effectively using ChatGPT\u2019s capabilities. Such initiatives can contribute to improved customer service and overall operations within the tourism industry.\n\n\nOriginality/value\nThis study integrates TPB with perceived risks in ChatGPT, thus providing empirical evidence. It highlights the importance of considering perceived risks in tourists\u2019 intentions and contributes to the sustainable development of generative AI in tourism. As such, it provides valuable insights for practitioners and policymakers.\n", "isOpenAccess": false, "url": ""}
{"paperId": "76ded171690200805c3bb417827f6b9749df2585", "year": 2023, "title": "On Hate Scaling Laws For Data-Swamps", "authors": "Abeba Birhane, Vinay Uday Prabhu, Sanghyun Han, Vishnu Naresh Boddeti", "venue": "arXiv.org", "citationCount": 37, "abstract": "`Scale the model, scale the data, scale the GPU-farms' is the reigning sentiment in the world of generative AI today. While model scaling has been extensively studied, data scaling and its downstream impacts remain under explored. This is especially of critical importance in the context of visio-linguistic datasets whose main source is the World Wide Web, condensed and packaged as the CommonCrawl dump. This large scale data-dump, which is known to have numerous drawbacks, is repeatedly mined and serves as the data-motherlode for large generative models. In this paper, we: 1) investigate the effect of scaling datasets on hateful content through a comparative audit of the LAION-400M and LAION-2B-en, containing 400 million and 2 billion samples respectively, and 2) evaluate the downstream impact of scale on visio-linguistic models trained on these dataset variants by measuring racial bias of the models trained on them using the Chicago Face Dataset (CFD) as a probe. Our results show that 1) the presence of hateful content in datasets, when measured with a Hate Content Rate (HCR) metric on the inferences of the Pysentimiento hate-detection Natural Language Processing (NLP) model, increased by nearly $12\\%$ and 2) societal biases and negative stereotypes were also exacerbated with scale on the models we evaluated. As scale increased, the tendency of the model to associate images of human faces with the `human being' class over 7 other offensive classes reduced by half. Furthermore, for the Black female category, the tendency of the model to associate their faces with the `criminal' class doubled, while quintupling for Black male faces. We present a qualitative and historical analysis of the model audit results, reflect on our findings and its implications for dataset curation practice, and close with a summary of our findings and potential future work to be done in this area.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.13141"}
{"paperId": "741d039aba804db2e2600fc7be7a1b8e303aec49", "year": 2024, "title": "AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence", "authors": "Alireza Ghafarollahi, Markus J. Buehler", "venue": "arXiv.org", "citationCount": 37, "abstract": "The design of alloys is a multi-scale problem that requires a holistic approach that involves retrieving relevant knowledge, applying advanced computational methods, conducting experimental validations, and analyzing the results, a process that is typically reserved for human experts. Machine learning (ML) can help accelerate this process, for instance, through the use of deep surrogate models that connect structural features to material properties, or vice versa. However, existing data-driven models often target specific material objectives, offering limited flexibility to integrate out-of-domain knowledge and cannot adapt to new, unforeseen challenges. Here, we overcome these limitations by leveraging the distinct capabilities of multiple AI agents that collaborate autonomously within a dynamic environment to solve complex materials design tasks. The proposed physics-aware generative AI platform, AtomAgents, synergizes the intelligence of large language models (LLM) the dynamic collaboration among AI agents with expertise in various domains, including knowledge retrieval, multi-modal data integration, physics-based simulations, and comprehensive results analysis across modalities that includes numerical data and images of physical simulation results. The concerted effort of the multi-agent system allows for addressing complex materials design problems, as demonstrated by examples that include autonomously designing metallic alloys with enhanced properties compared to their pure counterparts. Our results enable accurate prediction of key characteristics across alloys and highlight the crucial role of solid solution alloying to steer the development of advanced metallic alloys. Our framework enhances the efficiency of complex multi-objective design tasks and opens new avenues in fields such as biomedical materials engineering, renewable energy, and environmental sustainability.", "isOpenAccess": false, "url": ""}
{"paperId": "68fd6cc9b41291d625b41761149016be6485c0b3", "year": 2023, "title": "ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey", "authors": "S. Mohamadi, G. Mujtaba, N. Le, Gianfranco Doretto, Don Adjeroh", "venue": "arXiv.org", "citationCount": 37, "abstract": "ChatGPT is a large language model (LLM) created by OpenAI that has been carefully trained on a large amount of data. It has revolutionized the field of natural language processing (NLP) and has pushed the boundaries of LLM capabilities. ChatGPT has played a pivotal role in enabling widespread public interaction with generative artificial intelligence (GAI) on a large scale. It has also sparked research interest in developing similar technologies and investigating their applications and implications. In this paper, our primary goal is to provide a concise survey on the current lines of research on ChatGPT and its evolution. We considered both the glass box and black box views of ChatGPT, encompassing the components and foundational elements of the technology, as well as its applications, impacts, and implications. The glass box approach focuses on understanding the inner workings of the technology, and the black box approach embraces it as a complex system, and thus examines its inputs, outputs, and effects. This paves the way for a comprehensive exploration of the technology and provides a road map for further research and experimentation. We also lay out essential foundational literature on LLMs and GAI in general and their connection with ChatGPT. This overview sheds light on existing and missing research lines in the emerging field of LLMs, benefiting both public users and developers. Furthermore, the paper delves into the broad spectrum of applications and significant concerns in fields such as education, research, healthcare, finance, etc.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2307.04251"}
{"paperId": "586f5bd6befd5f8213d68aef603db735f1a5fda6", "year": 2023, "title": "The Impact, Advancements and Applications of Generative AI", "authors": "Balagopal Ramdurai, Prasanna Adhithya", "venue": "International Journal of Computer Science and Engineering", "citationCount": 37, "abstract": null, "isOpenAccess": true, "url": "https://www.internationaljournalssrg.org/../IJCSE/2023/Volume10-Issue6/IJCSE-V10I6P101.pdf"}
{"paperId": "523a4ec38bae8bfcf5baca17bdd8e487869f6986", "year": 2024, "title": "Creative partnerships with generative AI. Possibilities for education and beyond", "authors": "Edwin Creely, Joanne Blannin", "venue": "Thinking Skills and Creativity", "citationCount": 37, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.tsc.2024.101727"}
{"paperId": "51fe85e30a4c9d66a3fa127946d1f87a6fabeac7", "year": 2025, "title": "HalluLens: LLM Hallucination Benchmark", "authors": "Yejin Bang, Ziwei Ji, A. Schelten, A. Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung", "venue": "Annual Meeting of the Association for Computational Linguistics", "citationCount": 37, "abstract": "Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as\"hallucination.\"These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is essential for the advancement of LLMs. This paper introduces a comprehensive hallucination benchmark, incorporating both new extrinsic and existing intrinsic evaluation tasks, built upon clear taxonomy of hallucination. A major challenge in benchmarking hallucinations is the lack of a unified framework due to inconsistent definitions and categorizations. We disentangle LLM hallucination from\"factuality,\"proposing a clear taxonomy that distinguishes between extrinsic and intrinsic hallucinations, to promote consistency and facilitate research. Extrinsic hallucinations, where the generated content is not consistent with the training data, are increasingly important as LLMs evolve. Our benchmark includes dynamic test set generation to mitigate data leakage and ensure robustness against such leakage. We also analyze existing benchmarks, highlighting their limitations and saturation. The work aims to: (1) establish a clear taxonomy of hallucinations, (2) introduce new extrinsic hallucination tasks, with data that can be dynamically regenerated to prevent saturation by leakage, (3) provide a comprehensive analysis of existing benchmarks, distinguishing them from factuality evaluations.", "isOpenAccess": false, "url": ""}
{"paperId": "4ba69e4f0b7e9bbfeee091029f8eeccd2f984d09", "year": 2023, "title": "Generative AI in education: To embrace it or not\uff1f", "authors": "Samuel Ariyo Okaiyeto, Junwen Bai, Hongwei Xiao", "venue": "International Journal of Agricultural and Biological Engineering", "citationCount": 37, "abstract": "Within the first few years of introducing new technology, there is often a lot of excitement and hype surrounding its potential. People tend to overestimate its immediate impact, believing that it will revolutionize various aspects of society and bring about rapid change. However, during this early stage, the technology may still be in its early development phase, and it may face a series of challenges and limitations that could prevent it from reaching its full potential. This pattern can be observed in various technologies throughout history, such as the internet, mobile phones, and others. It is essential to consider this hype cycle when evaluating the potential impact of emerging technologies such as generative AI and to maintain a balanced perspective on their development and adoption. Therefore, universities should actively encourage research on the impact of Generative AI on education, the workforce", "isOpenAccess": true, "url": "https://www.ijabe.org/index.php/ijabe/article/download/8486/pdf"}
{"paperId": "4ad822679fbc9db864208bd703f70a093731c205", "year": 2024, "title": "AI and personalized learning: bridging the gap with modern educational goals", "authors": "Kristjan-Julius Laak, Jaan Aru", "venue": "arXiv.org", "citationCount": 37, "abstract": "Personalized learning (PL) aspires to provide an alternative to the one-size-fits-all approach in education. Technology-based PL solutions have shown notable effectiveness in enhancing learning performance. However, their alignment with the broader goals of modern education is inconsistent across technologies and research areas. In this paper, we examine the characteristics of AI-driven PL solutions in light of the goals outlined in the OECD Learning Compass 2030. Our analysis indicates a gap between the objectives of modern education and the technological approach to PL. We identify areas where the AI-based PL solutions could embrace essential elements of contemporary education, such as fostering learner's agency, cognitive engagement, and general competencies. While the PL solutions that narrowly focus on domain-specific knowledge acquisition are instrumental in aiding learning processes, the PL envisioned by educational experts extends beyond simple technological tools and requires a holistic change in the educational system. Finally, we explore the potential of generative AI, such as ChatGPT, and propose a hybrid model that blends artificial intelligence with a collaborative, teacher-facilitated approach to personalized learning.", "isOpenAccess": false, "url": ""}
{"paperId": "3deccc15671a823c91486cadebb4eb82526c1b8f", "year": 2024, "title": "Generative AI, Teacher Knowledge and Educational Research: Bridging Short- and Long-Term Perspectives", "authors": "Punya Mishra, Nicole Oster, D. Henriksen", "venue": "TechTrends", "citationCount": 37, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "3b3082520e59974f9f43c852ee37a7003911e953", "year": 2024, "title": "T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models", "authors": "Yibo Miao, Yifan Zhu, Yinpeng Dong, Lijia Yu, Jun Zhu, Xiao-Shan Gao", "venue": "Neural Information Processing Systems", "citationCount": 37, "abstract": "The recent development of Sora leads to a new era in text-to-video (T2V) generation. Along with this comes the rising concern about its security risks. The generated videos may contain illegal or unethical content, and there is a lack of comprehensive quantitative understanding of their safety, posing a challenge to their reliability and practical deployment. Previous evaluations primarily focus on the quality of video generation. While some evaluations of text-to-image models have considered safety, they cover fewer aspects and do not address the unique temporal risk inherent in video generation. To bridge this research gap, we introduce T2VSafetyBench, a new benchmark designed for conducting safety-critical assessments of text-to-video models. We define 12 critical aspects of video generation safety and construct a malicious prompt dataset including real-world prompts, LLM-generated prompts and jailbreak attack-based prompts. Based on our evaluation results, we draw several important findings, including: 1) no single model excels in all aspects, with different models showing various strengths; 2) the correlation between GPT-4 assessments and manual reviews is generally high; 3) there is a trade-off between the usability and safety of text-to-video generative models. This indicates that as the field of video generation rapidly advances, safety risks are set to surge, highlighting the urgency of prioritizing video safety. We hope that T2VSafetyBench can provide insights for better understanding the safety of video generation in the era of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "333b8fec8b88cf8e58cf270a372772f6d32a8dd9", "year": 2023, "title": "BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models", "authors": "J. Vice, Naveed Akhtar, Richard I. Hartley, A. Mian", "venue": "IEEE Transactions on Information Forensics and Security", "citationCount": 37, "abstract": "The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. We demonstrate that this technology can be attacked to generate content that subtly manipulates its users. We propose a Backdoor Attack on text-to-image Generative Models (BAGM), which upon triggering, infuses the generated images with manipulative details that are naturally blended in the content. Our attack is the first to target three popular text-to-image generative models across three stages of the generative process by modifying the behaviour of the embedded tokenizer, the language model or the image generative model. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. Given the existing gap within this domain, we also contribute a comprehensive set of quantitative metrics designed specifically for assessing the effectiveness of backdoor attacks on text-to-image models. The efficacy of BAGM is established by attacking state-of-the-art generative models, using a marketing scenario as the target domain. To that end, we contribute a dataset of branded product images. Our embedded backdoors increase the bias towards the target outputs by more than five times the usual, without compromising the model robustness or the generated content utility. By exposing generative AI\u2019s vulnerabilities, we encourage researchers to tackle these challenges and practitioners to exercise caution when using pre-trained models. Relevant code and input prompts can be found at https://github.com/JJ-Vice/BAGM, and the dataset is available at: https://ieee-dataport.org/documents/marketable-foods-mf-dataset", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2307.16489"}
{"paperId": "28f59093730d88719b96041f9544c73671f798bd", "year": 2024, "title": "USP: A Unified Sequence Parallelism Approach for Long Context Generative AI", "authors": "Jiarui Fang, Shangchun Zhao", "venue": "arXiv.org", "citationCount": 37, "abstract": "Sequence parallelism (SP), which divides the sequence dimension of input tensors across multiple computational devices, is becoming key to unlocking the long-context capabilities of generative AI models. This paper investigates the state-of-the-art SP approaches, i.e. DeepSpeed-Ulysses and Ring-Attention, and proposes a unified SP approach, which is more robust to transformer model architectures and network hardware topology. This paper compares the communication and memory cost of SP and existing parallelism, including data/tensor/zero/pipeline parallelism, and discusses the best practices for designing hybrid 4D parallelism involving SP. We achieved 47% MFU on two 8xA800 nodes using SP for the LLAMA3-8B model training using sequence length 208K. Our code is publicly available at https://github.com/feifeibear/long-context-attention.", "isOpenAccess": false, "url": ""}
{"paperId": "26a04935dc5effc7eefaedd7062a6f901cab13fb", "year": 2024, "title": "Empowering learners with ChatGPT: insights from a systematic literature exploration", "authors": "L. Mohebi", "venue": "Discover Education", "citationCount": 37, "abstract": "With the rapid emergence of artificial intelligence (AI) tools in the academic realm, understanding their implications, advantages, and challenges becomes crucial. ChatGPT, a leading AI conversational model, has gained significant traction in educational settings, warranting a comprehensive investigation into its academic impact. This systematic review aimed to elucidate the current state of research regarding implementing ChatGPT in academic cultures, focusing on its applications, challenges, and potential in reshaping contemporary pedagogies. An exhaustive review of 32 peer-reviewed articles from 2023 encompassed categorizing diverse research fields, journals, and studies. The research then delved into the challenges, factors affecting its use, and the myriad opportunities ChatGPT offers within academic settings. An overwhelming 75% of the studies emphasized the relevance of ChatGPT and generative AI tools within higher education, underscoring its importance. Significant challenges identified included pedagogical integration (31.25%) and student engagement (15.63%). However, ChatGPT's potentially inefficient content creation (25.00%) and enhanced personalized learning (21.88%) presented promising avenues for reshaping educational experiences. Furthermore, the tool's adaptability in catering to diverse student needs and fostering collaborative environments was notable. ChatGPT emerges as a transformative force in academia, with vast potential to revolutionize pedagogical practices. Yet, academic institutions must address inherent challenges to harness their full capabilities. Future directions point towards a symbiotic integration, with AI complementing human educators to promote inclusive, dynamic learning.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s44217-024-00120-y.pdf"}
{"paperId": "09565ba740f503f6f795bbaac1982cfcafa66d47", "year": 2024, "title": "TamGen: drug design with target-aware molecule generation through a chemical language model", "authors": "Kehan Wu, Yingce Xia, Pan Deng, Renhe Liu, Yuan Zhang, Han Guo, Yumeng Cui, Qizhi Pei, Lijun Wu, Shufang Xie, Si Chen, Xi Lu, Song Hu, Jinzhi Wu, C. Chan, Shawn Chen, Liangliang Zhou, Nenghai Yu, Enhong Chen, Haiguang Liu, Jinjiang Guo, Tao Qin, Tie-Yan Liu", "venue": "Nature Communications", "citationCount": 37, "abstract": "Generative drug design facilitates the creation of compounds effective against pathogenic target proteins. This opens up the potential to discover novel compounds within the vast chemical space and fosters the development of innovative therapeutic strategies. However, the practicality of generated molecules is often limited, as many designs focus on a narrow set of drug-related properties, failing to improve the success rate of subsequent drug discovery process. To overcome these challenges, we develop TamGen, a method that employs a GPT-like chemical language model and enables target-aware molecule generation and compound refinement. We demonstrate that the compounds generated by TamGen have improved molecular quality and viability. Additionally, we have integrated TamGen into a drug discovery pipeline and identified 14 compounds showing compelling inhibitory activity against the Tuberculosis ClpP protease, with the most effective compound exhibiting a half maximal inhibitory concentration (IC50) of 1.9\u2009\u03bcM. Our findings underscore the practical potential and real-world applicability of generative drug design approaches, paving the way for future advancements in the field. Generative AI holds promise for creating novel compounds. Here, authors introduce TamGen, a GPT-like model designed to generate molecules tailored to specific target proteins. TamGen identified 14 potent compounds against the Tuberculosis ClpP protease, showing its potential for drug discovery.", "isOpenAccess": true, "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11522292"}
{"paperId": "f11cb79663aac364a9204c069039c0ae75cf9015", "year": 2025, "title": "Generative AI in higher education: the ChatGPT effect", "authors": "Putri Beny Mawarsih, Hidayatun Nadzifah, Ananda Wahyu Puspa Widuri, Erika Kurniawati", "venue": "Asia Pacific Journal of Education", "citationCount": 36, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "e28a6013f50ba7daf09ea920977cf2c353f0c229", "year": 2024, "title": "Literacy in the Time of Artificial Intelligence", "authors": "M. Kalantzis, B. Cope", "venue": "Reading Research Quarterly", "citationCount": 36, "abstract": "The latest mutation of Artificial Intelligence, Generative AI, is more than anything a technology of writing. It is a machine that can write. In a world\u2010historical frame, the significance of this cannot be understated. This is a technology in which the unnatural language of code tangles with the natural language of everyday life. Its form of writing, moreover, is multimodal, able not only to write text as conventionally understood, but also to \u201cread\u201d images by matching textual labels and to \u201cwrite\u201d images from textual prompts. Within the scope of this peculiarly mechanical manufacturing of writing are mathematics, actionable software procedure, and algorithm. This paper explores the consequences of Generative AI for literacy teaching and learning. In its first part, we speak theoretically and historically, suggesting that this development is perhaps as momentous for society and education as Pi Sheng's invention of moveable type and Gutenberg's printing press\u2014and in its peculiar ways just as problematic. In the paper's second part, we go on to propose that literacy in the time of AI requires a new way to speak about itself, a revised \u201cgrammar\u201d of sorts. In a third part, we discuss an experimental application we have developed that puts Generative AI to work in support of literacy and learning. We end with some findings and implications for literacy education and with a proposal for what we will call cyber\u2010social literacy learning.", "isOpenAccess": true, "url": "https://doi.org/10.1002/rrq.591"}
{"paperId": "dce016ac05956399b2b2e1b360c6b4de5d02909d", "year": 2024, "title": "Investigating How Generative AI Can Create Personalized Learning Materials Tailored to Individual Student Needs", "authors": "M. Binhammad, Azzam Othman, Laila Abuljadayel, Huda Al Mheiri, Muna Alkaabi, Mohammad Almarri", "venue": "Creative Education", "citationCount": 36, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.4236/ce.2024.157091"}
{"paperId": "da3a6701bead27e1a210daff20a443b314941a14", "year": 2024, "title": "University Students\u2019 Insights of Generative Artificial Intelligence (AI) Writing Tools", "authors": "Al-Mothana M. Gasaymeh, Mohammad A. Beirat, Asma\u2019a A. Abu Qbeita", "venue": "Education sciences", "citationCount": 36, "abstract": "The current study examined university students\u2019 insights into generative AI writing tools regarding their familiarity with, perceived concerns about, and perceived benefits of these tools in their academic work. The study used a cross-sectional descriptive research design, and data were collected using a questionnaire instrument. The participants were ninety-five undergraduate and graduate students from a College of Education at a university in Jordan. The results show that university students show moderate familiarity with generative AI writing tools (M = 3.14, SD = 0.81), especially in engagement but lacking technical knowledge. They also have moderate concerns (M = 3.35, SD = 0.85), particularly about misinformation and data security. Despite these concerns, students recognize the benefits (M = 3.62, SD = 0.81), especially regarding the capabilities of these tools in simulating creativity and fostering innovation. In addition, the results showed that gender and educational level appear to have little effect on familiarity, concerns, and perceived benefits regarding these tools. Based on the findings, the study recommends enhancing students\u2019 familiarity with generative AI tools through providing technical training, hands-on opportunities, and ethical discussions. In addition, the study recommends addressing students\u2019 concerns regarding generative AI writing tools by improving data security related to generative AI, providing ethical guidelines regarding the use of these tools, and boosting AI literacy. Finally, it is recommended to enhance students\u2019 perceptions of the benefits of generative AI writing tools by highlighting the creative potential of these tools within the educational setting, using these tools to offer personalized learning experiences that adapt to individual learning styles, and promoting collaboration through generative AI writing tools.", "isOpenAccess": true, "url": "https://doi.org/10.3390/educsci14101062"}
{"paperId": "c279da6c3ed2d52987a3b91df37161a72c9c8c89", "year": 2024, "title": "Data Shapley in One Training Run", "authors": "Jiachen T. Wang, Prateek Mittal, Dawn Song, Ruoxi Jia", "venue": "International Conference on Learning Representations", "citationCount": 36, "abstract": "Data Shapley provides a principled framework for attributing data's contribution within machine learning contexts. However, existing approaches require re-training models on different data subsets, which is computationally intensive, foreclosing their application to large-scale models. Furthermore, they produce the same attribution score for any models produced by running the learning algorithm, meaning they cannot perform targeted attribution towards a specific model obtained from a single run of the algorithm. This paper introduces In-Run Data Shapley, which addresses these limitations by offering scalable data attribution for a target model of interest. In its most efficient implementation, our technique incurs negligible additional runtime compared to standard model training. This dramatic efficiency improvement makes it possible to perform data attribution for the foundation model pretraining stage for the first time. We present several case studies that offer fresh insights into pretraining data's contribution and discuss their implications for copyright in generative AI and pretraining data curation.", "isOpenAccess": false, "url": ""}
{"paperId": "bdfd54ed0a1a7363433ab5bfc1892532a60e8d82", "year": 2024, "title": "Integrating Generative AI into Financial Market Prediction for Improved Decision Making", "authors": "Chang Che, Zengyi Huang, Chen Li, Haotian Zheng, Xinyu Tian", "venue": "Applied and Computational Engineering", "citationCount": 36, "abstract": "This study provides an in-depth analysis of the model architecture and key technologies of generative artificial intelligence, combined with specific application cases, and uses conditional generative adversarial networks ( cGAN ) and time series analysis methods to simulate and predict dynamic changes in financial markets. The research results show that the cGAN model can effectively capture the complexity of financial market data, and the deviation between the prediction results and the actual market performance is minimal, showing a high degree of accuracy. Through investment return analysis, the application value of model predictions in actual investment strategies is confirmed, providing investors with new ways to improve the decision-making process. In addition, the evaluation of model stability and reliability also shows that although there are still challenges in responding to market emergencies, overall, GAI technology has shown great potential and application value in the field of financial market prediction. The conclusion points out that integrating generative artificial intelligence into financial market forecasts can not only improve the accuracy of forecasts, but also provide powerful data support for financial decisions, helping investors make more informed decisions in a complex and ever-changing market environment. choose.", "isOpenAccess": false, "url": ""}
{"paperId": "8b029a7af54147756cb1973631d2f1b27373a949", "year": 2023, "title": "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc", "authors": "D. Lenat, G. Marcus", "venue": "arXiv.org", "citationCount": 36, "abstract": "Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable. We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however a catch: if the logical language is expressive enough to fully represent the meaning of anything we can say in English, then the inference engine runs much too slowly. That's why symbolic AI systems typically settle for some fast but much less expressive logic, such as knowledge graphs. We describe how one AI system, Cyc, has developed ways to overcome that tradeoff and is able to reason in higher order logic in real time. We suggest that any trustworthy general AI will need to hybridize the approaches, the LLM approach and more formal approach, and lay out a path to realizing that dream.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.04445"}
{"paperId": "811b5f69f562cc940fa05e922edaf2134140a08c", "year": 2024, "title": "Use of Artificial Intelligence in Peer Review Among Top 100 Medical Journals", "authors": "Zhi-qiang Li, Hui-Lin Xu, Hui-juan Cao, Zhao-Lan Liu, Yu-Tong Fei, Jian-ping Liu", "venue": "JAMA Network Open", "citationCount": 36, "abstract": "This cross-sectional study of 100 top medical journals examines policies for use of artificial intelligence (AI) and generative AI in peer review.", "isOpenAccess": true, "url": "https://doi.org/10.1001/jamanetworkopen.2024.48609"}
{"paperId": "7bc68f9133024a79d2962fada8ba319a67efa715", "year": 2024, "title": "Empowering Personalized Pharmacogenomics with Generative AI Solutions", "authors": "M. Murugan, Bo Yuan, E. Venner, Christie M. Ballantyne, Katherine M Robinson, James C. Coons, Liwen Wang, P. Empey, R. A. Gibbs", "venue": "medRxiv", "citationCount": 36, "abstract": "Objective: This study evaluates an AI assistant developed using OpenAI's GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics, and to enhance patient care with equitable access. Methods: The AI assistant employs Retrieval Augmented Generation (RAG) combining retrieval and generative techniques. It employs a Knowledge Base (KB) comprising Clinical Pharmacogenetics Implementation Consortium (CPIC) data, with context-aware GPT-4 generating tailored responses to user queries from this KB, refined through prompt engineering and guardrails. Results: Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI's ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. Discussion: The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant's utility. RAG's ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. Conclusion: This study underscores generative AI's potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.", "isOpenAccess": true, "url": "https://www.medrxiv.org/content/medrxiv/early/2024/02/27/2024.02.21.24302946.full.pdf"}
{"paperId": "74f5eab32da49f26e33f964ce4781275d4cfd730", "year": 2024, "title": "garak: A Framework for Security Probing Large Language Models", "authors": "Leon Derczynski, Erick Galinkin, Jeffrey Martin, Subho Majumdar, Nanna Inie", "venue": "arXiv.org", "citationCount": 36, "abstract": "As Large Language Models (LLMs) are deployed and integrated into thousands of applications, the need for scalable evaluation of how models respond to adversarial attacks grows rapidly. However, LLM security is a moving target: models produce unpredictable output, are constantly updated, and the potential adversary is highly diverse: anyone with access to the internet and a decent command of natural language. Further, what constitutes a security weak in one context may not be an issue in a different context; one-fits-all guardrails remain theoretical. In this paper, we argue that it is time to rethink what constitutes ``LLM security'', and pursue a holistic approach to LLM security evaluation, where exploration and discovery of issues are central. To this end, this paper introduces garak (Generative AI Red-teaming and Assessment Kit), a framework which can be used to discover and identify vulnerabilities in a target LLM or dialog system. garak probes an LLM in a structured fashion to discover potential vulnerabilities. The outputs of the framework describe a target model's weaknesses, contribute to an informed discussion of what composes vulnerabilities in unique contexts, and can inform alignment and policy discussions for LLM deployment.", "isOpenAccess": false, "url": ""}
{"paperId": "6fc6f469e12656691cb31c118cdcd1b164630426", "year": 2023, "title": "The tools of the future are the challenges of today: The use of ChatGPT in problem-based learning medical education", "authors": "Christopher B Divito, Bryan M. Katchikian, Jenna E Gruenwald, Jennifer M Burgoon", "venue": "Medical Teacher", "citationCount": 36, "abstract": "Abstract What is the educational challenge? Incorporation of large language model (LLM) or generative artificial intelligence (AI) software poses a challenge to various areas of medical education, including problem-based learning (PBL). LLMs, such as ChatGPT, have incredible potential to transform educational systems and enhance student learning outcomes when used responsibly. What are the proposed solutions? ChatGPT can provide several ways to support students and assist facilitators with course responsibilities. Here we address factors of implementation and describe how ChatGPT can be responsibly utilized to support key elements of PBL. How was the solution implemented? Providing reasonable access is an essential element of novel software implementation. Additionally, training for both faculty and staff is vital to foster responsible usage, provide base-line proficiency, and guide users to critically evaluate the quality of output. What lessons were learned that are relevant to a wider audience? The use of LLMs or other generative AI is dramatically rising in the world. Appropriate and conscientious incorporation of AI into educational programs can foster responsible use and potentially enhance student learning. What are the next steps? Assessment of learning outcomes, student self-efficacy, group dynamics, and stakeholder feedback are required to measure the effects of ChatGPT in the PBL curriculum. Additionally, software programs competitive with ChatGPT are currently under development and will also need to be investigated for their potential role in education.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/0142159X.2023.2290997?needAccess=true"}
{"paperId": "6533817b6e3e375f20451a0e8f75fef2ef5af177", "year": 2024, "title": "Augmenting Large Language Models with Rules for Enhanced Domain-Specific Interactions: The Case of Medical Diagnosis", "authors": "Dimitrios P. Panagoulias, M. Virvou, G. Tsihrintzis", "venue": "Electronics", "citationCount": 36, "abstract": "In this paper, we present a novel Artificial Intelligence (AI) -empowered system that enhances large language models and other machine learning tools with rules to provide primary care diagnostic advice to patients. Specifically, we introduce a novel methodology, represented through a process diagram, which allows the definition of generative AI processes and functions with a focus on the rule-augmented approach. Our methodology separates various components of the generative AI process as blocks that can be used to generate an implementation data flow diagram. Building upon this framework, we utilize the concept of a dialogue process as a theoretical foundation. This is specifically applied to the interactions between a user and an AI-empowered software program, which is called \u201cMed|Primary AI assistant\u201d (Alpha Version at the time of writing), and provides symptom analysis and medical advice in the form of suggested diagnostics. By leveraging current advancements in natural language processing, a novel approach is proposed to define a blueprint of domain-specific knowledge and a context for instantiated advice generation. Our approach not only encompasses the interaction domain, but it also delves into specific content that is relevant to the user, offering a tailored and effective AI\u2013user interaction experience within a medical context. Lastly, using an evaluation process based on rules, defined by context and dialogue theory, we outline an algorithmic approach to measure content and responses.", "isOpenAccess": true, "url": "https://www.mdpi.com/2079-9292/13/2/320/pdf?version=1704964811"}
{"paperId": "63b1031c9eef388f5230ec9b9b5030c996d25ea3", "year": 2025, "title": "Overview of PAN 2025: Voight-Kampff Generative AI Detection, Multilingual Text Detoxification, Multi-author Writing Style Analysis, and Generative Plagiarism Detection", "authors": "Janek Bevendorff, Daryna Dementieva, Maik Fr\u00f6be, Bela Gipp, Andr\u00e9 Greiner-Petter, Jussi Karlgren, Maximilian Mayerl, Preslav Nakov, Alexander Panchenko, Martin Potthast, Artem Shelmanov, E. Stamatatos, Benno Stein, Yuxia Wang, Matti Wiegmann, Eva Zangerle", "venue": "Conference and Labs of the Evaluation Forum", "citationCount": 36, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "55a364012166cd34d081e327de5d70839e634f1c", "year": 2024, "title": "Unveiling the Dark Side of ChatGPT: Exploring Cyberattacks and Enhancing User Awareness", "authors": "Moatsum Alawida, Bayan Abu Shawar, Oludare Isaac Abiodun, Abid Mehmood, Abiodun Esther Omolara, A. K. Hwaitat", "venue": "Inf.", "citationCount": 36, "abstract": "The Chat Generative Pre-training Transformer (GPT), also known as ChatGPT, is a powerful generative AI model that can simulate human-like dialogues across a variety of domains. However, this popularity has attracted the attention of malicious actors who exploit ChatGPT to launch cyberattacks. This paper examines the tactics that adversaries use to leverage ChatGPT in a variety of cyberattacks. Attackers pose as regular users and manipulate ChatGPT\u2019s vulnerability to malicious interactions, particularly in the context of cyber assault. The paper presents illustrative examples of cyberattacks that are possible with ChatGPT and discusses the realm of ChatGPT-fueled cybersecurity threats. The paper also investigates the extent of user awareness of the relationship between ChatGPT and cyberattacks. A survey of 253 participants was conducted, and their responses were measured on a three-point Likert scale. The results provide a comprehensive understanding of how ChatGPT can be used to improve business processes and identify areas for improvement. Over 80% of the participants agreed that cyber criminals use ChatGPT for malicious purposes. This finding underscores the importance of improving the security of this novel model. Organizations must take steps to protect their computational infrastructure. This analysis also highlights opportunities for streamlining processes, improving service quality, and increasing efficiency. Finally, the paper provides recommendations for using ChatGPT in a secure manner, outlining ways to mitigate potential cyberattacks and strengthen defenses against adversaries.", "isOpenAccess": true, "url": "https://www.mdpi.com/2078-2489/15/1/27/pdf?version=1704188513"}
{"paperId": "527edf9306e7d138e4d49d44f53e5c8d1dfc46ea", "year": 2024, "title": "A Study on Teachers\u2019 Willingness to Use Generative AI Technology and Its Influencing Factors: Based on an Integrated Model", "authors": "Haili Lu, Lin He, Hao Yu, Tao Pan, Kefeng Fu", "venue": "Sustainability", "citationCount": 36, "abstract": "The development of new artificial intelligence-generated content (AIGC) technology creates new opportunities for the digital transformation of education. Teachers\u2019 willingness to adopt AIGC technology for collaborative teaching is key to its successful implementation. This study employs the TAM and TPB to construct a model analyzing teachers\u2019 acceptance of AIGC technology, focusing on the influencing factors and differences across various educational stages. The study finds that teachers\u2019 behavioral intentions to use AIGC technology are primarily influenced by perceived usefulness, perceived ease of use, behavioral attitudes, and perceived behavioral control. Perceived ease of use affects teachers\u2019 willingness both directly and indirectly across different groups. However, perceived behavioral control and behavioral attitudes only directly influence university teachers\u2019 willingness to use AIGC technology, with the impact of behavioral attitudes being stronger than that of perceived behavioral control. The empirical findings of this study promote the rational use of AIGC technology by teachers, providing guidance for encouraging teachers to actively explore the use of information technology in building new forms of digital education.", "isOpenAccess": true, "url": "https://www.mdpi.com/2071-1050/16/16/7216/pdf?version=1724320064"}
{"paperId": "3a6931210bdb236ad48f646017a88d6faaeb4988", "year": 2025, "title": "A generative AI-discovered TNIK inhibitor for idiopathic pulmonary fibrosis: a randomized phase 2a trial", "authors": "Zu-shan Xu, Fengzhi Ren, Ping Wang, Jie Cao, Chunting Tan, Dedong Ma, Li Zhao, Jinghong Dai, Yipeng Ding, Haohui Fang, Huiping Li, Hong Liu, Fengming Luo, Ying Meng, Pinhua Pan, Pingchao Xiang, Zuke Xiao, Sujata Rao, C. Satler, Sang Liu, Y. Lv, Heng Zhao, Shan Chen, H. Cui, Mikhail Korzinkin, David Gennert, Alex Zhavoronkov", "venue": "Nature Medicine", "citationCount": 36, "abstract": "Despite substantial progress in artificial intelligence (AI) for generative chemistry, few novel AI-discovered or AI-designed drugs have reached human clinical trials. Here we present the results of the first phase 2a multicenter, double-blind, randomized, placebo-controlled trial testing the safety and efficacy of rentosertib (formerly ISM001-055), a first-in-class AI-generated small-molecule inhibitor of TNIK, a first-in-class target in idiopathic pulmonary fibrosis (IPF) discovered using generative AI. IPF is an age-related progressive lung condition with no current therapies available that reverse the degenerative course of disease. Patients were randomized to 12\u2009weeks of treatment with 30\u2009mg rentosertib once daily (QD, n\u2009=\u200918), 30\u2009mg rentosertib twice daily (BID, n\u2009=\u200918), 60\u2009mg rentosertib QD (n\u2009=\u200918) or placebo (n\u2009=\u200917). The primary endpoint was the percentage of patients who have at least one treatment-emergent adverse event, which was similar across all treatment arms (72.2% in patients receiving 30\u2009mg rentosertib QD (n\u2009=\u200913/18), 83.3% for 30\u2009mg rentosertib BID (n\u2009=\u200915/18), 83.3% for 60\u2009mg rentosertib QD (n\u2009=\u200915/18) and 70.6% for placebo (n\u2009=\u200912/17)). Treatment-related serious adverse event rates were low and comparable across treatment groups, with the most common events leading to treatment discontinuation related to liver toxicity or diarrhea. Secondary endpoints included pharmacokinetic dynamics (Cmax, Ctrough, tmax, AUC0\u2013t/\u03c4/\u221e and t1/2), changes in lung function as measured by forced vital capacity, diffusion capacity of the lung for carbon monoxide, forced expiry in 1\u2009s and change in the Leicester Cough Questionnaire score, change in 6-min walk distance and the number and hospitalization duration of acute exacerbations of IPF. We observed increased forced vital capacity at the highest dosage with a mean change of +98.4\u2009ml (95% confidence interval 10.9 to 185.9) for patients in the 60\u2009mg rentosertib QD group, compared with \u221220.3\u2009ml (95% confidence interval \u2212116.1 to 75.6) for the placebo group. These results suggest that targeting TNIK with rentosertib is safe and well tolerated and warrants further investigation in larger-scale clinical trials of longer duration. ClinicalTrials.gov registration number: NCT05938920. Preliminary results from a phase 2a trial involving 71 patients suggest that a new agent, discovered and designed with artificial intelligence assistance, is safe and effective for the treatment of idiopathic pulmonary fibrosis.", "isOpenAccess": false, "url": ""}
{"paperId": "31babc068383c3966d322579eaaf79edc6a6bef4", "year": 2024, "title": "Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities", "authors": "M. Ferrag, Fatima Alwahedi, A. Battah, Bilel Cherif, Abdechakour Mechri, Norbert Tihanyi, Tam\u00e1s Bisztray, M. Debbah", "venue": "", "citationCount": 36, "abstract": "This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats.", "isOpenAccess": false, "url": ""}
{"paperId": "2f64604e824231fec4e216464854ed5847ffda4c", "year": 2024, "title": "People are skeptical of headlines labeled as AI-generated, even if true or human-made, because they assume full AI automation", "authors": "Sacha Altay, Fabrizio Gilardi", "venue": "PNAS Nexus", "citationCount": 36, "abstract": "Abstract The rise of generative AI tools has sparked debates about the labeling of AI-generated content. Yet, the impact of such labels remains uncertain. In two preregistered online experiments among US and UK participants (N = 4,976), we show that while participants did not equate \u201cAI-generated\u201d with \u201cFalse,\u201d labeling headlines as AI-generated lowered their perceived accuracy and participants\u2019 willingness to share them, regardless of whether the headlines were true or false, and created by humans or AI. The impact of labeling headlines as AI-generated was three times smaller than labeling them as false. This AI aversion is due to expectations that headlines labeled as AI-generated have been entirely written by AI with no human supervision. These findings suggest that the labeling of AI-generated content should be approached cautiously to avoid unintended negative effects on harmless or even beneficial AI-generated content and that effective deployment of labels requires transparency regarding their meaning.", "isOpenAccess": true, "url": "https://doi.org/10.1093/pnasnexus/pgae403"}
{"paperId": "25f8718f4964dfcf266d1c17197796f1114407e8", "year": 2024, "title": "AI Safety in Generative AI Large Language Models: A Survey", "authors": "Jaymari Chua, Yun Li, Shiyi Yang, Chen Wang, Lina Yao", "venue": "arXiv.org", "citationCount": 36, "abstract": "Large Language Model (LLMs) such as ChatGPT that exhibit generative AI capabilities are facing accelerated adoption and innovation. The increased presence of Generative AI (GAI) inevitably raises concerns about the risks and safety associated with these models. This article provides an up-to-date survey of recent trends in AI safety research of GAI-LLMs from a computer scientist's perspective: specific and technical. In this survey, we explore the background and motivation for the identified harms and risks in the context of LLMs being generative language models; our survey differentiates by emphasising the need for unified theories of the distinct safety challenges in the research development and applications of LLMs. We start our discussion with a concise introduction to the workings of LLMs, supported by relevant literature. Then we discuss earlier research that has pointed out the fundamental constraints of generative models, or lack of understanding thereof (e.g., performance and safety trade-offs as LLMs scale in number of parameters). We provide a sufficient coverage of LLM alignment -- delving into various approaches, contending methods and present challenges associated with aligning LLMs with human preferences. By highlighting the gaps in the literature and possible implementation oversights, our aim is to create a comprehensive analysis that provides insights for addressing AI safety in LLMs and encourages the development of aligned and secure models. We conclude our survey by discussing future directions of LLMs for AI safety, offering insights into ongoing research in this critical area.", "isOpenAccess": false, "url": ""}
{"paperId": "1391ace6e01248da666dc731b969bb27e6b90785", "year": 2024, "title": "AI and Generative AI for Research Discovery and Summarization", "authors": "Mark Glickman, Yi Zhang", "venue": "Special Issue 5: Grappling With the Generative AI Revolution", "citationCount": 36, "abstract": "AI and generative AI tools, including chatbots like ChatGPT that rely on large language models (LLMs), have burst onto the scene this year, creating incredible opportunities to increase work productivity and improve our lives. Statisticians and data scientists have begun experiencing the benefits from the availability of these tools in numerous ways, such as the generation of programming code from text prompts to analyze data or fit statistical models. One area that these tools can make a substantial impact is in research discovery and summarization. Standalone tools and plugins to chatbots are being developed that allow researchers to more quickly find relevant literature than pre-2023 search tools. Furthermore, generative AI tools have improved to the point where they can summarize and extract the key points from research articles in succinct language. Finally, chatbots based on highly parameterized LLMs can be used to simulate abductive reasoning, which provides researchers the ability to make connections among related technical topics, which can also be used for research discovery. We review the developments in AI and generative AI for research discovery and summarization, and propose directions where these types of tools are likely to head in the future that may be of interest to statistician and data scientists.", "isOpenAccess": false, "url": ""}
{"paperId": "015a127d4a0f11dcfeeece37d00a5013243459fd", "year": 2024, "title": "Large language models, social demography, and hegemony: comparing authorship in human and synthetic text", "authors": "A. Alvero, Jinsook Lee, Alejandra Regla-Vargas, Ren\u00e9 F. Kizilcec, Thorsten Joachims, Anthony Lising Antonio", "venue": "Journal of Big Data", "citationCount": 36, "abstract": "Large language models have become popular over a short period of time because they can generate text that resembles human writing across various domains and tasks. The popularity and breadth of use also put this technology in the position to fundamentally reshape how written language is perceived and evaluated. It is also the case that spoken language has long played a role in maintaining power and hegemony in society, especially through ideas of social identity and \u201ccorrect\u201d forms of language. But as human communication becomes even more reliant on text and writing, it is important to understand how these processes might shift and who is more likely to see their writing styles reflected back at them through modern AI. We therefore ask the following question: who does generative AI write like? To answer this, we compare writing style features in over 150,000 college admissions essays submitted to a large public university system and an engineering program at an elite private university with a corpus of over 25,000 essays generated with GPT-3.5 and GPT-4 to the same writing prompts. We find that human-authored essays exhibit more variability across various individual writing style features (e.g., verb usage) than AI-generated essays. Overall, we find that the AI-generated essays are most similar to essays authored by students who are males with higher levels of social privilege. These findings demonstrate critical misalignments between human and AI authorship characteristics, which may affect the evaluation of writing and calls for research on control strategies to improve alignment.", "isOpenAccess": true, "url": "https://doi.org/10.1186/s40537-024-00986-7"}
{"paperId": "f954585b54504c87838837f390c066466dd9b27a", "year": 2024, "title": "Correctness Comparison of ChatGPT\u20104, Gemini, Claude\u20103, and Copilot for Spatial Tasks", "authors": "H. Hochmair, L. Juh\u00e1sz, Takoda Kemp", "venue": "Trans. GIS", "citationCount": 35, "abstract": "Generative AI including large language models (LLMs) has recently gained significant interest in the geoscience community through its versatile task\u2010solving capabilities including programming, arithmetic reasoning, generation of sample data, time\u2010series forecasting, toponym recognition, or image classification. Existing performance assessments of LLMs for spatial tasks have primarily focused on ChatGPT, whereas other chatbots received less attention. To narrow this research gap, this study conducts a zero\u2010shot correctness evaluation for a set of 76 spatial tasks across seven task categories assigned to four prominent chatbots, that is, ChatGPT\u20104, Gemini, Claude\u20103, and Copilot. The chatbots generally performed well on tasks related to spatial literacy, GIS theory, and interpretation of programming code and functions, but revealed weaknesses in mapping, code writing, and spatial reasoning. Furthermore, there was a significant difference in the correctness of results between the four chatbots. Responses from repeated tasks assigned to each chatbot showed a high level of consistency in responses with matching rates of over 80% for most task categories in the four chatbots.", "isOpenAccess": false, "url": ""}
{"paperId": "f26cf91794aa61cf6d66fece18b82d5f3fdf0ad5", "year": 2023, "title": "The Ethics of Artificial Intelligence in the Era of Generative AI", "authors": "V. Kirova, Cyril S. Ku, Joseph R. Laracy, Thomas J. Marlowe", "venue": "Journal of Systemics, Cybernetics and Informatics", "citationCount": 35, "abstract": "In the early 2020s, advances in transformer-based deep neural networks enabled the development and growth of a number of generative artificial intelligence (GenAI) systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bard, and others. GenAI has applications across a wide range of industries, including art, writing, software development, product design, healthcare, finance, gaming, and more. In this paper, we place these recent advances in a historical, cybernetic context. We analyze ethical issues that arise in the area of software engineering and cyber-physical systems. In addition, we explore AI-based challenges in healthcare and medicine, including a number involving GenAI. This research shows the importance of rigorous ethical analysis and resulting safeguards to address the emerging issues with AI.", "isOpenAccess": true, "url": "https://doi.org/10.54808/jsci.21.04.42"}
{"paperId": "ee532afb014f01bce3be3f16c60b6574c87a2600", "year": 2024, "title": "Evolving Roles and Workflows of Creative Practitioners in the Age of Generative AI", "authors": "Srishti Palani, Gonzalo A. Ramos", "venue": "Creativity & Cognition", "citationCount": 35, "abstract": "Creative practitioners (like designers, software developers, and architects) have started to employ Generative AI models (GenAI) to produce text, images, and assets comparable to those made by people. While HCI research explores specific GenAI models and creativity support tools, little is known about practitioners\u2019 evolving roles and workflows with GenAI models across a project\u2019s stages. This knowledge is key to guide the development of the new generation of Creativity Support Tools. We contribute to this knowledge by employing a triangulated method to capture interviews, videos, and survey responses of creative practitioners reflecting on projects they completed with GenAI. Our observations let us derive a set of factors that capture practitioners\u2019 perceived roles, challenges, benefits, and interaction patterns when creating with GenAI. From these factors, we offer insights and propose design opportunities and priorities that serve to encourage reflection from the wider community of Creativity Support Tools and GenAI stakeholders such as systems creators, researchers, and educators on how to develop systems that meet the needs of creatives in human-centered ways.", "isOpenAccess": false, "url": ""}
{"paperId": "df5418c0fcec2f3701b9ebcf95122b1d60b21cb3", "year": 2025, "title": "World and Human Action Models towards gameplay ideation", "authors": "A. Kanervisto, David Bignell, Linda Yilin Wen, Martin Grayson, Raluca Georgescu, Sergio Valcarcel Macua, Shan Zheng Tan, Tabish Rashid, Tim Pearce, Yuhan Cao, Abdelhak Lemkhenter, Chentian Jiang, Gavin Costello, Gunshi Gupta, Marko Tot, Shu Ishida, Tarun Gupta, Udit Arora, Ryen W. White, Sam Devlin, Cecily Morrison, Katja Hofmann", "venue": "Nature", "citationCount": 35, "abstract": "Generative artificial intelligence (AI) has the potential to transform creative industries through supporting human creative ideation\u2014the generation of new ideas1, 2, 3, 4\u20135. However, limitations in model capabilities raise key challenges in integrating these technologies more fully into creative practices. Iterative tweaking and divergent thinking remain key to enabling creativity support using technology6,7, yet these practices are insufficiently supported by state-of-the-art generative AI models. Using game development as a lens, we demonstrate that we can make use of an understanding of user needs to drive the development and evaluation of generative AI models in a way that aligns with these creative practices. Concretely, we introduce a state-of-the-art generative model, the World and Human Action Model (WHAM), and show that it can generate consistent and diverse gameplay sequences and persist user modifications\u2014three capabilities that we identify as being critical for this alignment. In contrast to previous approaches to creativity support tools that required manually defining or extracting structure for relatively narrow domains, generative AI models can learn relevant structure from available data, opening the potential for a much broader range of applications. A state-of-the-art generative artificial intelligence model of a video game is introduced to allow the support of human creative ideation, with the analysis of user study data highlighting three necessary capabilities, namely, consistency, diversity and persistency.", "isOpenAccess": true, "url": "https://doi.org/10.1038/s41586-025-08600-3"}
{"paperId": "d8a68d8935ee259e06a52f737ba745d7d0439e36", "year": 2024, "title": "Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data", "authors": "Nahema Marchal, Rachel Xu, Rasmi Elasmar, Iason Gabriel, Beth Goldberg, William Isaac", "venue": "arXiv.org", "citationCount": 35, "abstract": "Generative, multimodal artificial intelligence (GenAI) offers transformative potential across industries, but its misuse poses significant risks. Prior research has shed light on the potential of advanced AI systems to be exploited for malicious purposes. However, we still lack a concrete understanding of how GenAI models are specifically exploited or abused in practice, including the tactics employed to inflict harm. In this paper, we present a taxonomy of GenAI misuse tactics, informed by existing academic literature and a qualitative analysis of approximately 200 observed incidents of misuse reported between January 2023 and March 2024. Through this analysis, we illuminate key and novel patterns in misuse during this time period, including potential motivations, strategies, and how attackers leverage and abuse system capabilities across modalities (e.g. image, text, audio, video) in the wild.", "isOpenAccess": false, "url": ""}
{"paperId": "c9fe3616130adfce3e361ccb6eb23a120f4cd510", "year": 2023, "title": "Perceptions and detection of AI use in manuscript preparation for academic journals", "authors": "Nir Chemaya, Daniel Martin", "venue": "PLoS ONE", "citationCount": 35, "abstract": "The rapid advances in Generative AI tools have produced both excitement and worry about how AI will impact academic writing. However, little is known about what norms are emerging around AI use in manuscript preparation or how these norms might be enforced. We address both gaps in the literature by conducting a survey of 271 academics about whether it is necessary to report ChatGPT use in manuscript preparation and by running GPT-modified abstracts from 2,716 published papers through a leading AI detection software to see if these detectors can detect different AI uses in manuscript preparation. We find that most academics do not think that using ChatGPT to fix grammar needs to be reported, but detection software did not always draw this distinction, as abstracts for which GPT was used to fix grammar were often flagged as having a high chance of being written by AI. We also find disagreements among academics on whether more substantial use of ChatGPT to rewrite text needs to be reported, and these differences were related to perceptions of ethics, academic role, and English language background. Finally, we found little difference in their perceptions about reporting ChatGPT and research assistant help, but significant differences in reporting perceptions between these sources of assistance and paid proofreading and other AI assistant tools (Grammarly and Word). Our results suggest that there might be challenges in getting authors to report AI use in manuscript preparation because (i) there is not uniform agreement about what uses of AI should be reported and (ii) journals might have trouble enforcing nuanced reporting requirements using AI detection tools.", "isOpenAccess": true, "url": "https://doi.org/10.1371/journal.pone.0304807"}
{"paperId": "c724da2469bba1b98e9aec9deb4c7073d624f308", "year": 2023, "title": "ChatGPT, Large Language Models, and Generative AI as Future Augments of Surgical Cancer Care", "authors": "MD A. N. Kothari", "venue": "Annals of Surgical Oncology", "citationCount": 35, "abstract": null, "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1245/s10434-023-13442-2.pdf"}
{"paperId": "c5885868c0e35ab03420007ea921669746c33861", "year": 2024, "title": "AI Art is Theft: Labour, Extraction, and Exploitation: Or, On the Dangers of Stochastic Pollocks", "authors": "T. Goetze", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 35, "abstract": "Since the launch of applications such as dall\u2022e, Midjourney, and Stable Diffusion, generative artificial intelligence has been controversial as a tool for creating artwork. Some writers have presented worries about these technologies as harbingers of fully automated futures to come, but more pressing is the impact of generative AI on creative labour in the present. Already, business leaders have begun replacing human artistic labour with AI-generated images. In response, the artistic community has launched a protest movement, which argues that AI image generation is a kind of theft. This paper analyzes, substantiates, and critiques these arguments, concluding that AI image generators involve an unethical kind of labour theft. If correct, many other AI applications also rely upon theft.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658898"}
{"paperId": "c308839fa3f732b6fe647a93cda5472597a0919d", "year": 2024, "title": "Who on Earth Is Using Generative AI ?", "authors": "Yan Liu, He Wang", "venue": "World Development", "citationCount": 35, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "be0180a415861fe85626e7080caeda9fc339823e", "year": 2024, "title": "When AIs become oracles: generative artificial intelligence, anticipatory urban governance, and the future of cities", "authors": "Federico Cugurullo, Ying Xu", "venue": "Policy & Society", "citationCount": 35, "abstract": "\n Generative Artificial Intelligence (AI) is boosting anticipatory forms of governance, through which state actors seek to predict the future and strategically intervene in the present. In this context, city brains represent an emerging type of generative AI currently employed in urban governance and public policy in a growing number of cities. City brains are large-scale AIs residing in vast digital urban platforms, which manage multiple urban domains including transport, safety, health, and environmental monitoring. They use Large Language Models (LLMs) to generate visions of urban futures: visions that are in turn used by policymakers to generate new urban policies. In this paper, we advance a twofold contribution. Theoretically, we develop a critical theory of anticipatory governance in the age of generative AI. More specifically, we focus on technocratic approaches to anticipatory governance, to explain how the act of governing extends into the future by means of predictive AI technology. Our approach is critical in order to expose the dangers that the use of AI (generative AI, in particular) in urban governance poses, and to identify their causes. These dangers include the formation of a policy process that, under the influence of unintelligible LLMs, risks losing transparency and thus accountability, and the marginalization of human stakeholders (citizens, in particular) as the role of AI in the management of cities keeps growing and governance begins to turn posthuman. Empirically, we critically examine an existing city brain project under development in China and ground our critical theory in a real-life example.", "isOpenAccess": false, "url": ""}
{"paperId": "bce3f9ca6b711b727944b6df3e71c2f42b2586e0", "year": 2024, "title": "A comparative vignette study: Evaluating the potential role of a generative AI model in enhancing clinical decision\u2010making in nursing", "authors": "M. Saban, Ilana Dubovi", "venue": "Journal of Advanced Nursing", "citationCount": 35, "abstract": "Abstract Aim This study explores the potential of a generative artificial intelligence tool (ChatGPT) as clinical support for nurses. Specifically, we aim to assess whether ChatGPT can demonstrate clinical decision\u2010making equivalent to that of expert nurses and novice nursing students. This will be evaluated by comparing ChatGPT responses to clinical scenarios to those of nurses on different levels of experience. Design This is a cross\u2010sectional study. Methods Emergency room registered nurses (i.e. experts; n\u2009=\u200930) and nursing students (i.e. novices; n\u2009=\u200938) were recruited during March\u2013April 2023. Clinical decision\u2010making was measured using three validated clinical scenarios involving an initial assessment and reevaluation. Clinical decision\u2010making aspects assessed were the accuracy of initial assessments, the appropriateness of recommended tests and resource use and the capacity to reevaluate decisions. Performance was also compared by timing response generations and word counts. Expert nurses and novice students completed online questionnaires (via Qualtrics), while ChatGPT responses were obtained from OpenAI. Results Concerning aspects of clinical decision\u2010making and compared to novices and experts: (1) ChatGPT exhibited indecisiveness in initial assessments; (2) ChatGPT tended to suggest unnecessary diagnostic tests; (3) When new information required re\u2010evaluation, ChatGPT responses demonstrated inaccurate understanding and inappropriate modifications. In terms of performance, the mean number of words utilized in ChatGPT answers was 27\u201341 times greater than that utilized by both experts and novices; and responses were provided approximately 4 times faster than those of novices and twice faster than expert nurses. ChatGPT responses maintained logical structure and clarity. Conclusions A generative AI tool demonstrated indecisiveness and a tendency towards over\u2010triage compared to human clinicians. Impact The study shows that it is important to approach the implementation of ChatGPT as a nurse's digital assistant with caution. More study is needed to optimize the model's training and algorithms to provide accurate healthcare support that aids clinical decision\u2010making. Reporting method This study adhered to relevant EQUATOR guidelines for reporting observational studies. Patient or public contribution Patients were not directly involved in the conduct of this study.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jan.16101"}
{"paperId": "ba8ddf95dc9a3e84acc040b60340898e9e42d93e", "year": 2024, "title": "Higher Education Faculty Perceptions of ChatGPT and the Influencing Factors: A Sentiment Analysis of X", "authors": "Yoseph Z. Mamo, Helen Crompton, D. Burke, Christine Nickel", "venue": "TechTrends", "citationCount": 35, "abstract": "ChatGPT, an AI chatbot developed by OpenAI, was released in November 2022, sparking a significant surge in global awareness and utilization of generative AI across various domains. Although recent studies have acknowledged the significance of ChatGPT in the education sector, they have yet to focus on exploring faculty attitudes toward ChatGPT. We gathered a comprehensive corpus of tweets containing \u201c#ChatGPT\u201d and \u201c#highered\u201d between November 30th, 2022, and April 30th, 2023. We analyzed data by triangulating VADER, NRC lexicon, and ground coding. Findings suggest that 40% of the expressed sentiments were positive, 51% were neutral, and 9% were negative. The study also revealed the diverse range of emotions held by higher education faculty regarding ChatGPT, with trust and joy being the most prevalent positive sentiments and fear and anger being the most prevalent negative sentiments. This study shed light on faculty members\u2019 perceptions of ChatGPT, contributing to a better understanding of the impact, emotions, and incorporation of ChatGPT in the higher education sector.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11528-024-00954-1.pdf"}
{"paperId": "b14bdd699cce2a7a7d894c3a020f0c1b1c798758", "year": 2023, "title": "PolyDiffuse: Polygonal Shape Reconstruction via Guided Set Diffusion Models", "authors": "Jiacheng Chen, Ruizhi Deng, Yasutaka Furukawa", "venue": "Neural Information Processing Systems", "citationCount": 35, "abstract": "This paper presents PolyDiffuse, a novel structured reconstruction algorithm that transforms visual sensor data into polygonal shapes with Diffusion Models (DM), an emerging machinery amid exploding generative AI, while formulating reconstruction as a generation process conditioned on sensor data. The task of structured reconstruction poses two fundamental challenges to DM: 1) A structured geometry is a ``set'' (e.g., a set of polygons for a floorplan geometry), where a sample of $N$ elements has $N!$ different but equivalent representations, making the denoising highly ambiguous; and 2) A ``reconstruction'' task has a single solution, where an initial noise needs to be chosen carefully, while any initial noise works for a generation task. Our technical contribution is the introduction of a Guided Set Diffusion Model where 1) the forward diffusion process learns guidance networks to control noise injection so that one representation of a sample remains distinct from its other permutation variants, thus resolving denoising ambiguity; and 2) the reverse denoising process reconstructs polygonal shapes, initialized and directed by the guidance networks, as a conditional generation process subject to the sensor data. We have evaluated our approach for reconstructing two types of polygonal shapes: floorplan as a set of polygons and HD map for autonomous cars as a set of polylines. Through extensive experiments on standard benchmarks, we demonstrate that PolyDiffuse significantly advances the current state of the art and enables broader practical applications.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2306.01461"}
{"paperId": "a0cfa2dc97773cbf223fd611349a0529eeedb8d0", "year": 2024, "title": "Teachers' motivation and engagement to harness generative AI for teaching and learning: The role of contextual, occupational, and background factors", "authors": "Rebecca J. Collie, Andrew J. Martin", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 35, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100224"}
{"paperId": "9e38c554a2d681ba0e81bfca7762f4a5e4b1895b", "year": 2024, "title": "Unveiling Insights: A Bibliometric Analysis of Artificial Intelligence in Teaching", "authors": "Malinka Ivanova, G. Grosseck, Carmen Holotescu", "venue": "Informatics", "citationCount": 35, "abstract": "The penetration of intelligent applications in education is rapidly increasing, posing a number of questions of a different nature to the educational community. This paper is coming to analyze and outline the influence of artificial intelligence (AI) on teaching practice which is an essential problem considering its growing utilization and pervasion on a global scale. A bibliometric approach is applied to outdraw the \u201cbig picture\u201d considering gathered bibliographic data from scientific databases Scopus and Web of Science. Data on relevant publications matching the query \u201cartificial intelligence and teaching\u201d over the past 5 years have been researched and processed through Biblioshiny in R environment in order to establish a descriptive structure of the scientific production, to determine the impact of scientific publications, to trace collaboration patterns and to identify key research areas and emerging trends. The results point out the growth in scientific production lately that is an indicator of increased interest in the investigated topic by researchers who mainly work in collaborative teams as some of them are from different countries and institutions. The identified key research areas include techniques used in educational applications, such as artificial intelligence, machine learning, and deep learning. Additionally, there is a focus on applicable technologies like ChatGPT, learning analytics, and virtual reality. The research also explores the context of application for these techniques and technologies in various educational settings, including teaching, higher education, active learning, e-learning, and online learning. Based on our findings, the trending research topics can be encapsulated by terms such as ChatGPT, chatbots, AI, generative AI, machine learning, emotion recognition, large language models, convolutional neural networks, and decision theory. These findings offer valuable insights into the current landscape of research interests in the field.", "isOpenAccess": true, "url": "https://www.mdpi.com/2227-9709/11/1/10/pdf?version=1708868690"}
{"paperId": "7a923d32c88d44fdadeb2b86c66685678bc9d4b1", "year": 2024, "title": "The Impact of Generative AI on Artists", "authors": "Reishiro Kawakami, Sukrit Venkatagiri", "venue": "Creativity & Cognition", "citationCount": 35, "abstract": "Generative AI has the potential to augment artists\u2019 creative expression, while simultaneously harming their professions through unethical data collection practices and replacement of human labor. We conducted a thematic analysis of social media posts to understand artists\u2019 perceptions and experiences of the direct and indirect impact of generative AI on their profession. Our findings also highlight growing public distrust toward artists amidst the rise of generative AI, with accusations of using AI tools leading to stress and fear of unemployment. Our study provides valuable insights into the complex interplay between artists, generative AI, and the public. We discuss potential protective measures for artists, including regulatory interventions and opt-in/out data collection, and explore future impacts of generative AI on artists\u2019 creative processes.", "isOpenAccess": false, "url": ""}
{"paperId": "7334967da38a0e9d6f0719d0a0e1ffa3403140b3", "year": 2024, "title": "Deep Lead Optimization: Leveraging Generative AI for Structural Modification", "authors": "Odin Zhang, Haitao Lin, Hui Zhang, Huifeng Zhao, Yufei Huang, Yuansheng Huang, Dejun Jiang, Chang-Yu Hsieh, P. Pan, Tingjun Hou", "venue": "Journal of the American Chemical Society", "citationCount": 35, "abstract": "The integration of deep learning-based molecular generation models into drug discovery has garnered significant attention for its potential to expedite the development process. Central to this is lead optimization, a critical phase where existing molecules are refined into viable drug candidates. As various methods for deep lead optimization continue to emerge, it is essential to classify these approaches more clearly. We categorize lead optimization methods into two main types: goal-directed and structure-directed. Our focus is on structure-directed optimization, which, while highly relevant to practical applications, is less explored compared to goal-directed methods. Through a systematic review of conventional computational approaches, we identify four tasks specific to structure-directed optimization: fragment replacement, linker design, scaffold hopping, and side-chain decoration. We discuss the motivations, training data construction, and current developments for each of these tasks. Additionally, we use classical optimization taxonomy to classify both goal-directed and structure-directed methods, highlighting their challenges and future development prospects. Finally, we propose a reference protocol for experimental chemists to effectively utilize Generative AI (GenAI)-based tools in structural modification tasks, bridging the gap between methodological advancements and practical applications.", "isOpenAccess": false, "url": ""}
{"paperId": "6edd83984242a0701b2d7538ec484695c5e34eb0", "year": 2023, "title": "Amodal Completion via Progressive Mixed Context Diffusion", "authors": "Katherine Xu, Lingzhi Zhang, Jianbo Shi", "venue": "Computer Vision and Pattern Recognition", "citationCount": 35, "abstract": "Our brain can effortlessly recognize objects even when partially hidden from view. Seeing the visible of the hidden is called amodal completion; however, this task remains a challenge for generative AI despite rapid progress. We propose to sidestep many of the difficulties of existing approaches, which typically involve a two-step process of predicting amodal masks and then generating pixels. Our method involves thinking outside the box, literally! We go outside the object bounding box to use its context to guide a pretrained diffusion inpainting model, and then progressively grow the occluded object and trim the extra background. We overcome two technical challenges: 1) how to be free of unwanted co-occurrence bias, which tends to regenerate similar occluders, and 2) how to judge if an amodal completion has succeeded. Our amodal completion method exhibits improved photorealistic completion results compared to existing approaches in numerous successful completion cases. And the best part? It doesn't require any special training or fine-tuning of models.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2312.15540"}
{"paperId": "6d6f80aaf63dc05760a9cc2bdc3bb344f539e11a", "year": 2023, "title": "The Acceptance and Diffusion of Generative Artificial Intelligence in Education: A Literature Review", "authors": "Ahmet Baytak", "venue": "Current Perspectives in Educational Research", "citationCount": 35, "abstract": "The last century can be considered the era of technology. There are always new technologies blooming. The time span between the developments of technology shortened. The acceptance and adoption of each new technology can be different. However, the technology acceptance model (TAM) and diffusion of innovation theory (DOI) propose that there are some patterns for usage of any new technologies. Meanwhile, there is tremendous interest on artificial intelligence (AI) technologies after the ChatGPT trend. Thus, the purpose of is study is to explore the most current literature review of the acceptance and adoption of ChatGPT and Google Bard type Large Language Models (LLM) and generative AI by educational settings. The study used literature review methodology. The review was a systematic perspective which going through the study on acceptance and adoption of some popular technology in education settings in the current days. The review of the literature shows that there is an acceptance of the models in education but with doubts.\u00a0\u00a0", "isOpenAccess": true, "url": "https://cuperjournal.org/index.php/cuper/article/download/7/7"}
{"paperId": "6b5fab072e5733752627c77cf9b750b083e08c36", "year": 2023, "title": "The Power of Generative AI to Augment for Enhanced Skin Cancer Classification: A Deep Learning Approach", "authors": "Mudassir Saeed, Asma Naseer, Hassan Masood, Shafiq ur Rehman, Volker Gruhn", "venue": "IEEE Access", "citationCount": 35, "abstract": "Skin cancer, particularly the malignant melanoma subtype, is widely recognized as a highly lethal form of cancer characterized by abnormal melanocyte cell growth. However, diagnosing and classifying skin lesions, as well as automatically recognizing malignant tumors from dermoscopy images, present significant challenges. To address this challenge, our study employs variants of Convolutional Neural Networks (CNNs) to effectively diagnose and classify various skin lesion types using the latest benchmark datasets ISIC 2019 and 2020. The dataset underwent rigorous preprocessing, which involves employing advanced Generative Artificial Intelligence (AI) techniques i.e., Generative Adversarial Networks (GANs) and Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN), for augmentation. These generative techniques are carefully evaluated and compared for their effectiveness. Our CNN-based approach involves aggregating results from multiple transfer learning models, including VGG16, VGG19, SVM along with a hybrid model in combination of VGG19 and SVM. On ISIC 2019, we have achieved promising accuracies of 92% for VGG16 and 93% for VGG19. Notably, the hybrid VGG19+SVM model exhibits the highest accuracy of 96%. On ISIC 2020, VGG16, VGG19, and SVM achieves accuracies of 90%, 92%, and 92%, respectively. Our findings underscore the potential of generative AI for augmentation, and the efficacy of CNN-based transfer learning models in improving skin cancer classification accuracy.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10318035.pdf"}
{"paperId": "51b19e85178c1894f9ce08b72cc3a938721af6e1", "year": 2023, "title": "Generative AI for Learning: Investigating the Potential of Learning Videos with Synthetic Virtual Instructors", "authors": "Daniel Leiker, Ashley Ricker Gyllen, Ismail Eldesouky, Mutlu Cukurova", "venue": "International Conference on Artificial Intelligence in Education", "citationCount": 35, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "4d9572d6491aa0431eb68f3c15607bc849ae22a5", "year": 2023, "title": "Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?", "authors": "Zhengyue Zhao, Jinhao Duan, Kaidi Xu, Chenan Wang, Rui Guo, Xing Hu", "venue": "Computer Vision and Pattern Recognition", "citationCount": 35, "abstract": "Stable Diffusion has established itself as a foundation model in generative AI artistic applications, receiving widespread research and application. Some recent fine-tuning methods have made it feasible for individuals to implant personalized concepts onto the basic Stable Diffusion model with minimal computational costs on small datasets. However, these innovations have also given rise to issues like facial privacy forgery and artistic copyright infringement. In recent studies, researchers have explored the addition of imperceptible adversarial perturbations to images to prevent potential unauthorized exploitation and infringements when personal data is used for fine-tuning Stable Dif-fusion. Although these studies have demonstrated the ability to protect images, it is essential to consider that these methods may not be entirely applicable in real-world scenarios. In this paper, we systematically evaluate the use of perturbations to protect images within a practical threat model. The results suggest that these approaches may not be sufficient to safeguard image privacy and copyright effectively. Furthermore, we introduce a purification method capable of removing protected perturbations while preserving the original image structure to the greatest extent possible. Experiments reveal that Stable Diffusion can effectively learn from purified images over all protective methods1.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2312.00084"}
{"paperId": "45714fd947e5ba818b91a6c8626863369d7f33e7", "year": 2023, "title": "Time to Move Beyond the ASWB Licensing Exams: Can Generative Artificial Intelligence Offer a Way Forward for Social Work?", "authors": "Bryan Victor, Sheryl Kubiak, B. Angell, Brian E Perron", "venue": "Research on social work practice", "citationCount": 35, "abstract": "Social work scholars have long questioned the validity and utility of the Association of Social Work Boards (ASWB) licensing exams. Data released in 2022 revealed severe disparities in pass rates based on race, age, and language, exacerbating these concerns. In this paper, we explore the potential of generative artificial intelligence (AI) such as ChatGPT to address core problems of the ASWB exams, including the use of a multiple-choice format that does not reflect real-world social work practice. To assess its social work reasoning, we used ChatGPT to answer ASWB-developed practice questions for the Bachelors, Masters, and Clinical exams. ChatGPT scored 76%, 80%, and 64%, respectively, and identified additional validity challenges. Based on this performance, we provide a proof-of-concept for how generative AI might move us toward a more valid and equitable exam. While we strongly support licensure requirements, state regulators and legislators should temporarily suspend the use of the ASWB exams for this purpose.", "isOpenAccess": true, "url": "https://journals.sagepub.com/doi/pdf/10.1177/10497315231166125"}
{"paperId": "3fa00e6eae6083ef312a95e7ce8eb01bc9ecbefd", "year": 2024, "title": "Generative Artificial Intelligence Biases, Limitations and Risks in Nuclear Medicine: An Argument for Appropriate Use Framework and Recommendations.", "authors": "G. Currie, K. E. Hawk, Eric M. Rohren", "venue": "Seminars in nuclear medicine", "citationCount": 35, "abstract": "Generative artificial intelligence (AI) algorithms for both text-to-text and text-to-image applications have seen rapid and widespread adoption in the general and medical communities. While limitations of generative AI have been widely reported, there remain valuable applications in patient and professional communities. Here, the limitations and biases of both text-to-text and text-to-image generative AI are explored using purported applications in medical imaging as case examples. A direct comparison of the capabilities of four common text-to-image generative AI algorithms is reported and recommendations for the most appropriate use, DALL-E 3, justified. The risks use and biases are outlined, and appropriate use guidelines framed for use of generative AI in nuclear medicine. Generative AI text-to-text and text-to-image generation includes inherent biases, particularly gender and ethnicity, that could misrepresent nuclear medicine. The assimilation of generative AI tools into medical education, image interpretation, patient education, health promotion and marketing in nuclear medicine risks propagating errors and amplification of biases. Mitigation strategies should reside inside appropriate use criteria and minimum standards for quality and professionalism for the application of generative AI in nuclear medicine.", "isOpenAccess": true, "url": "https://doi.org/10.1053/j.semnuclmed.2024.05.005"}
{"paperId": "38d72fd6a0b5ebd0f24b18376e1077438b4b7fec", "year": 2024, "title": "Translating musculoskeletal radiology reports into patient-friendly summaries using ChatGPT-4", "authors": "Ian J Kuckelman, Karla Wetley, Paul H. Yi, Andrew B. Ross", "venue": "Skeletal Radiology", "citationCount": 35, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "383dd48c83bd012ef1f59ad637d7d17dc39dcdb3", "year": 2024, "title": "Untangling the Relationship Between AI\u2010Mediated Informal Digital Learning of English (AI\u2010IDLE), foreign Language Enjoyment and the Ideal L2 Self: Evidence From Chinese University EFL Students", "authors": "G. Liu, M. Zou, Ali Soyoof, M. Chiu", "venue": "European Journal of Education", "citationCount": 35, "abstract": "Artificial intelligence\u2010mediated informal digital learning of English (AI\u2010IDLE) might strengthen second language (L2) learners' motivational self\u2010concept (e.g., the ideal L2 self) and enhance their foreign language enjoyment (FLE) by enabling them to build confidence, engagement, and willingness to practice their English skills in a self\u2010directed, instant feedback, and non\u2010judgemental learning environment. In our explanatory mixed\u2010method study, we collected questionnaire data from 299 Chinese undergraduate English as a foreign language (EFL) learners and interviewed 12 of them. Structural equation modelling showed that students who participated in AI\u2010IDLE more often reported a clearer ideal L2 self and greater FLE, but those with a greater ideal L2 self did not report more FLE. In addition, gender did not moderate the impact of AI\u2010IDLE on FLE. Analysis of the interview data not only corroborated the quantitative results but also highlighted that while EFL learners can acquire a sense of FLE and vivid ideal L2 selves as they agentively negotiate the affordances of generative AI for informal language learning purposes, the sense of FLE and motivational force may shift across contexts to shape their continued investment in AI\u2010IDLE practices. By comparing and integrating the quantitative and qualitative insights, this study highlights the pedagogical potential of AI\u2010IDLE activities that can strengthen EFL learners' motivation, enjoyment, and commitment to English learning.", "isOpenAccess": true, "url": "https://doi.org/10.1111/ejed.12846"}
{"paperId": "24cb3df34d2c90603e4c0116307ecbfbcfcbb0ce", "year": 2024, "title": "Machine Unlearning Doesn't Do What You Think: Lessons for Generative AI Policy, Research, and Practice", "authors": "A. F. Cooper, Christopher A. Choquette-Choo, Miranda Bogen, Matthew Jagielski, Katja Filippova, K. Liu, Alexandra Chouldechova, Jamie Hayes, Yangsibo Huang, Niloofar Mireshghallah, Ilia Shumailov, Eleni Triantafillou, Peter Kairouz, N. Mitchell, Percy Liang, Daniel E. Ho, Yejin Choi, Sanmi Koyejo, Fernando Delgado, James Grimmelmann, Vitaly Shmatikov, Christopher De Sa, Solon Barocas, Amy B. Cyphert, Mark A. Lemley, Danah Boyd, Jennifer Wortman Vaughan, M. Brundage, David Bau, Seth Neel, Abigail Z. Jacobs, Andreas Terzis, Hanna Wallach, Nicolas Papernot, Katherine Lee", "venue": "arXiv.org", "citationCount": 35, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "1c1b83df13de4334e48a4c2039bc7ddfa374c486", "year": 2023, "title": "ChatGPT for PLC/DCS Control Logic Generation", "authors": "Heiko Koziolek, Sten Gruener, Virendra Ashiwal", "venue": "IEEE International Conference on Emerging Technologies and Factory Automation", "citationCount": 35, "abstract": "Large language models (LLMs) providing generative AI have become popular to support software engineers in creating, summarizing, optimizing, and documenting source code. It is still unknown how LLMs can support control engineers using typical control programming languages in programming tasks. Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source code generation but did not yet tackle control logic programming. A key contribution of this paper is an exploratory study, for which we created 100 LLM prompts in 10 representative categories to analyze control logic generation for of PLCs and DCS from natural language. We tested the prompts by generating answers with ChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3 Structured Text code in many cases and demonstrated useful reasoning skills that could boost control engineer productivity. Our prompt collection is the basis for a more formal LLM benchmark to test and compare such models for control logic generation.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.15809"}
{"paperId": "0fe809899a3c367f02afb271756962302c457718", "year": 2024, "title": "Envisioning the Applications and Implications of Generative AI for News Media", "authors": "Sachita Nishal, N. Diakopoulos", "venue": "arXiv.org", "citationCount": 35, "abstract": "This article considers the increasing use of algorithmic decision-support systems and synthetic media in the newsroom, and explores how generative models can help reporters and editors across a range of tasks from the conception of a news story to its distribution. Specifically, we draw from a taxonomy of tasks associated with news production, and discuss where generative models could appropriately support reporters, the journalistic and ethical values that must be preserved within these interactions, and the resulting implications for design contributions in this area in the future. Our essay is relevant to practitioners and researchers as they consider using generative AI systems to support different tasks and workflows.", "isOpenAccess": false, "url": ""}
{"paperId": "0ecf2395e920fac80321d9bf2e32f0465bf4986c", "year": 2024, "title": "Factors Influencing University Students' Behavioural Intention to Use Generative Artificial Intelligence for Educational Purposes Based on a Revised UTAUT2 Model", "authors": "Xin Tang, Zhiqiang Yuan, Shaojun Qu", "venue": "Journal of Computer Assisted Learning", "citationCount": 35, "abstract": "Generative artificial intelligence (AI) represents a significant technological leap, with platforms like OpenAI's ChatGPT and Baidu's Ernie Bot at the forefront of innovation. This technology has seen widespread adoption across various sectors of society and is anticipated to revolutionise the educational landscape, especially in the domain of tertiary education. However, there is a gap in understanding factors influencing university students' behavioural intention to use generative AI, leading to hesitation in its adoption.The primary objective of this study was to investigate the factors that influence university students' behavioural intention to engage with and utilise generative AI. The study sought to delve into the fundamental reasons and obstacles that university students encounter when contemplating the adoption of this technology for their academic endeavours.The study used a quantitative research design, utilising a revised version of the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model. Data were collected from a sample of 380 university students in Changsha, the capital city of Hunan in China. Partial least squares structural equation modelling (PLS\u2010SEM) was used to analyse the relationships between the variables of the model, which included performance expectancy (PE), effort expectancy (EE), social influence (SI), facilitating conditions (FC), learning value, habit and behavioural intention.The analysis revealed that PE and EE have a direct impact on learning value. Additionally, SI and FC were found to directly affect the formation of habit. Among these factors, learning value emerged as the most potent predictor of university students' behavioural intention to use generative AI. Habit also demonstrated a significant, albeit smaller, effect on behavioural intention.The study's findings underscore the importance of learning value in driving the adoption of generative AI among university students. Efforts to enhance the learning value of generative AI could significantly increase its uptake in higher education. Furthermore, the role of habit, while less pronounced, suggests that consistent exposure and use can foster a greater inclination towards generative AI. These insights provide a foundation for targeted interventions aimed at improving the integration and application of generative AI within educational settings. Stakeholders, including educators, policymakers and designers of generative AI, can leverage these findings to create an environment conducive to the adoption and effective use of generative AI in higher education.", "isOpenAccess": false, "url": ""}
{"paperId": "039c5c3ef9da933f30a083766d00003385e63e7f", "year": 2024, "title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models", "authors": "Hamideh Ghanadian, Isar Nejadgholi, Hussein Al Osman", "venue": "IEEE Access", "citationCount": 35, "abstract": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10413447.pdf"}
{"paperId": "eb3ed13de8e4bb7d13a9de6dacee8f4ea5cd0c85", "year": 2024, "title": "CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming", "authors": "Xinying Hou, Zihan Wu, Xu Wang, B. Ericson", "venue": "ACM Conference on Learning @ Scale", "citationCount": 34, "abstract": "Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2401.12125"}
{"paperId": "e96f0bfaf89e1c9a979ebbbd06f3c8e1f0b5d19c", "year": 2024, "title": "Balancing Innovation and Regulation in the Age of Generative Artificial Intelligence", "authors": "Y. Wu, Xukang Wang", "venue": "Journal of Information Policy", "citationCount": 34, "abstract": "\n The emergence of generative artificial intelligence (AI), exemplified by models like ChatGPT, presents both opportunities and challenges. As these technologies become increasingly integrated into various aspects of society, the need for a harmonized legal framework to address the associated risks becomes crucial. This article presents a comprehensive analysis of the disruptive impact of generative AI, the legal risks of AI-generated content, and the governance strategies needed to strike a balance between innovation and regulation. Employing a three-pronged methodology\u2014literature review, doctrinal legal analysis, and case study integration\u2014the study examines the current legal landscape; synthesizes scholarly works on the technological, ethical, and socioeconomic implications of generative AI; and illustrates practical challenges through real-world case studies. The article assesses the strengths and limitations of US governance strategies for AI and proposes a harmonized legal framework emphasizing international collaboration, proactive legislation, and the establishment of a dedicated regulatory body. By engaging diverse stakeholders and identifying critical gaps in current research, the study contributes to the development of a legal framework that upholds ethical principles, protects individual rights, and fosters responsible innovation in the age of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "d9ec03d7ffec0d1af2776557201c3d3f7ebe2e23", "year": 2024, "title": "Why Generative AI Literacy, Why Now and Why it Matters in the Educational Landscape? Kings, Queens and GenAI Dragons", "authors": "Aras Bozkurt", "venue": "Open Praxis", "citationCount": 34, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.55982/openpraxis.16.3.739"}
{"paperId": "c57353a72f4e083f783e88b92ab1afc03e4bd381", "year": 2023, "title": "Automated Distractor and Feedback Generation for Math Multiple-choice Questions via In-context Learning", "authors": "Hunter McNichols, Wanyong Feng, Jaewook Lee, Alexander Scarlatos, Digory Smith, Simon Woodhead, Andrew S. Lan", "venue": "", "citationCount": 34, "abstract": "Multiple-choice questions (MCQs) are ubiquitous in almost all levels of education since they are easy to administer, grade, and are a reliable form of assessment. An important aspect of MCQs is the distractors, i.e., incorrect options that are designed to target specific misconceptions or insufficient knowledge among students. To date, the task of crafting high-quality distractors has largely remained a labor-intensive process for teachers and learning content designers, which has limited scalability. In this work, we explore the task of automated distractor and corresponding feedback message generation in math MCQs using large language models. We establish a formulation of these two tasks and propose a simple, in-context learning-based solution. Moreover, we propose generative AI-based metrics for evaluating the quality of the feedback messages. We conduct extensive experiments on these tasks using a real-world MCQ dataset. Our findings suggest that there is a lot of room for improvement in automated distractor and feedback generation; based on these findings, we outline several directions for future work.", "isOpenAccess": false, "url": ""}
{"paperId": "a5b0f508356b4ab0d2d4966e1015f993f9c8620a", "year": 2024, "title": "A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design", "authors": "Prajish Prasad, A. Sane", "venue": "Technical Symposium on Computer Science Education", "citationCount": 34, "abstract": "Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process. On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3626252.3630828"}
{"paperId": "99a7f1485a2a370339704c8bd351bb173a8a4601", "year": 2023, "title": "Generative AI Considered Harmful", "authors": "J. Fischer", "venue": "International Conference on Conversational User Interfaces", "citationCount": 34, "abstract": "The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs\u2014harmful and otherwise\u2014are produced, by whom, to what end, and with what consequences on societies.", "isOpenAccess": true, "url": "https://nottingham-repository.worktribe.com/preview/24080400/Provocation_CUI23%20%283%29.pdf"}
{"paperId": "9208c04bf16e7d769a07766d778610543f83c98e", "year": 2024, "title": "AI-powered EFL pedagogy: Integrating generative AI into university teaching preparation through UTAUT and activity theory", "authors": "M. Zaim, Safnil Arsyad, Budi Waluyo, Havid Ardi, Muhd. Al Hafizh, Muflihatuz Zakiyah, Widya Syafitri, Ahmad Nusi, Mei Hardiah", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 34, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "8f7f2cb5829d62ab4e21347f2ea1662b12220ecc", "year": 2024, "title": "A Structural equation modeling analysis of generative AI chatbots adoption among students and educators in higher education", "authors": "A. Saihi, Mohamed Ben-Daya, M. Hariga, Rami A\u015bad", "venue": "Computers and Education: Artificial Intelligence", "citationCount": 34, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.caeai.2024.100274"}
{"paperId": "8bdadc5c26d719e4372d5911aa7e6961e98f45e0", "year": 2024, "title": "University policies on generative AI in Asia: promising practices, gaps, and future directions", "authors": "Yun Dai, Sichen Lai, C. Lim, Angpeng Liu", "venue": "Journal of Asian Public Policy", "citationCount": 34, "abstract": "ABSTRACT Considering the opportunities and challenges raised by generative AI (GenAI) technologies, many universities have been developing policies to guide the integration of GenAI in their academic community. Focusing on Asian universities, this paper presents a scoping review of policy development regarding the GenAI integration. Guided by the theoretical framework of technology integration, this study examined the GenAI policies of 30 universities from the QS top 60 Asian universities with inductive content analysis. The review reveals that these policies prioritized text generation applications, student management, and academic integrity, suggesting an effort to uphold traditional academic values and encourage informed adoption. While the universities were at different stages of understanding and managing GenAI, they tended towards a comprehensive approach in formatting their guidance for internal stakeholders and assessment policies. The review also uncovered gaps in policymaking, such as the exclusion of non-academic staff, limited use of evidence-based practices, international misalignments, and a strong adherence to traditional academic paradigms. This scoping review provides a comprehensive and multifaceted overview of policy development in Asian universities, laying the groundwork for global discussions about the role of GenAI in higher education.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/17516234.2024.2379070?needAccess=true"}
{"paperId": "7cce514d89e74ebdab205e0a0cb44080c0d8e0c2", "year": 2024, "title": "Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals", "authors": "Kiduk Kim, Kyungjin Cho, Ryoungwoo Jang, Sunggu Kyung, Soyoung Lee, S. Ham, Edward Choi, G. Hong, Namkug Kim", "venue": "Korean Journal of Radiology", "citationCount": 34, "abstract": "The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential.", "isOpenAccess": true, "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10912493"}
{"paperId": "73c61432f14fbbc3759b3286b83fffd3138d366b", "year": 2024, "title": "Artificial Intelligence Integration: Pedagogical Strategies and Policies at Leading Universities", "authors": "Naifa Alqahtani, Zarina Wafula", "venue": "Innovative Higher Education", "citationCount": 34, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "6a04b7d0206552d7c657a1e673ad7274b7cd9935", "year": 2024, "title": "An Edge-Cloud Collaboration Framework for Generative AI Service Provision With Synergetic Big Cloud Model and Small Edge Models", "authors": "Yuqing Tian, Zhaoyang Zhang, Yuzhi Yang, Zirui Chen, Zhaohui Yang, Richeng Jin, Tony Q. S. Quek, Kai-Kit Wong", "venue": "IEEE Network", "citationCount": 34, "abstract": "Generative artificial intelligence (GenAI) offers various services to users through content creation, which is believed to be one of the most important components in future networks. However, training and deploying big artificial intelligence models (BAIMs) introduces substantial computational and communication overhead. This poses a critical challenge to centralized approaches, due to the need of high-performance computing infrastructure and the reliability, secrecy and timeliness issues in long-distance access of cloud services. Therefore, there is an urging need to decentralize the services, partly moving them from the cloud to the edge and establishing native GenAI services to enable private, timely, and personalized experiences. In this paper, we propose a brand-new bottom-up BAIM architecture with synergetic big cloud model and small edge models, and design a distributed training framework and a task-oriented deployment scheme for efficient provision of native GenAI services. The proposed framework can facilitate collaborative intelligence, enhance adaptability, gather edge knowledge and alleviate edge-cloud burden. The effectiveness of the proposed framework is demonstrated through an image generation use case. Finally, we outline fundamental research directions to fully exploit the collaborative potential of edge and cloud for native GenAI and BAIM applications.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2401.01666"}
{"paperId": "64be356792ffafec7c32ec1904d0d75f112d689d", "year": 2024, "title": "Empowering generative AI through mobile edge computing", "authors": "Laha Ale, Ning Zhang, Scott A. King, Dajiang Chen", "venue": "Nature Reviews Electrical Engineering", "citationCount": 34, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "5af3cc9b9f53dde89b965402fc58b74761a80527", "year": 2024, "title": "Enhancing reflective thinking in STEM education through experiential learning: The role of generative AI as a learning aid", "authors": "Chia-Ju Lin, Hsin\u2010Yu Lee, Wei-Sheng Wang, Yueh-Min Huang, Ting\u2010Ting Wu", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 34, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "52156e29d148f68304ca04c7830d9c82b0d56fa8", "year": 2024, "title": "Generative AI tools can enhance climate literacy but must be checked for biases and inaccuracies", "authors": "C. Atkins, Gina Girgente, M. Shirzaei, Junghwan Kim", "venue": "Communications Earth & Environment", "citationCount": 34, "abstract": "In the face of climate change, climate literacy is becoming increasingly important. With wide access to generative AI tools, such as OpenAI\u2019s ChatGPT, we explore the potential of AI platforms for ordinary citizens asking climate literacy questions. Here, we focus on a global scale and collect responses from ChatGPT (GPT-3.5 and GPT-4) on climate change-related hazard prompts over multiple iterations by utilizing the OpenAI\u2019s API and comparing the results with credible hazard risk indices. We find a general sense of agreement in comparisons and consistency in ChatGPT over the iterations. GPT-4 displayed fewer errors than GPT-3.5. Generative AI tools may be used in climate literacy, a timely topic of importance, but must be scrutinized for potential biases and inaccuracies moving forward and considered in a social context. Future work should identify and disseminate best practices for optimal use across various generative AI tools. Responses of GPT-3.5 and GPT-4 to prompts to list a country\u2019s vulnerability to climate hazards overall agree for floods and cyclones but less for droughts, with fewer errors from GPT-4, indicating a potential to enhance climate literacy, suggests a comparison of responses to hazard risk indices based on data from the IPCC.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s43247-024-01392-w.pdf"}
{"paperId": "4c694996bedd7c18c4dd851aa648f9e50213b35f", "year": 2023, "title": "The Design Space of Generative Models", "authors": "M. Morris, Carrie J. Cai, J. Holbrook, Chinmay Kulkarni, Michael Terry", "venue": "arXiv.org", "citationCount": 34, "abstract": "Card et al.'s classic paper\"The Design Space of Input Devices\"established the value of design spaces as a tool for HCI analysis and invention. We posit that developing design spaces for emerging pre-trained, generative AI models is necessary for supporting their integration into human-centered systems and practices. We explore what it means to develop an AI model design space by proposing two design spaces relating to generative AI models: the first considers how HCI can impact generative models (i.e., interfaces for models) and the second considers how generative models can impact HCI (i.e., models as an HCI prototyping material).", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.10547"}
{"paperId": "3aadb2b130320424dc5b11711715760c619fdb8d", "year": 2025, "title": "Privacy preserving strategies for electronic health records in the era of large language models", "authors": "Jitendra Jonnagaddala, Z. S. Wong", "venue": "npj Digital Medicine", "citationCount": 34, "abstract": "Electronic health records (EHRs) secondary usage with large language models (LLMs) raise privacy challenges. National regulations like GDPR and HIPAA offer protection frameworks, but specific strategies are needed to mitigate risk in generative AI. Risks can be reduced by using strategies like privacy-preserving locally deployed LLMs, synthetic data generation, differential privacy, and deidentification. Depending on the task, strategies should be employed to increase compliance with patient privacy regulatory frameworks.", "isOpenAccess": true, "url": "https://doi.org/10.1038/s41746-025-01429-0"}
{"paperId": "36da3edacf49e6be9878fd83c0e76bda8afaf349", "year": 2023, "title": "Generative AI and Author Remuneration", "authors": "Martin Senftleben", "venue": "IIC - International Review of Intellectual Property and Competition Law", "citationCount": 34, "abstract": "With the evolution of generative AI systems, machine-made productions in the literary and artistic field have reached a level of refinement that allows them to replace human creations. The increasing sophistication of AI systems will inevitably disrupt the market for human literary and artistic works. Generative AI systems provide literary and artistic output much faster and cheaper. It is therefore foreseeable that human authors will be exposed to substitution effects. They may lose income as they are replaced by machines in sectors ranging from journalism and writing to music and visual arts. Considering this trend, the question arises whether it is advisable to take measures to compensate human authors for the reduction in their market share and income. Copyright law could serve as a tool to introduce an AI levy system and ensure the payment of equitable remuneration. In combination with mandatory collective rights management, the new revenue stream could be used to finance social and cultural funds that improve the working and living conditions of flesh-and-blood authors.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s40319-023-01399-4.pdf"}
{"paperId": "34774d962d6ce9684245c8b4ec9d4e0886d65222", "year": 2024, "title": "Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI", "authors": "Robert Honig, Javier Rando, Nicholas Carlini, Florian Tram\u00e8r", "venue": "International Conference on Learning Representations", "citationCount": 34, "abstract": "Artists are increasingly concerned about advancements in image generation models that can closely replicate their unique artistic styles. In response, several protection tools against style mimicry have been developed that incorporate small adversarial perturbations into artworks published online. In this work, we evaluate the effectiveness of popular protections -- with millions of downloads -- and show they only provide a false sense of security. We find that low-effort and\"off-the-shelf\"techniques, such as image upscaling, are sufficient to create robust mimicry methods that significantly degrade existing protections. Through a user study, we demonstrate that all existing protections can be easily bypassed, leaving artists vulnerable to style mimicry. We caution that tools based on adversarial perturbations cannot reliably protect artists from the misuse of generative AI, and urge the development of alternative non-technological solutions.", "isOpenAccess": false, "url": ""}
{"paperId": "2ae1259153c5993d17b539d5ec96d277802525c3", "year": 2023, "title": "Consensus and Subjectivity of Skin Tone Annotation for ML Fairness", "authors": "Candice Schumann, Gbolahan O. Olanubi, Auriel Wright, Ellis P. Monk, Courtney Heldreth, Susanna Ricco", "venue": "Neural Information Processing Systems", "citationCount": 34, "abstract": "Understanding different human attributes and how they affect model behavior may become a standard need for all model creation and usage, from traditional computer vision tasks to the newest multimodal generative AI systems. In computer vision specifically, we have relied on datasets augmented with perceived attribute signals (e.g., gender presentation, skin tone, and age) and benchmarks enabled by these datasets. Typically labels for these tasks come from human annotators. However, annotating attribute signals, especially skin tone, is a difficult and subjective task. Perceived skin tone is affected by technical factors, like lighting conditions, and social factors that shape an annotator's lived experience. This paper examines the subjectivity of skin tone annotation through a series of annotation experiments using the Monk Skin Tone (MST) scale, a small pool of professional photographers, and a much larger pool of trained crowdsourced annotators. Along with this study we release the Monk Skin Tone Examples (MST-E) dataset, containing 1515 images and 31 videos spread across the full MST scale. MST-E is designed to help train human annotators to annotate MST effectively. Our study shows that annotators can reliably annotate skin tone in a way that aligns with an expert in the MST scale, even under challenging environmental conditions. We also find evidence that annotators from different geographic regions rely on different mental models of MST categories resulting in annotations that systematically vary across regions. Given this, we advise practitioners to use a diverse set of annotators and a higher replication count for each image when annotating skin tone for fairness research.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2305.09073"}
{"paperId": "1bc955e499771688466afcbf9187f3eb9f6da61a", "year": 2023, "title": "Impact of Conversational and Generative AI Systems on Libraries: A Use Case Large Language Model (LLM)", "authors": "Rahat Khan, Nidhi Gupta, A. Sinhababu, Prof. Rupak Chakravarty", "venue": "Science &amp; Technology Libraries", "citationCount": 34, "abstract": "ABSTRACT The study aims to examine how artificial intelligence (AI) could potentially affect specific services provided by academic libraries in the near future. To achieve this, the study uses three different Generative AI systems: ChatGPT, Perplexity, and iAsk.Ai. By analyzing the potential impact of AI on academic library services, the study aims to provide insights into how libraries can adapt to these changes to better serve their patrons. The three AI systems selected for this study represent different AI approaches that can be used in academic libraries. ChatGPT, for example, is a conversational AI system that can provide quick answers to patrons\u2019 queries, while Perplexity is a language model that can assist with tasks such as cataloging and content classification. iAsk.Ai is a natural language processing (NLP) system that can assist with research and reference inquiries. By assessing the potential impact of these AI systems on academic library services, the study can provide insights into the future of library services and how AI could be used to enhance them. Ultimately, this could help academic libraries prepare for and adapt to the changing technological landscape, ensuring that they continue to meet the needs of their patrons in the years to come.", "isOpenAccess": false, "url": ""}
{"paperId": "19f52837476cdccb292b311e6bca5d99d385ad36", "year": 2023, "title": "Generative Language Models and Open Notes: Exploring the Promise and Limitations", "authors": "C. Blease, J. Torous, Brian McMillan, M. H\u00e4gglund, K. D. Mandl", "venue": "JMIR Medical Education", "citationCount": 34, "abstract": "Patients\u2019 online record access (ORA) is growing worldwide. In some countries, including the United States and Sweden, access is advanced with patients obtaining rapid access to their full records on the web including laboratory and test results, lists of prescribed medications, vaccinations, and even the very narrative reports written by clinicians (the latter, commonly referred to as \u201copen notes\u201d). In the United States, patient\u2019s ORA is also available in a downloadable form for use with other apps. While survey studies have shown that some patients report many benefits from ORA, there remain challenges with implementation around writing clinical documentation that patients may now read. With ORA, the functionality of the record is evolving; it is no longer only an aide memoire for doctors but also a communication tool for patients. Studies suggest that clinicians are changing how they write documentation, inviting worries about accuracy and completeness. Other concerns include work burdens; while few objective studies have examined the impact of ORA on workload, some research suggests that clinicians are spending more time writing notes and answering queries related to patients\u2019 records. Aimed at addressing some of these concerns, clinician and patient education strategies have been proposed. In this viewpoint paper, we explore these approaches and suggest another longer-term strategy: the use of generative artificial intelligence (AI) to support clinicians in documenting narrative summaries that patients will find easier to understand. Applied to narrative clinical documentation, we suggest that such approaches may significantly help preserve the accuracy of notes, strengthen writing clarity and signals of empathy and patient-centered care, and serve as a buffer against documentation work burdens. However, we also consider the current risks associated with existing generative AI. We emphasize that for this innovation to play a key role in ORA, the cocreation of clinical notes will be imperative. We also caution that clinicians will need to be supported in how to work alongside generative AI to optimize its considerable potential.", "isOpenAccess": true, "url": "https://mededu.jmir.org/2024/1/e51183/PDF"}
{"paperId": "1066b1354bfa863ff6bf7da27e6b5f309afcd703", "year": 2024, "title": "Teacher professional development for a future with generative artificial intelligence \u2013 an integrative literature review", "authors": "A. Brand\u00e3o, L. Pedro, Nelson Zagalo", "venue": "Digital Education Review", "citationCount": 34, "abstract": "Artificial Intelligence (AI) has been part of every citizen's life for several years. Still, the emergence of generative AI (GenAI), accessible to all, has raised discussions about the ethical issues they raise, particularly in education. GenAI tools generate content according to user requests, but are students using these tools ethically and safely? Can teachers guide students in this use and use these tools in their teaching activities? This paper argues that teacher professional development (TPD) is an essential key trigger in adopting these emerging technologies. The paper will present an integrative literature review that discusses the components of TPD that may empower teachers to guide their students towards the ethical and safe use of GenAI. According to the literature review, one key component of TPD should be AI literacy, which involves understanding AI, its capabilities and limitations, and its potential benefits and drawbacks in education. Another essential component is hands-on activities that engage teachers, their peers, and students in actively using these tools during the training process. The paper will discuss the advantages of working with GenAI tools and designing lesson plans to implement them critically in the classroom.", "isOpenAccess": true, "url": "https://doi.org/10.1344/der.2024.45.151-157"}
{"paperId": "f221285cb13b8165abdfe1aa85f6f5dbdf7a9a57", "year": 2023, "title": "Hybrid intelligence: human\u2013AI collaboration in marketing analytics", "authors": "Maria Petrescu, Anjala S. Krishen", "venue": "Journal of Marketing Analytics", "citationCount": 33, "abstract": null, "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1057/s41270-023-00245-3.pdf"}
{"paperId": "e2688897c99b380fa5a8cab2540b6b3e98df6071", "year": 2023, "title": "Transparency in research: An analysis of ChatGPT usage acknowledgment by authors across disciplines and geographies", "authors": "R. Raman", "venue": "Accountability in Research", "citationCount": 33, "abstract": "ABSTRACT This investigation systematically reviews the recognition of generative AI tools, particularly ChatGPT, in scholarly literature. Utilizing 1,226 publications from the Dimensions database, ranging from November 2022 to July 2023, the research scrutinizes temporal trends and distribution across disciplines and regions. U.S.-based authors lead in acknowledgments, with notable contributions from China and India. Predominantly, Biomedical and Clinical Sciences, as well as Information and Computing Sciences, are engaging with these AI tools. Publications like \u201cThe Lancet Digital Health\u201d and platforms such as \u201cbioRxiv\u201d are recurrent venues for such acknowledgments, highlighting AI\u2019s growing impact on research dissemination. The analysis is confined to the Dimensions database, thus potentially overlooking other sources and grey literature. Additionally, the study abstains from examining the acknowledgments' quality or ethical considerations. Findings are beneficial for stakeholders, providing a basis for policy and scholarly discourse on ethical AI use in academia. This study represents the inaugural comprehensive empirical assessment of AI acknowledgment patterns in academic contexts, addressing a previously unexplored aspect of scholarly communication.", "isOpenAccess": false, "url": ""}
{"paperId": "de3c9e140af2be93b61d0203a1d182e343e52cb1", "year": 2024, "title": "A bibliometric analysis of generative AI in education: current status and development", "authors": "Jun Liu, Cong Wang, Zile Liu, Minghui Gao, Yanhua Xu, Jiayu Chen, Yichun Cheng", "venue": "Asia Pacific Journal of Education", "citationCount": 33, "abstract": "ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.", "isOpenAccess": false, "url": ""}
{"paperId": "dd44a086729e962af046aff808385b523fbcd856", "year": 2024, "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?", "authors": "Anna Yoo Jeong Ha, Josephine Passananti, Ronik Bhaskar, Shawn Shan, Reid Southen, Haitao Zheng, Ben Y. Zhao", "venue": "Conference on Computer and Communications Security", "citationCount": 33, "abstract": "The advent of generative AI images has completely disrupted the art world. Distinguishing AI generated images from human art is a challenging problem whose impact is growing over time. A failure to address this problem allows bad actors to defraud individuals paying a premium for human art and companies whose stated policies forbid AI imagery. It is also critical for content owners to establish copyright, and for model trainers interested in curating training data in order to avoid potential model collapse. There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 3800+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will persist, and argue that a combination of human and automated detectors provides the best combination of accuracy and robustness.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3658644.3670306"}
{"paperId": "dc9c53794ad566e1ec73ec2f979df5f63cb23eda", "year": 2024, "title": "Evaluating Contextually Personalized Programming Exercises Created with Generative AI", "authors": "Evanfiya Logacheva, Arto Hellas, J. Prather, Sami Sarsa, Juho Leinonen", "venue": "International Computing Education Research Workshop", "citationCount": 33, "abstract": "Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students\u2019 interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners\u2019 situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students\u2019 interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.", "isOpenAccess": false, "url": ""}
{"paperId": "c3a3d57a2ef87405058d4f8949d383fc31178b8a", "year": 2023, "title": "Leveraging Generative AI Solutions in Art and Design Education: Bridging Sustainable Creativity and Fostering Academic Integrity for Innovative Society", "authors": "A. F. C. A. Fathoni", "venue": "E3S Web of Conferences", "citationCount": 33, "abstract": "Artificial intelligence (AI) has transformed art and design education, giving students new ways to create, explore, and learn. Unfortunately, there is fear among academicians that students will use AI, especially text-to-image generators like Midjourney or Dall-E, as an illegal shortcut in creating their work. This article examines how generative AI solutions, such as text-to-image generators, can help students create innovative and sustainable designs while promoting academic integrity. The article shows how AI in art and design education can equip students with the skills and knowledge to succeed in a rapidly changing digital landscape. This research uses a qualitative method by analyzing the apps and literature reviews in journals and documents related to the problems studied. Case studies show how AI-based solutions can help students create innovative and sustainable designs while promoting academic integrity. Integrating controlled AI- based approaches in art and design education can promote academic integrity, creativity, and sustainability. AI-based art and design education solutions may help society become more innovative and sustainable. This article concludes that art and design educators must embrace AI-based solutions to prepare students for a rapidly changing digital world.", "isOpenAccess": true, "url": "https://www.e3s-conferences.org/articles/e3sconf/pdf/2023/63/e3sconf_icobar23_01102.pdf"}
{"paperId": "bfa056f5ca17a56113b88845e0fce15dda3d983e", "year": 2025, "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation", "authors": "Abhiram Maddukuri, Zhenyu Jiang, L. Chen, Soroush Nasiriany, Yuqi Xie, Yu Fang, Wenqi Huang, Zu Wang, Zhenjia Xu, Nikita Chernyadev, Scott Reed, Ken Goldberg, Ajay Mandlekar, Linxi Fan, Yuke Zhu", "venue": "Robotics", "citationCount": 33, "abstract": "Large real-world robot datasets hold great potential to train generalist robot models, but scaling real-world human data collection is time-consuming and resource-intensive. Simulation has great potential in supplementing large-scale data, especially with recent advances in generative AI and automated data generation tools that enable scalable creation of robot behavior datasets. However, training a policy solely in simulation and transferring it to the real world often demands substantial human effort to bridge the reality gap. A compelling alternative is to co-train the policy on a mixture of simulation and real-world datasets. Preliminary studies have recently shown this strategy to substantially improve the performance of a policy over one trained on a limited amount of real-world data. Nonetheless, the community lacks a systematic understanding of sim-and-real co-training and what it takes to reap the benefits of simulation data for real-robot learning. This work presents a simple yet effective recipe for utilizing simulation data to solve vision-based robotic manipulation tasks. We derive this recipe from comprehensive experiments that validate the co-training strategy on various simulation and real-world datasets. Using two domains--a robot arm and a humanoid--across diverse tasks, we demonstrate that simulation data can enhance real-world task performance by an average of 38%, even with notable differences between the simulation and real-world data. Videos and additional results can be found at https://co-training.github.io/", "isOpenAccess": false, "url": ""}
{"paperId": "b4820781eeeffa3251dbee395d78b54b2eca3aa2", "year": 2023, "title": "Generative AI: Challenges to higher education", "authors": "S. Yeralan, Laura Ancona Lee", "venue": "Sustainable Engineering and Innovation", "citationCount": 33, "abstract": "Generative Artificial Intelligence has rapidly expanded its footprint of use in educational institutions. It has been embraced by students, faculty, and staff alike. The technology is capable of carrying out a sustained sequence of interactive dialogs and creating reasonably meaningful text. Not surprisingly it seems to be routinely used by faculty to generate questions and assignments, by students to submit assignments and aid in self-learning, and administration to create manuals, memoranda, and policy documents. With its potential to lead to significant social innovation, tethering on the verge of becoming a disruptive technology, it seems most unlikely that it will fade away without being fully enfolded into almost all aspects of academic and pedagogical activity. While it is early to predict the exact place of this technology in education, we present thoughts to aid deliberations and give a brief review of the opportunities and challenges.", "isOpenAccess": true, "url": "https://sei.ardascience.com/index.php/journal/article/download/196/172"}
{"paperId": "ae5f701d93a609a79f540e0e3ddd50f80b8093cf", "year": 2023, "title": "Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation", "authors": "Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, William F. Godoy, K. Teranishi, Prasanna Balaprakash, Jeffrey S. Vetter", "venue": "International Workshop on Languages and Compilers for Parallel Computing", "citationCount": 33, "abstract": "We evaluate the use of the open-source Llama-2 model for generating well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on different parallel programming models and languages (e.g., C++: OpenMP, OpenMP Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python: numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built upon our previous work that is based on the OpenAI Codex, which is a descendant of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot. Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline by using a similar metric. Llama-2 has a simplified model that shows competitive or even superior accuracy. We also report on the differences between these foundational large language models as generative AI continues to redefine human-computer interactions. Overall, Copilot generates codes that are more reliable but less optimized, whereas codes generated by Llama-2 are less reliable but more optimized when correct.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.07103"}
{"paperId": "ae04406985760c01aab866922b238996291d5f81", "year": 2024, "title": "A Review of Computer Vision-Based Monitoring Approaches for Construction Workers\u2019 Work-Related Behaviors", "authors": "Jiaqi Li, Qi Miao, Zheng Zou, Huaguo Gao, Lixiao Zhang, Zhaobo Li, Nan Wang", "venue": "IEEE Access", "citationCount": 33, "abstract": "Construction workers\u2019 behaviors directly affects labor productivity and their own safety, thereby influencing project quality. Recognizing and monitoring the construction-related behaviors is therefore crucial for high-quality management and orderly construction site operation. Recent strides in computer vision technology suggest its potential to replace traditional manual supervision approaches. This paper explores research on monitoring construction workers\u2019 behaviors using computer vision. Through bibliometrics and content-based analysis, the authors present the latest research in this area from three perspectives: \u201cDetection, Localization, and Tracking for Construction Workers,\u201d \u201cRecognition of Workers\u2019 Construction Activities,\u201d and \u201cOccupational Health and Safety Behavior Monitoring.\u201d In terms of the literature\u2019s volume, there has been a notable increase in this field. Notably, the focus on safety-related literature is predominant, underscoring the concern for occupational health. Vision algorithms have witnessed an increase in the utilization of object detection. The ongoing and future research trajectory is anticipated to involve multi-algorithm integration and an emphasis on enhancing robustness. Then the authors summarize the review from engineering impact and technical suitability, and analyze the limitations of current research from the perspectives of technical approaches and application scenarios. Finally, it discusses future research directions in this field together with generative AI models. Furthermore, the authors hope this paper can serves as a valuable reference for both scholars and engineers.", "isOpenAccess": true, "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10382522.pdf"}
{"paperId": "adab086f6c7a4a413beb7ac10bbd2a4cdd2fbe58", "year": 2023, "title": "ChatGPT-Based Investment Portfolio Selection", "authors": "Oleksandr Romanko, Akhilesh Narayan, R. Kwon", "venue": "Operations Research Forum", "citationCount": 33, "abstract": "In this paper, we explore potential uses of generative AI models, such as ChatGPT, for investment portfolio selection. Trusting investment advice from Generative Pre-Trained Transformer (GPT) models is a challenge due to model \u201challucinations,\u201d necessitating careful verification and validation of the output. Therefore, we take an alternative approach. We use ChatGPT to obtain a universe of stocks from S&P500 market index that are potentially attractive for investing. Subsequently, we compared various portfolio optimization strategies that utilized this AI-generated trading universe, evaluating those against quantitative portfolio optimization models as well as comparing to some of the popular investment funds. Our findings indicate that ChatGPT is effective in stock selection but may not perform as well in assigning optimal weights to stocks within the portfolio. But when stocks selection by ChatGPT is combined with established portfolio optimization models, we achieve even better results. By blending strengths of AI-generated stock selection with advanced quantitative optimization techniques, we observed the potential for more robust and favorable investment outcomes, suggesting a hybrid approach for more effective and reliable investment decision-making in the future.", "isOpenAccess": true, "url": "https://www.researchsquare.com/article/rs-3359899/latest.pdf"}
{"paperId": "a158542c70239d3dc0927cd73d8ca1ec97539a00", "year": 2024, "title": "DNA-Diffusion: Leveraging Generative Models for Controlling Chromatin Accessibility and Gene Expression via Synthetic Regulatory Elements", "authors": "Lucas Ferreira DaSilva, Simon Senan, Z. M. Patel, Aniketh Janardhan Reddy, Sameer Gabbita, Zach Nussbaum, C\u00e9sar Miguel Valdez C\u00f3rdova, Aaron Wenteler, Noah Weber, Tin M. Tunjic, Talha Ahmad Khan, Zelun Li, Cameron Smith, Matei Bejan, L. Louis, Paola Cornejo, Will Connell, Emily S. Wong, Wouter Meuleman, L. Pinello", "venue": "bioRxiv", "citationCount": 33, "abstract": "The challenge of systematically modifying and optimizing regulatory elements for precise gene expression control is central to modern genomics and synthetic biology. Advancements in generative AI have paved the way for designing synthetic sequences with the aim of safely and accurately modulating gene expression. We leverage diffusion models to design context-specific DNA regulatory sequences, which hold significant potential toward enabling novel therapeutic applications requiring precise modulation of gene expression. Our framework uses a cell type-specific diffusion model to generate synthetic 200 bp regulatory elements based on chromatin accessibility across different cell types. We evaluate the generated sequences based on key metrics to ensure they retain properties of endogenous sequences: transcription factor binding site composition, potential for cell type-specific chromatin accessibility, and capacity for sequences generated by DNA diffusion to activate gene expression in different cell contexts using state-of-the-art prediction models. Our results demonstrate the ability to robustly generate DNA sequences with cell type-specific regulatory potential. DNA-Diffusion paves the way for revolutionizing a regulatory modulation approach to mammalian synthetic biology and precision gene therapy.", "isOpenAccess": true, "url": "https://www.biorxiv.org/content/biorxiv/early/2024/02/01/2024.02.01.578352.full.pdf"}
{"paperId": "a158516721539f76b19a0bbee027552b427544ba", "year": 2024, "title": "Cognitive and sociocultural dynamics of self-regulated use of machine translation and generative AI tools in academic EFL writing", "authors": "Yijen Wang", "venue": "System (Link\u00f6ping)", "citationCount": 33, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.system.2024.103505"}
{"paperId": "980011ddc3181e052df71e10b68ba0bec0c296c3", "year": 2023, "title": "Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia", "authors": "Sara Amani, Lance White, Trini Balart, Lakshay Arora, Kristi J. Shryock, K. Brumbelow, K. Watson", "venue": "arXiv.org", "citationCount": 33, "abstract": "ChatGPT is a natural language processing tool that can engage in human-like conversations and generate coherent and contextually relevant responses to various prompts. ChatGPT is capable of understanding natural text that is input by a user and generating appropriate responses in various forms. This tool represents a major step in how humans are interacting with technology. This paper specifically focuses on how ChatGPT is revolutionizing the realm of engineering education and the relationship between technology, students, and faculty and staff. Because this tool is quickly changing and improving with the potential for even greater future capability, it is a critical time to collect pertinent data. A survey was created to measure the effects of ChatGPT on students, faculty, and staff. This survey is shared as a Texas A&M University technical report to allow other universities and entities to use this survey and measure the effects elsewhere.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2304.14415"}
{"paperId": "940850069b318793875a1aa7e02b02d8caf66d25", "year": 2024, "title": "Vision-Enabled Large Language and Deep Learning Models for Image-Based Emotion Recognition", "authors": "Mohammad Nadeem, S. Sohail, Laeeba Javed, Faisal Anwer, Abdul Khader Jilani Saudagar, Khan Muhammad", "venue": "Cognitive Computation", "citationCount": 33, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "931ffb768ed4dd4f4048b9f7cf691991168db347", "year": 2024, "title": "Present and Future, Challenges of High Bandwith Memory (HBM)", "authors": "Kwiwook Kim, Myeong-jae Park", "venue": "International Memory Workshop", "citationCount": 33, "abstract": "In recent years, the demand for fast and high-capacity memory has surged due to the emergence of generative AI models such as GPT. To address this need, High Bandwidth Memory (HBM) has rapidly risen as a critical memory solution. This paper aims to elucidate why HBM plays a pivotal role in the AI industry and discusses the imminent challenges that need to be overcome in the development of HBM memory. By exploring the significance of HBM in the context of AI applications and outlining the pressing challenges ahead, this paper contributes to understanding the importance of HBM in meeting the memory requirements of advancing AI technologies.", "isOpenAccess": false, "url": ""}
{"paperId": "9008759082663390b496fe835bc84d835ded0008", "year": 2024, "title": "Histopathology in focus: a review on explainable multi-modal approaches for breast cancer diagnosis", "authors": "F. Abdullakutty, Younes Akbari, S. Al-maadeed, Ahmed Bouridane, Iman M. Talaat, R. Hamoudi", "venue": "Frontiers in Medicine", "citationCount": 33, "abstract": "Precision and timeliness in breast cancer detection are paramount for improving patient outcomes. Traditional diagnostic methods have predominantly relied on unimodal approaches, but recent advancements in medical data analytics have enabled the integration of diverse data sources beyond conventional imaging techniques. This review critically examines the transformative potential of integrating histopathology images with genomic data, clinical records, and patient histories to enhance diagnostic accuracy and comprehensiveness in multi-modal diagnostic techniques. It explores early, intermediate, and late fusion methods, as well as advanced deep multimodal fusion techniques, including encoder-decoder architectures, attention-based mechanisms, and graph neural networks. An overview of recent advancements in multimodal tasks such as Visual Question Answering (VQA), report generation, semantic segmentation, and cross-modal retrieval is provided, highlighting the utilization of generative AI and visual language models. Additionally, the review delves into the role of Explainable Artificial Intelligence (XAI) in elucidating the decision-making processes of sophisticated diagnostic algorithms, emphasizing the critical need for transparency and interpretability. By showcasing the importance of explainability, we demonstrate how XAI methods, including Grad-CAM, SHAP, LIME, trainable attention, and image captioning, enhance diagnostic precision, strengthen clinician confidence, and foster patient engagement. The review also discusses the latest XAI developments, such as X-VARs, LeGrad, LangXAI, LVLM-Interpret, and ex-ILP, to demonstrate their potential utility in multimodal breast cancer detection, while identifying key research gaps and proposing future directions for advancing the field.", "isOpenAccess": true, "url": "https://doi.org/10.3389/fmed.2024.1450103"}
{"paperId": "8f2623c532f574ae856fd5c4ce2eef2b4107f702", "year": 2024, "title": "Can the Administrative Loads of Physicians be Alleviated by AI-Facilitated Clinical Documentation?", "authors": "Henry Bundy, Jay Gerhart, Sally Baek, Crystal Danielle Connor, McKenzie Isreal, A. Dharod, Casey Stephens, Tsai-Ling Liu, Timothy C. Hetherington, Jeffery Cleveland", "venue": "Journal of general internal medicine", "citationCount": 33, "abstract": "Champions of AI-facilitated clinical documentation have suggested that the emergent technology may decrease the administrative loads of physicians, thereby reducing cognitive burden and forestalling burnout. Explorations of physicians\u2019 experiences with automated documentation are critical in evaluating these claims. To evaluate physicians\u2019 experiences with DAX Copilot (DAXC), a generative AI-facilitated clinical documentation tool. Semi-structured interviews were conducted in August and September of 2023 with physician-users of DAXC. A purposive sample of 12 interviewees, selected from 116 primary care physicians, employed at a multi-site academic learning health system. After completing all 12 interviews, three study personnel independently analyzed and coded the transcripts. Reconciliation sessions were then held to merge the three analyses into one summary, eliminating redundant codes, and grouping findings into themes. For a majority of interviewees, DAXC reduced the amount of time spent documenting encounters, and alleviated anxieties of having to retain important clinical details until there was time to make notes. DAXC also allowed physicians to be more engaged during appointments, resulting in more personable provider-patient encounters. However, some physicians weighed these benefits against an uneasy feeling that interviewees might be asked to see more patients if DAXC was mandated. Physicians also noted that the tool would occasionally imagine or misgender patients, offer unsolicited and inappropriate diagnoses, and mistake critical details in transcription. The few physicians less enthusiastic about the generative technology portrayed themselves as creatures of habit who had cultivated long-standing workflows and particular notation practices that DAXC could neither improve upon nor reproduce. According to physician interviewees, automated AI-driven clinical documentation has the potential to significantly reduce the administrative burden associated with particular types of provider-patient encounters. Addressing the growing pains of the incipient technology, identified here, may allow for a broader applicability for clinical practice.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s11606-024-08870-z.pdf"}
{"paperId": "8ed3851a65e1a649a439cf0e2cd192939558c479", "year": 2024, "title": "A pedagogical design for self-regulated learning in academic writing using text-based generative artificial intelligence tools: 6-P pedagogy of plan, prompt, preview, produce, peer-review, portfolio-tracking", "authors": "Siu-Cheung Kong, John Chi-Kin Lee, Olson Tsang", "venue": "Research and Practice in Technology Enhanced Learning", "citationCount": 33, "abstract": "The emergence and popularity of generative artificial intelligence (AI) tools, particularly text-based ones known as large language models, pose both opportunities and challenges to education. The ability of these tools to generate human-like texts based on minimal instructions causes concerns among educators about students\u2019 use of these tools for academic writing, which may constitute a breach of academic integrity. We propose a pedagogical design that models on self-regulated learning and the authoring cycle and develops students\u2019 critical thinking and self-regulation when composing academic writing using text-based generative AI tools. It contains six iterative and interactive phases. Students first plan the content and structure of the writing, then generate prompts for text-based generative AI tools. Next, students preview and verify the tools\u2019 output, followed by the fourth phase of producing the writing using the corrected output. Fifthly, peer review by fellow students may be required to polish and proofread the writing. Lastly, through portfolio-tracking, students reflect on the writing process, and formulate strategies for future usage of text-based generative AI tools for writing. This pedagogical design helps students and teachers embrace text-based generative AI while addressing the perils these tools present, and guides the development of education interventions and instruments.", "isOpenAccess": true, "url": "https://rptel.apsce.net/index.php/RPTEL/article/download/2024-19030/2024-19030"}
{"paperId": "804b39775461c5d4714cc1449053a99c90534fec", "year": 2023, "title": "Chinese University Students\u2019 Attitudes and Perceptions in Learning English Using ChatGPT", "authors": "Binghan Liu", "venue": "International Journal of Education and Humanities", "citationCount": 33, "abstract": "Since its release into the public domain, the generative AI tool - ChatGPT has arisen wide attention by its sophisticated capacity to carry out complex tasks. Many educators have researched the advanced tool in offering potential benefits for language teaching and learning. This research is designed for assessing Chinese university students\u2019 attitudes towards using ChatGPT to improve their English learning and their perceptions regarding the advantages and disadvantages of ChatGPT. In this study, data were collected from 109 undergraduate Chinese students, using a questionnaire consisting of 5-point Likert scale questions. The findings of the study show that the students believe ChatGPT is an effective tool to support them in learning English but information security should be taken into further consideration. Policymakers, technology experts, researchers, and educators could work together on how ChatGPT and other evolving generative AI tools could be used safely and effectively in English teaching and learning", "isOpenAccess": true, "url": "https://i-jeh.com/index.php/ijeh/article/download/145/93"}
{"paperId": "7926d85328517dbd16fa5ca20ca6b936cd6fb52b", "year": 2023, "title": "Generative AI models should include detection mechanisms as a condition for public release", "authors": "Alistair Knott, Dino Pedreschi, Raja Chatila, Tapabrata Chakraborti, Susan Leavy, Ricardo A. Baeza-Yates, D. Eyers, Andrew Trotman, Paul D. Teal, P. Biecek, Stuart Russell, Y. Bengio", "venue": "Ethics and Information Technology", "citationCount": 33, "abstract": "The new wave of \u2018foundation models\u2019\u2014general-purpose generative AI models, for production of text (e.g., ChatGPT) or images (e.g., MidJourney)\u2014represent a dramatic advance in the state of the art for AI. But their use also introduces a range of new risks, which has prompted an ongoing conversation about possible regulatory mechanisms. Here we propose a specific principle that should be incorporated into legislation: that any organization developing a foundation model intended for public use must demonstrate a reliable detection mechanism for the content it generates, as a condition of its public release. The detection mechanism should be made publicly available in a tool that allows users to query, for an arbitrary item of content, whether the item was generated (wholly or partly) by the model. In this paper, we argue that this requirement is technically feasible and would play an important role in reducing certain risks from new AI models in many domains. We also outline a number of options for the tool\u2019s design, and summarize a number of points where further input from policymakers and researchers would be required.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s10676-023-09728-4.pdf"}
{"paperId": "5f225b274181a0c07852f047ef6f7dbab9ab170e", "year": 2024, "title": "Source Tracing of Audio Deepfake Systems", "authors": "Nicholas Klein, Tianxiang Chen, Hemlata Tak, Ricardo Casal, Elie Khoury", "venue": "Interspeech", "citationCount": 33, "abstract": "Recent progress in generative AI technology has made audio deepfakes remarkably more realistic. While current research on anti-spoofing systems primarily focuses on assessing whether a given audio sample is fake or genuine, there has been limited attention on discerning the specific techniques to create the audio deepfakes. Algorithms commonly used in audio deepfake generation, like text-to-speech (TTS) and voice conversion (VC), undergo distinct stages including input processing, acoustic modeling, and waveform generation. In this work, we introduce a system designed to classify various spoofing attributes, capturing the distinctive features of individual modules throughout the entire generation pipeline. We evaluate our system on two datasets: the ASVspoof 2019 Logical Access and the Multi-Language Audio Anti-Spoofing Dataset (MLAAD). Results from both experiments demonstrate the robustness of the system to identify the different spoofing attributes of deepfake generation systems.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2407.08016"}
{"paperId": "5afe0f1ae0a147348cf26c5d9a8943e05f956404", "year": 2024, "title": "Plato\u2019s Shadows in the Digital Cave: Controlling Cultural Bias in Generative AI", "authors": "K. Karpouzis", "venue": "Electronics", "citationCount": 33, "abstract": "Generative Artificial Intelligence (AI) systems, like ChatGPT, have the potential to perpetuate and amplify cultural biases embedded in their training data, which are predominantly produced by dominant cultural groups. This paper explores the philosophical and technical challenges of detecting and mitigating cultural bias in generative AI, drawing on Plato\u2019s Allegory of the Cave to frame the issue as a problem of limited and distorted representation. We propose a multifaceted approach combining technical interventions, such as data diversification and culturally aware model constraints, with a deeper engagement with the cultural and philosophical dimensions of the problem. Drawing on theories of extended cognition and situated knowledge, we argue that mitigating AI biases requires a reflexive interrogation of the cultural contexts of AI development and a commitment to empowering marginalized voices and perspectives. We claim that controlling cultural bias in generative AI is inseparable from the larger project of promoting equity, diversity, and inclusion in AI development and governance. By bridging philosophical reflection with technical innovation, this paper contributes to the growing discourse on responsible and inclusive AI, offering a roadmap for detecting and mitigating cultural biases while grappling with the profound cultural implications of these powerful technologies.", "isOpenAccess": true, "url": "https://www.mdpi.com/2079-9292/13/8/1457/pdf?version=1712846385"}
{"paperId": "595dd3553e3233f461b8ef4f71d4023f723f3376", "year": 2024, "title": "Artificial intelligence generated content (AIGC) in medicine: A narrative review.", "authors": "Liangjing Shao, Benshuang Chen, Ziqun Zhang, Zhen Zhang, Xinrong Chen", "venue": "Mathematical biosciences and engineering : MBE", "citationCount": 33, "abstract": "Recently, artificial intelligence generated content (AIGC) has been receiving increased attention and is growing exponentially. AIGC is generated based on the intentional information extracted from human-provided instructions by generative artificial intelligence (AI) models. AIGC quickly and automatically generates large amounts of high-quality content. Currently, there is a shortage of medical resources and complex medical procedures in medicine. Due to its characteristics, AIGC can help alleviate these problems. As a result, the application of AIGC in medicine has gained increased attention in recent years. Therefore, this paper provides a comprehensive review on the recent state of studies involving AIGC in medicine. First, we present an overview of AIGC. Furthermore, based on recent studies, the application of AIGC in medicine is reviewed from two aspects: medical image processing and medical text generation. The basic generative AI models, tasks, target organs, datasets and contribution of studies are considered and summarized. Finally, we also discuss the limitations and challenges faced by AIGC and propose possible solutions with relevant studies. We hope this review can help readers understand the potential of AIGC in medicine and obtain some innovative ideas in this field.", "isOpenAccess": true, "url": "https://doi.org/10.3934/mbe.2024073"}
{"paperId": "4b9eaa8b2963c70e41b765a099c5ec21873178da", "year": 2024, "title": "Exploring learners\u2019 experiences and perceptions of ChatGPT as a learning tool in higher education", "authors": "Wali Khan Monib, Atika Qazi, M. Mahmud", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 33, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "35430050b1f655f2866ac3a606359eed222a3fc1", "year": 2023, "title": "Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion", "authors": "Zhilun Zhou, Jingtao Ding, Yu Liu, Depeng Jin, Yong Li", "venue": "SIGSPATIAL/GIS", "citationCount": 33, "abstract": "Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3589132.3625641"}
{"paperId": "309ba4139cfacbcb13b45576af005e8df9d3e7d8", "year": 2024, "title": "Exploring Consumer Acceptance of AI-Generated Advertisements: From the Perspectives of Perceived Eeriness and Perceived Intelligence", "authors": "Chenyan Gu, Shuyue Jia, Jiaying Lai, Ruli Chen, Xinsiyu Chang", "venue": "Journal of Theoretical and Applied Electronic Commerce Research", "citationCount": 33, "abstract": "The rapid popularity of ChatGPT has brought generative AI into broad focus. The content generation model represented by AI-generated content (AIGC) has reshaped the advertising industry. This study explores the mechanisms by which the characteristics of AI-generated advertisements affect consumers\u2019 willingness to accept these advertisements from the perspectives of perceived eeriness and perceived intelligence. It found that the verisimilitude and imagination of AI-generated advertisements negatively affect the degree of perceived eeriness by consumers, while synthesis positively affects it. Conversely, verisimilitude, vitality, and imagination positively affect the perceived intelligence, while synthesis negatively affects it. Meanwhile, consumers\u2019 perceived eeriness negatively affects their acceptance of AI-generated advertisements, while perceived intelligence positively affects their willingness to accept AI-generated advertisements. This study helps explain consumers\u2019 attitudes toward AI-generated advertisements and offers strategies for brands and advertisers for how to use AI technology more scientifically to optimize advertisements. Advertisers should cautiously assess the possible impact of AI-generated advertisements according to their characteristics, allowing generative AI to play a more valuable role in advertising.", "isOpenAccess": false, "url": ""}
{"paperId": "2f425691f27b0373df21f40673859c3ee0f6cded", "year": 2024, "title": "Artificial intelligence in infrastructure construction: A critical review", "authors": "Ke Chen, Xiaojie Zhou, Zhikang Bao, M. Skibniewski, Weili Fang", "venue": "Frontiers of Engineering Management", "citationCount": 33, "abstract": "Artificial intelligence (AI) has emerged as a promising technological solution for addressing critical infrastructure construction challenges, such as elevated accident rates, suboptimal productivity, and persistent labor shortages. This review aims to thoroughly analyze the contemporary landscape of AI applications in the infrastructure construction sector. We conducted both quantitative and qualitative analyses based on 594 and 91 selected papers, respectively. The results reveal that the primary focus of current AI research in this field centers on safety monitoring and control, as well as process management. Key technologies such as machine learning, computer vision, and natural language processing are prominent, with significant attention given to the development of smart construction sites. Our review also highlights several areas for future research, including broadening the scope of AI applications, exploring the potential of diverse AI technologies, and improving AI applications through standardized data sets and generative AI models. These directions are promising for further advancements in infrastructure construction, offering potential solutions to its significant challenges.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s42524-024-3128-5"}
{"paperId": "1b0d059d275219a9860ed89f3d67e9271e60de0b", "year": 2023, "title": "Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With: A Comparative Case Study", "authors": "R. P. D. Santos", "venue": "Social Science Research Network", "citationCount": 33, "abstract": "This study explores the potential of Generative AI chatbots (GenAIbots) such as ChatGPT and Bing Chat, in Chemistry education, within a constructionist theoretical framework. A single-case study methodology was used to analyse extensive interaction logs between students and both AI systems in simulated Chemistry learning experiences. The results highlight the ability of ChatGPT and Bing Chat to act as 'agents-to-think-with', fostering critical thinking, problem-solving, concept comprehension, creativity, and personalised learning experiences. By employing a Socratic-like questioning approach, GenAIbots nurture students' curiosity and promote active learning. The study emphasises the significance of prompt crafting, a technique to elicit desired responses from GenAIbots, fostering iterative reflections and interactions. It underlines the need for comprehensive educator training to effectively integrate these tools into classrooms. The study concludes that while ChatGPT and Bing Chat as agents-to-think-with offer promising avenues to revolutionise STEM education through a constructionist lens, fostering a more interactive, inclusive learning environment and promoting deeper comprehension and critical thinking in students across diverse Chemistry topics, ChatGPT consistently outperformed Bing Chat, providing more comprehensive, detailed, and accurate responses and skillfully addressing nuances and context.", "isOpenAccess": false, "url": ""}
{"paperId": "119477c444f84b07357844e4b8c770cb78d4ce7d", "year": 2024, "title": "Can interaction with generative artificial intelligence enhance learning autonomy? A longitudinal study from comparative perspectives of virtual companionship and knowledge acquisition preferences", "authors": "Zehang Xie, Xinzhu Wu, Yunxiang Xie", "venue": "Journal of Computer Assisted Learning", "citationCount": 33, "abstract": "With the development of artificial intelligence (AI) technology, generative AI has been widely used in the field of education and represents a groundbreaking shift in overcoming the constraints of time and space within educational activities. However, previous literature has not paid enough attention to AI\u2010involved teaching patterns, and it is necessary to evaluate the effects of this learning pattern.ObjectivesBased on the social presence theory and the community of inquiry model, the main purpose of this study is to evaluate whether and how interaction frequency with chatbots (IFC) affects people's learning autonomy (LA) under two preferences: knowledge acquisition and virtual companionship, and whether social presence (SP) plays a mediating role.The 1\u2010year longitudinal study was designed to be conducted from May 2022 to May 2023 and included three rounds of surveys of 1155 undergraduate students on their use of robots for learning.For learners preferring virtual companionship, no direct correlation was found between IFC and LA. However, SP acted as a mediating factor, enhancing LA through increased chatbot interactions. This suggests that while direct interactions may not directly influence LA, the resulting SP can foster it. Conversely, for learners favouring knowledge acquisition, higher IFC negatively impacted both SP and LA. Despite this, a strong sense of SP consistently correlated positively with LA, indicating it could offset some negative effects of frequent chatbot use.", "isOpenAccess": false, "url": ""}
{"paperId": "0bc72e0c31df7bd821b8becd8f43c77c27af5155", "year": 2024, "title": "Large Language Models and Video Games: A Preliminary Scoping Review", "authors": "Penny Sweetser", "venue": "International Conference on Conversational User Interfaces", "citationCount": 33, "abstract": "Large language models (LLMs) hold interesting potential for the design, development, and research of video games. Building on the decades of prior research on generative AI in games, many researchers have sped to investigate the power and potential of LLMs for games. Given the recent spike in LLM-related research in games, there is already a wealth of relevant research to survey. In order to capture a snapshot of the state of LLM research in games, and to help lay the foundation for future work, we carried out an initial scoping review of relevant papers published so far. In this paper, we review 76 papers published between 2022 to early 2024 on LLMs and video games, with key focus areas in game AI, game development, narrative, and game research and reviews. Our paper provides an early state of the field and lays the groundwork for future research and reviews on this topic.", "isOpenAccess": false, "url": ""}
{"paperId": "084d9bf272608e1fb7ecde4c30224c3ffa850774", "year": 2024, "title": "Designing for Human-Agent Alignment: Understanding what humans want from their agents", "authors": "Nitesh Goyal, Minsuk Chang, Michael Terry", "venue": "CHI Extended Abstracts", "citationCount": 33, "abstract": "Our ability to build autonomous agents that leverage Generative AI continues to increase by the day. As builders and users of such agents it is unclear what parameters we need to align on before the agents start performing tasks on our behalf. To discover these parameters, we ran a qualitative empirical research study about designing agents that can negotiate during a fictional yet relatable task of selling a camera online. We found that for an agent to perform the task successfully, humans/users and agents need to align over 6 dimensions: 1) Knowledge Schema Alignment 2) Autonomy and Agency Alignment 3) Operational Alignment and Training 4) Reputational Heuristics Alignment 5) Ethics Alignment and 6) Human Engagement Alignment. These empirical findings expand previous work related to process and specification alignment and the need for values and safety in Human-AI interactions. Subsequently we discuss three design directions for designers who are imagining a world filled with Human-Agent collaborations.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613905.3650948"}
{"paperId": "0604ab5c23e14d7a8b0eaa8052b383492f42ecbf", "year": 2024, "title": "The Real Dangers of Generative AI", "authors": "Danielle Allen \u064a\u0646\u0644\u0623 \u0644\u064a\u064a\u0646\u0627\u062f, Eric Glen, Weyl \u0644\u064a\u0648, \u064a\u0625 \u064a\u0646\u0644\u063a, Translated By, Abdou Moussa El-Bermawy, \u064a\u0648\u0627\u0645\u0628\u0631\u0644\u0627, .\u0629\u064a\u062f\u062f\u0639\u062a\u0644\u0627 \u062f\u0647\u0639\u0645 \u0633\u064a\u0626\u0631\u0648, .\u062a\u0627\u0633\u0627\u064a\u0633\u0644\u0627 \u0629\u0633\u0627\u0631\u062f\u0648, \u062b\u0627\u062d\u0628\u0644\u0623\u0644 \u0628\u064a\u0631\u0639\u0644\u0627 \u0632\u0643\u0631\u0644\u0645\u0627 \u0641\u064a \u062b\u062d\u0627\u0628, Danielle Allen, E. G. Weyl", "venue": "Journal of Democracy", "citationCount": 33, "abstract": "Abstract:As perhaps the most consequential technology of our time, Generative Foundation Models (GFMs) present unprecedented challenges for democratic institutions. By allowing deception and de-contextualized information sharing at a previously unimaginable scale and pace, GFMs could undermine the foundations of democracy. At the same time, the investment scale required to develop the models and the race dynamics around that development threaten to enable concentrations of democratically unaccountable power (both public and private). This essay examines the twin threats of collapse and singularity occasioned by the rise of GFMs.", "isOpenAccess": false, "url": ""}
{"paperId": "f721c54d572f033dd72d6e5e6b1833731738e0a9", "year": 2024, "title": "Leveraging generative AI to prioritize drug repurposing candidates for Alzheimer\u2019s disease with real-world clinical validation", "authors": "Chao Yan, M. Grabowska, Alyson L. Dickson, Bingshan Li, Zhexing Wen, Dan M. Roden, C. Michael Stein, Peter J. Emb\u00ed, Josh F. Peterson, Q. Feng, Brad Malin, Wei-Qi Wei", "venue": "npj Digital Medicine", "citationCount": 32, "abstract": "Drug repurposing represents an attractive alternative to the costly and time-consuming process of new drug development, particularly for serious, widespread conditions with limited effective treatments, such as Alzheimer\u2019s disease (AD). Emerging generative artificial intelligence (GAI) technologies like ChatGPT offer the promise of expediting the review and summary of scientific knowledge. To examine the feasibility of using GAI for identifying drug repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty most promising drugs for repurposing in AD, and tested the top ten for risk of incident AD in exposed and unexposed individuals over age 65 in two large clinical datasets: (1) Vanderbilt University Medical Center and (2) the All of Us Research Program. Among the candidates suggested by ChatGPT, metformin, simvastatin, and losartan were associated with lower AD risk in meta-analysis. These findings suggest GAI technologies can assimilate scientific insights from an extensive Internet-based search space, helping to prioritize drug repurposing candidates and facilitate the treatment of diseases.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s41746-024-01038-3.pdf"}
{"paperId": "e904f894b0995242bbe61b763e020784cd683b11", "year": 2025, "title": "Generative AI-Enabled Wireless Communications for Robust Low-Altitude Economy Networking", "authors": "Changyuan Zhao, Jiacheng Wang, Ruichen Zhang, D. Niyato, Geng Sun, Hongyang Du, Dong In Kim, Abbas Jamalipour", "venue": "IEEE wireless communications", "citationCount": 32, "abstract": "Low-Altitude Economy Networks (LAENets) have emerged as significant enablers of social activities, offering low-altitude services such as the transportation of packages, groceries, and medical supplies. Owing to their control mechanisms and ever-changing operational factors, LAENets are inherently more complex and vulnerable to security threats than traditional terrestrial networks. As applications of LAENet continue to expand, the robustness of these systems becomes crucial. In this paper, we propose a generative artificial intelligence (GenAI) optimization framework that tackles robustness challenges in LAENets. We conduct a systematic analysis of robustness requirements for LAENets, complemented by a comprehensive review of robust Quality of Service (QoS) metrics from the wireless physical layer perspective. We then investigate existing GenAI-enabled approaches for robustness enhancement. This leads to our proposal of a novel diffusion-based optimization framework with a Mixture of Experts (MoE)-transformer actor network. In the robust beamforming case study, the proposed framework demonstrates its effectiveness by optimizing beamforming under uncertainties, achieving a more than 15% increase over four learning baselines in the worst-case achievable secrecy rate. These findings highlight the significant potential of GenAI in strengthening LAENet robustness.", "isOpenAccess": false, "url": ""}
{"paperId": "e79802b2b86d2a814fe441f4275a56992ab9c93d", "year": 2023, "title": "Beyond ChatGPT: Multimodal generative AI for L2 writers", "authors": "Joohoon Kang, Youngjoo Yi", "venue": "Journal of Second Language Writing", "citationCount": 32, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "e2948044167458c51ee53f3178f9fb2b678de0e5", "year": 2023, "title": "AI in the Public Eye: Investigating Public AI Literacy Through AI Art", "authors": "D. Hemment, Morgan E. Currie, S. Bennett, Jake Elwes, Anna Ridler, Caroline Sinders, Matjaz Vidmar, Robin L. Hill, Holly Warner", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 32, "abstract": "Recent advances in diffusion models and large language models have underpinned a new generation of powerful and accessible tools, and some of the most publicly visible applications are for artistic endeavour. Such tools, however, provide little scope for deeper understanding of AI systems, while the growing public interest in them can eclipse notice of the vibrant community of artists who have long worked with other forms of AI. We explore the potential for AI Art \u2013 particularly work in which AI is both tool and topic \u2013 to facilitate public AI literacies and consider how tactics developed before the current generative AI boom have continued relevance today. We look at the strategies of critical AI artists to scaffold public understanding of AI and enhance legibility for non-experts. This paper also investigates how collaborations between artists and AI researchers and designers can illuminate key technical and social issues relevant to the development of AI. The study entailed workshops between three professional artists who work with AI and a cross-disciplinary set of academic participants. This paper reports on these workshops and presents the intentions and strategies expressed by the artists, as well as insights of relevance to the research community on public AI literacies. We find that critical AI art can link underlying technical systems to structural issues of power and facilitate experiential learning that is situated and embodied, valuing interpretation over explanation. The findings also demonstrate the importance of transdisciplinary conversations around art, ethics and the political economy of AI technologies and how these dialogues may feed into AI design processes.", "isOpenAccess": true, "url": "https://www.pure.ed.ac.uk/ws/files/363373785/HemmentEtalACM2023AIInThePublicEye.pdf"}
{"paperId": "d058fee1b44689fa89be9cbb6e10675c40ee599e", "year": 2024, "title": "SceneTeller: Language-to-3D Scene Generation", "authors": "Basak Melis \u00d6cal, Maxim Tatarchenko, Sezer Karaoglu, Theo Gevers", "venue": "European Conference on Computer Vision", "citationCount": 32, "abstract": "Designing high-quality indoor 3D scenes is important in many practical applications, such as room planning or game development. Conventionally, this has been a time-consuming process which requires both artistic skill and familiarity with professional software, making it hardly accessible for layman users. However, recent advances in generative AI have established solid foundation for democratizing 3D design. In this paper, we propose a pioneering approach for text-based 3D room design. Given a prompt in natural language describing the object placement in the room, our method produces a high-quality 3D scene corresponding to it. With an additional text prompt the users can change the appearance of the entire scene or of individual objects in it. Built using in-context learning, CAD model retrieval and 3D-Gaussian-Splatting-based stylization, our turnkey pipeline produces state-of-the-art 3D scenes, while being easy to use even for novices. Our project page is available at https://sceneteller.github.io/.", "isOpenAccess": false, "url": ""}
{"paperId": "c8ee7e28712d302d36a9e14c4ad1af00b13d3e18", "year": 2025, "title": "Comparing Generative AI and teacher feedback: student perceptions of usefulness and trustworthiness", "authors": "Michael Henderson, M. Bearman, Jennifer Chung, Tim Fawns, S. Buckingham Shum, Kelly E. Matthews, Jimena de Mello Heredia", "venue": "Assessment &amp; Evaluation in Higher Education", "citationCount": 32, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1080/02602938.2025.2502582"}
{"paperId": "c0359ad23c7374bde0a361e01854553f7d73b80e", "year": 2023, "title": "IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI", "authors": "Bochuan Cao, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li, Jinghui Chen", "venue": "Neural Information Processing Systems", "citationCount": 32, "abstract": "Diffusion-based image generation models, such as Stable Diffusion or DALL-E 2, are able to learn from given images and generate high-quality samples following the guidance from prompts. For instance, they can be used to create artistic images that mimic the style of an artist based on his/her original artworks or to maliciously edit the original images for fake content. However, such ability also brings serious ethical issues without proper authorization from the owner of the original images. In response, several attempts have been made to protect the original images from such unauthorized data usage by adding imperceptible perturbations, which are designed to mislead the diffusion model and make it unable to properly generate new samples. In this work, we introduce a perturbation purification platform, named IMPRESS, to evaluate the effectiveness of imperceptible perturbations as a protective measure. IMPRESS is based on the key observation that imperceptible perturbations could lead to a perceptible inconsistency between the original image and the diffusion-reconstructed image, which can be used to devise a new optimization strategy for purifying the image, which may weaken the protection of the original image from unauthorized data usage (e.g., style mimicking, malicious editing). The proposed IMPRESS platform offers a comprehensive evaluation of several contemporary protection methods, and can be used as an evaluation platform for future protection methods.", "isOpenAccess": false, "url": ""}
{"paperId": "bad7723e87c91611718b2e6aded1299a2b9940e3", "year": 2023, "title": "The Case for Generative AI in Scholarly Practice", "authors": "C. Berg", "venue": "Social Science Research Network", "citationCount": 32, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "b000b13fe83df45a6bd16420f0440d36b32cc0e4", "year": 2024, "title": "Fake news detection: comparative evaluation of BERT-like models and large language models with generative AI-annotated data", "authors": "Shaina Raza, Drai Paulen-Patterson, Chen Ding", "venue": "Knowledge and Information Systems", "citationCount": 32, "abstract": "Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2412.14276"}
{"paperId": "a50460939f867b89a55db6103bd4e2fdef71ee13", "year": 2023, "title": "Joint Sensing, Communication, and AI: A Trifecta for Resilient THz User Experiences", "authors": "C. Chaccour, W. Saad, M. Debbah, H. Poor", "venue": "IEEE Transactions on Wireless Communications", "citationCount": 32, "abstract": "In this paper a novel joint sensing, communication, and artificial intelligence (AI) framework is proposed so as to optimize extended reality (XR) experiences over terahertz (THz) wireless systems. Within this framework, active reconfigurable intelligent surfaces (RISs) are incorporated as pivotal elements, serving as enhanced base stations in the THz band to enhance Line-of-Sight (LoS) communication. The proposed framework consists of three main components. First, a tensor decomposition framework is proposed to extract unique sensing parameters for XR users and their environment by exploiting the THz channel sparsity. Essentially, the THz band\u2019s quasi-opticality is exploited and the sensing parameters are extracted from the uplink communication signal, thereby allowing for the use of the same waveform, spectrum, and hardware for both communication and sensing functionalities. Then, the Cram\u00e9r-Rao lower bound is derived to assess the accuracy of the estimated sensing parameters. Second, a non-autoregressive multi-resolution generative AI framework integrated with an adversarial transformer is proposed to predict missing and future sensing information. The proposed framework offers robust and comprehensive historical sensing information and anticipatory forecasts of future environmental changes, which are generalizable to fluctuations in both known and unforeseen user behaviors and environmental conditions. Third, a multi-agent deep recurrent hysteretic Q-neural network is developed to control the handover policy of RIS subarrays, leveraging the informative nature of sensing information to minimize handover cost, maximize the individual quality of personal experiences (QoPEs), and improve the robustness and resilience of THz links. Simulation results show a high generalizability of the proposed unsupervised generative artificial intelligence (AI) framework to fluctuations in user behavior and velocity, leading to a 61% improvement in instantaneous reliability compared to schemes with known channel state information.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2305.00135"}
{"paperId": "9cbbb250a565228ba328038ee7944b89cff53e84", "year": 2023, "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning", "authors": "Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu", "venue": "arXiv.org", "citationCount": 32, "abstract": "The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream language tasks. We further discover that instruction finetuning can elicit zero-shot and few-shot in-context learning abilities that help tackle many unseen tasks by following natural language instructions, and show promise in advanced and challenging abilities such as reasoning.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.12219"}
{"paperId": "97295f6751dfef9d9e26aca2d0a11af06dd4b23c", "year": 2023, "title": "Artificial Intelligence in Dental Education: Opportunities and Challenges of Large Language Models and Multimodal Foundation Models", "authors": "Daniel Claman, Emre Sezgin", "venue": "JMIR Medical Education", "citationCount": 32, "abstract": "Abstract Instructional and clinical technologies have been transforming dental education. With the emergence of artificial intelligence (AI), the opportunities of using AI in education has increased. With the recent advancement of generative AI, large language models (LLMs) and foundation models gained attention with their capabilities in natural language understanding and generation as well as combining multiple types of data, such as text, images, and audio. A common example has been ChatGPT, which is based on a powerful LLM\u2014the GPT model. This paper discusses the potential benefits and challenges of incorporating LLMs in dental education, focusing on periodontal charting with a use case to outline capabilities of LLMs. LLMs can provide personalized feedback, generate case scenarios, and create educational content to contribute to the quality of dental education. However, challenges, limitations, and risks exist, including bias and inaccuracy in the content created, privacy and security concerns, and the risk of overreliance. With guidance and oversight, and by effectively and ethically integrating LLMs, dental education can incorporate engaging and personalized learning experiences for students toward readiness for real-life clinical practice.", "isOpenAccess": false, "url": ""}
{"paperId": "8f2216188f2e0a81e3074d14ae0aa0643d4587b3", "year": 2023, "title": "Generative AI-aided Optimization for AI-Generated Content (AIGC) Services in Edge Networks", "authors": "Hongyang Du, Zonghang Li, D. Niyato, Jiawen Kang, Zehui Xiong, Huawei Huang, Shiwen Mao", "venue": "arXiv.org", "citationCount": 32, "abstract": null, "isOpenAccess": true, "url": "http://arxiv.org/pdf/2303.13052"}
{"paperId": "8ed4342a94c68c1a5a4ce491765b0bf08b1c396f", "year": 2024, "title": "Perception of generative AI use in UK higher education", "authors": "Abayomi Arowosegbe, J. Alqahtani, Tope Oyelade", "venue": "Frontiers in Education", "citationCount": 32, "abstract": "Generative artificial intelligence (Gen-AI) has emerged as a transformative tool in research and education. However, there is a mixed perception about its use. This study assessed the use, perception, prospect, and challenges of Gen-AI use in higher education.This is a prospective, cross-sectional survey of university students in the United Kingdom (UK) distributed online between January and April 2024. Demography of participants and their perception of Gen-AI and other AI tools were collected and statistically analyzed to assess the difference in perception between various subgroups.A total of 136 students responded to the survey of which 59% (80) were male. The majority were aware of Gen-AI and other AI use in academia (61%) with 52% having personal experience of the tools. Grammar correction and idea generation were the two most common tasks of use, with 37% being regular users. Fifty-six percent of respondents agreed that AI gives an academic edge with 40% holding a positive overall perception about the use in academia. Comparatively, there was a statistically significant difference in overall perception between different age ranges (I2\u2009=\u200927.39; p\u2009=\u20090.002) and levels of education (I2\u2009=\u200920.07; p\u2009<\u20090.001). Also, 83% of students believe AI use will increase in academia with over half agreeing it should be integrated into learning. Plagiarism (33%), privacy issues (14%), and lack of clarity by the university (13%) remain the top concerns regarding the use of Gen-AI and other AI tools in academia.Gen-AI and other AI tools are being used and their use will continue to grow in higher education. While current use is challenging due mainly to plagiarism fear and lack of clarity by the university, most users believe AI should be integrated into the university curriculum.", "isOpenAccess": false, "url": ""}
{"paperId": "8d6c95ccf0e328107eb317b19591f325ac0fd614", "year": 2023, "title": "Generative Artificial Intelligence (ChatGPT & Bard) in Public Administration Research: A Double-Edged Sword for Street-Level Bureaucracy Studies", "authors": "Mohammed Salah, Fadi Abdelfattah, Hussan Al Halbusi", "venue": "International Journal of Public Administration", "citationCount": 32, "abstract": "ABSTRACT This manuscript critically examines the adoption of generative AI tools, notably ChatGPT and Bard, within public administration research, especially in street-level bureaucracy. While these tools offer revolutionary insights into bureaucratic behaviors and decision-making, they pose significant ethical dilemmas, including potential biases and data privacy concerns. The paper offers comprehensive recommendations designed to help researchers navigate these challenges, emphasizing the need for robust data validation, enhanced transparency, and continuous adherence to evolving ethical standards. The overarching aim is to facilitate responsible AI integration, ensuring research methodologies\u2019 efficacy and preserving ethical integrity in public administration inquiries.", "isOpenAccess": true, "url": "https://www.tandfonline.com/doi/pdf/10.1080/01900692.2023.2274801?needAccess=true"}
{"paperId": "8aa035778b17e14d209f37c9837c7c84ee61201c", "year": 2024, "title": "A systematic literature review of attitudes, intentions and behaviours of teaching academics pertaining to AI and generative AI (GenAI) in higher education: An analysis of GenAI adoption using the UTAUT framework", "authors": "Sasha Nikolic, Isabelle Wentworth, Lynne Sheridan, S. Moss, Elisabeth Duursma, Rachel A. Jones, Montserrat Ros, Rebekkah Middleton", "venue": "Australasian Journal of Educational Technology", "citationCount": 32, "abstract": "The rapid advancement of artificial intelligence (AI) has outpaced existing research and regulatory frameworks in higher education, leading to varied institutional responses. Although some educators and institutions have embraced AI and generative AI (GenAI), other individuals remain cautious. This systematic literature review explored teaching academics' attitudes, perceptions and intentions towards AI and GenAI, identifying perceived benefits and obstacles. Utilising the unified theory of acceptance and use of technology framework, this study reveals positive attitudes towards AI's efficiency and teaching enhancement, but also significant concerns about academic integrity, accuracy, reliability, skill development and the need for comprehensive training and policies. These findings underscore the necessity for institutional support to navigate the integration of AI and GenAI in tertiary education.\n\u00a0\nImplications for practice or policy:\n\nAttitudes towards AI and GenAI integration are diverse with educators recognising benefits but raising ethical and practical concerns. These concerns indicate a need for a more comprehensive understanding and dialogue within academic communities.\nAcademics' intentions to use these technologies are contingent upon the development of robust ethical guidelines and supportive institutional policies.\nInstitutional support and training shape behaviours. The scarcity of formal training, systematic guidelines and policy frameworks currently limits effective integration.\n", "isOpenAccess": false, "url": ""}
{"paperId": "7d6a31853432f3d4ce508f445c46d497afe9997c", "year": 2023, "title": "People devalue generative AI\u2019s competence but not its advice in addressing societal and personal challenges", "authors": "Robert B\u00f6hm, Moritz J\u00f6rling, Leonhard Reiter, Christoph Fuchs", "venue": "Communications psychology", "citationCount": 32, "abstract": "The release of ChatGPT and related tools have made generative artificial intelligence (AI) easily accessible for the broader public. We conducted four preregistered experimental studies (total N\u2009=\u20093308; participants from the US) to investigate people\u2019s perceptions of generative AI and the advice it generates on how to address societal and personal challenges. The results indicate that when individuals are (vs. are not) aware that the advice was generated by AI, they devalue the author\u2019s competence but not the content or the intention to share and follow the advice on how to address societal challenges (Study 1) and personal challenges (Studies 2a and 2b). Study 3 further shows that individuals\u2019 preference to receive advice from AI (vs. human experts) increases when they gained positive experience with generative AI advice in the past. The results are discussed regarding the nature of AI aversion in the context of generative AI and beyond.", "isOpenAccess": true, "url": "https://www.nature.com/articles/s44271-023-00032-x.pdf"}
{"paperId": "77b6affdcfd1b901db154093b2817368e5fb306d", "year": 2024, "title": "Being Human in the Age of Generative AI: Young People's Ethical Concerns about Writing and Living with Machines", "authors": "Jennifer Higgs, A. Stornaiuolo", "venue": "Reading Research Quarterly", "citationCount": 32, "abstract": "The recent unveiling of chatbots such as ChatGPT has catalyzed vigorous debates about generative AI's impact on how learners read, write, and communicate. Largely missing from these debates is careful consideration of how young people are experiencing AI in their everyday lives and how they are making sense of the questions that these rapidly evolving cultural tools raise about ethics, power, and social participation. Engaging cultural\u2010historical perspectives on technology, the present study drew on student survey and focus group data from English language arts classes in two culturally and linguistically diverse high schools to answer the following questions: (1) How are young people using AI in their everyday lives, if at all?; (2) What do young people identify as key considerations related to AI\u2010mediated writing?; and (3) What ethical and critical considerations, if any, inform young people's sensemaking of and practices with AI? Young people reported using generative AI for diverse purposes in and out of school, including to accomplish routine organizational and information tasks, to entertain themselves through experimenting with AI technologies, and to catalyze their thinking and writing processes. Survey and focus group participants' responses suggested their regular navigation of ethical and critical dimensions of AI use and their contemplation of what it means to be human through and with advancing technologies. Young people also reported a lack of opportunity to examine AI practices and perspectives in school, suggesting the important role schools can play in supporting youths' development of AI ethics.", "isOpenAccess": true, "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/rrq.552"}
{"paperId": "758b9fa417e2cb2e805bb5d839430fe524aa5faf", "year": 2023, "title": "Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion", "authors": "Jordan J. Bird, Ahmad Lotfi", "venue": "arXiv.org", "citationCount": 32, "abstract": "There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learning models over 10-fold cross validation, it is found that the Extreme Gradient Boosting model can achieve an average classification accuracy of 99.3% and can classify speech in real-time, at around 0.004 milliseconds given one second of speech. All data generated for this study is released publicly for future research on AI speech detection.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.12734"}
{"paperId": "71ae0f0316f2e894f3cdf3833ecb87370e428d9d", "year": 2025, "title": "Understanding tourist barriers and personality influences in embracing generative AI for travel planning and decision-making", "authors": "Siamak Seyfi, Myung Ja Kim, Amin Nazifi, Samantha Murdy, Tan Vo\u2010Thanh", "venue": "International Journal of Hospitality Management", "citationCount": 32, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.ijhm.2025.104105"}
{"paperId": "6b6fedd8c9e015d373477a571c755e850f81a521", "year": 2023, "title": "Arthrosis diagnosis and treatment recommendations in clinical practice: an exploratory investigation with the generative AI model GPT-4", "authors": "Stefano Pagano, Sabrina Holzapfel, T. Kappenschneider, Matthias Meyer, G. Maderbacher, Joachim Grifka, D. Holzapfel", "venue": "Journal of Orthopaedics and Traumatology", "citationCount": 32, "abstract": "Background The spread of artificial intelligence (AI) has led to transformative advancements in diverse sectors, including healthcare. Specifically, generative writing systems have shown potential in various applications, but their effectiveness in clinical settings has been barely investigated. In this context, we evaluated the proficiency of ChatGPT-4 in diagnosing gonarthrosis and coxarthrosis and recommending appropriate treatments compared with orthopaedic specialists. Methods A retrospective review was conducted using anonymized medical records of 100 patients previously diagnosed with either knee or hip arthrosis. ChatGPT-4 was employed to analyse these historical records, formulating both a diagnosis and potential treatment suggestions. Subsequently, a comparative analysis was conducted to assess the concordance between the AI\u2019s conclusions and the original clinical decisions made by the physicians. Results In diagnostic evaluations, ChatGPT-4 consistently aligned with the conclusions previously drawn by physicians. In terms of treatment recommendations, there was an 83% agreement between the AI and orthopaedic specialists. The therapeutic concordance was verified by the calculation of a Cohen\u2019s Kappa coefficient of 0.580 ( p \u2009<\u20090.001). This indicates a moderate-to-good level of agreement. In recommendations pertaining to surgical treatment, the AI demonstrated a sensitivity and specificity of 78% and 80%, respectively. Multivariable logistic regression demonstrated that the variables reduced quality of life (OR 49.97, p \u2009<\u20090.001) and start-up pain (OR 12.54, p \u2009=\u20090.028) have an influence on ChatGPT-4\u2019s recommendation for a surgery. Conclusion This study emphasises ChatGPT-4\u2019s notable potential in diagnosing conditions such as gonarthrosis and coxarthrosis and in aligning its treatment recommendations with those of orthopaedic specialists. However, it is crucial to acknowledge that AI tools such as ChatGPT-4 are not meant to replace the nuanced expertise and clinical judgment of seasoned orthopaedic surgeons, particularly in complex decision-making scenarios regarding treatment indications. Due to the exploratory nature of the study, further research with larger patient populations and more complex diagnoses is necessary to validate the findings and explore the broader potential of AI in healthcare. Level of Evidence : Level III evidence.", "isOpenAccess": true, "url": "https://jorthoptraumatol.springeropen.com/counter/pdf/10.1186/s10195-023-00740-4"}
{"paperId": "5dd2d8d899e12062164c2a43cff728b28dc1defe", "year": 2023, "title": "Generative AI in the Manufacturing Process: Theoretical Considerations", "authors": "Doung Cong Doanh, Zden\u011bk Dufek, J. Ejdys, R. Ginevi\u010dius, P. Korzy\u0144ski, G. Mazurek, Joanna Paliszkiewicz, Krzysztof Wach, E. Ziemba", "venue": "Engineering Management in Production and Services", "citationCount": 32, "abstract": "Abstract The paper aims to identify how digital transformation and Generative Artificial Intelligence (GAI), in particular, affect the manufacturing processes. Several dimensions of the Industry 4.0 field have been considered, such as the design of new products, workforce and skill optimisation, enhancing quality control, predictive maintenance, demand forecasting, and marketing strategy. The paper adopts qualitative research based on a critical review approach. It provides evidence of the GAI technology support in the mentioned areas. Appropriate use of emerging technology allows managers to transform manufacturing by optimising processes, improving product design, enhancing quality control, and contributing to overall efficiency and innovation in the industry. Simultaneously, GAI technologies facilitate predictive analytics to forecast and anticipate future demand, quality issues, and potential risks, improve a marketing strategy and identify market trends.", "isOpenAccess": true, "url": "https://sciendo.com/pdf/10.2478/emj-2023-0029"}
{"paperId": "5c0984f0956882f1c599c5403e1a0f8614363d37", "year": 2024, "title": "Generative AI and Its Impact on Personalized Intelligent Tutoring Systems", "authors": "Subhankar Maity, Aniket Deroy", "venue": "arXiv.org", "citationCount": 32, "abstract": "Generative Artificial Intelligence (AI) is revolutionizing educational technology by enabling highly personalized and adaptive learning environments within Intelligent Tutoring Systems (ITS). This report delves into the integration of Generative AI, particularly large language models (LLMs) like GPT-4, into ITS to enhance personalized education through dynamic content generation, real-time feedback, and adaptive learning pathways. We explore key applications such as automated question generation, customized feedback mechanisms, and interactive dialogue systems that respond to individual learner needs. The report also addresses significant challenges, including ensuring pedagogical accuracy, mitigating inherent biases in AI models, and maintaining learner engagement. Future directions highlight the potential advancements in multimodal AI integration, emotional intelligence in tutoring systems, and the ethical implications of AI-driven education. By synthesizing current research and practical implementations, this report underscores the transformative potential of Generative AI in creating more effective, equitable, and engaging educational experiences.", "isOpenAccess": false, "url": ""}
{"paperId": "509d4c6778baf9d42abd86e56be69488804ddeda", "year": 2024, "title": "Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey)", "authors": "K. Kenthapadi, M. Sameki, Ankur Taly", "venue": "Knowledge Discovery and Data Mining", "citationCount": 32, "abstract": "With the ongoing rapid adoption of Artificial Intelligence (AI)-based systems in high-stakes domains, ensuring the trustworthiness, safety, and observability of these systems has become crucial. It is essential to evaluate and monitor AI systems not only for accuracy and quality-related metrics but also for robustness, bias, security, interpretability, and other responsible AI dimensions. We focus on large language models (LLMs) and other generative AI models, which present additional challenges such as hallucinations, harmful and manipulative content, and copyright infringement. In this survey article accompanying our tutorial, we highlight a wide range of harms associated with generative AI systems, and survey state of the art approaches (along with open challenges) to address these harms.", "isOpenAccess": false, "url": ""}
{"paperId": "489dec417db049ef9111e4e8af8909d112a76f0b", "year": 2025, "title": "Generative AI and its Transformative Value for Digital Platforms", "authors": "Michael Wessel, Martin Adam, Alexander Benlian, Ann Majchrzak, Ferdinand Thies", "venue": "Journal of Management Information Systems", "citationCount": 32, "abstract": "ABSTRACT The emergence of generative artificial intelligence (GenAI) represents a watershed moment in the evolution of digital platforms. The capabilities of this AI technology go beyond traditional AI systems, enabling the autonomous generation of novel outcomes with significant implications for platform value creation, architecture, governance, and stakeholder interactions. We develop an integrative conceptual framework that identifies four key mechanisms through which GenAI transforms digital platforms: intelligent automation, democratization, hyper-personalization, and collaborative innovation. Through intelligent automation, GenAI transforms boundary resources from passive interfaces into active, intelligent mediators of value creation. Democratization systematically lowers barriers to platform participation. Hyper-personalization enables dynamic, individual-level adaptation of platform content. Collaborative innovation transforms platform innovation by making GenAI an active participant in human-AI value co-creation. We use this framework to situate the papers in the special issue and develop a research agenda that explores the transformative impact of GenAI on platform stakeholder relationships.", "isOpenAccess": false, "url": ""}
{"paperId": "40eb2d45e251f4b065aea627c8323b4094e3a290", "year": 2025, "title": "Understanding Human-Centred AI: a review of its defining elements and a research agenda", "authors": "Stefan Schmager, Ilias O. Pappas, P. Vassilakopoulou", "venue": "Behavior and Information Technology", "citationCount": 32, "abstract": "ABSTRACT The rapid advancements in artificial intelligence (AI) have ushered in a new era of innovative applications, while also prompting concerns regarding risks and adverse consequences. In light of the growing interest in comprehending AI's impact on society and its alignment with human values and needs, Human-Centred Artificial Intelligence (HCAI) has emerged as a potential approach to address questions and concerns. In this Systematic Literature Review, we aim to contribute to conceptual clarity around the definition, conceptualisation, and implementation of HCAI. The first part of our review addresses how HCAI is defined in the existing literature, culminating in a novel comprehensive HCAI definition. Subsequently, we delve into the identified constituent elements of HCAI, namely \u2018purpose\u2019, \u2018values\u2019, and \u2018properties\u2019. Purposes include augmentation, AI autonomy, and automation. Values relate to ethics, safety, and performance. Properties cover oversight, comprehension, and integrity. The third part of the review explores Human-Centred Design processes, methods, and tools and their applicability for HCAI. In conclusion, we discuss the characteristics and critiques of HCAI and provide a research agenda. This literature review contributes to advancing the discourse on HCAI, thus enhancing human welfare and societal well-being. Abbreviations: AI: artificial intelligence; AI-HLEG: high-level expert group on artificial intelligence; GenAI: generative AI; HCAI: human-centred artificial intelligence; HCD: human-centred design; HCI: human-computer interaction; ISO: international organization for standardization; OECD: organisation for economic co-operation and development.", "isOpenAccess": true, "url": "https://doi.org/10.1080/0144929x.2024.2448719"}
{"paperId": "39095a175536d17b5071f9f888b015fb37ccee83", "year": 2024, "title": "How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context", "authors": "Michelle Brachman, Amina El-Ashry, Casey Dugan, Werner Geyer", "venue": "CHI Extended Abstracts", "citationCount": 32, "abstract": "Large Language Models (LLMs) have introduced a paradigm shift in interaction with AI technology, enabling knowledge workers to complete tasks by specifying their desired outcome in natural language. LLMs have the potential to increase productivity and reduce tedious tasks in an unprecedented way. A systematic study of LLM adoption for work can provide insight into how LLMs can best support these workers. To explore knowledge workers\u2019 current and desired usage of LLMs, we ran a survey (n=216). Workers described tasks they already used LLMs for, like generating code or improving text, but imagined a future with LLMs integrated into their workflows and data. We discuss implications for adoption and design of generative AI technologies for knowledge work.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613905.3650841"}
{"paperId": "3234cb5c0df9ea0a7646bb1c70979817741a6853", "year": 2023, "title": "Toward Clinical Generative AI: Conceptual Framework", "authors": "N. Bragazzi, Sergio Garbarino", "venue": "JMIR AI", "citationCount": 32, "abstract": "Clinical decision-making is a crucial aspect of health care, involving the balanced integration of scientific evidence, clinical judgment, ethical considerations, and patient involvement. This process is dynamic and multifaceted, relying on clinicians\u2019 knowledge, experience, and intuitive understanding to achieve optimal patient outcomes through informed, evidence-based choices. The advent of generative artificial intelligence (AI) presents a revolutionary opportunity in clinical decision-making. AI\u2019s advanced data analysis and pattern recognition capabilities can significantly enhance the diagnosis and treatment of diseases, processing vast medical data to identify patterns, tailor treatments, predict disease progression, and aid in proactive patient management. However, the incorporation of AI into clinical decision-making raises concerns regarding the reliability and accuracy of AI-generated insights. To address these concerns, 11 \u201cverification paradigms\u201d are proposed in this paper, with each paradigm being a unique method to verify the evidence-based nature of AI in clinical decision-making. This paper also frames the concept of \u201cclinically explainable, fair, and responsible, clinician-, expert-, and patient-in-the-loop AI.\u201d This model focuses on ensuring AI\u2019s comprehensibility, collaborative nature, and ethical grounding, advocating for AI to serve as an augmentative tool, with its decision-making processes being transparent and understandable to clinicians and patients. The integration of AI should enhance, not replace, the clinician\u2019s judgment and should involve continuous learning and adaptation based on real-world outcomes and ethical and legal compliance. In conclusion, while generative AI holds immense promise in enhancing clinical decision-making, it is essential to ensure that it produces evidence-based, reliable, and impactful knowledge. Using the outlined paradigms and approaches can help the medical and patient communities harness AI\u2019s potential while maintaining high patient care standards.", "isOpenAccess": true, "url": "https://s3.ca-central-1.amazonaws.com/assets.jmir.org/assets/preprints/preprint-55957-accepted.pdf"}
{"paperId": "2850fe5e25dece3bcf71331e59235af9e4122412", "year": 2024, "title": "Toward Democratized Generative AI in Next-Generation Mobile Edge Networks", "authors": "Ruichen Zhang, Jiayi He, Xiaofeng Luo, D. Niyato, Jiawen Kang, Zehui Xiong, Yonghui Li, Biplab Sikdar", "venue": "IEEE Network", "citationCount": 32, "abstract": "The rapid development of generative artificial intelligence (AI) technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.", "isOpenAccess": true, "url": "http://arxiv.org/pdf/2411.09148"}
{"paperId": "15da6ba1f672f23e34d69d5bfd0733bc3d785050", "year": 2024, "title": "Programming education and learner motivation in the age of generative AI: student and educator perspectives", "authors": "Samuel Boguslawski, Rowan Deer, Mark G. Dawson", "venue": "Information and Learning Sciences", "citationCount": 32, "abstract": "\nPurpose\nProgramming education is being rapidly transformed by generative AI tools and educators must determine how best to support students in this context. This study aims to explore the experiences of programming educators and students to inform future education provision.\n\n\nDesign/methodology/approach\nTwelve students and six members of faculty in a small technology-focused university were interviewed. Thematic analysis of the interview data was combined with data collected from a survey of 44 students at the same university. Self-determination theory was applied as an analytical framework.\n\n\nFindings\nThree themes were identified \u2013 bespoke learning, affect and support \u2013 that significantly impact motivation and learning outcomes in programming education. It was also found that students are already making extensive use of large language models (LLMs). LLMs can significantly improve learner autonomy and sense of competence by improving the options for bespoke learning; fostering emotions that are conducive to engendering and maintaining motivation; and inhibiting the negative affective states that discourage learning. However, current LLMs cannot adequately provide or replace social support, which is still a key factor in learner motivation.\n\n\nResearch limitations/implications\nIntegrating the use of LLMs into curricula can improve learning motivation and outcomes. It can also free educators from certain tasks, leaving them with more time and capacity to focus their attention on developing social learning opportunities to further enhance learner motivation.\n\n\nOriginality/value\nTo the best of the authors\u2019 knowledge, this is the first attempt to explore the relationship between motivation and LLM use in programming education.\n", "isOpenAccess": false, "url": ""}
{"paperId": "157958cb8a4a33f8f051b45c2e0b0da8e26d4ab8", "year": 2023, "title": "Harnessing Generative AI to Decode Enzyme Catalysis and Evolution for Enhanced Engineering", "authors": "Wenjun Xie, A. Warshel", "venue": "bioRxiv", "citationCount": 32, "abstract": "Enzymes, as paramount protein catalysts, occupy a central role in fostering remarkable progress across numerous fields. However, the intricacy of sequence-function relationships continues to obscure our grasp of enzyme behaviors and curtails our capabilities in rational enzyme engineering. Generative artificial intelligence (AI), known for its proficiency in handling intricate data distributions, holds the potential to offer novel perspectives in enzyme research. By applying generative models, we could discern elusive patterns within the vast sequence space and uncover new functional enzyme sequences. This review highlights the recent advancements in employing generative AI for enzyme sequence analysis. We delve into the impact of generative AI in predicting mutation effects on enzyme fitness, activity, and stability, rationalizing the laboratory evolution of de novo enzymes, decoding protein sequence semantics, and its applications in enzyme engineering. Notably, the prediction of enzyme activity and stability using natural enzyme sequences serves as a vital link, indicating how enzyme catalysis shapes enzyme evolution. Overall, we foresee that the integration of generative AI into enzyme studies will remarkably enhance our knowledge of enzymes and expedite the creation of superior biocatalysts.", "isOpenAccess": true, "url": "https://academic.oup.com/nsr/advance-article-pdf/doi/10.1093/nsr/nwad331/54930752/nwad331.pdf"}
{"paperId": "10492261b25d05da1537920c93ba61053ef4ad68", "year": 2024, "title": "ChatGPT as an AI L2 teaching support: A case study of an EFL teacher", "authors": "Manuela Mena Octavio, M. V. Gonz\u00e1lez Arg\u00fcello, Joan-Tom\u00e0s Pujol\u00e0", "venue": "Technology in Language Teaching &amp; Learning", "citationCount": 32, "abstract": "The present study investigates the potential of ChatGPT as an L2 teaching support and aims to explore the extent to which this Generative AI-powered tool is helpful for English as a Foreign Language (EFL) teachers. Therefore, this exploratory single instrumental case study followed an EFL teacher using ChatGPT for seven months, from January to June 2023, as an aid for her English classes in a private language school in Spain. Data were collected from her ChatGPT history in relation to her prompting tasks and outputs received, from her lesson plans when she implemented ChatGPT in class, and from a post semi-structured interview.\u00a0 The analysis followed a qualitative approach using thematic analysis of the data to identify the type of support received by ChatGPT and to determine the level of reliability and helpfulness of the outputs. The results indicate that ChatGPT offers significant support to EFL teachers in planning and designing lessons, in implementing ChatGPT in lessons and in assessing learners\u2019 writing. Our data highlights the potential of ChatGPT as a support for EFL teachers as long as they possess specific AI competencies, such as prompt crafting to obtain useful and meaningful outputs, and critical thinking, together with EFL teaching knowledge, to be able to recognize inaccuracies and identify relevant outcomes.", "isOpenAccess": true, "url": "https://www.castledown.com/journals/tltl/article/download/1142/239"}
{"paperId": "0ae9a7d83c086a87e04b66dd90381fb4c82c2fbf", "year": 2023, "title": "Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI", "authors": "Faraz Faruqi, Ahmed Katary, Tarik Hasic, Amira Abdel-Rahman, Nayeemur Rahman, Leandra Tejedor, Mackenzie Leake, Megan Hofmann, Stefanie Mueller", "venue": "ACM Symposium on User Interface Software and Technology", "citationCount": 32, "abstract": "With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models. However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world. For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over. We introduce a method for automatically segmenting 3D models into functional and aesthetic elements. This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments. To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse. With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements. We propose a system called Style2Fab that allows users to selectively stylize 3D models without compromising their functionality. We evaluate the effectiveness of our classification method compared to human-annotated data, and demonstrate the utility of Style2Fab with a user study to show that functionality-aware segmentation helps preserve model functionality.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3586183.3606723"}
{"paperId": "071d057b0693682f16a694cb3ecae720b971e33e", "year": 2024, "title": "Driving Factors of Generative AI Adoption in New Product Development Teams from a UTAUT Perspective", "authors": "Yan Xia, Yue Chen", "venue": "International journal of human computer interactions", "citationCount": 32, "abstract": "Abstract Recent new product development (NPD) teams apply various generative AI (GenAI) tools in the development process, yet it is not fully understood about the factors affecting teams\u2019 adoption of these tools. This research identifies factors driving the use and attitudes toward GenAI in NPD tasks based on the Unified Theory of Acceptance and Use of Technology (UTAUT). We interviewed nine GenAI users in NPD teams and conducted a survey study with 309 participants. By exploratory factor analysis and hierarchical regressions, we identified a composite factor of performance expectancy and anthropomorphism as the strongest positive predictor of attitudes, and task-tool fitness as the strongest positive predictor of behavioral intention. Besides, we also identified significant predictors including several other factors in UTAUT and individual differences in AI self-efficacy. The findings can be used for developing UTAUT models and designing GenAI tools specific to NPD purposes.", "isOpenAccess": false, "url": ""}
{"paperId": "f9f5e109e8a5bf29c6ec0aa2e7b95024b677f9da", "year": 2025, "title": "AI in the classroom: Exploring students\u2019 interaction with ChatGPT in programming learning", "authors": "Hacer G\u00fcner, Erkan Er", "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education", "citationCount": 31, "abstract": "As being more prevalent in educational settings, understanding the impact of artificial intelligence tools on student behaviors and interactions has become crucial. In this regard, this study investigates the dynamic interactions between students and ChatGPT in programming learning, focusing on how different instructional interventions influence their learning and AI-interaction. Conducted over three sessions, students were allowed to use ChatGPT to complete programming tasks. The first session had no guidance, the second included hands-on training in prompt writing and effective ChatGPT use, and the third provided a lab guide with sample prompts. After each session, students took a post-test on the activity\u2019s subject. Analyzing students\u2019 prompting behaviors, five AI interaction profiles were identified: AI-Reliant Code Generators, AI-Reliant Code Generator & Refiners, AI-Collaborative Coders, AI-Assisted Code Refiners, and AI-Independent Coders. These profiles were examined to understand their evolution across interventions and their relationship with students\u2019 learning performance. Findings revealed significant changes in profile distribution across interventions, and a notable difference between students\u2019 post-test scores and their AI interaction profiles. Besides, training in prompting skills and effective use of AI significantly impacted students\u2019 interactions with AI. These insights can contribute to the knowledge of integrating generative AI tools in education, highlighting how AI can enhance teaching practices. Understanding student-AI interaction dynamics can allow educators to tailor instructional strategies for optimal learning. This study also underscores the importance of guidance on effective AI use and prompting skills, which can lead students to use AI more meaningfully for their learning.", "isOpenAccess": true, "url": "https://doi.org/10.1007/s10639-025-13337-7"}
{"paperId": "f61267a1e26c7b38097c2183245dfb654b1d2ac3", "year": 2023, "title": "Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy", "authors": "Eric J. York", "venue": "ACM International Conference on Design of Communication", "citationCount": 31, "abstract": "The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\u00efvely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.", "isOpenAccess": false, "url": ""}
{"paperId": "e99c9b0dd750bece8bef047e4058605c5ab1d79a", "year": 2024, "title": "Discourse Analysis on the Ethical Dilemmas on the Use of AI in Academic Settings from ICT, Science, and Language Instructors", "authors": "Jason V. Chavez, Jhordan T. Cuilan, Sali S. Mannan, Narrin U. Ibrahim, Aisha A. Carolino, Abubakar Radjuni, Salman E. Albani, Benigno A. Garil", "venue": "Forum for Linguistic Studies", "citationCount": 31, "abstract": "Artificial intelligence (AI) in education has the potential to revolutionize learning by addressing significant challenges and accelerating progress. Generative AI, such as ChatGPT, has demonstrated the ability to produce high-quality text and other content, potentially transforming academic tasks like essay writing. Despite these advantages, educators are concerned about the ethical implications of AI use. Risks such as misinformation, academic dishonesty, and overreliance on AI must be thoroughly assessed. This discourse analysis explored the perceptions of teachers on AI use in academic settings, highlighting concepts leading to ethical issues involved in its use. Convenience sampling (n=30) was used to select the participants for a one-on-one interview. Findings indicated that overreliance, dishonesty, cheating, are plagiarism were some ethical issues that emerged from the discourse. Convenience, driven by ease and accessibility, can lead students to excessively use AI, which may inadvertently hamper their learning processes. Overreliance, fueled by trust in generated outputs, can result in students depending heavily on AI-generated information, which may not always be accurate or critically analyzed. Students who feel incapable of producing quality work on their own may resort to AI, believing they lack the necessary skills. This reliance on AI can erode their confidence and critical thinking abilities, further entrenching their dependence on technology. While AI can enhance learning and efficiency, it also poses risks of academic dishonesty, overreliance, and diminished student engagement with the learning process. Teachers perceive AI use as unethical, primarily due to how students interact with and depend on AI, ultimately affecting their academic integrity and genuine intellectual development.", "isOpenAccess": true, "url": "https://journals.bilpubgroup.com/index.php/fls/article/download/6765/5537"}
{"paperId": "e5bafaae57503b59a59386d0b74fc6eb40225ba8", "year": 2023, "title": "Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle", "authors": "Thomas Dohmke, M. Iansiti, Gregory L. Richards", "venue": "", "citationCount": 31, "abstract": "This study examines the impact of GitHub Copilot on a large sample of Copilot users (n=934,533). The analysis shows that users on average accept nearly 30% of the suggested code, leading to increased productivity. Furthermore, our research demonstrates that the acceptance rate rises over time and is particularly high among less experienced developers, providing them with substantial benefits. Additionally, our estimations indicate that the adoption of generative AI productivity tools could potentially contribute to a $1.5 trillion increase in global GDP by 2030. Moreover, our investigation sheds light on the diverse contributors in the generative AI landscape, including major technology companies, startups, academia, and individual developers. The findings suggest that the driving force behind generative AI software innovation lies within the open-source ecosystem, particularly in the United States. Remarkably, a majority of repositories on GitHub are led by individual developers. As more developers embrace these tools and acquire proficiency in the art of prompting with generative AI, it becomes evident that this novel approach to software development has forged a unique inextricable link between humans and artificial intelligence. This symbiotic relationship has the potential to shape the construction of the world's software for future generations.", "isOpenAccess": false, "url": ""}
{"paperId": "e2116ff028aeea041b862928a38a81f8b7fd9415", "year": 2024, "title": "Copyright Law and the Lifecycle of Machine Learning Models", "authors": "Martin Kretschmer, Thomas Margoni, Pinar Oruc", "venue": "IIC - International Review of Intellectual Property and Competition Law", "citationCount": 31, "abstract": "Machine learning, a subfield of artificial intelligence (AI), relies on large corpora of data as input for learning algorithms, resulting in trained models that can perform a variety of tasks. While data or information are not subject matter within copyright law, almost all materials used to construct corpora for machine learning are protected by copyright law: texts, images, videos, and so on. There are global policy moves to address the copyright implications of machine learning, in particular in the context of so-called \u201cfoundation models\u201d that underpin generative AI. This paper takes a step back, exploring empirically three technological settings through detailed case studies. We set out the established industry methodology of a lifecycle of AI (collecting data, organising data, model training, model operation) to arrive at descriptions suitable for legal analysis. This will allow an assessment of the challenges for a harmonisation of rights, exceptions and disclosure under EU copyright law. The three case studies are: 1. Machine learning for scientific purposes, in the context of a study of regional short-term letting markets; 2. Natural Language Processing (NLP), in the context of large language models; 3. Computer vision, in the context of content moderation of images. We find that the nature and quality of data corpora at the input stage is central to the lifecycle of machine learning. Because of the uncertain legal status of data collection and processing, combined with the competitive advantage gained by firms not disclosing technological advances, the inputs of the models deployed are often unknown. Moreover, the \u201clawful access\u201d requirement of the EU exception for text and data mining may turn the exception into a decision by rightholders to allow machine learning in the context of their decision to allow access. We assess policy interventions at EU level, seeking to clarify the legal status of input data via copyright exceptions, opt-outs or the forced disclosure of copyright materials. We find that the likely result is a fully copyright-licensed environment of machine learning that may have problematic effects for the structure of industry, innovation and scientific research.", "isOpenAccess": true, "url": "https://link.springer.com/content/pdf/10.1007/s40319-023-01419-3.pdf"}
{"paperId": "e09cae7f61b9480fd767f9b582ddd8f988e00e9b", "year": 2024, "title": "The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing", "authors": "Hilda Hadan, Derrick M. Wang, Reza Hadi Mogavi, Joseph Tu, Leah Zhang-Kennedy, Lennart E. Nacke", "venue": "Computers in Human Behavior", "citationCount": 31, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "d5a6fc6aa139066e3b66ba63002e7d84c109aebc", "year": 2023, "title": "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing", "authors": "Sonish Sivarajkumar, Mark Kelley, Alyssa Samolyk-Mazzanti, S. Visweswaran, Yanshan Wang", "venue": "arXiv.org", "citationCount": 31, "abstract": "Large language models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), especially in domains where labeled data is scarce or expensive, such as clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. In this paper, we present a comprehensive and systematic experimental study on prompt engineering for five clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence Extraction, Coreference Resolution, Medication Status Extraction, and Medication Attribute Extraction. We assessed the prompts proposed in recent literature, including simple prefix, simple cloze, chain of thought, and anticipatory prompts, and introduced two new types of prompts, namely heuristic prompting and ensemble prompting. We evaluated the performance of these prompts on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted zero-shot prompting with few-shot prompting, and provide novel insights and guidelines for prompt engineering for LLMs in clinical NLP. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative AI, and we hope that it will inspire and inform future research in this area.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2309.08008"}
{"paperId": "cdd35ae5735f4163925823f6c2561835e9a6e721", "year": 2024, "title": "A world model: On the political logics of generative AI", "authors": "Louise Amoore, Alexander Campolo, Benjamin Jacobsen, Ludovico Rella", "venue": "Political Geography", "citationCount": 31, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.polgeo.2024.103134"}
{"paperId": "bba4b5a6eb604a4f5ad377589e395157df1428f7", "year": 2023, "title": "Car-Following Models: A Multidisciplinary Review", "authors": "T. Zhang, Peter J. Jin, Sean T. McQuade, Alexandre M. Bayen, B. Piccoli", "venue": "IEEE Transactions on Intelligent Vehicles", "citationCount": 31, "abstract": "Car-following (CF) algorithms are crucial components of traffic simulations and have been integrated into many production vehicles equipped with Advanced Driving Assistance Systems (ADAS). Insights from the model of car-following behavior help researchers to understand the causes of various macro phenomena that arise from interactions between pairs of vehicles. Car-following Models encompass multiple disciplines, including traffic engineering, physics, dynamic system control, cognitive science, machine learning, deep learning, and reinforcement learning. This paper presents an extensive survey highlighting the differences, complementarities, and overlaps among microscopic traffic flow and control models based on their underlying principles and design logic. It reviews a range of representative algorithms, from theory-based Kinematic Models, Psycho-Physical Models, and Adaptive Cruise Control Models to learning-based algorithms like Reinforcement Learning (RL) and Imitation Learning (IL). Additionally, it considers the impact of large Generative AI (GenAI) models, categorized as Knowledge-Driven models. The survey discusses the strengths and limitations of these models, explores their applications in various contexts, and summarizes available datasets across different domains to address knowledge gaps. By synthesizing historical developments and current trends, this survey provides a comprehensive overview of the evolution and future directions of car-following models. It highlights the importance of interdisciplinary approaches and the need for continued innovation to address emerging challenges.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2304.07143"}
{"paperId": "b5187ab65ad87597e880505a66b048497a8c4a8d", "year": 2024, "title": "Transforming Software Development with Generative AI: Empirical Insights on Collaboration and Workflow", "authors": "Rasmus Ulfsnes, N. Moe, V. Stray, Marianne Skarpen", "venue": "arXiv.org", "citationCount": 31, "abstract": "Generative AI (GenAI) has fundamentally changed how knowledge workers, such as software developers, solve tasks and collaborate to build software products. Introducing innovative tools like ChatGPT and Copilot has created new opportunities to assist and augment software developers across various problems. We conducted an empirical study involving interviews with 13 data scientists, managers, developers, designers, and frontend developers to investigate the usage of GenAI. Our study reveals that ChatGPT signifies a paradigm shift in the workflow of software developers. The technology empowers developers by enabling them to work more efficiently, speed up the learning process, and increase motivation by reducing tedious and repetitive tasks. Moreover, our results indicate a change in teamwork collaboration due to software engineers using GenAI for help instead of asking co-workers which impacts the learning loop in agile teams.", "isOpenAccess": false, "url": ""}
{"paperId": "b508d003368c9499a2c73a571a9d1a92b2bfe404", "year": 2023, "title": "Evaluating ChatGPT-4\u2019s Diagnostic Accuracy: Impact of Visual Data Integration", "authors": "Takanobu Hirosawa, Yukinori Harada, K. Tokumasu, Takahiro Ito, Tomoharu Suzuki, T. Shimizu", "venue": "JMIR Medical Informatics", "citationCount": 31, "abstract": "Background In the evolving field of health care, multimodal generative artificial intelligence (AI) systems, such as ChatGPT-4 with vision (ChatGPT-4V), represent a significant advancement, as they integrate visual data with text data. This integration has the potential to revolutionize clinical diagnostics by offering more comprehensive analysis capabilities. However, the impact on diagnostic accuracy of using image data to augment ChatGPT-4 remains unclear. Objective This study aims to assess the impact of adding image data on ChatGPT-4\u2019s diagnostic accuracy and provide insights into how image data integration can enhance the accuracy of multimodal AI in medical diagnostics. Specifically, this study endeavored to compare the diagnostic accuracy between ChatGPT-4V, which processed both text and image data, and its counterpart, ChatGPT-4, which only uses text data. Methods We identified a total of 557 case reports published in the American Journal of Case Reports from January 2022 to March 2023. After excluding cases that were nondiagnostic, pediatric, and lacking image data, we included 363 case descriptions with their final diagnoses and associated images. We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without vision based on their ability to include the final diagnoses within differential diagnosis lists. Two independent physicians evaluated their accuracy, with a third resolving any discrepancies, ensuring a rigorous and objective analysis. Results The integration of image data into ChatGPT-4V did not significantly enhance diagnostic accuracy, showing that final diagnoses were included in the top 10 differential diagnosis lists at a rate of 85.1% (n=309), comparable to the rate of 87.9% (n=319) for the text-only version (P=.33). Notably, ChatGPT-4V\u2019s performance in correctly identifying the top diagnosis was inferior, at 44.4% (n=161), compared with 55.9% (n=203) for the text-only version (P=.002, \u03c72 test). Additionally, ChatGPT-4\u2019s self-reports showed that image data accounted for 30% of the weight in developing the differential diagnosis lists in more than half of cases. Conclusions Our findings reveal that currently, ChatGPT-4V predominantly relies on textual data, limiting its ability to fully use the diagnostic potential of visual information. This study underscores the need for further development of multimodal generative AI systems to effectively integrate and use clinical image data. Enhancing the diagnostic performance of such AI systems through improved multimodal data integration could significantly benefit patient care by providing more accurate and comprehensive diagnostic insights. Future research should focus on overcoming these limitations, paving the way for the practical application of advanced AI in medicine.", "isOpenAccess": true, "url": "https://doi.org/10.2196/55627"}
{"paperId": "b4b0a5989b2568a04fef6a6a3c159cdcac039494", "year": 2024, "title": "LLMs in Web-Development: Evaluating LLM-Generated PHP code unveiling vulnerabilities and limitations", "authors": "Rebeka T'oth, Tamas Bisztray, L'aszl'o Erdodi", "venue": "International Conference on Computer Safety, Reliability, and Security", "citationCount": 31, "abstract": "This study evaluates the security of web application code generated by Large Language Models, analyzing 2,500 GPT-4 generated PHP websites. These were deployed in Docker containers and tested for vulnerabilities using a hybrid approach of Burp Suite active scanning, static analysis, and manual review. Our investigation focuses on identifying Insecure File Upload, SQL Injection, Stored XSS, and Reflected XSS in GPT-4 generated PHP code. This analysis highlights potential security risks and the implications of deploying such code in real-world scenarios. Overall, our analysis found 2,440 vulnerable parameters. According to Burp's Scan, 11.56% of the sites can be straight out compromised. Adding static scan results, 26% had at least one vulnerability that can be exploited through web interaction. Certain coding scenarios, like file upload functionality, are insecure 78% of the time, underscoring significant risks to software safety and security. To support further research, we have made the source codes and a detailed vulnerability record for each sample publicly available. This study emphasizes the crucial need for thorough testing and evaluation if generative AI technologies are used in software development.", "isOpenAccess": false, "url": ""}
{"paperId": "b390f269e2f4d27bb5b27577c47fae2156cf38c8", "year": 2023, "title": "Generative models for protein sequence modeling: recent advances and future directions", "authors": "Mehrsa Mardikoraem, Zirui Wang, Nathaniel Pascual, Daniel R. Woldring", "venue": "Briefings Bioinform.", "citationCount": 31, "abstract": "Abstract The widespread adoption of high-throughput omics technologies has exponentially increased the amount of protein sequence data involved in many salient disease pathways and their respective therapeutics and diagnostics. Despite the availability of large-scale sequence data, the lack of experimental fitness annotations underpins the need for self-supervised and unsupervised machine learning (ML) methods. These techniques leverage the meaningful features encoded in abundant unlabeled sequences to accomplish complex protein engineering tasks. Proficiency in the rapidly evolving fields of protein engineering and generative AI is required to realize the full potential of ML models as a tool for protein fitness landscape navigation. Here, we support this work by (i) providing an overview of the architecture and mathematical details of the most successful ML models applicable to sequence data (e.g. variational autoencoders, autoregressive models, generative adversarial neural networks, and diffusion models), (ii) guiding how to effectively implement these models on protein sequence data to predict fitness or generate high-fitness sequences and (iii) highlighting several successful studies that implement these techniques in protein engineering (from paratope regions and subcellular localization prediction to high-fitness sequences and protein design rules generation). By providing a comprehensive survey of model details, novel architecture developments, comparisons of model applications, and current challenges, this study intends to provide structured guidance and robust framework for delivering a prospective outlook in the ML-driven protein engineering field.", "isOpenAccess": true, "url": "https://academic.oup.com/bib/article-pdf/24/6/bbad358/52312609/bbad358.pdf"}
{"paperId": "abb07cfecd00810bc9b1754ea78bead5a3cd0a95", "year": 2024, "title": "The Metaverse: innovations and generative AI", "authors": "Jussi S. Jauhiainen", "venue": "International Journal of Innovation Studies", "citationCount": 31, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.ijis.2024.04.004"}
{"paperId": "99c2ba6717264cfd998cac2f9735fda90538a556", "year": 2024, "title": "Generative Artificial Intelligence in Product Design Education: Navigating Concerns of Originality and Ethics", "authors": "Kristin A. Bartlett, J. Camba", "venue": "Int. J. Interact. Multim. Artif. Intell.", "citationCount": 31, "abstract": "Image-generative artificial intelligence (AI) is increasingly being used in the product design process. In this paper, we present examples of how it is being used and discuss the possibilities of how applications may evolve in the future. We discuss the legal and ethical implications of image-generative AI, including concerns about bias, hidden labor, theft from artists, lack of originality in the outputs, and lack of copyright protection. We discuss how these concerns apply to design education and provide recommendations to educators about how AI should be addressed in the design classroom. We recommend that educators introduce AI as one tool among many in the designer\u2019s toolkit and encourage it to be used as a process tool rather than for generating final design deliverables. We also provide guidance for how educators might engage students in discussions about AI to enhance their learning.", "isOpenAccess": true, "url": "https://doi.org/10.9781/ijimai.2024.02.006"}
{"paperId": "981e0fbddb9378fddd68a2101cfde186cd5f6531", "year": 2023, "title": "REACT2023: The First Multiple Appropriate Facial Reaction Generation Challenge", "authors": "Siyang Song, Micol Spitale, Cheng Luo, Germ\u00e1n Barquero, Cristina Palmero, Sergio Escalera, M. Valstar, Tobias Baur, F. Ringeval, Elisabeth Andr\u00e9, Hatice Gunes", "venue": "ACM Multimedia", "citationCount": 31, "abstract": "The Multiple Appropriate Facial Reaction Generation Challenge (REACT2023) is the first competition event focused on evaluating multimedia processing and machine learning techniques for generating human-appropriate facial reactions in various dyadic interaction scenarios, with all participants competing strictly under the same conditions. The goal of the challenge is to provide the first benchmark test set for multi-modal information processing and to foster collaboration among the audio, visual, and audio-visual behaviour analysis and behaviour generation (a.k.a generative AI) communities, to compare the relative merits of the approaches to automatic appropriate facial reaction generation under different spontaneous dyadic interaction conditions. This paper presents: (i) the novelties, contributions and guidelines of the REACT2023 challenge; (ii) the dataset utilized in the challenge; and (iii) the performance of the baseline systems on the two proposed sub-challenges: Offline Multiple Appropriate Facial Reaction Generation and Online Multiple Appropriate Facial Reaction Generation, respectively. The challenge baseline code is publicly available at https://github.com/reactmultimodalchallenge/baseline_react2023.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3581783.3612832"}
{"paperId": "91ce9ec1df2d1d41fee63b8479b816aedd44b7cc", "year": 2023, "title": "The Use of Assistive Technologies Including Generative AI by Test Takers in Language Assessment: A Debate of Theory and Practice", "authors": "Erik Voss, Sara T. Cushing, G. Ockey, Xun Yan", "venue": "Language Assessment Quarterly", "citationCount": 31, "abstract": "ABSTRACT Assistive writing tools that provide suggestions for word choice, sentence structure, and grammar correction are allowed as accommodations for students with learning disabilities on a case-by-case basis. These assistive technologies, including generative artificial intelligence (AI) tools, are increasingly accessible to more people than ever and are being utilized for second language classroom instruction and learning. In light of this trend, at a meeting of the Automated Language Assessment (ALA) SIG at the Language Testing Research Colloquium (LTRC) in New York City, a debate took place on the topic of allowing access to assistive technologies including generative AI in language assessment. This commentary, building and expanding on the debate that occurred between two opposing teams who argued for or against allowing students\u2019 access to these assistive technologies during language assessment, extends the exchange of ideas in a written debate. The debate raises issues related to construct definition, scoring and rubric design, validity, fairness, equity, bias and copyright. The debate also speculates on the use of generative AI by test takers at different proficiency levels and different stakes (high vs. low) assessments. The debate ends with thoughts on AI\u2019s impact on language teaching and learning and when access to such technologies might emerge in language assessment. The issues and questions raised in the debate forecast discussions regarding the feasibility of allowing test takers to use assistive technologies including generative AI during language assessment and the extent to which humans interact and collaborate with these new technologies.", "isOpenAccess": false, "url": ""}
{"paperId": "8e764b91d7c0bab9f21508969d1abbf84f409bc6", "year": 2024, "title": "Improved Noise Schedule for Diffusion Training", "authors": "Tiankai Hang, Shuyang Gu", "venue": "arXiv.org", "citationCount": 31, "abstract": "Diffusion models have emerged as the de facto choice for generating high-quality visual signals across various domains. However, training a single model to predict noise across various levels poses significant challenges, necessitating numerous iterations and incurring significant computational costs. Various approaches, such as loss weighting strategy design and architectural refinements, have been introduced to expedite convergence and improve model performance. In this study, we propose a novel approach to design the noise schedule for enhancing the training of diffusion models. Our key insight is that the importance sampling of the logarithm of the Signal-to-Noise ratio ($\\log \\text{SNR}$), theoretically equivalent to a modified noise schedule, is particularly beneficial for training efficiency when increasing the sample frequency around $\\log \\text{SNR}=0$. This strategic sampling allows the model to focus on the critical transition point between signal dominance and noise dominance, potentially leading to more robust and accurate predictions.We empirically demonstrate the superiority of our noise schedule over the standard cosine schedule.Furthermore, we highlight the advantages of our noise schedule design on the ImageNet benchmark, showing that the designed schedule consistently benefits different prediction targets. Our findings contribute to the ongoing efforts to optimize diffusion models, potentially paving the way for more efficient and effective training paradigms in the field of generative AI.", "isOpenAccess": false, "url": ""}
{"paperId": "889ddf7fba896b747f01cd61477a10abd634b756", "year": 2023, "title": "Data-driven Learning Meets Generative AI: Introducing the Framework of Metacognitive Resource Use", "authors": "Atsushi Mizumoto", "venue": "Applied Corpus Linguistics", "citationCount": 31, "abstract": null, "isOpenAccess": true, "url": "https://doi.org/10.1016/j.acorp.2023.100074"}
{"paperId": "7f64665e2349d0a5fa6b3af5dddecea1c4d5e8e5", "year": 2023, "title": "\"\\\"Call me Kiran\\\" \u2013 ChatGPT as a Tutoring Chatbot in a Computer Science Course\"", "authors": "Jaakko Rajala, Jenni Hukkanen, Mia Hartikainen, Pia Niemel\u00e4", "venue": "International Conference on Entertainment and Media in the Ubiquitous Era", "citationCount": 31, "abstract": "Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students\u2019 perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students\u2019 learning processes, but does not replace it.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3616961.3616974"}
{"paperId": "72f0acc688f3d7968c5783a39bc3469c6c6282fc", "year": 2023, "title": "In AI, is bigger always better?", "authors": "A. Ananthaswamy", "venue": "Nature", "citationCount": 31, "abstract": null, "isOpenAccess": false, "url": ""}
{"paperId": "6df4593d8a7cd92d2d2de94a639a43804251285a", "year": 2025, "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "authors": "Yuping Wang, Shuo Xing, Cui Can, Renjie Li, Hongyuan Hua, Kexin Tian, Zhaobin Mo, Xiangbo Gao, Keshu Wu, Sulong Zhou, Hengxu You, Juntong Peng, Junge Zhang, Zehao Wang, Rui Song, Mingxuan Yan, Walter Zimmer, Xingcheng Zhou, Peiran Li, Zhaohan Lu, Chia-Ju Chen, Yue Huang, Ryan A. Rossi, Lichao Sun, Hongkai Yu, Zhiwen Fan, Frank Yang, Yuhao Kang, Ross Greer, Chenxi Liu, Eun Hak Lee, Xuan Di, Xinyue Ye, Liu Ren, Alois Knoll, Xiaopeng Li, Shuiwang Ji, Masayoshi Tomizuka, Marco Pavone, Tianbao Yang, Jingsai Du, Mingbiao Yang, Hua Wei, Ziran Wang, Yang Zhou, Jiachen Li, Zhengzhong Tu", "venue": "arXiv.org", "citationCount": 31, "abstract": "Generative Artificial Intelligence (GenAI) constitutes a transformative technological wave that reconfigures industries through its unparalleled capabilities for content creation, reasoning, planning, and multimodal understanding. This revolutionary force offers the most promising path yet toward solving one of engineering's grandest challenges: achieving reliable, fully autonomous driving, particularly the pursuit of Level 5 autonomy. This survey delivers a comprehensive and critical synthesis of the emerging role of GenAI across the autonomous driving stack. We begin by distilling the principles and trade-offs of modern generative modeling, encompassing VAEs, GANs, Diffusion Models, and Large Language Models (LLMs). We then map their frontier applications in image, LiDAR, trajectory, occupancy, video generation as well as LLM-guided reasoning and decision making. We categorize practical applications, such as synthetic data workflows, end-to-end driving strategies, high-fidelity digital twin systems, smart transportation networks, and cross-domain transfer to embodied AI. We identify key obstacles and possibilities such as comprehensive generalization across rare cases, evaluation and safety checks, budget-limited implementation, regulatory compliance, ethical concerns, and environmental effects, while proposing research plans across theoretical assurances, trust metrics, transport integration, and socio-technical influence. By unifying these threads, the survey provides a forward-looking reference for researchers, engineers, and policymakers navigating the convergence of generative AI and advanced autonomous mobility. An actively maintained repository of cited works is available at https://github.com/taco-group/GenAI4AD.", "isOpenAccess": false, "url": ""}
{"paperId": "63d13037130b50d652c9f288586bf8458da9a5b0", "year": 2023, "title": "Benchmarking LLM powered Chatbots: Methods and Metrics", "authors": "D. Banerjee, Pooja Singh, Arjun Avadhanam, Shashank Srivastava", "venue": "arXiv.org", "citationCount": 31, "abstract": "Autonomous conversational agents, i.e. chatbots, are becoming an increasingly common mechanism for enterprises to provide support to customers and partners. In order to rate chatbots, especially ones powered by Generative AI tools like Large Language Models (LLMs) we need to be able to accurately assess their performance. This is where chatbot benchmarking becomes important. In this paper, we propose the use of a novel benchmark that we call the E2E (End to End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy and usefulness of the answers provided by chatbots, especially ones powered by LLMs. We evaluate an example chatbot at different levels of sophistication based on both our E2E benchmark, as well as other available metrics commonly used in the state of art, and observe that the proposed benchmark show better results compared to others. In addition, while some metrics proved to be unpredictable, the metric associated with the E2E benchmark, which uses cosine similarity performed well in evaluating chatbots. The performance of our best models shows that there are several benefits of using the cosine similarity score as a metric in the E2E benchmark.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2308.04624"}
{"paperId": "61bd6660f9407e327e2ccfeb5dc6c1c8812f8af2", "year": 2023, "title": "More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT", "authors": "Mei Tan, Hariharan Subramonyam", "venue": "International Conference on Human Factors in Computing Systems", "citationCount": 31, "abstract": "ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT\u2019s capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642592"}
{"paperId": "574130ae32cc7e55971a6382c344953906cdd707", "year": 2024, "title": "INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge", "authors": "Angelika Romanou, Negar Foroutan, Anna Sotnikova, Zeming Chen, Sree Harsha Nelaturu, Shivalika Singh, Rishabh Maheshwary, Micol Altomare, Mohamed A. Haggag, A. Snegha, Alfonso Amayuelas, A. Amirudin, Viraat Aryabumi, Danylo Boiko, Michael Chang, Jenny Chim, Gal Cohen, Aditya Kumar Dalmia, Abraham Diress, Sharad Duwal, Daniil Dzenhaliou, Daniel Fernando Erazo Florez, Fabian Farestam, Joseph Marvin Imperial, Shayekh Bin Islam, Perttu Isotalo, Maral Jabbarishiviari, B\u00f6rje F. Karlsson, Eldar Khalilov, Christopher Klamm, Fajri Koto, Dominik Krzemi'nski, Gabriel Adriano de Melo, Syrielle Montariol, Yiyang Nan, Joel Niklaus, Jekaterina Novikova, Johan Samir Obando Ceron, Debjit Paul, Esther Ploeger, Jebish Purbey, Swati Rajwal, Selvan Sunitha Ravi, Sara Rydell, Roshan Santhosh, Drishti Sharma, M. Skenduli, Arshia Soltani Moakhar, Bardia Soltani Moakhar, Ran Tamir, A. Tarun, Azmine Toushik Wasi, Thenuka Ovin Weerasinghe, Serhan Yilmaz, Mike Zhang, Imanol Schlag, Marzieh Fadaee, Sara Hooker, A. Bosselut", "venue": "International Conference on Learning Representations", "citationCount": 31, "abstract": "The performance differential of large language models (LLM) between languages hinders their effective deployment in many regions, inhibiting the potential economic and societal value of generative AI tools in many communities. However, the development of functional LLMs in many languages (\\ie, multilingual LLMs) is bottlenecked by the lack of high-quality evaluation resources in languages other than English. Moreover, current practices in multilingual benchmark construction often translate English resources, ignoring the regional and cultural knowledge of the environments in which multilingual systems would be used. In this work, we construct an evaluation suite of 197,243 QA pairs from local exam sources to measure the capabilities of multilingual LLMs in a variety of regional contexts. Our novel resource, INCLUDE, is a comprehensive knowledge- and reasoning-centric benchmark across 44 written languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed.", "isOpenAccess": false, "url": ""}
{"paperId": "50aaac5fdc2b5a33bfd3ba93cdf4e5e302f34297", "year": 2023, "title": "LLMs Killed the Script Kiddie: How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing", "authors": "Stephen Moskal, Sam Laney, Erik Hemberg, Una-May O\u2019Reilly", "venue": "arXiv.org", "citationCount": 31, "abstract": "In this paper, we explore the potential of Large Language Models (LLMs) to reason about threats, generate information about tools, and automate cyber campaigns. We begin with a manual exploration of LLMs in supporting specific threat-related actions and decisions. We proceed by automating the decision process in a cyber campaign. We present prompt engineering approaches for a plan-act-report loop for one action of a threat campaign and and a prompt chaining design that directs the sequential decision process of a multi-action campaign. We assess the extent of LLM's cyber-specific knowledge w.r.t the short campaign we demonstrate and provide insights into prompt design for eliciting actionable responses. We discuss the potential impact of LLMs on the threat landscape and the ethical considerations of using LLMs for accelerating threat actor capabilities. We report a promising, yet concerning, application of generative AI to cyber threats. However, the LLM's capabilities to deal with more complex networks, sophisticated vulnerabilities, and the sensitivity of prompts are open questions. This research should spur deliberations over the inevitable advancements in LLM-supported cyber adversarial landscape.", "isOpenAccess": true, "url": "https://arxiv.org/pdf/2310.06936"}
{"paperId": "4f0119a0929c26f33d8c4c3a7cbedd5a7496e0ff", "year": 2024, "title": "Empirische Arbeit: Comparing Generative AI and Expert Feedback to Students\u2019 Writing: Insights from Student Teachers", "authors": "Thorben Jansen, Lars H\u00f6ft, Luca Bahr, Johanna Fleckenstein, Jens M\u00f6ller, Olaf K\u00f6ller, Jennifer Meyer", "venue": "Psychologie in Erziehung und Unterricht", "citationCount": 31, "abstract": null, "isOpenAccess": true, "url": "https://reinhardt-journals.de/index.php/peu/article/download/156746/6896"}
{"paperId": "4e10096df319d1d9adc5572499aae9e8eff12d76", "year": 2024, "title": "The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models", "authors": "Abeba Birhane, Sepehr Dehdashtian, Vinay Prabhu, Vishnu Naresh Boddeti", "venue": "Conference on Fairness, Accountability and Transparency", "citationCount": 31, "abstract": "\u2018Scale the model, scale the data, scale the GPU farms\u2019 is the reigning sentiment in the world of generative AI today. While model scaling has been extensively studied, data scaling and its downstream impacts on model performance remain under-explored. This is particularly important in the context of multimodal datasets whose main source is the World Wide Web, condensed and packaged as the Common Crawl dump, which is known to exhibit numerous drawbacks. In this paper, we evaluate the downstream impact of dataset scaling on 14 visio-linguistic models (VLMs) trained on the LAION400-M and LAION-2B datasets by measuring racial and gender bias using the Chicago Face Dataset (CFD) as the probe. Our results show that as the training data increased, the probability of a pre-trained CLIP model misclassifying human images as offensive non-human classes such as chimpanzee, gorilla, and orangutan decreased, but misclassifying the same images as human offensive classes such as criminal increased. Furthermore, of the 14 Vision Transformer-based VLMs we evaluated, the probability of predicting an image of a Black man and a Latino man as criminal increases by 65% and 69%, respectively, when the dataset is scaled from 400M to 2B samples for the larger ViT-L models. Conversely, for the smaller base ViT-B models, the probability of predicting an image of a Black man and a Latino man as criminal decreases by 20% and 47%, respectively, when the dataset is scaled from 400M to 2B samples. We ground the model audit results in a qualitative and historical analysis, reflect on our findings and their implications for dataset curation practice, and close with a summary of mitigation mechanisms and ways forward. All the meta-datasets curated in this endeavor and the code used are shared at: https://github.com/SepehrDehdashtian/the-dark-side-of-dataset-scaling. Content warning: This article contains racially dehumanising and offensive descriptions.", "isOpenAccess": true, "url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3658968"}
{"paperId": "4ae95f6dcdf5d4e2269869f23b205b358f2b7b17", "year": 2023, "title": "AI-native Interconnect Framework for Integration of Large Language Model Technologies in 6G Systems", "authors": "Sasu Tarkoma, Roberto Morabito, Jaakko Sauvola", "venue": "arXiv.org", "citationCount": 31, "abstract": "The evolution towards 6G architecture promises a transformative shift in communication networks, with artificial intelligence (AI) playing a pivotal role. This paper delves deep into the seamless integration of Large Language Models (LLMs) and Generalized Pretrained Transformers (GPT) within 6G systems. Their ability to grasp intent, strategize, and execute intricate commands will be pivotal in redefining network functionalities and interactions. Central to this is the AI Interconnect framework, intricately woven to facilitate AI-centric operations within the network. Building on the continuously evolving current state-of-the-art, we present a new architectural perspective for the upcoming generation of mobile networks. Here, LLMs and GPTs will collaboratively take center stage alongside traditional pre-generative AI and machine learning (ML) algorithms. This union promises a novel confluence of the old and new, melding tried-and-tested methods with transformative AI technologies. Along with providing a conceptual overview of this evolution, we delve into the nuances of practical applications arising from such an integration. Through this paper, we envisage a symbiotic integration where AI becomes the cornerstone of the next-generation communication paradigm, offering insights into the structural and functional facets of an AI-native 6G network.", "isOpenAccess": false, "url": ""}
